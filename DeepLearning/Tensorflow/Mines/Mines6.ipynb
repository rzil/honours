{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Softmax classifier for guessing minesweeper board position and whether it has a mine or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ruben/anaconda3/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "# Import libraries for simulation\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import random as r\n",
    "import datetime as dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dimensions = (12,12)\n",
    "mineProbability = 0.16      # Probability that a square contain a mine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# This is a matrix that maps mine board vectors to mine count vectors\n",
    "def minesweepMatrix(dimensions):\n",
    "    rows,cols = dimensions\n",
    "    size = rows * cols\n",
    "    A = np.zeros([size,size],dtype=int)\n",
    "    for rA in range(size):\n",
    "        for cA in range(size):\n",
    "            inRow, inCol = divmod(rA,cols)\n",
    "            outRow, outCol = divmod(cA,cols)\n",
    "            A[rA,cA] = abs(inRow-outRow) <= 1 and abs(inCol-outCol) <= 1\n",
    "    return(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Converts a board of mines into a board of mine counts\n",
    "def boardMineCounts(board):\n",
    "    return(minesweepMatrix(board.shape).dot(board.flatten()).reshape(board.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# This takes a mine board and gives a mine count with mines removed, and other random squares removed\n",
    "def boardPartialMineCounts(board):\n",
    "    missingProbability = r.uniform(0.05,0.8)\n",
    "    result = boardMineCounts(board)\n",
    "    for index, x in np.ndenumerate(board):\n",
    "        if x: result[index] = -1\n",
    "        elif r.uniform(0, 1) < missingProbability: result[index] = -1\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Generates a random training batch of size at most n\n",
    "def next_training_batch(n):\n",
    "    batch_xs = []\n",
    "    batch_ys = []\n",
    "    for _ in range(n):\n",
    "        board = np.random.random(dimensions) < mineProbability\n",
    "        counts = boardPartialMineCounts(board)\n",
    "        validGuesses = np.append(((counts == -1).astype(int) - board).flatten().astype(float),\n",
    "                                 board.flatten().astype(float))\n",
    "        validGuessesSum = sum(validGuesses)\n",
    "        if validGuessesSum > 0:\n",
    "            batch_xs.append(counts.flatten())\n",
    "            batch_ys.append(validGuesses / validGuessesSum)\n",
    "    return (np.asarray(batch_xs), np.asarray(batch_ys))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create the model\n",
    "rows, cols = dimensions\n",
    "size = rows*cols\n",
    "mineCounts = tf.placeholder(tf.int32, [None, size], name=\"mineCounts\")\n",
    "mineCountsOneHot = tf.reshape(tf.one_hot(mineCounts+1,10), [-1, size*10])\n",
    "W = tf.Variable(tf.random_normal([size*10, size*2], stddev=0.01), name=\"W\")\n",
    "b = tf.Variable(tf.random_normal([size*2], stddev=0.01), name=\"b\")\n",
    "y = tf.matmul(mineCountsOneHot, W) + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "validGuessAverages = tf.placeholder(tf.float32, [None, size*2], name=\"validGuessAverages\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Loss function\n",
    "cross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=validGuessAverages, logits=y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Summaries for tensorboard\n",
    "with tf.name_scope('W_reshape'):\n",
    "    image_shaped_W = tf.reshape(W, [-1, size*10, size*2, 1])\n",
    "    tf.summary.image('W', image_shaped_W, 1000)\n",
    "\n",
    "with tf.name_scope('b_reshape'):\n",
    "    image_shaped_b = tf.reshape(b, [-1, rows*2, cols, 1])\n",
    "    tf.summary.image('b', image_shaped_b, 1000)\n",
    "\n",
    "_ = tf.summary.scalar('accuracy', cross_entropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Optimiser\n",
    "train_step = tf.train.AdamOptimizer().minimize(cross_entropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create session and initialise or restore stuff\n",
    "savePath = './saves.tf.Mines6/' + str(dimensions) + '/'\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "sess = tf.InteractiveSession()\n",
    "\n",
    "merged = tf.summary.merge_all()\n",
    "writer = tf.summary.FileWriter('.', sess.graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.global_variables_initializer().run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./saves.tf.Mines6/(12, 12)/model-8000\n"
     ]
    }
   ],
   "source": [
    "# Restore model?\n",
    "saver.restore(sess, savePath + \"model-8000\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Train\n",
    "for iteration in range(10001):\n",
    "    batch_xs, batch_ys = next_training_batch(100)\n",
    "    if iteration % 10 == 0:\n",
    "        summary, loss, _ = sess.run([merged, cross_entropy, train_step],\n",
    "                                   feed_dict={mineCounts: batch_xs, validGuessAverages: batch_ys})\n",
    "        writer.add_summary(summary, iteration)\n",
    "        print('%s: Loss at step %s: %s' % (dt.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"), iteration, loss))\n",
    "    else:\n",
    "        _ = sess.run(train_step, feed_dict={mineCounts: batch_xs, validGuessAverages: batch_ys})\n",
    "    if iteration % 1000 == 0:\n",
    "        save_path = saver.save(sess, savePath + 'model', global_step=iteration)\n",
    "        print(\"Model saved in file: %s\" % save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.57926\n"
     ]
    }
   ],
   "source": [
    "# Test trained model on larger batch size\n",
    "batch_xs, batch_ys = next_training_batch(1000)\n",
    "print(sess.run(cross_entropy, feed_dict={mineCounts: batch_xs, validGuessAverages: batch_ys}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of errors for batch size of  10000\n",
      "91\n"
     ]
    }
   ],
   "source": [
    "# Run a test\n",
    "batchSize = 10000\n",
    "batch_xs, batch_ys = next_training_batch(batchSize)\n",
    "\n",
    "predictions = sess.run(tf.nn.softmax(y), feed_dict={mineCounts: batch_xs, validGuessAverages: batch_ys})\n",
    "bestSquares = [pred.argmax() for pred in predictions]\n",
    "unfrees = (batch_ys == 0).astype(int)\n",
    "frees = [unfrees[i][bestSquares[i]] for i in range(batchSize)]\n",
    "print(\"Number of errors for batch size of \", batchSize)\n",
    "print(sum(frees))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1 -1 -1 -1 -1 -1  1 -1 -1  0  0  0]\n",
      " [-1 -1 -1 -1 -1 -1 -1 -1 -1 -1  0 -1]\n",
      " [-1  2 -1 -1 -1  3 -1 -1  1  1 -1 -1]\n",
      " [ 2 -1 -1 -1  3 -1 -1 -1 -1 -1 -1 -1]\n",
      " [-1 -1 -1  3 -1 -1 -1 -1 -1 -1  2 -1]\n",
      " [ 2 -1 -1 -1 -1 -1 -1 -1 -1  0 -1 -1]\n",
      " [-1  0 -1 -1 -1 -1 -1 -1 -1 -1  1 -1]\n",
      " [-1 -1 -1 -1 -1 -1  0  1 -1  1 -1 -1]\n",
      " [-1  3 -1  3 -1 -1 -1 -1 -1 -1 -1 -1]\n",
      " [ 2 -1 -1 -1  2 -1 -1  1  2 -1 -1 -1]\n",
      " [-1  2  3  4 -1 -1 -1 -1 -1 -1 -1  1]\n",
      " [-1  1 -1 -1 -1  2 -1 -1 -1 -1 -1 -1]]\n",
      "[[-1 -1 -1  0  0  0  1 -1 -1 -1 -1 -1]\n",
      " [-1 -1 -1 -1 -1 -1  1 -1 -1  0 -1 -1]\n",
      " [ 1  1  2 -1  3  2  1  0  0  0  0 -1]\n",
      " [-1 -1  2  2 -1 -1 -1 -1  1 -1  1 -1]\n",
      " [ 1  2 -1 -1  4  4  2  0 -1 -1  2 -1]\n",
      " [ 1 -1 -1 -1 -1 -1  1 -1 -1 -1 -1 -1]\n",
      " [-1 -1 -1 -1 -1  4  1 -1 -1  1  1  0]\n",
      " [-1  1  2 -1 -1  4  1 -1 -1  0  0 -1]\n",
      " [-1  1 -1 -1 -1  4 -1  3 -1  0 -1  0]\n",
      " [-1  1  1  2  2 -1 -1 -1 -1 -1  0 -1]\n",
      " [-1  1 -1 -1 -1  1  3 -1 -1 -1 -1  0]\n",
      " [-1 -1 -1  1  1  0 -1 -1  1 -1  0 -1]]\n",
      "[[ 0 -1 -1 -1 -1  2  1 -1 -1 -1  2  1]\n",
      " [-1 -1  2 -1 -1 -1  2 -1 -1 -1 -1 -1]\n",
      " [-1  1 -1 -1 -1  1  2 -1  2  2 -1 -1]\n",
      " [-1  3 -1  0 -1 -1  2  1 -1  0  0  0]\n",
      " [-1 -1 -1 -1  1 -1  1 -1 -1  1  0 -1]\n",
      " [-1  3 -1  1 -1 -1 -1 -1 -1 -1 -1 -1]\n",
      " [-1  2  1  2 -1 -1 -1 -1 -1 -1  0  0]\n",
      " [ 0 -1 -1 -1 -1  4 -1 -1 -1 -1 -1 -1]\n",
      " [-1  1 -1  1  1 -1  3  2  2  2  2  1]\n",
      " [-1  0  0 -1 -1  1 -1 -1 -1 -1 -1  3]\n",
      " [ 0  0 -1  0  0 -1 -1  0 -1  4 -1 -1]\n",
      " [-1 -1  0 -1  0  0 -1  0 -1  2 -1 -1]]\n",
      "[[ 2 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1  1]\n",
      " [-1 -1 -1 -1 -1 -1  4 -1 -1  2  1  1]\n",
      " [ 3 -1 -1 -1  1 -1 -1 -1 -1  0 -1  0]\n",
      " [-1  2 -1 -1 -1 -1 -1 -1 -1 -1  0  0]\n",
      " [-1  1  1 -1 -1 -1 -1 -1 -1 -1 -1 -1]\n",
      " [ 0  0 -1 -1 -1 -1  2  2 -1 -1 -1 -1]\n",
      " [-1 -1  1 -1  1  0  0 -1  1 -1 -1 -1]\n",
      " [-1 -1 -1 -1 -1 -1 -1 -1 -1  1  1  0]\n",
      " [ 3 -1 -1 -1 -1 -1 -1 -1 -1 -1  1 -1]\n",
      " [-1 -1 -1 -1  0  1 -1 -1 -1 -1 -1 -1]\n",
      " [ 4 -1  3 -1 -1 -1 -1 -1 -1 -1 -1 -1]\n",
      " [-1 -1 -1  1  0 -1 -1 -1 -1 -1 -1 -1]]\n",
      "[[ 1  1 -1 -1  1 -1 -1 -1  2 -1 -1  0]\n",
      " [-1 -1  2 -1 -1 -1 -1 -1 -1 -1  2  0]\n",
      " [-1  2  3 -1 -1 -1 -1 -1  3 -1 -1  1]\n",
      " [-1 -1 -1 -1 -1 -1  2 -1  3 -1 -1 -1]\n",
      " [-1 -1 -1 -1  2 -1 -1 -1 -1 -1 -1 -1]\n",
      " [-1 -1 -1 -1 -1 -1 -1  4  2  2 -1 -1]\n",
      " [-1 -1 -1 -1  1 -1 -1 -1 -1  2 -1  1]\n",
      " [-1 -1 -1  1 -1 -1 -1 -1  4 -1  1 -1]\n",
      " [ 1 -1  2 -1  3 -1 -1 -1 -1 -1  2 -1]\n",
      " [ 1 -1 -1 -1 -1 -1 -1 -1  1 -1  2 -1]\n",
      " [ 0 -1  1  2 -1 -1 -1  1  0 -1 -1 -1]\n",
      " [ 0  0  0 -1 -1 -1 -1 -1  0 -1 -1 -1]]\n",
      "[[ 0  0 -1  0 -1 -1 -1 -1  1 -1  1 -1]\n",
      " [-1 -1 -1 -1 -1  2 -1 -1  1  1  1 -1]\n",
      " [ 0  2 -1 -1  0  0 -1 -1 -1  0 -1 -1]\n",
      " [ 0 -1 -1 -1 -1  1 -1  0 -1 -1  2 -1]\n",
      " [-1 -1  1  2 -1  1  1  1  2 -1 -1  3]\n",
      " [-1 -1  0  1 -1 -1 -1 -1  3 -1 -1 -1]\n",
      " [-1 -1 -1  1 -1  0  1  2 -1 -1 -1 -1]\n",
      " [-1 -1 -1 -1 -1 -1  1  3 -1 -1 -1 -1]\n",
      " [-1  1 -1  1  0 -1 -1 -1 -1 -1 -1 -1]\n",
      " [-1  1 -1  0 -1 -1  3 -1  4 -1  2 -1]\n",
      " [-1 -1 -1 -1  2 -1 -1 -1 -1 -1 -1 -1]\n",
      " [ 1 -1  0  1 -1 -1 -1 -1 -1 -1  1  0]]\n",
      "[[-1 -1 -1  1 -1 -1 -1 -1 -1 -1 -1  1]\n",
      " [-1 -1  0  1  1  1 -1  0  0  1 -1 -1]\n",
      " [-1 -1 -1 -1 -1 -1 -1 -1  1  2  2  2]\n",
      " [ 1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1  1]\n",
      " [-1  2 -1  1 -1  1  1  1 -1  3 -1 -1]\n",
      " [-1  1 -1 -1  1  1  1 -1  1 -1 -1 -1]\n",
      " [-1 -1  0 -1 -1 -1 -1  0  2 -1 -1 -1]\n",
      " [ 2 -1  1  0 -1 -1  1 -1 -1 -1  3 -1]\n",
      " [-1 -1  2  2 -1  1 -1 -1  2 -1 -1 -1]\n",
      " [-1  3 -1  3 -1 -1 -1 -1 -1  1  1  0]\n",
      " [ 0 -1  2 -1 -1 -1 -1  1 -1 -1  0  0]\n",
      " [ 0 -1 -1  2 -1  1 -1 -1  1  0 -1  0]]\n",
      "[[-1  1 -1  0  0  0 -1 -1 -1  1  1  1]\n",
      " [-1 -1  1  2  2  1  1 -1  2  1  1 -1]\n",
      " [-1  2  2 -1 -1  2 -1  1  1  0 -1 -1]\n",
      " [ 2 -1 -1  4 -1  2 -1  1  2 -1  1  0]\n",
      " [ 1  2 -1  3  2  2  1 -1  2 -1  1  0]\n",
      " [ 0  1  1 -1 -1 -1 -1 -1 -1  1  1 -1]\n",
      " [-1  0  0  3 -1  4  1  2 -1  1 -1 -1]\n",
      " [ 0  0  0  2 -1 -1 -1  2 -1  1  0  0]\n",
      " [ 0 -1  1  2 -1  2  1  2  2  3  3  2]\n",
      " [-1 -1  1 -1  1 -1  0  1  2 -1 -1 -1]\n",
      " [ 1  1  1 -1  1  0 -1 -1 -1 -1 -1 -1]\n",
      " [-1 -1  0 -1 -1 -1 -1 -1  1 -1 -1 -1]]\n"
     ]
    }
   ],
   "source": [
    "# Find boards that we failed on\n",
    "batchSize = 1000\n",
    "batch_xs, batch_ys = next_training_batch(batchSize)\n",
    "\n",
    "predictions = sess.run(tf.nn.softmax(y), feed_dict={mineCounts: batch_xs, validGuessAverages: batch_ys})\n",
    "bestSquares = [pred.argmax() for pred in predictions]\n",
    "unfrees = (batch_ys == 0).astype(int)\n",
    "guesses = [unfrees[i][bestSquares[i]] for i in range(batchSize)]\n",
    "for i in range(batchSize):\n",
    "    if guesses[i] == 1:\n",
    "        print(batch_xs[i].reshape(dimensions))\n",
    "        summary = sess.run(tf.summary.image('mine_miss', tf.reshape((batch_xs[i]+1).astype(float),[-1,rows,cols,1]), 100))\n",
    "        writer.add_summary(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
