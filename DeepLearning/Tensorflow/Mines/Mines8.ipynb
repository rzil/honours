{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Softmax classifier for guessing minesweeper board position and whether it has a mine or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ruben/tensorflow/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "# Import libraries for simulation\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import random as r\n",
    "import datetime as dt\n",
    "import multiprocessing as mp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dimensions = (8,8)\n",
    "mineProbability = 0.16      # Probability that a square contain a mine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clears a square on the minesweeper board.\n",
    "# If it had a mine, return true\n",
    "# Otherwise if it has no adjacent mines, recursively run on adjacent squares\n",
    "# Return false\n",
    "def clearSquare(board,adjacency,row,col):\n",
    "    rows,cols = dimensions\n",
    "    if board[row,col] == 1:\n",
    "        return True\n",
    "    if adjacency[row,col] >= 0:\n",
    "        return False\n",
    "    n = 0\n",
    "    for r in range(row-1,row+2):\n",
    "        for c in range(col-1,col+2):\n",
    "            if 0 <= r and r < rows and 0 <= c and c < cols:\n",
    "                n += board[r,c]\n",
    "    adjacency[row,col] = n\n",
    "    if n == 0:\n",
    "        for r in range(row-1,row+2):\n",
    "            for c in range(col-1,col+2):\n",
    "                if 0 <= r and r < rows and 0 <= c and c < cols:\n",
    "                    clearSquare(board,adjacency,r,c)\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This takes a mine board and gives a mine count with mines removed, and other random squares removed\n",
    "def boardPartialMineCounts(board):\n",
    "    clearProbability = r.uniform(0.05,0.5)\n",
    "    result = np.full(dimensions,-1)\n",
    "    for index, x in np.random.permutation(list(np.ndenumerate(board))):\n",
    "        row,col = index\n",
    "        if not(x) and result[row,col] == -1 and r.uniform(0,1) < clearProbability:\n",
    "            clearSquare(board,result,row,col)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generates a random training batch of size n\n",
    "def randomBoard(i):\n",
    "    return(np.random.random(dimensions) < mineProbability)\n",
    "\n",
    "def encodeCountsOneHot(counts):\n",
    "    countsOneHot = np.zeros((counts.size,10))\n",
    "    countsOneHot[np.arange(counts.size), counts.flatten() + 1] = 1\n",
    "    return(countsOneHot.flatten())\n",
    "\n",
    "def validGuesses(boardAndCounts):\n",
    "    board,counts = boardAndCounts\n",
    "    validGuesses = np.append(((counts == -1).astype(int) - board).flatten().astype(float),\n",
    "        board.flatten().astype(float))\n",
    "    validGuessesSum = sum(validGuesses)\n",
    "    if validGuessesSum > 0:\n",
    "        return(validGuesses / validGuessesSum)\n",
    "    else:\n",
    "        return(np.zeros(board.size*2))\n",
    "\n",
    "try:\n",
    "    cpus = mp.cpu_count()\n",
    "except NotImplementedError:\n",
    "    cpus = 2   # arbitrary default\n",
    "\n",
    "pool = mp.Pool(processes=cpus)\n",
    "\n",
    "def next_training_batch(n):\n",
    "    boards = pool.map(randomBoard, range(n))\n",
    "    counts = pool.map(boardPartialMineCounts, boards)\n",
    "    batch_xs = pool.map(encodeCountsOneHot, counts)\n",
    "    batch_ys = pool.map(validGuesses, zip(boards,counts))\n",
    "    return(batch_xs, batch_ys, boards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows, cols = dimensions\n",
    "size = rows*cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(tf.keras.layers.Dense(units=size, input_dim=size*10))\n",
    "model.add(tf.keras.layers.Activation('relu'))\n",
    "\n",
    "model.add(tf.keras.layers.Reshape((rows, cols, 1)))\n",
    "\n",
    "model.add(tf.keras.layers.Conv2D(32, (5, 5), padding='same'))\n",
    "model.add(tf.keras.layers.Activation('relu'))\n",
    "model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(tf.keras.layers.Reshape((4*4*32,)))\n",
    "\n",
    "#model.add(tf.keras.layers.Dense(units=1024))\n",
    "#model.add(tf.keras.layers.Activation('relu'))\n",
    "\n",
    "#model.add(tf.keras.layers.Dropout(rate=0.5))\n",
    "\n",
    "model.add(tf.keras.layers.Dense(units=size*2))\n",
    "model.add(tf.keras.layers.Activation('softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='poisson')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['loss']\n"
     ]
    }
   ],
   "source": [
    "print(model.metrics_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "savePath = \"/media/ruben/BigDisk/tensorflow/tensorflow-logs/tf.Mines8\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-11-10 19:24:28: Loss at step 0: 0.04574406519532204\n",
      "2017-11-10 19:24:30: Loss at step 1: 0.04570643976330757\n",
      "2017-11-10 19:24:32: Loss at step 2: 0.045675598084926605\n",
      "2017-11-10 19:24:34: Loss at step 3: 0.04564366489648819\n",
      "2017-11-10 19:24:36: Loss at step 4: 0.045610737055540085\n",
      "2017-11-10 19:24:38: Loss at step 5: 0.04557596519589424\n",
      "2017-11-10 19:24:40: Loss at step 6: 0.045546479523181915\n",
      "2017-11-10 19:24:42: Loss at step 7: 0.04550795257091522\n",
      "2017-11-10 19:24:45: Loss at step 8: 0.045479610562324524\n",
      "2017-11-10 19:24:47: Loss at step 9: 0.04544918239116669\n",
      "2017-11-10 19:24:49: Loss at step 10: 0.045431364327669144\n",
      "2017-11-10 19:24:51: Loss at step 11: 0.04542260617017746\n",
      "2017-11-10 19:24:53: Loss at step 12: 0.04540497437119484\n",
      "2017-11-10 19:24:55: Loss at step 13: 0.04537178948521614\n",
      "2017-11-10 19:24:57: Loss at step 14: 0.04534301534295082\n",
      "2017-11-10 19:24:59: Loss at step 15: 0.045312389731407166\n",
      "2017-11-10 19:25:01: Loss at step 16: 0.045268259942531586\n",
      "2017-11-10 19:25:04: Loss at step 17: 0.04524463042616844\n",
      "2017-11-10 19:25:06: Loss at step 18: 0.04519825428724289\n",
      "2017-11-10 19:25:08: Loss at step 19: 0.04516226798295975\n",
      "2017-11-10 19:25:10: Loss at step 20: 0.04510578140616417\n",
      "2017-11-10 19:25:12: Loss at step 21: 0.04506409168243408\n",
      "2017-11-10 19:25:14: Loss at step 22: 0.045020002871751785\n",
      "2017-11-10 19:25:16: Loss at step 23: 0.044958245009183884\n",
      "2017-11-10 19:25:18: Loss at step 24: 0.04489978030323982\n",
      "2017-11-10 19:25:21: Loss at step 25: 0.04483598470687866\n",
      "2017-11-10 19:25:23: Loss at step 26: 0.04476497322320938\n",
      "2017-11-10 19:25:25: Loss at step 27: 0.04468746855854988\n",
      "2017-11-10 19:25:27: Loss at step 28: 0.04459915682673454\n",
      "2017-11-10 19:25:29: Loss at step 29: 0.04451889172196388\n",
      "2017-11-10 19:25:31: Loss at step 30: 0.04443083330988884\n",
      "2017-11-10 19:25:33: Loss at step 31: 0.044326018542051315\n",
      "2017-11-10 19:25:35: Loss at step 32: 0.044232409447431564\n",
      "2017-11-10 19:25:37: Loss at step 33: 0.04414738342165947\n",
      "2017-11-10 19:25:40: Loss at step 34: 0.04402570798993111\n",
      "2017-11-10 19:25:42: Loss at step 35: 0.04393033683300018\n",
      "2017-11-10 19:25:44: Loss at step 36: 0.04381285235285759\n",
      "2017-11-10 19:25:46: Loss at step 37: 0.04374053701758385\n",
      "2017-11-10 19:25:48: Loss at step 38: 0.043614353984594345\n",
      "2017-11-10 19:25:50: Loss at step 39: 0.04354167357087135\n",
      "2017-11-10 19:25:52: Loss at step 40: 0.04342692717909813\n",
      "2017-11-10 19:25:54: Loss at step 41: 0.04335588216781616\n",
      "2017-11-10 19:25:57: Loss at step 42: 0.043228618800640106\n",
      "2017-11-10 19:25:59: Loss at step 43: 0.043169621378183365\n",
      "2017-11-10 19:26:01: Loss at step 44: 0.04307325556874275\n",
      "2017-11-10 19:26:03: Loss at step 45: 0.04302709177136421\n",
      "2017-11-10 19:26:05: Loss at step 46: 0.042952731251716614\n",
      "2017-11-10 19:26:07: Loss at step 47: 0.042839329689741135\n",
      "2017-11-10 19:26:09: Loss at step 48: 0.04277506098151207\n",
      "2017-11-10 19:26:11: Loss at step 49: 0.042691804468631744\n",
      "2017-11-10 19:26:13: Loss at step 50: 0.0426517128944397\n"
     ]
    }
   ],
   "source": [
    "for iteration in range(1000001):\n",
    "    x_batch, y_batch, _ = next_training_batch(10000)\n",
    "    loss = model.train_on_batch(np.array(x_batch), np.array(y_batch))\n",
    "    print('{0}: Loss at step {1}: {2}'.format(dt.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"), iteration, loss))\n",
    "    np.save('{0}/training_data/x_batch-{1}.npy'.format(savePath, iteration), np.array(x_batch))\n",
    "    np.save('{0}/training_data/y_batch-{1}.npy'.format(savePath, iteration), np.array(y_batch))\n",
    "    if iteration % 500 == 0:\n",
    "        model.save('{0}/model-{1}.h5'.format(savePath, iteration))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
