{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Softmax classifier for guessing minesweeper board position and whether it has a mine or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ruben/tensorflow/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "# Import libraries for simulation\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import random as r\n",
    "import datetime as dt\n",
    "import multiprocessing as mp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dimensions = (8,8)\n",
    "mineProbability = 0.16      # Probability that a square contain a mine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clears a square on the minesweeper board.\n",
    "# If it had a mine, return true\n",
    "# Otherwise if it has no adjacent mines, recursively run on adjacent squares\n",
    "# Return false\n",
    "def clearSquare(board,adjacency,row,col):\n",
    "    rows,cols = dimensions\n",
    "    if board[row,col] == 1:\n",
    "        return True\n",
    "    if adjacency[row,col] >= 0:\n",
    "        return False\n",
    "    n = 0\n",
    "    for r in range(row-1,row+2):\n",
    "        for c in range(col-1,col+2):\n",
    "            if 0 <= r and r < rows and 0 <= c and c < cols:\n",
    "                n += board[r,c]\n",
    "    adjacency[row,col] = n\n",
    "    if n == 0:\n",
    "        for r in range(row-1,row+2):\n",
    "            for c in range(col-1,col+2):\n",
    "                if 0 <= r and r < rows and 0 <= c and c < cols:\n",
    "                    clearSquare(board,adjacency,r,c)\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This takes a mine board and gives a mine count with mines removed, and other random squares removed\n",
    "# At least one square will be clear\n",
    "def boardPartialMineCounts(board):\n",
    "    clearProbability = r.uniform(0.05,0.5)\n",
    "    result = np.full(dimensions,-1)\n",
    "    didClear = False\n",
    "    while not(didClear):\n",
    "        for index, x in np.random.permutation(list(np.ndenumerate(board))):\n",
    "            row,col = index\n",
    "            if not(x) and result[row,col] == -1 and r.uniform(0,1) < clearProbability:\n",
    "                clearSquare(board,result,row,col)\n",
    "                didClear = True\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process ForkPoolWorker-3:\n",
      "Process ForkPoolWorker-7:\n",
      "Process ForkPoolWorker-6:\n",
      "Process ForkPoolWorker-8:\n",
      "Process ForkPoolWorker-5:\n",
      "Process ForkPoolWorker-4:\n",
      "Process ForkPoolWorker-2:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 119, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 119, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 119, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 119, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 119, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 44, in mapstar\n",
      "    return list(map(*args))\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 44, in mapstar\n",
      "    return list(map(*args))\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 44, in mapstar\n",
      "    return list(map(*args))\n",
      "  File \"<ipython-input-4-2dcf4148d008>\", line 8, in boardPartialMineCounts\n",
      "    for index, x in np.random.permutation(list(np.ndenumerate(board))):\n",
      "  File \"<ipython-input-4-2dcf4148d008>\", line 11, in boardPartialMineCounts\n",
      "    clearSquare(board,result,row,col)\n",
      "  File \"<ipython-input-3-fe9f3b44f6bc>\", line 21, in clearSquare\n",
      "    clearSquare(board,adjacency,r,c)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 44, in mapstar\n",
      "    return list(map(*args))\n",
      "  File \"<ipython-input-3-fe9f3b44f6bc>\", line 21, in clearSquare\n",
      "    clearSquare(board,adjacency,r,c)\n",
      "  File \"<ipython-input-3-fe9f3b44f6bc>\", line 21, in clearSquare\n",
      "    clearSquare(board,adjacency,r,c)\n",
      "  [Previous line repeated 11 more times]\n",
      "Traceback (most recent call last):\n",
      "  File \"<ipython-input-3-fe9f3b44f6bc>\", line 15, in clearSquare\n",
      "    n += board[r,c]\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 44, in mapstar\n",
      "    return list(map(*args))\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"<ipython-input-4-2dcf4148d008>\", line 11, in boardPartialMineCounts\n",
      "    clearSquare(board,result,row,col)\n",
      "  File \"/home/ruben/tensorflow/lib/python3.6/site-packages/numpy/lib/index_tricks.py\", line 528, in __next__\n",
      "    return self.iter.coords, next(self.iter)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "KeyboardInterrupt\n",
      "  File \"<ipython-input-4-2dcf4148d008>\", line 8, in boardPartialMineCounts\n",
      "    for index, x in np.random.permutation(list(np.ndenumerate(board))):\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 119, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"<ipython-input-3-fe9f3b44f6bc>\", line 21, in clearSquare\n",
      "    clearSquare(board,adjacency,r,c)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 119, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "KeyboardInterrupt\n",
      "  File \"<ipython-input-4-2dcf4148d008>\", line 11, in boardPartialMineCounts\n",
      "    clearSquare(board,result,row,col)\n",
      "  File \"<ipython-input-3-fe9f3b44f6bc>\", line 15, in clearSquare\n",
      "    n += board[r,c]\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 44, in mapstar\n",
      "    return list(map(*args))\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 44, in mapstar\n",
      "    return list(map(*args))\n",
      "  File \"<ipython-input-4-2dcf4148d008>\", line 11, in boardPartialMineCounts\n",
      "    clearSquare(board,result,row,col)\n",
      "  File \"<ipython-input-4-2dcf4148d008>\", line 11, in boardPartialMineCounts\n",
      "    clearSquare(board,result,row,col)\n",
      "  File \"<ipython-input-3-fe9f3b44f6bc>\", line 21, in clearSquare\n",
      "    clearSquare(board,adjacency,r,c)\n",
      "  File \"<ipython-input-3-fe9f3b44f6bc>\", line 21, in clearSquare\n",
      "    clearSquare(board,adjacency,r,c)\n",
      "  File \"<ipython-input-3-fe9f3b44f6bc>\", line 21, in clearSquare\n",
      "    clearSquare(board,adjacency,r,c)\n",
      "  File \"<ipython-input-3-fe9f3b44f6bc>\", line 21, in clearSquare\n",
      "    clearSquare(board,adjacency,r,c)\n",
      "  File \"<ipython-input-3-fe9f3b44f6bc>\", line 15, in clearSquare\n",
      "    n += board[r,c]\n",
      "  File \"<ipython-input-3-fe9f3b44f6bc>\", line 21, in clearSquare\n",
      "    clearSquare(board,adjacency,r,c)\n",
      "  File \"<ipython-input-3-fe9f3b44f6bc>\", line 21, in clearSquare\n",
      "    clearSquare(board,adjacency,r,c)\n",
      "KeyboardInterrupt\n",
      "  File \"<ipython-input-3-fe9f3b44f6bc>\", line 21, in clearSquare\n",
      "    clearSquare(board,adjacency,r,c)\n",
      "  [Previous line repeated 5 more times]\n",
      "  File \"<ipython-input-3-fe9f3b44f6bc>\", line 15, in clearSquare\n",
      "    n += board[r,c]\n",
      "  [Previous line repeated 2 more times]\n",
      "  File \"<ipython-input-3-fe9f3b44f6bc>\", line 7, in clearSquare\n",
      "    if board[row,col] == 1:\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "Process ForkPoolWorker-1:\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 119, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 44, in mapstar\n",
      "    return list(map(*args))\n",
      "  File \"<ipython-input-4-2dcf4148d008>\", line 11, in boardPartialMineCounts\n",
      "    clearSquare(board,result,row,col)\n",
      "  File \"<ipython-input-3-fe9f3b44f6bc>\", line 15, in clearSquare\n",
      "    n += board[r,c]\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "# Generates a random training batch of size n\n",
    "def randomBoard(i):\n",
    "    return(np.random.random(dimensions) < mineProbability)\n",
    "\n",
    "def encodeCountsOneHot(counts):\n",
    "    countsOneHot = np.zeros((counts.size,10))\n",
    "    countsOneHot[np.arange(counts.size), counts.flatten() + 1] = 1\n",
    "    return(countsOneHot.flatten())\n",
    "\n",
    "def validGuesses(boardAndCounts):\n",
    "    board,counts = boardAndCounts\n",
    "    validGuesses = np.append(((counts == -1).astype(int) - board).flatten().astype(float),\n",
    "        board.flatten().astype(float))\n",
    "    validGuessesSum = sum(validGuesses)\n",
    "    if validGuessesSum > 0:\n",
    "        return(validGuesses / validGuessesSum)\n",
    "    else:\n",
    "        return(np.zeros(board.size*2))\n",
    "\n",
    "try:\n",
    "    cpus = mp.cpu_count()\n",
    "except NotImplementedError:\n",
    "    cpus = 2   # arbitrary default\n",
    "\n",
    "pool = mp.Pool(processes=cpus)\n",
    "\n",
    "def next_training_batch(n):\n",
    "    boards = pool.map(randomBoard, range(n))\n",
    "    counts = pool.map(boardPartialMineCounts, boards)\n",
    "    batch_xs = pool.map(encodeCountsOneHot, counts)\n",
    "    batch_ys = pool.map(validGuesses, zip(boards,counts))\n",
    "    return(batch_xs, batch_ys, boards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows, cols = dimensions\n",
    "size = rows*cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(tf.keras.layers.Dense(units=size, input_dim=size*10))\n",
    "model.add(tf.keras.layers.Activation('relu'))\n",
    "\n",
    "model.add(tf.keras.layers.Reshape((rows, cols, 1)))\n",
    "\n",
    "model.add(tf.keras.layers.Conv2D(32, (5, 5), padding='same'))\n",
    "model.add(tf.keras.layers.Activation('relu'))\n",
    "model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(tf.keras.layers.Reshape((4*4*32,)))\n",
    "\n",
    "#model.add(tf.keras.layers.Dense(units=1024))\n",
    "#model.add(tf.keras.layers.Activation('relu'))\n",
    "\n",
    "#model.add(tf.keras.layers.Dropout(rate=0.5))\n",
    "\n",
    "model.add(tf.keras.layers.Dense(units=size*2))\n",
    "model.add(tf.keras.layers.Activation('softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='poisson')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model.metrics_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "savePath = \"/media/ruben/BigDisk/tensorflow/tensorflow-logs/tf.Mines8\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model('{0}/model-3500.h5'.format(savePath))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-11-11 06:52:33: Loss at step 3501: 0.036921218037605286\n",
      "2017-11-11 06:52:35: Loss at step 3502: 0.03676200285553932\n",
      "2017-11-11 06:52:38: Loss at step 3503: 0.036942172795534134\n",
      "2017-11-11 06:52:40: Loss at step 3504: 0.036985404789447784\n",
      "2017-11-11 06:52:42: Loss at step 3505: 0.03677597641944885\n",
      "2017-11-11 06:52:44: Loss at step 3506: 0.03680059313774109\n",
      "2017-11-11 06:52:46: Loss at step 3507: 0.03687511757016182\n",
      "2017-11-11 06:52:48: Loss at step 3508: 0.036910898983478546\n",
      "2017-11-11 06:52:50: Loss at step 3509: 0.03695701062679291\n",
      "2017-11-11 06:52:53: Loss at step 3510: 0.03688173368573189\n",
      "2017-11-11 06:52:55: Loss at step 3511: 0.03668404370546341\n",
      "2017-11-11 06:52:57: Loss at step 3512: 0.03682910278439522\n",
      "2017-11-11 06:52:59: Loss at step 3513: 0.036751989275217056\n",
      "2017-11-11 06:53:01: Loss at step 3514: 0.036820635199546814\n",
      "2017-11-11 06:53:03: Loss at step 3515: 0.03678290545940399\n",
      "2017-11-11 06:53:06: Loss at step 3516: 0.036781515926122665\n",
      "2017-11-11 06:53:08: Loss at step 3517: 0.036831025034189224\n",
      "2017-11-11 06:53:10: Loss at step 3518: 0.0368858203291893\n",
      "2017-11-11 06:53:13: Loss at step 3519: 0.03683767095208168\n",
      "2017-11-11 06:53:15: Loss at step 3520: 0.03684648871421814\n",
      "2017-11-11 06:53:17: Loss at step 3521: 0.03687470033764839\n",
      "2017-11-11 06:53:19: Loss at step 3522: 0.03674947842955589\n",
      "2017-11-11 06:53:21: Loss at step 3523: 0.0368412584066391\n",
      "2017-11-11 06:53:23: Loss at step 3524: 0.036776911467313766\n",
      "2017-11-11 06:53:26: Loss at step 3525: 0.03681548684835434\n",
      "2017-11-11 06:53:28: Loss at step 3526: 0.03690539672970772\n",
      "2017-11-11 06:53:30: Loss at step 3527: 0.036798108369112015\n",
      "2017-11-11 06:53:32: Loss at step 3528: 0.036691803485155106\n",
      "2017-11-11 06:53:34: Loss at step 3529: 0.03675353527069092\n",
      "2017-11-11 06:53:36: Loss at step 3530: 0.036751244217157364\n",
      "2017-11-11 06:53:39: Loss at step 3531: 0.03681902214884758\n",
      "2017-11-11 06:53:41: Loss at step 3532: 0.03677716851234436\n",
      "2017-11-11 06:53:43: Loss at step 3533: 0.036772482097148895\n",
      "2017-11-11 06:53:45: Loss at step 3534: 0.03683270514011383\n",
      "2017-11-11 06:53:47: Loss at step 3535: 0.03675392270088196\n",
      "2017-11-11 06:53:50: Loss at step 3536: 0.03690709173679352\n",
      "2017-11-11 06:53:52: Loss at step 3537: 0.03691001236438751\n",
      "2017-11-11 06:53:54: Loss at step 3538: 0.03681446239352226\n",
      "2017-11-11 06:53:56: Loss at step 3539: 0.036815039813518524\n",
      "2017-11-11 06:53:58: Loss at step 3540: 0.03687582537531853\n",
      "2017-11-11 06:54:00: Loss at step 3541: 0.03678156062960625\n",
      "2017-11-11 06:54:02: Loss at step 3542: 0.03696093708276749\n",
      "2017-11-11 06:54:04: Loss at step 3543: 0.03685147315263748\n",
      "2017-11-11 06:54:07: Loss at step 3544: 0.03676741197705269\n",
      "2017-11-11 06:54:09: Loss at step 3545: 0.03674808889627457\n",
      "2017-11-11 06:54:11: Loss at step 3546: 0.036768846213817596\n",
      "2017-11-11 06:54:13: Loss at step 3547: 0.03679179027676582\n",
      "2017-11-11 06:54:15: Loss at step 3548: 0.03680291771888733\n",
      "2017-11-11 06:54:17: Loss at step 3549: 0.036790888756513596\n",
      "2017-11-11 06:54:20: Loss at step 3550: 0.03688078746199608\n",
      "2017-11-11 06:54:22: Loss at step 3551: 0.036789391189813614\n",
      "2017-11-11 06:54:24: Loss at step 3552: 0.03697816655039787\n",
      "2017-11-11 06:54:26: Loss at step 3553: 0.03692067414522171\n",
      "2017-11-11 06:54:28: Loss at step 3554: 0.036959197372198105\n",
      "2017-11-11 06:54:30: Loss at step 3555: 0.03674791380763054\n",
      "2017-11-11 06:54:32: Loss at step 3556: 0.036693986505270004\n",
      "2017-11-11 06:54:34: Loss at step 3557: 0.036948010325431824\n",
      "2017-11-11 06:54:36: Loss at step 3558: 0.03678020089864731\n",
      "2017-11-11 06:54:39: Loss at step 3559: 0.03687015920877457\n",
      "2017-11-11 06:54:41: Loss at step 3560: 0.03693945333361626\n",
      "2017-11-11 06:54:43: Loss at step 3561: 0.0369119830429554\n",
      "2017-11-11 06:54:45: Loss at step 3562: 0.03683965653181076\n",
      "2017-11-11 06:54:47: Loss at step 3563: 0.036741480231285095\n",
      "2017-11-11 06:54:50: Loss at step 3564: 0.036706436425447464\n",
      "2017-11-11 06:54:52: Loss at step 3565: 0.03679713234305382\n",
      "2017-11-11 06:54:54: Loss at step 3566: 0.03671770542860031\n",
      "2017-11-11 06:54:56: Loss at step 3567: 0.03684677556157112\n",
      "2017-11-11 06:54:58: Loss at step 3568: 0.03687819838523865\n",
      "2017-11-11 06:55:00: Loss at step 3569: 0.036890409886837006\n",
      "2017-11-11 06:55:03: Loss at step 3570: 0.03674520179629326\n",
      "2017-11-11 06:55:05: Loss at step 3571: 0.03677091747522354\n",
      "2017-11-11 06:55:07: Loss at step 3572: 0.036856312304735184\n",
      "2017-11-11 06:55:09: Loss at step 3573: 0.03678907826542854\n",
      "2017-11-11 06:55:11: Loss at step 3574: 0.03677907586097717\n",
      "2017-11-11 06:55:14: Loss at step 3575: 0.036765459924936295\n",
      "2017-11-11 06:55:16: Loss at step 3576: 0.036691706627607346\n",
      "2017-11-11 06:55:18: Loss at step 3577: 0.03681453689932823\n",
      "2017-11-11 06:55:20: Loss at step 3578: 0.03688912093639374\n",
      "2017-11-11 06:55:22: Loss at step 3579: 0.03678781911730766\n",
      "2017-11-11 06:55:24: Loss at step 3580: 0.03683307394385338\n",
      "2017-11-11 06:55:27: Loss at step 3581: 0.036733873188495636\n",
      "2017-11-11 06:55:29: Loss at step 3582: 0.036772340536117554\n",
      "2017-11-11 06:55:31: Loss at step 3583: 0.03683244809508324\n",
      "2017-11-11 06:55:33: Loss at step 3584: 0.03690298646688461\n",
      "2017-11-11 06:55:35: Loss at step 3585: 0.036793287843465805\n",
      "2017-11-11 06:55:37: Loss at step 3586: 0.03683425113558769\n",
      "2017-11-11 06:55:39: Loss at step 3587: 0.03683134540915489\n",
      "2017-11-11 06:55:41: Loss at step 3588: 0.03680026903748512\n",
      "2017-11-11 06:55:43: Loss at step 3589: 0.036746300756931305\n",
      "2017-11-11 06:55:46: Loss at step 3590: 0.036757368594408035\n",
      "2017-11-11 06:55:48: Loss at step 3591: 0.0369187630712986\n",
      "2017-11-11 06:55:50: Loss at step 3592: 0.03679812699556351\n",
      "2017-11-11 06:55:52: Loss at step 3593: 0.03680996224284172\n",
      "2017-11-11 06:55:54: Loss at step 3594: 0.036832891404628754\n",
      "2017-11-11 06:55:56: Loss at step 3595: 0.03694061189889908\n",
      "2017-11-11 06:55:59: Loss at step 3596: 0.036847103387117386\n",
      "2017-11-11 06:56:01: Loss at step 3597: 0.03688420355319977\n",
      "2017-11-11 06:56:03: Loss at step 3598: 0.03679485246539116\n",
      "2017-11-11 06:56:05: Loss at step 3599: 0.03688526153564453\n",
      "2017-11-11 06:56:07: Loss at step 3600: 0.03694882243871689\n",
      "2017-11-11 06:56:09: Loss at step 3601: 0.03689442202448845\n",
      "2017-11-11 06:56:11: Loss at step 3602: 0.03685920685529709\n",
      "2017-11-11 06:56:13: Loss at step 3603: 0.036953624337911606\n",
      "2017-11-11 06:56:16: Loss at step 3604: 0.03689301013946533\n",
      "2017-11-11 06:56:18: Loss at step 3605: 0.03682311251759529\n",
      "2017-11-11 06:56:20: Loss at step 3606: 0.036784008145332336\n",
      "2017-11-11 06:56:23: Loss at step 3607: 0.036861851811409\n",
      "2017-11-11 06:56:25: Loss at step 3608: 0.036728907376527786\n",
      "2017-11-11 06:56:27: Loss at step 3609: 0.03676103055477142\n",
      "2017-11-11 06:56:29: Loss at step 3610: 0.036879438906908035\n",
      "2017-11-11 06:56:31: Loss at step 3611: 0.036801405251026154\n",
      "2017-11-11 06:56:33: Loss at step 3612: 0.036846812814474106\n",
      "2017-11-11 06:56:35: Loss at step 3613: 0.03682003915309906\n",
      "2017-11-11 06:56:37: Loss at step 3614: 0.036753345280885696\n",
      "2017-11-11 06:56:40: Loss at step 3615: 0.03676366060972214\n",
      "2017-11-11 06:56:42: Loss at step 3616: 0.036691177636384964\n",
      "2017-11-11 06:56:44: Loss at step 3617: 0.036870408803224564\n",
      "2017-11-11 06:56:46: Loss at step 3618: 0.036835428327322006\n",
      "2017-11-11 06:56:48: Loss at step 3619: 0.0368315763771534\n",
      "2017-11-11 06:56:50: Loss at step 3620: 0.03679966926574707\n",
      "2017-11-11 06:56:53: Loss at step 3621: 0.03683555871248245\n",
      "2017-11-11 06:56:55: Loss at step 3622: 0.0367741584777832\n",
      "2017-11-11 06:56:57: Loss at step 3623: 0.0367901474237442\n",
      "2017-11-11 06:56:59: Loss at step 3624: 0.03681645169854164\n",
      "2017-11-11 06:57:01: Loss at step 3625: 0.036773331463336945\n",
      "2017-11-11 06:57:03: Loss at step 3626: 0.03675239905714989\n",
      "2017-11-11 06:57:06: Loss at step 3627: 0.03674349933862686\n",
      "2017-11-11 06:57:08: Loss at step 3628: 0.03680502250790596\n",
      "2017-11-11 06:57:10: Loss at step 3629: 0.03680313751101494\n",
      "2017-11-11 06:57:12: Loss at step 3630: 0.03678647801280022\n",
      "2017-11-11 06:57:14: Loss at step 3631: 0.03671019896864891\n",
      "2017-11-11 06:57:16: Loss at step 3632: 0.03689451143145561\n",
      "2017-11-11 06:57:19: Loss at step 3633: 0.03675350174307823\n",
      "2017-11-11 06:57:21: Loss at step 3634: 0.03672989085316658\n",
      "2017-11-11 06:57:23: Loss at step 3635: 0.03678000345826149\n",
      "2017-11-11 06:57:25: Loss at step 3636: 0.03686380013823509\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-11-11 06:57:27: Loss at step 3637: 0.036783184856176376\n",
      "2017-11-11 06:57:30: Loss at step 3638: 0.036862097680568695\n",
      "2017-11-11 06:57:32: Loss at step 3639: 0.03683163598179817\n",
      "2017-11-11 06:57:34: Loss at step 3640: 0.03677985817193985\n",
      "2017-11-11 06:57:36: Loss at step 3641: 0.03683692589402199\n",
      "2017-11-11 06:57:38: Loss at step 3642: 0.03678060695528984\n",
      "2017-11-11 06:57:41: Loss at step 3643: 0.036833830177783966\n",
      "2017-11-11 06:57:43: Loss at step 3644: 0.036763835698366165\n",
      "2017-11-11 06:57:45: Loss at step 3645: 0.03690661862492561\n",
      "2017-11-11 06:57:47: Loss at step 3646: 0.03689483180642128\n",
      "2017-11-11 06:57:49: Loss at step 3647: 0.03680440038442612\n",
      "2017-11-11 06:57:51: Loss at step 3648: 0.03680308908224106\n",
      "2017-11-11 06:57:53: Loss at step 3649: 0.03684573993086815\n",
      "2017-11-11 06:57:55: Loss at step 3650: 0.03679755702614784\n",
      "2017-11-11 06:57:57: Loss at step 3651: 0.036869700998067856\n",
      "2017-11-11 06:58:00: Loss at step 3652: 0.036748021841049194\n",
      "2017-11-11 06:58:02: Loss at step 3653: 0.03679000213742256\n",
      "2017-11-11 06:58:04: Loss at step 3654: 0.03676868602633476\n",
      "2017-11-11 06:58:06: Loss at step 3655: 0.03678898885846138\n",
      "2017-11-11 06:58:09: Loss at step 3656: 0.03672191500663757\n",
      "2017-11-11 06:58:11: Loss at step 3657: 0.036812715232372284\n",
      "2017-11-11 06:58:13: Loss at step 3658: 0.03676240146160126\n",
      "2017-11-11 06:58:15: Loss at step 3659: 0.0367637500166893\n",
      "2017-11-11 06:58:17: Loss at step 3660: 0.03676411882042885\n",
      "2017-11-11 06:58:19: Loss at step 3661: 0.036858782172203064\n",
      "2017-11-11 06:58:21: Loss at step 3662: 0.036771245300769806\n",
      "2017-11-11 06:58:23: Loss at step 3663: 0.03681578487157822\n",
      "2017-11-11 06:58:26: Loss at step 3664: 0.03683074191212654\n",
      "2017-11-11 06:58:28: Loss at step 3665: 0.03674985468387604\n",
      "2017-11-11 06:58:30: Loss at step 3666: 0.036867279559373856\n",
      "2017-11-11 06:58:32: Loss at step 3667: 0.0368255190551281\n",
      "2017-11-11 06:58:34: Loss at step 3668: 0.03683791309595108\n",
      "2017-11-11 06:58:37: Loss at step 3669: 0.03678084537386894\n",
      "2017-11-11 06:58:39: Loss at step 3670: 0.03674894571304321\n",
      "2017-11-11 06:58:41: Loss at step 3671: 0.03684958443045616\n",
      "2017-11-11 06:58:43: Loss at step 3672: 0.036804456263780594\n",
      "2017-11-11 06:58:45: Loss at step 3673: 0.03672942891716957\n",
      "2017-11-11 06:58:47: Loss at step 3674: 0.0368337444961071\n",
      "2017-11-11 06:58:49: Loss at step 3675: 0.03679456561803818\n",
      "2017-11-11 06:58:51: Loss at step 3676: 0.03683185577392578\n",
      "2017-11-11 06:58:54: Loss at step 3677: 0.03685615956783295\n",
      "2017-11-11 06:58:56: Loss at step 3678: 0.03691578656435013\n",
      "2017-11-11 06:58:58: Loss at step 3679: 0.0368213914334774\n",
      "2017-11-11 06:59:00: Loss at step 3680: 0.03679482266306877\n",
      "2017-11-11 06:59:02: Loss at step 3681: 0.036720920354127884\n",
      "2017-11-11 06:59:04: Loss at step 3682: 0.03682626411318779\n",
      "2017-11-11 06:59:07: Loss at step 3683: 0.03668912872672081\n",
      "2017-11-11 06:59:09: Loss at step 3684: 0.0367216058075428\n",
      "2017-11-11 06:59:11: Loss at step 3685: 0.03684156388044357\n",
      "2017-11-11 06:59:13: Loss at step 3686: 0.036889348179101944\n",
      "2017-11-11 06:59:15: Loss at step 3687: 0.0368068665266037\n",
      "2017-11-11 06:59:17: Loss at step 3688: 0.03681648150086403\n",
      "2017-11-11 06:59:19: Loss at step 3689: 0.036749113351106644\n",
      "2017-11-11 06:59:21: Loss at step 3690: 0.036745358258485794\n",
      "2017-11-11 06:59:24: Loss at step 3691: 0.03668360039591789\n",
      "2017-11-11 06:59:26: Loss at step 3692: 0.036866694688797\n",
      "2017-11-11 06:59:28: Loss at step 3693: 0.03674061968922615\n",
      "2017-11-11 06:59:30: Loss at step 3694: 0.036855436861515045\n",
      "2017-11-11 06:59:32: Loss at step 3695: 0.036846015602350235\n",
      "2017-11-11 06:59:34: Loss at step 3696: 0.03685897961258888\n",
      "2017-11-11 06:59:36: Loss at step 3697: 0.03681620582938194\n",
      "2017-11-11 06:59:39: Loss at step 3698: 0.036719463765621185\n",
      "2017-11-11 06:59:41: Loss at step 3699: 0.03674892708659172\n",
      "2017-11-11 06:59:43: Loss at step 3700: 0.03675578907132149\n",
      "2017-11-11 06:59:45: Loss at step 3701: 0.03673204779624939\n",
      "2017-11-11 06:59:47: Loss at step 3702: 0.03683479502797127\n",
      "2017-11-11 06:59:49: Loss at step 3703: 0.03681829944252968\n",
      "2017-11-11 06:59:52: Loss at step 3704: 0.036814868450164795\n",
      "2017-11-11 06:59:54: Loss at step 3705: 0.03673990070819855\n",
      "2017-11-11 06:59:56: Loss at step 3706: 0.03680408373475075\n",
      "2017-11-11 06:59:58: Loss at step 3707: 0.036795105785131454\n",
      "2017-11-11 07:00:00: Loss at step 3708: 0.03683491796255112\n",
      "2017-11-11 07:00:02: Loss at step 3709: 0.03683906048536301\n",
      "2017-11-11 07:00:05: Loss at step 3710: 0.036748845130205154\n",
      "2017-11-11 07:00:07: Loss at step 3711: 0.03674449399113655\n",
      "2017-11-11 07:00:09: Loss at step 3712: 0.03679012879729271\n",
      "2017-11-11 07:00:11: Loss at step 3713: 0.036819398403167725\n",
      "2017-11-11 07:00:13: Loss at step 3714: 0.03694954887032509\n",
      "2017-11-11 07:00:15: Loss at step 3715: 0.03670916706323624\n",
      "2017-11-11 07:00:18: Loss at step 3716: 0.03678680583834648\n",
      "2017-11-11 07:00:20: Loss at step 3717: 0.03677413612604141\n",
      "2017-11-11 07:00:22: Loss at step 3718: 0.03678559511899948\n",
      "2017-11-11 07:00:24: Loss at step 3719: 0.03677927330136299\n",
      "2017-11-11 07:00:26: Loss at step 3720: 0.03674335405230522\n",
      "2017-11-11 07:00:28: Loss at step 3721: 0.03685814142227173\n",
      "2017-11-11 07:00:31: Loss at step 3722: 0.03677814453840256\n",
      "2017-11-11 07:00:33: Loss at step 3723: 0.03682427480816841\n",
      "2017-11-11 07:00:35: Loss at step 3724: 0.03682198002934456\n",
      "2017-11-11 07:00:37: Loss at step 3725: 0.036843881011009216\n",
      "2017-11-11 07:00:39: Loss at step 3726: 0.03686441481113434\n",
      "2017-11-11 07:00:41: Loss at step 3727: 0.036856088787317276\n",
      "2017-11-11 07:00:43: Loss at step 3728: 0.036769136786460876\n",
      "2017-11-11 07:00:46: Loss at step 3729: 0.03677797690033913\n",
      "2017-11-11 07:00:48: Loss at step 3730: 0.03674139454960823\n",
      "2017-11-11 07:00:50: Loss at step 3731: 0.03680849447846413\n",
      "2017-11-11 07:00:52: Loss at step 3732: 0.03681160882115364\n",
      "2017-11-11 07:00:54: Loss at step 3733: 0.03679291158914566\n",
      "2017-11-11 07:00:57: Loss at step 3734: 0.036892980337142944\n",
      "2017-11-11 07:00:59: Loss at step 3735: 0.03687998279929161\n",
      "2017-11-11 07:01:01: Loss at step 3736: 0.036828868091106415\n",
      "2017-11-11 07:01:03: Loss at step 3737: 0.03693574294447899\n",
      "2017-11-11 07:01:05: Loss at step 3738: 0.03688080981373787\n",
      "2017-11-11 07:01:07: Loss at step 3739: 0.036884237080812454\n",
      "2017-11-11 07:01:09: Loss at step 3740: 0.03683529794216156\n",
      "2017-11-11 07:01:11: Loss at step 3741: 0.0368766188621521\n",
      "2017-11-11 07:01:14: Loss at step 3742: 0.036873530596494675\n",
      "2017-11-11 07:01:16: Loss at step 3743: 0.03670022636651993\n",
      "2017-11-11 07:01:18: Loss at step 3744: 0.03684275224804878\n",
      "2017-11-11 07:01:20: Loss at step 3745: 0.0368441566824913\n",
      "2017-11-11 07:01:22: Loss at step 3746: 0.03692350536584854\n",
      "2017-11-11 07:01:25: Loss at step 3747: 0.03685451298952103\n",
      "2017-11-11 07:01:27: Loss at step 3748: 0.03678935021162033\n",
      "2017-11-11 07:01:29: Loss at step 3749: 0.03696485236287117\n",
      "2017-11-11 07:01:31: Loss at step 3750: 0.0368955060839653\n",
      "2017-11-11 07:01:33: Loss at step 3751: 0.03692157566547394\n",
      "2017-11-11 07:01:35: Loss at step 3752: 0.03691675886511803\n",
      "2017-11-11 07:01:37: Loss at step 3753: 0.03689630702137947\n",
      "2017-11-11 07:01:39: Loss at step 3754: 0.036935608834028244\n",
      "2017-11-11 07:01:42: Loss at step 3755: 0.03696136549115181\n",
      "2017-11-11 07:01:44: Loss at step 3756: 0.036858197301626205\n",
      "2017-11-11 07:01:46: Loss at step 3757: 0.036796629428863525\n",
      "2017-11-11 07:01:48: Loss at step 3758: 0.03689822554588318\n",
      "2017-11-11 07:01:50: Loss at step 3759: 0.03681369498372078\n",
      "2017-11-11 07:01:52: Loss at step 3760: 0.036900464445352554\n",
      "2017-11-11 07:01:55: Loss at step 3761: 0.036880698055028915\n",
      "2017-11-11 07:01:57: Loss at step 3762: 0.036919817328453064\n",
      "2017-11-11 07:01:59: Loss at step 3763: 0.036844246089458466\n",
      "2017-11-11 07:02:01: Loss at step 3764: 0.03683314844965935\n",
      "2017-11-11 07:02:03: Loss at step 3765: 0.03688119351863861\n",
      "2017-11-11 07:02:05: Loss at step 3766: 0.03696206957101822\n",
      "2017-11-11 07:02:07: Loss at step 3767: 0.036831654608249664\n",
      "2017-11-11 07:02:09: Loss at step 3768: 0.03684839606285095\n",
      "2017-11-11 07:02:12: Loss at step 3769: 0.0368606336414814\n",
      "2017-11-11 07:02:14: Loss at step 3770: 0.036953385919332504\n",
      "2017-11-11 07:02:16: Loss at step 3771: 0.03693389892578125\n",
      "2017-11-11 07:02:18: Loss at step 3772: 0.03694317117333412\n",
      "2017-11-11 07:02:20: Loss at step 3773: 0.036838941276073456\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-11-11 07:02:22: Loss at step 3774: 0.03683708235621452\n",
      "2017-11-11 07:02:25: Loss at step 3775: 0.03674326837062836\n",
      "2017-11-11 07:02:27: Loss at step 3776: 0.036864910274744034\n",
      "2017-11-11 07:02:29: Loss at step 3777: 0.03692103922367096\n",
      "2017-11-11 07:02:31: Loss at step 3778: 0.03693343326449394\n",
      "2017-11-11 07:02:33: Loss at step 3779: 0.03693638741970062\n",
      "2017-11-11 07:02:35: Loss at step 3780: 0.03694935142993927\n",
      "2017-11-11 07:02:38: Loss at step 3781: 0.036845654249191284\n",
      "2017-11-11 07:02:40: Loss at step 3782: 0.03680649772286415\n",
      "2017-11-11 07:02:42: Loss at step 3783: 0.036757029592990875\n",
      "2017-11-11 07:02:44: Loss at step 3784: 0.036862291395664215\n",
      "2017-11-11 07:02:46: Loss at step 3785: 0.036874134093523026\n",
      "2017-11-11 07:02:48: Loss at step 3786: 0.03688378259539604\n",
      "2017-11-11 07:02:51: Loss at step 3787: 0.036756839603185654\n",
      "2017-11-11 07:02:53: Loss at step 3788: 0.036815494298934937\n",
      "2017-11-11 07:02:55: Loss at step 3789: 0.036760784685611725\n",
      "2017-11-11 07:02:57: Loss at step 3790: 0.03674517944455147\n",
      "2017-11-11 07:02:59: Loss at step 3791: 0.036845359951257706\n",
      "2017-11-11 07:03:01: Loss at step 3792: 0.03686567768454552\n",
      "2017-11-11 07:03:04: Loss at step 3793: 0.0367879681289196\n",
      "2017-11-11 07:03:06: Loss at step 3794: 0.03694708272814751\n",
      "2017-11-11 07:03:08: Loss at step 3795: 0.036854565143585205\n",
      "2017-11-11 07:03:10: Loss at step 3796: 0.036726292222738266\n",
      "2017-11-11 07:03:12: Loss at step 3797: 0.03666527196764946\n",
      "2017-11-11 07:03:14: Loss at step 3798: 0.036809101700782776\n",
      "2017-11-11 07:03:17: Loss at step 3799: 0.03666934743523598\n",
      "2017-11-11 07:03:19: Loss at step 3800: 0.036978594958782196\n",
      "2017-11-11 07:03:21: Loss at step 3801: 0.03684278577566147\n",
      "2017-11-11 07:03:23: Loss at step 3802: 0.03680640831589699\n",
      "2017-11-11 07:03:25: Loss at step 3803: 0.03669792041182518\n",
      "2017-11-11 07:03:27: Loss at step 3804: 0.03678590804338455\n",
      "2017-11-11 07:03:29: Loss at step 3805: 0.03670339286327362\n",
      "2017-11-11 07:03:31: Loss at step 3806: 0.036715373396873474\n",
      "2017-11-11 07:03:34: Loss at step 3807: 0.03677475452423096\n",
      "2017-11-11 07:03:36: Loss at step 3808: 0.03683038055896759\n",
      "2017-11-11 07:03:38: Loss at step 3809: 0.03685016930103302\n",
      "2017-11-11 07:03:40: Loss at step 3810: 0.03675481677055359\n",
      "2017-11-11 07:03:42: Loss at step 3811: 0.03670460358262062\n",
      "2017-11-11 07:03:44: Loss at step 3812: 0.03674362227320671\n",
      "2017-11-11 07:03:46: Loss at step 3813: 0.03679334744811058\n",
      "2017-11-11 07:03:49: Loss at step 3814: 0.03685690462589264\n",
      "2017-11-11 07:03:51: Loss at step 3815: 0.03685013949871063\n",
      "2017-11-11 07:03:53: Loss at step 3816: 0.03691145032644272\n",
      "2017-11-11 07:03:55: Loss at step 3817: 0.036751486361026764\n",
      "2017-11-11 07:03:57: Loss at step 3818: 0.03675545006990433\n",
      "2017-11-11 07:03:59: Loss at step 3819: 0.0368083119392395\n",
      "2017-11-11 07:04:01: Loss at step 3820: 0.03676183894276619\n",
      "2017-11-11 07:04:03: Loss at step 3821: 0.036833375692367554\n",
      "2017-11-11 07:04:05: Loss at step 3822: 0.03683168813586235\n",
      "2017-11-11 07:04:08: Loss at step 3823: 0.036815643310546875\n",
      "2017-11-11 07:04:10: Loss at step 3824: 0.03682830557227135\n",
      "2017-11-11 07:04:12: Loss at step 3825: 0.03682538494467735\n",
      "2017-11-11 07:04:14: Loss at step 3826: 0.0367346927523613\n",
      "2017-11-11 07:04:16: Loss at step 3827: 0.03681837022304535\n",
      "2017-11-11 07:04:18: Loss at step 3828: 0.03680496662855148\n",
      "2017-11-11 07:04:20: Loss at step 3829: 0.03680580481886864\n",
      "2017-11-11 07:04:22: Loss at step 3830: 0.036847420036792755\n",
      "2017-11-11 07:04:25: Loss at step 3831: 0.036819685250520706\n",
      "2017-11-11 07:04:27: Loss at step 3832: 0.03675204515457153\n",
      "2017-11-11 07:04:29: Loss at step 3833: 0.03679654374718666\n",
      "2017-11-11 07:04:31: Loss at step 3834: 0.03684363514184952\n",
      "2017-11-11 07:04:33: Loss at step 3835: 0.036851320415735245\n",
      "2017-11-11 07:04:35: Loss at step 3836: 0.036835767328739166\n",
      "2017-11-11 07:04:38: Loss at step 3837: 0.03684935346245766\n",
      "2017-11-11 07:04:40: Loss at step 3838: 0.03677551448345184\n",
      "2017-11-11 07:04:42: Loss at step 3839: 0.03683735057711601\n",
      "2017-11-11 07:04:44: Loss at step 3840: 0.03673744201660156\n",
      "2017-11-11 07:04:46: Loss at step 3841: 0.03675326332449913\n",
      "2017-11-11 07:04:48: Loss at step 3842: 0.03679342195391655\n",
      "2017-11-11 07:04:50: Loss at step 3843: 0.03687895089387894\n",
      "2017-11-11 07:04:52: Loss at step 3844: 0.036829978227615356\n",
      "2017-11-11 07:04:55: Loss at step 3845: 0.03690018877387047\n",
      "2017-11-11 07:04:57: Loss at step 3846: 0.03692419081926346\n",
      "2017-11-11 07:04:59: Loss at step 3847: 0.03690529242157936\n",
      "2017-11-11 07:05:01: Loss at step 3848: 0.036860015243291855\n",
      "2017-11-11 07:05:03: Loss at step 3849: 0.036854419857263565\n",
      "2017-11-11 07:05:05: Loss at step 3850: 0.036882854998111725\n",
      "2017-11-11 07:05:07: Loss at step 3851: 0.03684476017951965\n",
      "2017-11-11 07:05:09: Loss at step 3852: 0.036896832287311554\n",
      "2017-11-11 07:05:12: Loss at step 3853: 0.03682880848646164\n",
      "2017-11-11 07:05:14: Loss at step 3854: 0.03680871054530144\n",
      "2017-11-11 07:05:16: Loss at step 3855: 0.036801986396312714\n",
      "2017-11-11 07:05:18: Loss at step 3856: 0.036837223917245865\n",
      "2017-11-11 07:05:20: Loss at step 3857: 0.03669489175081253\n",
      "2017-11-11 07:05:22: Loss at step 3858: 0.036842815577983856\n",
      "2017-11-11 07:05:24: Loss at step 3859: 0.03682270273566246\n",
      "2017-11-11 07:05:26: Loss at step 3860: 0.03684169054031372\n",
      "2017-11-11 07:05:29: Loss at step 3861: 0.03687991946935654\n",
      "2017-11-11 07:05:31: Loss at step 3862: 0.036894574761390686\n",
      "2017-11-11 07:05:33: Loss at step 3863: 0.03689766302704811\n",
      "2017-11-11 07:05:35: Loss at step 3864: 0.03684540465474129\n",
      "2017-11-11 07:05:37: Loss at step 3865: 0.03687746822834015\n",
      "2017-11-11 07:05:39: Loss at step 3866: 0.03680811822414398\n",
      "2017-11-11 07:05:41: Loss at step 3867: 0.03681332245469093\n",
      "2017-11-11 07:05:43: Loss at step 3868: 0.03681481257081032\n",
      "2017-11-11 07:05:46: Loss at step 3869: 0.036762818694114685\n",
      "2017-11-11 07:05:48: Loss at step 3870: 0.03683004528284073\n",
      "2017-11-11 07:05:50: Loss at step 3871: 0.0368061400949955\n",
      "2017-11-11 07:05:52: Loss at step 3872: 0.03680895268917084\n",
      "2017-11-11 07:05:54: Loss at step 3873: 0.03685733303427696\n",
      "2017-11-11 07:05:56: Loss at step 3874: 0.036893267184495926\n",
      "2017-11-11 07:05:58: Loss at step 3875: 0.036798518151044846\n",
      "2017-11-11 07:06:00: Loss at step 3876: 0.036850083619356155\n",
      "2017-11-11 07:06:03: Loss at step 3877: 0.036655064672231674\n",
      "2017-11-11 07:06:05: Loss at step 3878: 0.03675302863121033\n",
      "2017-11-11 07:06:07: Loss at step 3879: 0.03675054758787155\n",
      "2017-11-11 07:06:09: Loss at step 3880: 0.03674163669347763\n",
      "2017-11-11 07:06:11: Loss at step 3881: 0.036749809980392456\n",
      "2017-11-11 07:06:13: Loss at step 3882: 0.03675905615091324\n",
      "2017-11-11 07:06:15: Loss at step 3883: 0.03682438284158707\n",
      "2017-11-11 07:06:17: Loss at step 3884: 0.036780402064323425\n",
      "2017-11-11 07:06:20: Loss at step 3885: 0.0367867536842823\n",
      "2017-11-11 07:06:22: Loss at step 3886: 0.0367724746465683\n",
      "2017-11-11 07:06:24: Loss at step 3887: 0.03683864697813988\n",
      "2017-11-11 07:06:26: Loss at step 3888: 0.0367884524166584\n",
      "2017-11-11 07:06:28: Loss at step 3889: 0.03675420209765434\n",
      "2017-11-11 07:06:30: Loss at step 3890: 0.03680948540568352\n",
      "2017-11-11 07:06:33: Loss at step 3891: 0.03676687180995941\n",
      "2017-11-11 07:06:35: Loss at step 3892: 0.03675968199968338\n",
      "2017-11-11 07:06:37: Loss at step 3893: 0.03670431673526764\n",
      "2017-11-11 07:06:39: Loss at step 3894: 0.03672102093696594\n",
      "2017-11-11 07:06:41: Loss at step 3895: 0.03668273240327835\n",
      "2017-11-11 07:06:43: Loss at step 3896: 0.03676975518465042\n",
      "2017-11-11 07:06:45: Loss at step 3897: 0.03684760630130768\n",
      "2017-11-11 07:06:48: Loss at step 3898: 0.0368434377014637\n",
      "2017-11-11 07:06:50: Loss at step 3899: 0.03674653172492981\n",
      "2017-11-11 07:06:52: Loss at step 3900: 0.0368913896381855\n",
      "2017-11-11 07:06:54: Loss at step 3901: 0.036786891520023346\n",
      "2017-11-11 07:06:56: Loss at step 3902: 0.03682757541537285\n",
      "2017-11-11 07:06:58: Loss at step 3903: 0.036694932729005814\n",
      "2017-11-11 07:07:00: Loss at step 3904: 0.036782506853342056\n",
      "2017-11-11 07:07:02: Loss at step 3905: 0.036830317229032516\n",
      "2017-11-11 07:07:05: Loss at step 3906: 0.036942120641469955\n",
      "2017-11-11 07:07:07: Loss at step 3907: 0.036782488226890564\n",
      "2017-11-11 07:07:09: Loss at step 3908: 0.03678920120000839\n",
      "2017-11-11 07:07:11: Loss at step 3909: 0.03682655468583107\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-11-11 07:07:13: Loss at step 3910: 0.03674496337771416\n",
      "2017-11-11 07:07:15: Loss at step 3911: 0.0367145799100399\n",
      "2017-11-11 07:07:17: Loss at step 3912: 0.03667007014155388\n",
      "2017-11-11 07:07:20: Loss at step 3913: 0.03679288178682327\n",
      "2017-11-11 07:07:22: Loss at step 3914: 0.03669046610593796\n",
      "2017-11-11 07:07:24: Loss at step 3915: 0.03671008348464966\n",
      "2017-11-11 07:07:26: Loss at step 3916: 0.03673507273197174\n",
      "2017-11-11 07:07:28: Loss at step 3917: 0.03674417734146118\n",
      "2017-11-11 07:07:30: Loss at step 3918: 0.03686463460326195\n",
      "2017-11-11 07:07:32: Loss at step 3919: 0.036740049719810486\n",
      "2017-11-11 07:07:35: Loss at step 3920: 0.036817535758018494\n",
      "2017-11-11 07:07:37: Loss at step 3921: 0.03676178678870201\n",
      "2017-11-11 07:07:39: Loss at step 3922: 0.03680400177836418\n",
      "2017-11-11 07:07:41: Loss at step 3923: 0.03674845024943352\n",
      "2017-11-11 07:07:43: Loss at step 3924: 0.03675954043865204\n",
      "2017-11-11 07:07:45: Loss at step 3925: 0.03685895726084709\n",
      "2017-11-11 07:07:48: Loss at step 3926: 0.0367698036134243\n",
      "2017-11-11 07:07:50: Loss at step 3927: 0.03675774484872818\n",
      "2017-11-11 07:07:52: Loss at step 3928: 0.036798954010009766\n",
      "2017-11-11 07:07:54: Loss at step 3929: 0.03676392138004303\n",
      "2017-11-11 07:07:56: Loss at step 3930: 0.036811329424381256\n",
      "2017-11-11 07:07:58: Loss at step 3931: 0.036795474588871\n",
      "2017-11-11 07:08:00: Loss at step 3932: 0.036669500172138214\n",
      "2017-11-11 07:08:02: Loss at step 3933: 0.03686482459306717\n",
      "2017-11-11 07:08:05: Loss at step 3934: 0.036953724920749664\n",
      "2017-11-11 07:08:07: Loss at step 3935: 0.036697834730148315\n",
      "2017-11-11 07:08:09: Loss at step 3936: 0.036736227571964264\n",
      "2017-11-11 07:08:11: Loss at step 3937: 0.03687596321105957\n",
      "2017-11-11 07:08:13: Loss at step 3938: 0.03685412555932999\n",
      "2017-11-11 07:08:15: Loss at step 3939: 0.03685363009572029\n",
      "2017-11-11 07:08:17: Loss at step 3940: 0.03685123473405838\n",
      "2017-11-11 07:08:20: Loss at step 3941: 0.03683457896113396\n",
      "2017-11-11 07:08:22: Loss at step 3942: 0.03681618347764015\n",
      "2017-11-11 07:08:24: Loss at step 3943: 0.03684509918093681\n",
      "2017-11-11 07:08:26: Loss at step 3944: 0.036812782287597656\n",
      "2017-11-11 07:08:28: Loss at step 3945: 0.036736756563186646\n",
      "2017-11-11 07:08:30: Loss at step 3946: 0.0367678664624691\n",
      "2017-11-11 07:08:32: Loss at step 3947: 0.03676407411694527\n",
      "2017-11-11 07:08:35: Loss at step 3948: 0.03669445589184761\n",
      "2017-11-11 07:08:37: Loss at step 3949: 0.03680621460080147\n",
      "2017-11-11 07:08:39: Loss at step 3950: 0.03677866980433464\n",
      "2017-11-11 07:08:41: Loss at step 3951: 0.03675151988863945\n",
      "2017-11-11 07:08:43: Loss at step 3952: 0.036767832934856415\n",
      "2017-11-11 07:08:45: Loss at step 3953: 0.03675466775894165\n",
      "2017-11-11 07:08:47: Loss at step 3954: 0.036666661500930786\n",
      "2017-11-11 07:08:50: Loss at step 3955: 0.03671208396553993\n",
      "2017-11-11 07:08:52: Loss at step 3956: 0.03679024055600166\n",
      "2017-11-11 07:08:54: Loss at step 3957: 0.03680489957332611\n",
      "2017-11-11 07:08:56: Loss at step 3958: 0.036844585090875626\n",
      "2017-11-11 07:08:58: Loss at step 3959: 0.03676486760377884\n",
      "2017-11-11 07:09:00: Loss at step 3960: 0.03678317740559578\n",
      "2017-11-11 07:09:02: Loss at step 3961: 0.03688114508986473\n",
      "2017-11-11 07:09:05: Loss at step 3962: 0.03682801499962807\n",
      "2017-11-11 07:09:07: Loss at step 3963: 0.036828525364398956\n",
      "2017-11-11 07:09:09: Loss at step 3964: 0.036748554557561874\n",
      "2017-11-11 07:09:11: Loss at step 3965: 0.0368366539478302\n",
      "2017-11-11 07:09:13: Loss at step 3966: 0.036713287234306335\n",
      "2017-11-11 07:09:15: Loss at step 3967: 0.0366344191133976\n",
      "2017-11-11 07:09:17: Loss at step 3968: 0.03674381226301193\n",
      "2017-11-11 07:09:20: Loss at step 3969: 0.036792103201150894\n",
      "2017-11-11 07:09:22: Loss at step 3970: 0.036773681640625\n",
      "2017-11-11 07:09:24: Loss at step 3971: 0.03686189278960228\n",
      "2017-11-11 07:09:26: Loss at step 3972: 0.03679222613573074\n",
      "2017-11-11 07:09:28: Loss at step 3973: 0.03683452308177948\n",
      "2017-11-11 07:09:30: Loss at step 3974: 0.036804359406232834\n",
      "2017-11-11 07:09:32: Loss at step 3975: 0.036800190806388855\n",
      "2017-11-11 07:09:35: Loss at step 3976: 0.036737192422151566\n",
      "2017-11-11 07:09:37: Loss at step 3977: 0.03675500676035881\n",
      "2017-11-11 07:09:39: Loss at step 3978: 0.036855101585388184\n",
      "2017-11-11 07:09:41: Loss at step 3979: 0.036849942058324814\n",
      "2017-11-11 07:09:43: Loss at step 3980: 0.03676470369100571\n",
      "2017-11-11 07:09:45: Loss at step 3981: 0.036752186715602875\n",
      "2017-11-11 07:09:47: Loss at step 3982: 0.03675844147801399\n",
      "2017-11-11 07:09:50: Loss at step 3983: 0.036779388785362244\n",
      "2017-11-11 07:09:52: Loss at step 3984: 0.03679630905389786\n",
      "2017-11-11 07:09:54: Loss at step 3985: 0.036816444247961044\n",
      "2017-11-11 07:09:56: Loss at step 3986: 0.03674789518117905\n",
      "2017-11-11 07:09:58: Loss at step 3987: 0.03684290871024132\n",
      "2017-11-11 07:10:00: Loss at step 3988: 0.03690009191632271\n",
      "2017-11-11 07:10:02: Loss at step 3989: 0.036770109087228775\n",
      "2017-11-11 07:10:04: Loss at step 3990: 0.036739643663167953\n",
      "2017-11-11 07:10:07: Loss at step 3991: 0.03679459169507027\n",
      "2017-11-11 07:10:09: Loss at step 3992: 0.03675524890422821\n",
      "2017-11-11 07:10:11: Loss at step 3993: 0.03677544370293617\n",
      "2017-11-11 07:10:13: Loss at step 3994: 0.03682759404182434\n",
      "2017-11-11 07:10:15: Loss at step 3995: 0.036751117557287216\n",
      "2017-11-11 07:10:17: Loss at step 3996: 0.0367596261203289\n",
      "2017-11-11 07:10:19: Loss at step 3997: 0.0367557518184185\n",
      "2017-11-11 07:10:22: Loss at step 3998: 0.036679938435554504\n",
      "2017-11-11 07:10:24: Loss at step 3999: 0.036798276007175446\n",
      "2017-11-11 07:10:26: Loss at step 4000: 0.036832913756370544\n",
      "2017-11-11 07:10:28: Loss at step 4001: 0.036727748811244965\n",
      "2017-11-11 07:10:30: Loss at step 4002: 0.0368274450302124\n",
      "2017-11-11 07:10:32: Loss at step 4003: 0.036809761077165604\n",
      "2017-11-11 07:10:35: Loss at step 4004: 0.036858465522527695\n",
      "2017-11-11 07:10:37: Loss at step 4005: 0.036861542612314224\n",
      "2017-11-11 07:10:39: Loss at step 4006: 0.036904048174619675\n",
      "2017-11-11 07:10:41: Loss at step 4007: 0.03674283251166344\n",
      "2017-11-11 07:10:43: Loss at step 4008: 0.03678514063358307\n",
      "2017-11-11 07:10:45: Loss at step 4009: 0.036718375980854034\n",
      "2017-11-11 07:10:47: Loss at step 4010: 0.036790844053030014\n",
      "2017-11-11 07:10:49: Loss at step 4011: 0.03675111010670662\n",
      "2017-11-11 07:10:52: Loss at step 4012: 0.03683629259467125\n",
      "2017-11-11 07:10:54: Loss at step 4013: 0.03686215728521347\n",
      "2017-11-11 07:10:56: Loss at step 4014: 0.03689039871096611\n",
      "2017-11-11 07:10:58: Loss at step 4015: 0.03680645301938057\n",
      "2017-11-11 07:11:00: Loss at step 4016: 0.03674377501010895\n",
      "2017-11-11 07:11:02: Loss at step 4017: 0.03683572635054588\n",
      "2017-11-11 07:11:04: Loss at step 4018: 0.03685656562447548\n",
      "2017-11-11 07:11:07: Loss at step 4019: 0.03687683865427971\n",
      "2017-11-11 07:11:09: Loss at step 4020: 0.0368800163269043\n",
      "2017-11-11 07:11:11: Loss at step 4021: 0.03682968020439148\n",
      "2017-11-11 07:11:13: Loss at step 4022: 0.03666846826672554\n",
      "2017-11-11 07:11:15: Loss at step 4023: 0.03681052848696709\n",
      "2017-11-11 07:11:17: Loss at step 4024: 0.036810748279094696\n",
      "2017-11-11 07:11:19: Loss at step 4025: 0.036772698163986206\n",
      "2017-11-11 07:11:21: Loss at step 4026: 0.03678852692246437\n",
      "2017-11-11 07:11:24: Loss at step 4027: 0.03683455288410187\n",
      "2017-11-11 07:11:26: Loss at step 4028: 0.03681294992566109\n",
      "2017-11-11 07:11:28: Loss at step 4029: 0.036855023354291916\n",
      "2017-11-11 07:11:30: Loss at step 4030: 0.03671154007315636\n",
      "2017-11-11 07:11:32: Loss at step 4031: 0.03682156279683113\n",
      "2017-11-11 07:11:34: Loss at step 4032: 0.03680085763335228\n",
      "2017-11-11 07:11:36: Loss at step 4033: 0.03676605597138405\n",
      "2017-11-11 07:11:39: Loss at step 4034: 0.03680811822414398\n",
      "2017-11-11 07:11:41: Loss at step 4035: 0.036791715770959854\n",
      "2017-11-11 07:11:43: Loss at step 4036: 0.03684061020612717\n",
      "2017-11-11 07:11:45: Loss at step 4037: 0.036771174520254135\n",
      "2017-11-11 07:11:47: Loss at step 4038: 0.036767926067113876\n",
      "2017-11-11 07:11:49: Loss at step 4039: 0.03684976324439049\n",
      "2017-11-11 07:11:51: Loss at step 4040: 0.03683416172862053\n",
      "2017-11-11 07:11:53: Loss at step 4041: 0.03679834306240082\n",
      "2017-11-11 07:11:56: Loss at step 4042: 0.03684930503368378\n",
      "2017-11-11 07:11:58: Loss at step 4043: 0.03679532930254936\n",
      "2017-11-11 07:12:00: Loss at step 4044: 0.036823906004428864\n",
      "2017-11-11 07:12:02: Loss at step 4045: 0.036807380616664886\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-11-11 07:12:04: Loss at step 4046: 0.03684917092323303\n",
      "2017-11-11 07:12:06: Loss at step 4047: 0.03681929409503937\n",
      "2017-11-11 07:12:08: Loss at step 4048: 0.03674627095460892\n",
      "2017-11-11 07:12:10: Loss at step 4049: 0.0369245745241642\n",
      "2017-11-11 07:12:13: Loss at step 4050: 0.03674446418881416\n",
      "2017-11-11 07:12:15: Loss at step 4051: 0.036795489490032196\n",
      "2017-11-11 07:12:17: Loss at step 4052: 0.03675193339586258\n",
      "2017-11-11 07:12:19: Loss at step 4053: 0.03674726560711861\n",
      "2017-11-11 07:12:21: Loss at step 4054: 0.03670770302414894\n",
      "2017-11-11 07:12:23: Loss at step 4055: 0.03677024692296982\n",
      "2017-11-11 07:12:25: Loss at step 4056: 0.03679041564464569\n",
      "2017-11-11 07:12:28: Loss at step 4057: 0.03675834834575653\n",
      "2017-11-11 07:12:30: Loss at step 4058: 0.03678632155060768\n",
      "2017-11-11 07:12:32: Loss at step 4059: 0.03678560629487038\n",
      "2017-11-11 07:12:34: Loss at step 4060: 0.036765944212675095\n",
      "2017-11-11 07:12:36: Loss at step 4061: 0.03680328279733658\n",
      "2017-11-11 07:12:38: Loss at step 4062: 0.03679991886019707\n",
      "2017-11-11 07:12:40: Loss at step 4063: 0.03682092949748039\n",
      "2017-11-11 07:12:43: Loss at step 4064: 0.03674548491835594\n",
      "2017-11-11 07:12:45: Loss at step 4065: 0.036814864724874496\n",
      "2017-11-11 07:12:47: Loss at step 4066: 0.036829590797424316\n",
      "2017-11-11 07:12:49: Loss at step 4067: 0.03680189326405525\n",
      "2017-11-11 07:12:51: Loss at step 4068: 0.036761701107025146\n",
      "2017-11-11 07:12:53: Loss at step 4069: 0.036802541464567184\n",
      "2017-11-11 07:12:55: Loss at step 4070: 0.03675254061818123\n",
      "2017-11-11 07:12:58: Loss at step 4071: 0.036773037165403366\n",
      "2017-11-11 07:13:00: Loss at step 4072: 0.03681105747818947\n",
      "2017-11-11 07:13:02: Loss at step 4073: 0.036837074905633926\n",
      "2017-11-11 07:13:04: Loss at step 4074: 0.036736976355314255\n",
      "2017-11-11 07:13:06: Loss at step 4075: 0.03680561110377312\n",
      "2017-11-11 07:13:08: Loss at step 4076: 0.03680434450507164\n",
      "2017-11-11 07:13:10: Loss at step 4077: 0.03688172996044159\n",
      "2017-11-11 07:13:12: Loss at step 4078: 0.03680279850959778\n",
      "2017-11-11 07:13:15: Loss at step 4079: 0.03685881197452545\n",
      "2017-11-11 07:13:17: Loss at step 4080: 0.03672601655125618\n",
      "2017-11-11 07:13:19: Loss at step 4081: 0.03686393424868584\n",
      "2017-11-11 07:13:21: Loss at step 4082: 0.03674948588013649\n",
      "2017-11-11 07:13:23: Loss at step 4083: 0.03669646754860878\n",
      "2017-11-11 07:13:25: Loss at step 4084: 0.03670685738325119\n",
      "2017-11-11 07:13:27: Loss at step 4085: 0.03679859638214111\n",
      "2017-11-11 07:13:30: Loss at step 4086: 0.036860156804323196\n",
      "2017-11-11 07:13:32: Loss at step 4087: 0.036884911358356476\n",
      "2017-11-11 07:13:34: Loss at step 4088: 0.03684764355421066\n",
      "2017-11-11 07:13:36: Loss at step 4089: 0.036863330751657486\n",
      "2017-11-11 07:13:38: Loss at step 4090: 0.03678944706916809\n",
      "2017-11-11 07:13:40: Loss at step 4091: 0.0368204340338707\n",
      "2017-11-11 07:13:42: Loss at step 4092: 0.03684708848595619\n",
      "2017-11-11 07:13:44: Loss at step 4093: 0.03674875944852829\n",
      "2017-11-11 07:13:47: Loss at step 4094: 0.03689023479819298\n",
      "2017-11-11 07:13:49: Loss at step 4095: 0.03683142364025116\n",
      "2017-11-11 07:13:51: Loss at step 4096: 0.03680034354329109\n",
      "2017-11-11 07:13:53: Loss at step 4097: 0.03684860095381737\n",
      "2017-11-11 07:13:55: Loss at step 4098: 0.0367773212492466\n",
      "2017-11-11 07:13:58: Loss at step 4099: 0.03685922175645828\n",
      "2017-11-11 07:14:00: Loss at step 4100: 0.03685533255338669\n",
      "2017-11-11 07:14:02: Loss at step 4101: 0.03676312789320946\n",
      "2017-11-11 07:14:04: Loss at step 4102: 0.036848414689302444\n",
      "2017-11-11 07:14:06: Loss at step 4103: 0.03679271414875984\n",
      "2017-11-11 07:14:08: Loss at step 4104: 0.036836933344602585\n",
      "2017-11-11 07:14:10: Loss at step 4105: 0.036782000213861465\n",
      "2017-11-11 07:14:12: Loss at step 4106: 0.03681521490216255\n",
      "2017-11-11 07:14:15: Loss at step 4107: 0.036741483956575394\n",
      "2017-11-11 07:14:17: Loss at step 4108: 0.03687518462538719\n",
      "2017-11-11 07:14:19: Loss at step 4109: 0.0368032343685627\n",
      "2017-11-11 07:14:21: Loss at step 4110: 0.03683330863714218\n",
      "2017-11-11 07:14:23: Loss at step 4111: 0.03686662018299103\n",
      "2017-11-11 07:14:25: Loss at step 4112: 0.03679365664720535\n",
      "2017-11-11 07:14:27: Loss at step 4113: 0.03680006042122841\n",
      "2017-11-11 07:14:30: Loss at step 4114: 0.03679082170128822\n",
      "2017-11-11 07:14:32: Loss at step 4115: 0.03672727569937706\n",
      "2017-11-11 07:14:34: Loss at step 4116: 0.03676871210336685\n",
      "2017-11-11 07:14:36: Loss at step 4117: 0.03682525455951691\n",
      "2017-11-11 07:14:38: Loss at step 4118: 0.036789670586586\n",
      "2017-11-11 07:14:40: Loss at step 4119: 0.036777906119823456\n",
      "2017-11-11 07:14:42: Loss at step 4120: 0.0367412231862545\n",
      "2017-11-11 07:14:45: Loss at step 4121: 0.036812637001276016\n",
      "2017-11-11 07:14:47: Loss at step 4122: 0.03676396608352661\n",
      "2017-11-11 07:14:49: Loss at step 4123: 0.036801643669605255\n",
      "2017-11-11 07:14:51: Loss at step 4124: 0.03683726117014885\n",
      "2017-11-11 07:14:53: Loss at step 4125: 0.03689087554812431\n",
      "2017-11-11 07:14:55: Loss at step 4126: 0.03687811642885208\n",
      "2017-11-11 07:14:57: Loss at step 4127: 0.03681567311286926\n",
      "2017-11-11 07:15:00: Loss at step 4128: 0.03694390878081322\n",
      "2017-11-11 07:15:02: Loss at step 4129: 0.03682670369744301\n",
      "2017-11-11 07:15:04: Loss at step 4130: 0.036847759038209915\n",
      "2017-11-11 07:15:06: Loss at step 4131: 0.036864716559648514\n",
      "2017-11-11 07:15:08: Loss at step 4132: 0.03679042309522629\n",
      "2017-11-11 07:15:10: Loss at step 4133: 0.03681762143969536\n",
      "2017-11-11 07:15:12: Loss at step 4134: 0.036858897656202316\n",
      "2017-11-11 07:15:14: Loss at step 4135: 0.03683736175298691\n",
      "2017-11-11 07:15:17: Loss at step 4136: 0.03686203062534332\n",
      "2017-11-11 07:15:19: Loss at step 4137: 0.036851461976766586\n",
      "2017-11-11 07:15:21: Loss at step 4138: 0.0368083193898201\n",
      "2017-11-11 07:15:23: Loss at step 4139: 0.03669439256191254\n",
      "2017-11-11 07:15:25: Loss at step 4140: 0.036796122789382935\n",
      "2017-11-11 07:15:27: Loss at step 4141: 0.03686833009123802\n",
      "2017-11-11 07:15:29: Loss at step 4142: 0.03683258220553398\n",
      "2017-11-11 07:15:31: Loss at step 4143: 0.03675825893878937\n",
      "2017-11-11 07:15:34: Loss at step 4144: 0.036824822425842285\n",
      "2017-11-11 07:15:36: Loss at step 4145: 0.03680801019072533\n",
      "2017-11-11 07:15:38: Loss at step 4146: 0.03678165748715401\n",
      "2017-11-11 07:15:40: Loss at step 4147: 0.03681601211428642\n",
      "2017-11-11 07:15:42: Loss at step 4148: 0.03680073097348213\n",
      "2017-11-11 07:15:44: Loss at step 4149: 0.03681498393416405\n",
      "2017-11-11 07:15:46: Loss at step 4150: 0.03674742579460144\n",
      "2017-11-11 07:15:49: Loss at step 4151: 0.036741748452186584\n",
      "2017-11-11 07:15:51: Loss at step 4152: 0.036866120994091034\n",
      "2017-11-11 07:15:53: Loss at step 4153: 0.03674855828285217\n",
      "2017-11-11 07:15:55: Loss at step 4154: 0.036748871207237244\n",
      "2017-11-11 07:15:57: Loss at step 4155: 0.03677397966384888\n",
      "2017-11-11 07:15:59: Loss at step 4156: 0.03690635412931442\n",
      "2017-11-11 07:16:01: Loss at step 4157: 0.03684096783399582\n",
      "2017-11-11 07:16:04: Loss at step 4158: 0.03674374520778656\n",
      "2017-11-11 07:16:06: Loss at step 4159: 0.03682101145386696\n",
      "2017-11-11 07:16:08: Loss at step 4160: 0.036776117980480194\n",
      "2017-11-11 07:16:10: Loss at step 4161: 0.036833230406045914\n",
      "2017-11-11 07:16:12: Loss at step 4162: 0.03682659938931465\n",
      "2017-11-11 07:16:14: Loss at step 4163: 0.03681989014148712\n",
      "2017-11-11 07:16:16: Loss at step 4164: 0.03674189746379852\n",
      "2017-11-11 07:16:19: Loss at step 4165: 0.03682241216301918\n",
      "2017-11-11 07:16:21: Loss at step 4166: 0.03687006235122681\n",
      "2017-11-11 07:16:23: Loss at step 4167: 0.03682290017604828\n",
      "2017-11-11 07:16:25: Loss at step 4168: 0.0368228405714035\n",
      "2017-11-11 07:16:27: Loss at step 4169: 0.03673340007662773\n",
      "2017-11-11 07:16:29: Loss at step 4170: 0.036853667348623276\n",
      "2017-11-11 07:16:32: Loss at step 4171: 0.036793265491724014\n",
      "2017-11-11 07:16:34: Loss at step 4172: 0.036838043481111526\n",
      "2017-11-11 07:16:36: Loss at step 4173: 0.03673218563199043\n",
      "2017-11-11 07:16:38: Loss at step 4174: 0.03686158359050751\n",
      "2017-11-11 07:16:40: Loss at step 4175: 0.03678127005696297\n",
      "2017-11-11 07:16:42: Loss at step 4176: 0.03676733747124672\n",
      "2017-11-11 07:16:44: Loss at step 4177: 0.03679579496383667\n",
      "2017-11-11 07:16:46: Loss at step 4178: 0.03687925636768341\n",
      "2017-11-11 07:16:49: Loss at step 4179: 0.03683885931968689\n",
      "2017-11-11 07:16:51: Loss at step 4180: 0.03677356243133545\n",
      "2017-11-11 07:16:53: Loss at step 4181: 0.03691842779517174\n",
      "2017-11-11 07:16:55: Loss at step 4182: 0.03680163249373436\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-11-11 07:16:57: Loss at step 4183: 0.03676663711667061\n",
      "2017-11-11 07:16:59: Loss at step 4184: 0.036852363497018814\n",
      "2017-11-11 07:17:01: Loss at step 4185: 0.03685683012008667\n",
      "2017-11-11 07:17:04: Loss at step 4186: 0.0368259996175766\n",
      "2017-11-11 07:17:06: Loss at step 4187: 0.03690797835588455\n",
      "2017-11-11 07:17:08: Loss at step 4188: 0.03691825270652771\n",
      "2017-11-11 07:17:10: Loss at step 4189: 0.036797668784856796\n",
      "2017-11-11 07:17:12: Loss at step 4190: 0.03681565448641777\n",
      "2017-11-11 07:17:14: Loss at step 4191: 0.036838188767433167\n",
      "2017-11-11 07:17:16: Loss at step 4192: 0.03677576780319214\n",
      "2017-11-11 07:17:18: Loss at step 4193: 0.03683064132928848\n",
      "2017-11-11 07:17:21: Loss at step 4194: 0.036912817507982254\n",
      "2017-11-11 07:17:23: Loss at step 4195: 0.03689521923661232\n",
      "2017-11-11 07:17:25: Loss at step 4196: 0.03682512789964676\n",
      "2017-11-11 07:17:27: Loss at step 4197: 0.03688908740878105\n",
      "2017-11-11 07:17:29: Loss at step 4198: 0.03683195635676384\n",
      "2017-11-11 07:17:31: Loss at step 4199: 0.03686053305864334\n",
      "2017-11-11 07:17:34: Loss at step 4200: 0.03694179654121399\n",
      "2017-11-11 07:17:36: Loss at step 4201: 0.03687143698334694\n",
      "2017-11-11 07:17:38: Loss at step 4202: 0.03679376095533371\n",
      "2017-11-11 07:17:40: Loss at step 4203: 0.03670787438750267\n",
      "2017-11-11 07:17:42: Loss at step 4204: 0.03689839318394661\n",
      "2017-11-11 07:17:44: Loss at step 4205: 0.03683396428823471\n",
      "2017-11-11 07:17:46: Loss at step 4206: 0.036826372146606445\n",
      "2017-11-11 07:17:49: Loss at step 4207: 0.0369204543530941\n",
      "2017-11-11 07:17:51: Loss at step 4208: 0.03691231831908226\n",
      "2017-11-11 07:17:53: Loss at step 4209: 0.03693731874227524\n",
      "2017-11-11 07:17:55: Loss at step 4210: 0.036795031279325485\n",
      "2017-11-11 07:17:57: Loss at step 4211: 0.03682461008429527\n",
      "2017-11-11 07:17:59: Loss at step 4212: 0.0368572436273098\n",
      "2017-11-11 07:18:01: Loss at step 4213: 0.036819152534008026\n",
      "2017-11-11 07:18:03: Loss at step 4214: 0.036751359701156616\n",
      "2017-11-11 07:18:06: Loss at step 4215: 0.036876678466796875\n",
      "2017-11-11 07:18:08: Loss at step 4216: 0.036866456270217896\n",
      "2017-11-11 07:18:10: Loss at step 4217: 0.03675253689289093\n",
      "2017-11-11 07:18:12: Loss at step 4218: 0.036740269511938095\n",
      "2017-11-11 07:18:14: Loss at step 4219: 0.03681551665067673\n",
      "2017-11-11 07:18:16: Loss at step 4220: 0.036775920540094376\n",
      "2017-11-11 07:18:18: Loss at step 4221: 0.03678615763783455\n",
      "2017-11-11 07:18:21: Loss at step 4222: 0.03682399541139603\n",
      "2017-11-11 07:18:23: Loss at step 4223: 0.03682522475719452\n",
      "2017-11-11 07:18:25: Loss at step 4224: 0.03680655360221863\n",
      "2017-11-11 07:18:27: Loss at step 4225: 0.03679550811648369\n",
      "2017-11-11 07:18:29: Loss at step 4226: 0.03686816990375519\n",
      "2017-11-11 07:18:31: Loss at step 4227: 0.036746785044670105\n",
      "2017-11-11 07:18:34: Loss at step 4228: 0.0367622897028923\n",
      "2017-11-11 07:18:36: Loss at step 4229: 0.03685832396149635\n",
      "2017-11-11 07:18:38: Loss at step 4230: 0.036793891340494156\n",
      "2017-11-11 07:18:40: Loss at step 4231: 0.03674933314323425\n",
      "2017-11-11 07:18:42: Loss at step 4232: 0.03678488731384277\n",
      "2017-11-11 07:18:44: Loss at step 4233: 0.03677218779921532\n",
      "2017-11-11 07:18:46: Loss at step 4234: 0.03682338073849678\n",
      "2017-11-11 07:18:48: Loss at step 4235: 0.03676773980259895\n",
      "2017-11-11 07:18:51: Loss at step 4236: 0.03693268820643425\n",
      "2017-11-11 07:18:53: Loss at step 4237: 0.03679002821445465\n",
      "2017-11-11 07:18:55: Loss at step 4238: 0.036754198372364044\n",
      "2017-11-11 07:18:57: Loss at step 4239: 0.036838091909885406\n",
      "2017-11-11 07:18:59: Loss at step 4240: 0.03679853677749634\n",
      "2017-11-11 07:19:01: Loss at step 4241: 0.03683317080140114\n",
      "2017-11-11 07:19:03: Loss at step 4242: 0.036803849041461945\n",
      "2017-11-11 07:19:06: Loss at step 4243: 0.036738473922014236\n",
      "2017-11-11 07:19:08: Loss at step 4244: 0.03669033572077751\n",
      "2017-11-11 07:19:10: Loss at step 4245: 0.036908943206071854\n",
      "2017-11-11 07:19:12: Loss at step 4246: 0.036793846637010574\n",
      "2017-11-11 07:19:14: Loss at step 4247: 0.036881834268569946\n",
      "2017-11-11 07:19:16: Loss at step 4248: 0.036909643560647964\n",
      "2017-11-11 07:19:18: Loss at step 4249: 0.036759164184331894\n",
      "2017-11-11 07:19:20: Loss at step 4250: 0.03675210103392601\n",
      "2017-11-11 07:19:23: Loss at step 4251: 0.03684687986969948\n",
      "2017-11-11 07:19:25: Loss at step 4252: 0.03690161928534508\n",
      "2017-11-11 07:19:27: Loss at step 4253: 0.036767564713954926\n",
      "2017-11-11 07:19:29: Loss at step 4254: 0.036773569881916046\n",
      "2017-11-11 07:19:31: Loss at step 4255: 0.036763500422239304\n",
      "2017-11-11 07:19:33: Loss at step 4256: 0.036786820739507675\n",
      "2017-11-11 07:19:35: Loss at step 4257: 0.036803651601076126\n",
      "2017-11-11 07:19:38: Loss at step 4258: 0.03681803122162819\n",
      "2017-11-11 07:19:40: Loss at step 4259: 0.03682086989283562\n",
      "2017-11-11 07:19:42: Loss at step 4260: 0.03674693778157234\n",
      "2017-11-11 07:19:44: Loss at step 4261: 0.03686266764998436\n",
      "2017-11-11 07:19:46: Loss at step 4262: 0.03683341294527054\n",
      "2017-11-11 07:19:48: Loss at step 4263: 0.03685967996716499\n",
      "2017-11-11 07:19:50: Loss at step 4264: 0.036783959716558456\n",
      "2017-11-11 07:19:52: Loss at step 4265: 0.03675902634859085\n",
      "2017-11-11 07:19:55: Loss at step 4266: 0.036859214305877686\n",
      "2017-11-11 07:19:57: Loss at step 4267: 0.03674904257059097\n",
      "2017-11-11 07:19:59: Loss at step 4268: 0.03678764030337334\n",
      "2017-11-11 07:20:01: Loss at step 4269: 0.03675450384616852\n",
      "2017-11-11 07:20:03: Loss at step 4270: 0.03677775710821152\n",
      "2017-11-11 07:20:05: Loss at step 4271: 0.03680015355348587\n",
      "2017-11-11 07:20:07: Loss at step 4272: 0.036857835948467255\n",
      "2017-11-11 07:20:10: Loss at step 4273: 0.03685774281620979\n",
      "2017-11-11 07:20:12: Loss at step 4274: 0.0367225706577301\n",
      "2017-11-11 07:20:14: Loss at step 4275: 0.03680508956313133\n",
      "2017-11-11 07:20:16: Loss at step 4276: 0.03684920817613602\n",
      "2017-11-11 07:20:18: Loss at step 4277: 0.03683679923415184\n",
      "2017-11-11 07:20:20: Loss at step 4278: 0.03686690703034401\n",
      "2017-11-11 07:20:22: Loss at step 4279: 0.036820124834775925\n",
      "2017-11-11 07:20:25: Loss at step 4280: 0.03673691302537918\n",
      "2017-11-11 07:20:27: Loss at step 4281: 0.036827459931373596\n",
      "2017-11-11 07:20:29: Loss at step 4282: 0.036730438470840454\n",
      "2017-11-11 07:20:31: Loss at step 4283: 0.03675838187336922\n",
      "2017-11-11 07:20:33: Loss at step 4284: 0.036783307790756226\n",
      "2017-11-11 07:20:35: Loss at step 4285: 0.03682391345500946\n",
      "2017-11-11 07:20:38: Loss at step 4286: 0.0368289016187191\n",
      "2017-11-11 07:20:40: Loss at step 4287: 0.03679792582988739\n",
      "2017-11-11 07:20:42: Loss at step 4288: 0.03685639053583145\n",
      "2017-11-11 07:20:44: Loss at step 4289: 0.03683643415570259\n",
      "2017-11-11 07:20:46: Loss at step 4290: 0.03684685379266739\n",
      "2017-11-11 07:20:48: Loss at step 4291: 0.03679536283016205\n",
      "2017-11-11 07:20:50: Loss at step 4292: 0.03673667088150978\n",
      "2017-11-11 07:20:52: Loss at step 4293: 0.03685750812292099\n",
      "2017-11-11 07:20:55: Loss at step 4294: 0.03677961602807045\n",
      "2017-11-11 07:20:57: Loss at step 4295: 0.03681130334734917\n",
      "2017-11-11 07:20:59: Loss at step 4296: 0.03676815330982208\n",
      "2017-11-11 07:21:01: Loss at step 4297: 0.03690754249691963\n",
      "2017-11-11 07:21:03: Loss at step 4298: 0.03676425665616989\n",
      "2017-11-11 07:21:05: Loss at step 4299: 0.036753807216882706\n",
      "2017-11-11 07:21:08: Loss at step 4300: 0.03679923713207245\n",
      "2017-11-11 07:21:10: Loss at step 4301: 0.03676622360944748\n",
      "2017-11-11 07:21:12: Loss at step 4302: 0.03676537051796913\n",
      "2017-11-11 07:21:14: Loss at step 4303: 0.03683403879404068\n",
      "2017-11-11 07:21:16: Loss at step 4304: 0.0367717482149601\n",
      "2017-11-11 07:21:18: Loss at step 4305: 0.0367937907576561\n",
      "2017-11-11 07:21:20: Loss at step 4306: 0.03676806762814522\n",
      "2017-11-11 07:21:23: Loss at step 4307: 0.03676088526844978\n",
      "2017-11-11 07:21:25: Loss at step 4308: 0.03686961531639099\n",
      "2017-11-11 07:21:27: Loss at step 4309: 0.03688269108533859\n",
      "2017-11-11 07:21:29: Loss at step 4310: 0.03687196224927902\n",
      "2017-11-11 07:21:31: Loss at step 4311: 0.036956787109375\n",
      "2017-11-11 07:21:33: Loss at step 4312: 0.03689686208963394\n",
      "2017-11-11 07:21:35: Loss at step 4313: 0.03681837022304535\n",
      "2017-11-11 07:21:37: Loss at step 4314: 0.036835815757513046\n",
      "2017-11-11 07:21:40: Loss at step 4315: 0.0367923267185688\n",
      "2017-11-11 07:21:42: Loss at step 4316: 0.03681911155581474\n",
      "2017-11-11 07:21:44: Loss at step 4317: 0.03680521994829178\n",
      "2017-11-11 07:21:46: Loss at step 4318: 0.03683413192629814\n",
      "2017-11-11 07:21:48: Loss at step 4319: 0.036884795874357224\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-11-11 07:21:50: Loss at step 4320: 0.03679546341300011\n",
      "2017-11-11 07:21:52: Loss at step 4321: 0.03676209971308708\n",
      "2017-11-11 07:21:54: Loss at step 4322: 0.036793053150177\n",
      "2017-11-11 07:21:57: Loss at step 4323: 0.03677064925432205\n",
      "2017-11-11 07:21:59: Loss at step 4324: 0.036790989339351654\n",
      "2017-11-11 07:22:01: Loss at step 4325: 0.036791060119867325\n",
      "2017-11-11 07:22:03: Loss at step 4326: 0.03679526224732399\n",
      "2017-11-11 07:22:05: Loss at step 4327: 0.03674650192260742\n",
      "2017-11-11 07:22:07: Loss at step 4328: 0.03673017770051956\n",
      "2017-11-11 07:22:09: Loss at step 4329: 0.0368083119392395\n",
      "2017-11-11 07:22:12: Loss at step 4330: 0.03680064529180527\n",
      "2017-11-11 07:22:14: Loss at step 4331: 0.03681934252381325\n",
      "2017-11-11 07:22:16: Loss at step 4332: 0.03682645410299301\n",
      "2017-11-11 07:22:18: Loss at step 4333: 0.03687991574406624\n",
      "2017-11-11 07:22:20: Loss at step 4334: 0.036810535937547684\n",
      "2017-11-11 07:22:22: Loss at step 4335: 0.03684905543923378\n",
      "2017-11-11 07:22:24: Loss at step 4336: 0.03681160882115364\n",
      "2017-11-11 07:22:27: Loss at step 4337: 0.03687295690178871\n",
      "2017-11-11 07:22:29: Loss at step 4338: 0.03680884465575218\n",
      "2017-11-11 07:22:31: Loss at step 4339: 0.03685391694307327\n",
      "2017-11-11 07:22:33: Loss at step 4340: 0.03681831806898117\n",
      "2017-11-11 07:22:35: Loss at step 4341: 0.03679164499044418\n",
      "2017-11-11 07:22:37: Loss at step 4342: 0.036680515855550766\n",
      "2017-11-11 07:22:39: Loss at step 4343: 0.0367419496178627\n",
      "2017-11-11 07:22:42: Loss at step 4344: 0.03680085390806198\n",
      "2017-11-11 07:22:44: Loss at step 4345: 0.03681279346346855\n",
      "2017-11-11 07:22:46: Loss at step 4346: 0.036767348647117615\n",
      "2017-11-11 07:22:48: Loss at step 4347: 0.036824584007263184\n",
      "2017-11-11 07:22:50: Loss at step 4348: 0.03681830316781998\n",
      "2017-11-11 07:22:52: Loss at step 4349: 0.036813221871852875\n",
      "2017-11-11 07:22:54: Loss at step 4350: 0.03677130863070488\n",
      "2017-11-11 07:22:57: Loss at step 4351: 0.03674525022506714\n",
      "2017-11-11 07:22:59: Loss at step 4352: 0.03684651479125023\n",
      "2017-11-11 07:23:01: Loss at step 4353: 0.03677339106798172\n",
      "2017-11-11 07:23:03: Loss at step 4354: 0.03677525743842125\n",
      "2017-11-11 07:23:05: Loss at step 4355: 0.03673625737428665\n",
      "2017-11-11 07:23:07: Loss at step 4356: 0.03685680031776428\n",
      "2017-11-11 07:23:09: Loss at step 4357: 0.03678242862224579\n",
      "2017-11-11 07:23:11: Loss at step 4358: 0.036782555282115936\n",
      "2017-11-11 07:23:14: Loss at step 4359: 0.03679781034588814\n",
      "2017-11-11 07:23:16: Loss at step 4360: 0.036802858114242554\n",
      "2017-11-11 07:23:18: Loss at step 4361: 0.036775194108486176\n",
      "2017-11-11 07:23:20: Loss at step 4362: 0.0368090383708477\n",
      "2017-11-11 07:23:22: Loss at step 4363: 0.03672916442155838\n",
      "2017-11-11 07:23:24: Loss at step 4364: 0.03672625869512558\n",
      "2017-11-11 07:23:26: Loss at step 4365: 0.036780547350645065\n",
      "2017-11-11 07:23:29: Loss at step 4366: 0.036771342158317566\n",
      "2017-11-11 07:23:31: Loss at step 4367: 0.03679315000772476\n",
      "2017-11-11 07:23:33: Loss at step 4368: 0.03678136691451073\n",
      "2017-11-11 07:23:35: Loss at step 4369: 0.0367247611284256\n",
      "2017-11-11 07:23:37: Loss at step 4370: 0.03678042069077492\n",
      "2017-11-11 07:23:39: Loss at step 4371: 0.03678488731384277\n",
      "2017-11-11 07:23:41: Loss at step 4372: 0.03676086291670799\n",
      "2017-11-11 07:23:44: Loss at step 4373: 0.03675642982125282\n",
      "2017-11-11 07:23:46: Loss at step 4374: 0.03677615523338318\n",
      "2017-11-11 07:23:48: Loss at step 4375: 0.03681587055325508\n",
      "2017-11-11 07:23:50: Loss at step 4376: 0.03677171468734741\n",
      "2017-11-11 07:23:52: Loss at step 4377: 0.036863941699266434\n",
      "2017-11-11 07:23:54: Loss at step 4378: 0.03683161735534668\n",
      "2017-11-11 07:23:56: Loss at step 4379: 0.0367378294467926\n",
      "2017-11-11 07:23:59: Loss at step 4380: 0.03678501769900322\n",
      "2017-11-11 07:24:01: Loss at step 4381: 0.03683125972747803\n",
      "2017-11-11 07:24:03: Loss at step 4382: 0.03678396716713905\n",
      "2017-11-11 07:24:05: Loss at step 4383: 0.03689057007431984\n",
      "2017-11-11 07:24:07: Loss at step 4384: 0.036869581788778305\n",
      "2017-11-11 07:24:09: Loss at step 4385: 0.03683962672948837\n",
      "2017-11-11 07:24:11: Loss at step 4386: 0.0368826724588871\n",
      "2017-11-11 07:24:14: Loss at step 4387: 0.03672734275460243\n",
      "2017-11-11 07:24:16: Loss at step 4388: 0.036773134022951126\n",
      "2017-11-11 07:24:18: Loss at step 4389: 0.03683367371559143\n",
      "2017-11-11 07:24:20: Loss at step 4390: 0.036881666630506516\n",
      "2017-11-11 07:24:22: Loss at step 4391: 0.03679154813289642\n",
      "2017-11-11 07:24:24: Loss at step 4392: 0.03678061068058014\n",
      "2017-11-11 07:24:26: Loss at step 4393: 0.03675517067313194\n",
      "2017-11-11 07:24:29: Loss at step 4394: 0.03676777333021164\n",
      "2017-11-11 07:24:31: Loss at step 4395: 0.036755941808223724\n",
      "2017-11-11 07:24:33: Loss at step 4396: 0.03674450144171715\n",
      "2017-11-11 07:24:35: Loss at step 4397: 0.036745600402355194\n",
      "2017-11-11 07:24:37: Loss at step 4398: 0.036805689334869385\n",
      "2017-11-11 07:24:39: Loss at step 4399: 0.03673265874385834\n",
      "2017-11-11 07:24:41: Loss at step 4400: 0.03685620427131653\n",
      "2017-11-11 07:24:44: Loss at step 4401: 0.036839574575424194\n",
      "2017-11-11 07:24:46: Loss at step 4402: 0.03689795359969139\n",
      "2017-11-11 07:24:48: Loss at step 4403: 0.03679001331329346\n",
      "2017-11-11 07:24:50: Loss at step 4404: 0.03675641492009163\n",
      "2017-11-11 07:24:52: Loss at step 4405: 0.036780934780836105\n",
      "2017-11-11 07:24:54: Loss at step 4406: 0.03682159632444382\n",
      "2017-11-11 07:24:56: Loss at step 4407: 0.036788005381822586\n",
      "2017-11-11 07:24:59: Loss at step 4408: 0.03687889501452446\n",
      "2017-11-11 07:25:01: Loss at step 4409: 0.03685813024640083\n",
      "2017-11-11 07:25:03: Loss at step 4410: 0.03680935502052307\n",
      "2017-11-11 07:25:05: Loss at step 4411: 0.03688756749033928\n",
      "2017-11-11 07:25:07: Loss at step 4412: 0.03687174618244171\n",
      "2017-11-11 07:25:09: Loss at step 4413: 0.03683125600218773\n",
      "2017-11-11 07:25:11: Loss at step 4414: 0.03679775446653366\n",
      "2017-11-11 07:25:13: Loss at step 4415: 0.036826856434345245\n",
      "2017-11-11 07:25:16: Loss at step 4416: 0.036789752542972565\n",
      "2017-11-11 07:25:18: Loss at step 4417: 0.03687926009297371\n",
      "2017-11-11 07:25:20: Loss at step 4418: 0.03683334216475487\n",
      "2017-11-11 07:25:22: Loss at step 4419: 0.03676890209317207\n",
      "2017-11-11 07:25:24: Loss at step 4420: 0.036825310438871384\n",
      "2017-11-11 07:25:26: Loss at step 4421: 0.03692205250263214\n",
      "2017-11-11 07:25:28: Loss at step 4422: 0.03688439354300499\n",
      "2017-11-11 07:25:31: Loss at step 4423: 0.036842308938503265\n",
      "2017-11-11 07:25:33: Loss at step 4424: 0.036756303161382675\n",
      "2017-11-11 07:25:35: Loss at step 4425: 0.036892689764499664\n",
      "2017-11-11 07:25:37: Loss at step 4426: 0.03676602244377136\n",
      "2017-11-11 07:25:39: Loss at step 4427: 0.03674869239330292\n",
      "2017-11-11 07:25:41: Loss at step 4428: 0.03676148131489754\n",
      "2017-11-11 07:25:43: Loss at step 4429: 0.0367828905582428\n",
      "2017-11-11 07:25:45: Loss at step 4430: 0.036791395395994186\n",
      "2017-11-11 07:25:48: Loss at step 4431: 0.03681793063879013\n",
      "2017-11-11 07:25:50: Loss at step 4432: 0.03685919940471649\n",
      "2017-11-11 07:25:52: Loss at step 4433: 0.036776911467313766\n",
      "2017-11-11 07:25:54: Loss at step 4434: 0.03683154657483101\n",
      "2017-11-11 07:25:56: Loss at step 4435: 0.0368044450879097\n",
      "2017-11-11 07:25:58: Loss at step 4436: 0.0367821604013443\n",
      "2017-11-11 07:26:00: Loss at step 4437: 0.03682640939950943\n",
      "2017-11-11 07:26:03: Loss at step 4438: 0.036828845739364624\n",
      "2017-11-11 07:26:05: Loss at step 4439: 0.036694902926683426\n",
      "2017-11-11 07:26:07: Loss at step 4440: 0.03683741018176079\n",
      "2017-11-11 07:26:09: Loss at step 4441: 0.03672904148697853\n",
      "2017-11-11 07:26:11: Loss at step 4442: 0.036740247160196304\n",
      "2017-11-11 07:26:13: Loss at step 4443: 0.03682463988661766\n",
      "2017-11-11 07:26:15: Loss at step 4444: 0.03683207556605339\n",
      "2017-11-11 07:26:18: Loss at step 4445: 0.03674488514661789\n",
      "2017-11-11 07:26:20: Loss at step 4446: 0.03676970675587654\n",
      "2017-11-11 07:26:22: Loss at step 4447: 0.03682411462068558\n",
      "2017-11-11 07:26:24: Loss at step 4448: 0.03685205802321434\n",
      "2017-11-11 07:26:26: Loss at step 4449: 0.036754533648490906\n",
      "2017-11-11 07:26:28: Loss at step 4450: 0.03682751581072807\n",
      "2017-11-11 07:26:30: Loss at step 4451: 0.03677954152226448\n",
      "2017-11-11 07:26:33: Loss at step 4452: 0.036840133368968964\n",
      "2017-11-11 07:26:35: Loss at step 4453: 0.036911740899086\n",
      "2017-11-11 07:26:37: Loss at step 4454: 0.036793019622564316\n",
      "2017-11-11 07:26:39: Loss at step 4455: 0.036857541650533676\n",
      "2017-11-11 07:26:41: Loss at step 4456: 0.03684672713279724\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-11-11 07:26:43: Loss at step 4457: 0.036934178322553635\n",
      "2017-11-11 07:26:45: Loss at step 4458: 0.036819156259298325\n",
      "2017-11-11 07:26:48: Loss at step 4459: 0.03684905171394348\n",
      "2017-11-11 07:26:50: Loss at step 4460: 0.03687296807765961\n",
      "2017-11-11 07:26:52: Loss at step 4461: 0.03674305975437164\n",
      "2017-11-11 07:26:54: Loss at step 4462: 0.03685790300369263\n",
      "2017-11-11 07:26:56: Loss at step 4463: 0.03679955005645752\n",
      "2017-11-11 07:26:58: Loss at step 4464: 0.03679758310317993\n",
      "2017-11-11 07:27:00: Loss at step 4465: 0.036778297275304794\n",
      "2017-11-11 07:27:03: Loss at step 4466: 0.036836203187704086\n",
      "2017-11-11 07:27:05: Loss at step 4467: 0.03690183162689209\n",
      "2017-11-11 07:27:07: Loss at step 4468: 0.03683513030409813\n",
      "2017-11-11 07:27:09: Loss at step 4469: 0.03676626831293106\n",
      "2017-11-11 07:27:11: Loss at step 4470: 0.03682905435562134\n",
      "2017-11-11 07:27:13: Loss at step 4471: 0.03675508871674538\n",
      "2017-11-11 07:27:15: Loss at step 4472: 0.03683052211999893\n",
      "2017-11-11 07:27:17: Loss at step 4473: 0.036891065537929535\n",
      "2017-11-11 07:27:20: Loss at step 4474: 0.036843739449977875\n",
      "2017-11-11 07:27:22: Loss at step 4475: 0.036784544587135315\n",
      "2017-11-11 07:27:24: Loss at step 4476: 0.03672939911484718\n",
      "2017-11-11 07:27:26: Loss at step 4477: 0.03681236132979393\n",
      "2017-11-11 07:27:28: Loss at step 4478: 0.03689223527908325\n",
      "2017-11-11 07:27:30: Loss at step 4479: 0.036821283400058746\n",
      "2017-11-11 07:27:32: Loss at step 4480: 0.03681746870279312\n",
      "2017-11-11 07:27:35: Loss at step 4481: 0.036816637963056564\n",
      "2017-11-11 07:27:37: Loss at step 4482: 0.03682860732078552\n",
      "2017-11-11 07:27:39: Loss at step 4483: 0.03691425547003746\n",
      "2017-11-11 07:27:41: Loss at step 4484: 0.036781858652830124\n",
      "2017-11-11 07:27:43: Loss at step 4485: 0.03685220330953598\n",
      "2017-11-11 07:27:45: Loss at step 4486: 0.03668944537639618\n",
      "2017-11-11 07:27:47: Loss at step 4487: 0.03677685558795929\n",
      "2017-11-11 07:27:50: Loss at step 4488: 0.03673253953456879\n",
      "2017-11-11 07:27:52: Loss at step 4489: 0.03687901794910431\n",
      "2017-11-11 07:27:54: Loss at step 4490: 0.03685157373547554\n",
      "2017-11-11 07:27:56: Loss at step 4491: 0.03684329241514206\n",
      "2017-11-11 07:27:58: Loss at step 4492: 0.03680434450507164\n",
      "2017-11-11 07:28:00: Loss at step 4493: 0.03683095797896385\n",
      "2017-11-11 07:28:02: Loss at step 4494: 0.03688895329833031\n",
      "2017-11-11 07:28:04: Loss at step 4495: 0.03680383414030075\n",
      "2017-11-11 07:28:07: Loss at step 4496: 0.03685528039932251\n",
      "2017-11-11 07:28:09: Loss at step 4497: 0.036920152604579926\n",
      "2017-11-11 07:28:11: Loss at step 4498: 0.03685646876692772\n",
      "2017-11-11 07:28:13: Loss at step 4499: 0.03682919591665268\n",
      "2017-11-11 07:28:15: Loss at step 4500: 0.036931268870830536\n",
      "2017-11-11 07:28:17: Loss at step 4501: 0.036881040781736374\n",
      "2017-11-11 07:28:19: Loss at step 4502: 0.03687600418925285\n",
      "2017-11-11 07:28:22: Loss at step 4503: 0.03692426159977913\n",
      "2017-11-11 07:28:24: Loss at step 4504: 0.03686162084341049\n",
      "2017-11-11 07:28:26: Loss at step 4505: 0.03692115470767021\n",
      "2017-11-11 07:28:28: Loss at step 4506: 0.036857057362794876\n",
      "2017-11-11 07:28:30: Loss at step 4507: 0.03696935623884201\n",
      "2017-11-11 07:28:32: Loss at step 4508: 0.0369100384414196\n",
      "2017-11-11 07:28:35: Loss at step 4509: 0.036891888827085495\n",
      "2017-11-11 07:28:37: Loss at step 4510: 0.03694099932909012\n",
      "2017-11-11 07:28:39: Loss at step 4511: 0.03710529953241348\n",
      "2017-11-11 07:28:41: Loss at step 4512: 0.03703586384654045\n",
      "2017-11-11 07:28:43: Loss at step 4513: 0.036967478692531586\n",
      "2017-11-11 07:28:45: Loss at step 4514: 0.03703967481851578\n",
      "2017-11-11 07:28:47: Loss at step 4515: 0.037043023854494095\n",
      "2017-11-11 07:28:49: Loss at step 4516: 0.03697999194264412\n",
      "2017-11-11 07:28:52: Loss at step 4517: 0.037006184458732605\n",
      "2017-11-11 07:28:54: Loss at step 4518: 0.03698175773024559\n",
      "2017-11-11 07:28:56: Loss at step 4519: 0.03686180338263512\n",
      "2017-11-11 07:28:58: Loss at step 4520: 0.03702166676521301\n",
      "2017-11-11 07:29:00: Loss at step 4521: 0.03698767349123955\n",
      "2017-11-11 07:29:02: Loss at step 4522: 0.0368880070745945\n",
      "2017-11-11 07:29:04: Loss at step 4523: 0.03692387416958809\n",
      "2017-11-11 07:29:07: Loss at step 4524: 0.03694656491279602\n",
      "2017-11-11 07:29:09: Loss at step 4525: 0.03689957410097122\n",
      "2017-11-11 07:29:11: Loss at step 4526: 0.036838408559560776\n",
      "2017-11-11 07:29:13: Loss at step 4527: 0.03690813109278679\n",
      "2017-11-11 07:29:15: Loss at step 4528: 0.036805033683776855\n",
      "2017-11-11 07:29:17: Loss at step 4529: 0.036844585090875626\n",
      "2017-11-11 07:29:19: Loss at step 4530: 0.03691922500729561\n",
      "2017-11-11 07:29:22: Loss at step 4531: 0.03682173416018486\n",
      "2017-11-11 07:29:24: Loss at step 4532: 0.03684462979435921\n",
      "2017-11-11 07:29:26: Loss at step 4533: 0.03689516708254814\n",
      "2017-11-11 07:29:28: Loss at step 4534: 0.03679018095135689\n",
      "2017-11-11 07:29:30: Loss at step 4535: 0.036832500249147415\n",
      "2017-11-11 07:29:32: Loss at step 4536: 0.036805883049964905\n",
      "2017-11-11 07:29:34: Loss at step 4537: 0.036767151206731796\n",
      "2017-11-11 07:29:37: Loss at step 4538: 0.036781784147024155\n",
      "2017-11-11 07:29:39: Loss at step 4539: 0.03677268698811531\n",
      "2017-11-11 07:29:41: Loss at step 4540: 0.03681802377104759\n",
      "2017-11-11 07:29:43: Loss at step 4541: 0.03674384951591492\n",
      "2017-11-11 07:29:45: Loss at step 4542: 0.03680247813463211\n",
      "2017-11-11 07:29:47: Loss at step 4543: 0.03673939406871796\n",
      "2017-11-11 07:29:49: Loss at step 4544: 0.036823298782110214\n",
      "2017-11-11 07:29:51: Loss at step 4545: 0.03670124709606171\n",
      "2017-11-11 07:29:54: Loss at step 4546: 0.03680679574608803\n",
      "2017-11-11 07:29:56: Loss at step 4547: 0.036844488233327866\n",
      "2017-11-11 07:29:58: Loss at step 4548: 0.036775633692741394\n",
      "2017-11-11 07:30:00: Loss at step 4549: 0.03680657967925072\n",
      "2017-11-11 07:30:02: Loss at step 4550: 0.03679024428129196\n",
      "2017-11-11 07:30:04: Loss at step 4551: 0.03685791417956352\n",
      "2017-11-11 07:30:06: Loss at step 4552: 0.036773212254047394\n",
      "2017-11-11 07:30:09: Loss at step 4553: 0.03684864565730095\n",
      "2017-11-11 07:30:11: Loss at step 4554: 0.03677528724074364\n",
      "2017-11-11 07:30:13: Loss at step 4555: 0.03672725707292557\n",
      "2017-11-11 07:30:15: Loss at step 4556: 0.03682407736778259\n",
      "2017-11-11 07:30:17: Loss at step 4557: 0.03692014142870903\n",
      "2017-11-11 07:30:19: Loss at step 4558: 0.03683355078101158\n",
      "2017-11-11 07:30:21: Loss at step 4559: 0.03670544549822807\n",
      "2017-11-11 07:30:24: Loss at step 4560: 0.0367460772395134\n",
      "2017-11-11 07:30:26: Loss at step 4561: 0.03686021640896797\n",
      "2017-11-11 07:30:28: Loss at step 4562: 0.03676055371761322\n",
      "2017-11-11 07:30:30: Loss at step 4563: 0.03670526668429375\n",
      "2017-11-11 07:30:32: Loss at step 4564: 0.036732856184244156\n",
      "2017-11-11 07:30:34: Loss at step 4565: 0.03679944574832916\n",
      "2017-11-11 07:30:37: Loss at step 4566: 0.036841485649347305\n",
      "2017-11-11 07:30:39: Loss at step 4567: 0.03685867041349411\n",
      "2017-11-11 07:30:41: Loss at step 4568: 0.03683316707611084\n",
      "2017-11-11 07:30:43: Loss at step 4569: 0.036846257746219635\n",
      "2017-11-11 07:30:45: Loss at step 4570: 0.036794018000364304\n",
      "2017-11-11 07:30:47: Loss at step 4571: 0.03676682710647583\n",
      "2017-11-11 07:30:49: Loss at step 4572: 0.03678756579756737\n",
      "2017-11-11 07:30:51: Loss at step 4573: 0.03681620582938194\n",
      "2017-11-11 07:30:54: Loss at step 4574: 0.036806270480155945\n",
      "2017-11-11 07:30:56: Loss at step 4575: 0.036809291690588\n",
      "2017-11-11 07:30:58: Loss at step 4576: 0.03678475320339203\n",
      "2017-11-11 07:31:00: Loss at step 4577: 0.03686489909887314\n",
      "2017-11-11 07:31:02: Loss at step 4578: 0.03684133291244507\n",
      "2017-11-11 07:31:04: Loss at step 4579: 0.036766666918992996\n",
      "2017-11-11 07:31:06: Loss at step 4580: 0.03679237142205238\n",
      "2017-11-11 07:31:09: Loss at step 4581: 0.03680643439292908\n",
      "2017-11-11 07:31:11: Loss at step 4582: 0.036786098033189774\n",
      "2017-11-11 07:31:13: Loss at step 4583: 0.03683089092373848\n",
      "2017-11-11 07:31:15: Loss at step 4584: 0.036816176027059555\n",
      "2017-11-11 07:31:17: Loss at step 4585: 0.03676057606935501\n",
      "2017-11-11 07:31:19: Loss at step 4586: 0.03679724782705307\n",
      "2017-11-11 07:31:21: Loss at step 4587: 0.03682297095656395\n",
      "2017-11-11 07:31:24: Loss at step 4588: 0.036874376237392426\n",
      "2017-11-11 07:31:26: Loss at step 4589: 0.036852069199085236\n",
      "2017-11-11 07:31:28: Loss at step 4590: 0.03677237033843994\n",
      "2017-11-11 07:31:30: Loss at step 4591: 0.03676483407616615\n",
      "2017-11-11 07:31:32: Loss at step 4592: 0.036796581000089645\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-11-11 07:31:34: Loss at step 4593: 0.03677451238036156\n",
      "2017-11-11 07:31:36: Loss at step 4594: 0.03673306107521057\n",
      "2017-11-11 07:31:39: Loss at step 4595: 0.036736443638801575\n",
      "2017-11-11 07:31:41: Loss at step 4596: 0.036779116839170456\n",
      "2017-11-11 07:31:43: Loss at step 4597: 0.03668849170207977\n",
      "2017-11-11 07:31:45: Loss at step 4598: 0.0368763767182827\n",
      "2017-11-11 07:31:47: Loss at step 4599: 0.036811549216508865\n",
      "2017-11-11 07:31:49: Loss at step 4600: 0.03674056753516197\n",
      "2017-11-11 07:31:51: Loss at step 4601: 0.03679642826318741\n",
      "2017-11-11 07:31:53: Loss at step 4602: 0.03677472472190857\n",
      "2017-11-11 07:31:56: Loss at step 4603: 0.03678395226597786\n",
      "2017-11-11 07:31:58: Loss at step 4604: 0.036830704659223557\n",
      "2017-11-11 07:32:00: Loss at step 4605: 0.03686445951461792\n",
      "2017-11-11 07:32:02: Loss at step 4606: 0.03686058893799782\n",
      "2017-11-11 07:32:04: Loss at step 4607: 0.036823224276304245\n",
      "2017-11-11 07:32:06: Loss at step 4608: 0.036815814673900604\n",
      "2017-11-11 07:32:08: Loss at step 4609: 0.03678331896662712\n",
      "2017-11-11 07:32:11: Loss at step 4610: 0.03683320805430412\n",
      "2017-11-11 07:32:13: Loss at step 4611: 0.03684650734066963\n",
      "2017-11-11 07:32:15: Loss at step 4612: 0.03672679886221886\n",
      "2017-11-11 07:32:17: Loss at step 4613: 0.03672538325190544\n",
      "2017-11-11 07:32:19: Loss at step 4614: 0.03673470392823219\n",
      "2017-11-11 07:32:21: Loss at step 4615: 0.03673567622900009\n",
      "2017-11-11 07:32:23: Loss at step 4616: 0.0368005707859993\n",
      "2017-11-11 07:32:26: Loss at step 4617: 0.0367860421538353\n",
      "2017-11-11 07:32:28: Loss at step 4618: 0.03680022060871124\n",
      "2017-11-11 07:32:30: Loss at step 4619: 0.03674859553575516\n",
      "2017-11-11 07:32:32: Loss at step 4620: 0.03673188388347626\n",
      "2017-11-11 07:32:34: Loss at step 4621: 0.03686801716685295\n",
      "2017-11-11 07:32:36: Loss at step 4622: 0.03674745187163353\n",
      "2017-11-11 07:32:38: Loss at step 4623: 0.036771804094314575\n",
      "2017-11-11 07:32:41: Loss at step 4624: 0.03672240301966667\n",
      "2017-11-11 07:32:43: Loss at step 4625: 0.036815330386161804\n",
      "2017-11-11 07:32:45: Loss at step 4626: 0.036822445690631866\n",
      "2017-11-11 07:32:47: Loss at step 4627: 0.036706067621707916\n",
      "2017-11-11 07:32:49: Loss at step 4628: 0.03675789758563042\n",
      "2017-11-11 07:32:51: Loss at step 4629: 0.036832354962825775\n",
      "2017-11-11 07:32:53: Loss at step 4630: 0.036837153136730194\n",
      "2017-11-11 07:32:56: Loss at step 4631: 0.03687000647187233\n",
      "2017-11-11 07:32:58: Loss at step 4632: 0.036692991852760315\n",
      "2017-11-11 07:33:00: Loss at step 4633: 0.03672884404659271\n",
      "2017-11-11 07:33:02: Loss at step 4634: 0.036732789129018784\n",
      "2017-11-11 07:33:04: Loss at step 4635: 0.03679133951663971\n",
      "2017-11-11 07:33:06: Loss at step 4636: 0.03680849447846413\n",
      "2017-11-11 07:33:08: Loss at step 4637: 0.036786384880542755\n",
      "2017-11-11 07:33:11: Loss at step 4638: 0.03676290810108185\n",
      "2017-11-11 07:33:13: Loss at step 4639: 0.03673342242836952\n",
      "2017-11-11 07:33:15: Loss at step 4640: 0.03679657354950905\n",
      "2017-11-11 07:33:17: Loss at step 4641: 0.03672686964273453\n",
      "2017-11-11 07:33:19: Loss at step 4642: 0.0367649607360363\n",
      "2017-11-11 07:33:21: Loss at step 4643: 0.03689318895339966\n",
      "2017-11-11 07:33:23: Loss at step 4644: 0.036766260862350464\n",
      "2017-11-11 07:33:26: Loss at step 4645: 0.03679030016064644\n",
      "2017-11-11 07:33:28: Loss at step 4646: 0.03675997257232666\n",
      "2017-11-11 07:33:30: Loss at step 4647: 0.036725565791130066\n",
      "2017-11-11 07:33:32: Loss at step 4648: 0.036824967712163925\n",
      "2017-11-11 07:33:34: Loss at step 4649: 0.036809783428907394\n",
      "2017-11-11 07:33:36: Loss at step 4650: 0.03679046034812927\n",
      "2017-11-11 07:33:38: Loss at step 4651: 0.03673798218369484\n",
      "2017-11-11 07:33:41: Loss at step 4652: 0.03688023239374161\n",
      "2017-11-11 07:33:43: Loss at step 4653: 0.0368182510137558\n",
      "2017-11-11 07:33:45: Loss at step 4654: 0.03680184856057167\n",
      "2017-11-11 07:33:47: Loss at step 4655: 0.03675193339586258\n",
      "2017-11-11 07:33:49: Loss at step 4656: 0.036847203969955444\n",
      "2017-11-11 07:33:51: Loss at step 4657: 0.03680490702390671\n",
      "2017-11-11 07:33:53: Loss at step 4658: 0.03684047982096672\n",
      "2017-11-11 07:33:55: Loss at step 4659: 0.03674933686852455\n",
      "2017-11-11 07:33:58: Loss at step 4660: 0.03675760328769684\n",
      "2017-11-11 07:34:00: Loss at step 4661: 0.036769475787878036\n",
      "2017-11-11 07:34:02: Loss at step 4662: 0.036936547607183456\n",
      "2017-11-11 07:34:04: Loss at step 4663: 0.03676503151655197\n",
      "2017-11-11 07:34:06: Loss at step 4664: 0.036752354353666306\n",
      "2017-11-11 07:34:08: Loss at step 4665: 0.03671405836939812\n",
      "2017-11-11 07:34:10: Loss at step 4666: 0.03675772622227669\n",
      "2017-11-11 07:34:13: Loss at step 4667: 0.036898985505104065\n",
      "2017-11-11 07:34:15: Loss at step 4668: 0.03679422289133072\n",
      "2017-11-11 07:34:17: Loss at step 4669: 0.03684886544942856\n",
      "2017-11-11 07:34:19: Loss at step 4670: 0.036824412643909454\n",
      "2017-11-11 07:34:21: Loss at step 4671: 0.03681602329015732\n",
      "2017-11-11 07:34:23: Loss at step 4672: 0.0368223637342453\n",
      "2017-11-11 07:34:25: Loss at step 4673: 0.03678765147924423\n",
      "2017-11-11 07:34:28: Loss at step 4674: 0.03686380758881569\n",
      "2017-11-11 07:34:30: Loss at step 4675: 0.03673924505710602\n",
      "2017-11-11 07:34:32: Loss at step 4676: 0.03679455444216728\n",
      "2017-11-11 07:34:34: Loss at step 4677: 0.03685350343585014\n",
      "2017-11-11 07:34:36: Loss at step 4678: 0.036795295774936676\n",
      "2017-11-11 07:34:38: Loss at step 4679: 0.036903563886880875\n",
      "2017-11-11 07:34:40: Loss at step 4680: 0.036857377737760544\n",
      "2017-11-11 07:34:43: Loss at step 4681: 0.03681640326976776\n",
      "2017-11-11 07:34:45: Loss at step 4682: 0.03688922896981239\n",
      "2017-11-11 07:34:47: Loss at step 4683: 0.03679797425866127\n",
      "2017-11-11 07:34:49: Loss at step 4684: 0.03675626218318939\n",
      "2017-11-11 07:34:51: Loss at step 4685: 0.03676597401499748\n",
      "2017-11-11 07:34:53: Loss at step 4686: 0.03678150475025177\n",
      "2017-11-11 07:34:55: Loss at step 4687: 0.036944035440683365\n",
      "2017-11-11 07:34:58: Loss at step 4688: 0.03678670525550842\n",
      "2017-11-11 07:35:00: Loss at step 4689: 0.036787357181310654\n",
      "2017-11-11 07:35:02: Loss at step 4690: 0.03678423538804054\n",
      "2017-11-11 07:35:04: Loss at step 4691: 0.03675391525030136\n",
      "2017-11-11 07:35:06: Loss at step 4692: 0.0367642380297184\n",
      "2017-11-11 07:35:08: Loss at step 4693: 0.036690037697553635\n",
      "2017-11-11 07:35:10: Loss at step 4694: 0.036766473203897476\n",
      "2017-11-11 07:35:13: Loss at step 4695: 0.036799266934394836\n",
      "2017-11-11 07:35:15: Loss at step 4696: 0.03674664348363876\n",
      "2017-11-11 07:35:17: Loss at step 4697: 0.03680398687720299\n",
      "2017-11-11 07:35:19: Loss at step 4698: 0.0367257185280323\n",
      "2017-11-11 07:35:21: Loss at step 4699: 0.036779966205358505\n",
      "2017-11-11 07:35:23: Loss at step 4700: 0.036671459674835205\n",
      "2017-11-11 07:35:26: Loss at step 4701: 0.03676163777709007\n",
      "2017-11-11 07:35:28: Loss at step 4702: 0.03674290329217911\n",
      "2017-11-11 07:35:30: Loss at step 4703: 0.036670904606580734\n",
      "2017-11-11 07:35:32: Loss at step 4704: 0.036857374012470245\n",
      "2017-11-11 07:35:34: Loss at step 4705: 0.036745306104421616\n",
      "2017-11-11 07:35:36: Loss at step 4706: 0.036736395210027695\n",
      "2017-11-11 07:35:39: Loss at step 4707: 0.03668598085641861\n",
      "2017-11-11 07:35:41: Loss at step 4708: 0.03668620437383652\n",
      "2017-11-11 07:35:43: Loss at step 4709: 0.036740295588970184\n",
      "2017-11-11 07:35:45: Loss at step 4710: 0.036863554269075394\n",
      "2017-11-11 07:35:47: Loss at step 4711: 0.03680538013577461\n",
      "2017-11-11 07:35:49: Loss at step 4712: 0.03683155030012131\n",
      "2017-11-11 07:35:52: Loss at step 4713: 0.03678082302212715\n",
      "2017-11-11 07:35:54: Loss at step 4714: 0.03684692829847336\n",
      "2017-11-11 07:35:56: Loss at step 4715: 0.03679891303181648\n",
      "2017-11-11 07:35:58: Loss at step 4716: 0.03685550391674042\n",
      "2017-11-11 07:36:00: Loss at step 4717: 0.036797910928726196\n",
      "2017-11-11 07:36:02: Loss at step 4718: 0.03671962767839432\n",
      "2017-11-11 07:36:05: Loss at step 4719: 0.03678373992443085\n",
      "2017-11-11 07:36:07: Loss at step 4720: 0.036786992102861404\n",
      "2017-11-11 07:36:09: Loss at step 4721: 0.0367797389626503\n",
      "2017-11-11 07:36:11: Loss at step 4722: 0.03674793988466263\n",
      "2017-11-11 07:36:13: Loss at step 4723: 0.036674290895462036\n",
      "2017-11-11 07:36:15: Loss at step 4724: 0.036633171141147614\n",
      "2017-11-11 07:36:17: Loss at step 4725: 0.03673558309674263\n",
      "2017-11-11 07:36:20: Loss at step 4726: 0.03679034486413002\n",
      "2017-11-11 07:36:22: Loss at step 4727: 0.03677404299378395\n",
      "2017-11-11 07:36:24: Loss at step 4728: 0.0367596298456192\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-11-11 07:36:26: Loss at step 4729: 0.03675154969096184\n",
      "2017-11-11 07:36:28: Loss at step 4730: 0.036789700388908386\n",
      "2017-11-11 07:36:30: Loss at step 4731: 0.03675869479775429\n",
      "2017-11-11 07:36:33: Loss at step 4732: 0.03682006150484085\n",
      "2017-11-11 07:36:35: Loss at step 4733: 0.03668932616710663\n",
      "2017-11-11 07:36:37: Loss at step 4734: 0.036763422191143036\n",
      "2017-11-11 07:36:39: Loss at step 4735: 0.036730583757162094\n",
      "2017-11-11 07:36:41: Loss at step 4736: 0.036821939051151276\n",
      "2017-11-11 07:36:43: Loss at step 4737: 0.03676929324865341\n",
      "2017-11-11 07:36:45: Loss at step 4738: 0.03680058568716049\n",
      "2017-11-11 07:36:48: Loss at step 4739: 0.03677249327301979\n",
      "2017-11-11 07:36:50: Loss at step 4740: 0.036715321242809296\n",
      "2017-11-11 07:36:52: Loss at step 4741: 0.03679325059056282\n",
      "2017-11-11 07:36:54: Loss at step 4742: 0.0368347242474556\n",
      "2017-11-11 07:36:56: Loss at step 4743: 0.03682859241962433\n",
      "2017-11-11 07:36:58: Loss at step 4744: 0.03678324073553085\n",
      "2017-11-11 07:37:01: Loss at step 4745: 0.036721423268318176\n",
      "2017-11-11 07:37:03: Loss at step 4746: 0.03674192354083061\n",
      "2017-11-11 07:37:05: Loss at step 4747: 0.03673572838306427\n",
      "2017-11-11 07:37:07: Loss at step 4748: 0.0367560051381588\n",
      "2017-11-11 07:37:09: Loss at step 4749: 0.036797501146793365\n",
      "2017-11-11 07:37:11: Loss at step 4750: 0.036709703505039215\n",
      "2017-11-11 07:37:13: Loss at step 4751: 0.036757856607437134\n",
      "2017-11-11 07:37:16: Loss at step 4752: 0.03678019344806671\n",
      "2017-11-11 07:37:18: Loss at step 4753: 0.03680938854813576\n",
      "2017-11-11 07:37:20: Loss at step 4754: 0.03670581057667732\n",
      "2017-11-11 07:37:22: Loss at step 4755: 0.03683865815401077\n",
      "2017-11-11 07:37:24: Loss at step 4756: 0.03678987920284271\n",
      "2017-11-11 07:37:26: Loss at step 4757: 0.03682570531964302\n",
      "2017-11-11 07:37:28: Loss at step 4758: 0.036748964339494705\n",
      "2017-11-11 07:37:31: Loss at step 4759: 0.0367298386991024\n",
      "2017-11-11 07:37:33: Loss at step 4760: 0.03684577718377113\n",
      "2017-11-11 07:37:35: Loss at step 4761: 0.03676076978445053\n",
      "2017-11-11 07:37:37: Loss at step 4762: 0.036778323352336884\n",
      "2017-11-11 07:37:39: Loss at step 4763: 0.036837153136730194\n",
      "2017-11-11 07:37:41: Loss at step 4764: 0.03681732714176178\n",
      "2017-11-11 07:37:43: Loss at step 4765: 0.036714766174554825\n",
      "2017-11-11 07:37:45: Loss at step 4766: 0.03679192438721657\n",
      "2017-11-11 07:37:48: Loss at step 4767: 0.036669209599494934\n",
      "2017-11-11 07:37:50: Loss at step 4768: 0.036763258278369904\n",
      "2017-11-11 07:37:52: Loss at step 4769: 0.03673948720097542\n",
      "2017-11-11 07:37:54: Loss at step 4770: 0.03678188845515251\n",
      "2017-11-11 07:37:56: Loss at step 4771: 0.03675616905093193\n",
      "2017-11-11 07:37:59: Loss at step 4772: 0.036800891160964966\n",
      "2017-11-11 07:38:01: Loss at step 4773: 0.03679153695702553\n",
      "2017-11-11 07:38:03: Loss at step 4774: 0.03679487481713295\n",
      "2017-11-11 07:38:05: Loss at step 4775: 0.03675771504640579\n",
      "2017-11-11 07:38:07: Loss at step 4776: 0.03675011545419693\n",
      "2017-11-11 07:38:09: Loss at step 4777: 0.03678559139370918\n",
      "2017-11-11 07:38:12: Loss at step 4778: 0.03671516850590706\n",
      "2017-11-11 07:38:14: Loss at step 4779: 0.03676397725939751\n",
      "2017-11-11 07:38:16: Loss at step 4780: 0.03674990311264992\n",
      "2017-11-11 07:38:18: Loss at step 4781: 0.03674597293138504\n",
      "2017-11-11 07:38:20: Loss at step 4782: 0.036874376237392426\n",
      "2017-11-11 07:38:22: Loss at step 4783: 0.03675735741853714\n",
      "2017-11-11 07:38:25: Loss at step 4784: 0.03685061261057854\n",
      "2017-11-11 07:38:27: Loss at step 4785: 0.036773186177015305\n",
      "2017-11-11 07:38:29: Loss at step 4786: 0.036826856434345245\n",
      "2017-11-11 07:38:31: Loss at step 4787: 0.03673151135444641\n",
      "2017-11-11 07:38:34: Loss at step 4788: 0.03681536018848419\n",
      "2017-11-11 07:38:36: Loss at step 4789: 0.036774687469005585\n",
      "2017-11-11 07:38:38: Loss at step 4790: 0.036767084151506424\n",
      "2017-11-11 07:38:41: Loss at step 4791: 0.03668535128235817\n",
      "2017-11-11 07:38:43: Loss at step 4792: 0.036803748458623886\n",
      "2017-11-11 07:38:45: Loss at step 4793: 0.03681716322898865\n",
      "2017-11-11 07:38:47: Loss at step 4794: 0.036781150847673416\n",
      "2017-11-11 07:38:49: Loss at step 4795: 0.036722809076309204\n",
      "2017-11-11 07:38:52: Loss at step 4796: 0.03680019453167915\n",
      "2017-11-11 07:38:54: Loss at step 4797: 0.03675105795264244\n",
      "2017-11-11 07:38:56: Loss at step 4798: 0.03677374869585037\n",
      "2017-11-11 07:38:58: Loss at step 4799: 0.03683428838849068\n",
      "2017-11-11 07:39:00: Loss at step 4800: 0.03679754212498665\n",
      "2017-11-11 07:39:03: Loss at step 4801: 0.0368218868970871\n",
      "2017-11-11 07:39:05: Loss at step 4802: 0.03674835339188576\n",
      "2017-11-11 07:39:07: Loss at step 4803: 0.03677763417363167\n",
      "2017-11-11 07:39:09: Loss at step 4804: 0.03669029474258423\n",
      "2017-11-11 07:39:11: Loss at step 4805: 0.03678899630904198\n",
      "2017-11-11 07:39:13: Loss at step 4806: 0.036816343665122986\n",
      "2017-11-11 07:39:15: Loss at step 4807: 0.03675328940153122\n",
      "2017-11-11 07:39:18: Loss at step 4808: 0.0367337241768837\n",
      "2017-11-11 07:39:20: Loss at step 4809: 0.03677104040980339\n",
      "2017-11-11 07:39:22: Loss at step 4810: 0.03671812266111374\n",
      "2017-11-11 07:39:24: Loss at step 4811: 0.036744531244039536\n",
      "2017-11-11 07:39:26: Loss at step 4812: 0.03679553046822548\n",
      "2017-11-11 07:39:28: Loss at step 4813: 0.03677760064601898\n",
      "2017-11-11 07:39:30: Loss at step 4814: 0.036677036434412\n",
      "2017-11-11 07:39:33: Loss at step 4815: 0.036767009645700455\n",
      "2017-11-11 07:39:35: Loss at step 4816: 0.036728013306856155\n",
      "2017-11-11 07:39:37: Loss at step 4817: 0.03676071763038635\n",
      "2017-11-11 07:39:39: Loss at step 4818: 0.0366891585290432\n",
      "2017-11-11 07:39:41: Loss at step 4819: 0.03678810968995094\n",
      "2017-11-11 07:39:44: Loss at step 4820: 0.0367511510848999\n",
      "2017-11-11 07:39:46: Loss at step 4821: 0.03666018694639206\n",
      "2017-11-11 07:39:48: Loss at step 4822: 0.036738768219947815\n",
      "2017-11-11 07:39:50: Loss at step 4823: 0.036809489130973816\n",
      "2017-11-11 07:39:52: Loss at step 4824: 0.036823827773332596\n",
      "2017-11-11 07:39:54: Loss at step 4825: 0.03674805164337158\n",
      "2017-11-11 07:39:57: Loss at step 4826: 0.03682003170251846\n",
      "2017-11-11 07:39:59: Loss at step 4827: 0.03681058809161186\n",
      "2017-11-11 07:40:01: Loss at step 4828: 0.03674599528312683\n",
      "2017-11-11 07:40:03: Loss at step 4829: 0.03674989193677902\n",
      "2017-11-11 07:40:05: Loss at step 4830: 0.03672247380018234\n",
      "2017-11-11 07:40:07: Loss at step 4831: 0.03674780949950218\n",
      "2017-11-11 07:40:10: Loss at step 4832: 0.03681570664048195\n",
      "2017-11-11 07:40:12: Loss at step 4833: 0.03675299510359764\n",
      "2017-11-11 07:40:14: Loss at step 4834: 0.03667990118265152\n",
      "2017-11-11 07:40:16: Loss at step 4835: 0.036835651844739914\n",
      "2017-11-11 07:40:18: Loss at step 4836: 0.03678419068455696\n",
      "2017-11-11 07:40:20: Loss at step 4837: 0.03683333098888397\n",
      "2017-11-11 07:40:23: Loss at step 4838: 0.0367116741836071\n",
      "2017-11-11 07:40:25: Loss at step 4839: 0.036678362637758255\n",
      "2017-11-11 07:40:27: Loss at step 4840: 0.036765724420547485\n",
      "2017-11-11 07:40:29: Loss at step 4841: 0.036751747131347656\n",
      "2017-11-11 07:40:31: Loss at step 4842: 0.03674374520778656\n",
      "2017-11-11 07:40:33: Loss at step 4843: 0.03676528483629227\n",
      "2017-11-11 07:40:36: Loss at step 4844: 0.036778856068849564\n",
      "2017-11-11 07:40:38: Loss at step 4845: 0.03679027035832405\n",
      "2017-11-11 07:40:40: Loss at step 4846: 0.03682228550314903\n",
      "2017-11-11 07:40:42: Loss at step 4847: 0.036764197051525116\n",
      "2017-11-11 07:40:44: Loss at step 4848: 0.03669331967830658\n",
      "2017-11-11 07:40:46: Loss at step 4849: 0.03673778846859932\n",
      "2017-11-11 07:40:49: Loss at step 4850: 0.03684421256184578\n",
      "2017-11-11 07:40:51: Loss at step 4851: 0.03672739118337631\n",
      "2017-11-11 07:40:53: Loss at step 4852: 0.03664349764585495\n",
      "2017-11-11 07:40:55: Loss at step 4853: 0.03670366853475571\n",
      "2017-11-11 07:40:58: Loss at step 4854: 0.03682384639978409\n",
      "2017-11-11 07:41:00: Loss at step 4855: 0.03686060011386871\n",
      "2017-11-11 07:41:02: Loss at step 4856: 0.036819517612457275\n",
      "2017-11-11 07:41:04: Loss at step 4857: 0.036773502826690674\n",
      "2017-11-11 07:41:06: Loss at step 4858: 0.036741893738508224\n",
      "2017-11-11 07:41:08: Loss at step 4859: 0.036762550473213196\n",
      "2017-11-11 07:41:11: Loss at step 4860: 0.03680881857872009\n",
      "2017-11-11 07:41:13: Loss at step 4861: 0.036798521876335144\n",
      "2017-11-11 07:41:15: Loss at step 4862: 0.03673770651221275\n",
      "2017-11-11 07:41:17: Loss at step 4863: 0.03671625256538391\n",
      "2017-11-11 07:41:19: Loss at step 4864: 0.03682883456349373\n",
      "2017-11-11 07:41:21: Loss at step 4865: 0.036796119064092636\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-11-11 07:41:24: Loss at step 4866: 0.03675248846411705\n",
      "2017-11-11 07:41:26: Loss at step 4867: 0.03673023357987404\n",
      "2017-11-11 07:41:28: Loss at step 4868: 0.03673931583762169\n",
      "2017-11-11 07:41:30: Loss at step 4869: 0.0367916002869606\n",
      "2017-11-11 07:41:32: Loss at step 4870: 0.03674592450261116\n",
      "2017-11-11 07:41:34: Loss at step 4871: 0.0367649644613266\n",
      "2017-11-11 07:41:36: Loss at step 4872: 0.036749791353940964\n",
      "2017-11-11 07:41:39: Loss at step 4873: 0.036732017993927\n",
      "2017-11-11 07:41:41: Loss at step 4874: 0.03671158850193024\n",
      "2017-11-11 07:41:43: Loss at step 4875: 0.03679746389389038\n",
      "2017-11-11 07:41:45: Loss at step 4876: 0.036800824105739594\n",
      "2017-11-11 07:41:47: Loss at step 4877: 0.036812543869018555\n",
      "2017-11-11 07:41:49: Loss at step 4878: 0.03680940717458725\n",
      "2017-11-11 07:41:51: Loss at step 4879: 0.03672867268323898\n",
      "2017-11-11 07:41:54: Loss at step 4880: 0.03678452596068382\n",
      "2017-11-11 07:41:56: Loss at step 4881: 0.03681967034935951\n",
      "2017-11-11 07:41:58: Loss at step 4882: 0.036773353815078735\n",
      "2017-11-11 07:42:00: Loss at step 4883: 0.03674505650997162\n",
      "2017-11-11 07:42:02: Loss at step 4884: 0.036734797060489655\n",
      "2017-11-11 07:42:04: Loss at step 4885: 0.036733467131853104\n",
      "2017-11-11 07:42:07: Loss at step 4886: 0.03677205741405487\n",
      "2017-11-11 07:42:09: Loss at step 4887: 0.03683919459581375\n",
      "2017-11-11 07:42:11: Loss at step 4888: 0.03677283227443695\n",
      "2017-11-11 07:42:13: Loss at step 4889: 0.03674730658531189\n",
      "2017-11-11 07:42:15: Loss at step 4890: 0.036749206483364105\n",
      "2017-11-11 07:42:17: Loss at step 4891: 0.03678089380264282\n",
      "2017-11-11 07:42:19: Loss at step 4892: 0.03683725744485855\n",
      "2017-11-11 07:42:22: Loss at step 4893: 0.036774829030036926\n",
      "2017-11-11 07:42:24: Loss at step 4894: 0.03683001920580864\n",
      "2017-11-11 07:42:26: Loss at step 4895: 0.036872126162052155\n",
      "2017-11-11 07:42:28: Loss at step 4896: 0.036771561950445175\n",
      "2017-11-11 07:42:30: Loss at step 4897: 0.03682754561305046\n",
      "2017-11-11 07:42:32: Loss at step 4898: 0.0367523692548275\n",
      "2017-11-11 07:42:35: Loss at step 4899: 0.036848656833171844\n",
      "2017-11-11 07:42:37: Loss at step 4900: 0.03683391585946083\n",
      "2017-11-11 07:42:39: Loss at step 4901: 0.036776959896087646\n",
      "2017-11-11 07:42:41: Loss at step 4902: 0.03679856285452843\n",
      "2017-11-11 07:42:43: Loss at step 4903: 0.03680715337395668\n",
      "2017-11-11 07:42:45: Loss at step 4904: 0.036855317652225494\n",
      "2017-11-11 07:42:47: Loss at step 4905: 0.03670930489897728\n",
      "2017-11-11 07:42:49: Loss at step 4906: 0.03676500543951988\n",
      "2017-11-11 07:42:52: Loss at step 4907: 0.036712322384119034\n",
      "2017-11-11 07:42:54: Loss at step 4908: 0.03676550090312958\n",
      "2017-11-11 07:42:56: Loss at step 4909: 0.03683933988213539\n",
      "2017-11-11 07:42:58: Loss at step 4910: 0.03683175519108772\n",
      "2017-11-11 07:43:00: Loss at step 4911: 0.03680306673049927\n",
      "2017-11-11 07:43:02: Loss at step 4912: 0.03680465742945671\n",
      "2017-11-11 07:43:05: Loss at step 4913: 0.03676123172044754\n",
      "2017-11-11 07:43:07: Loss at step 4914: 0.03673972934484482\n",
      "2017-11-11 07:43:09: Loss at step 4915: 0.03670359402894974\n",
      "2017-11-11 07:43:11: Loss at step 4916: 0.03673246502876282\n",
      "2017-11-11 07:43:13: Loss at step 4917: 0.036858100444078445\n",
      "2017-11-11 07:43:15: Loss at step 4918: 0.036780405789613724\n",
      "2017-11-11 07:43:17: Loss at step 4919: 0.03679969534277916\n",
      "2017-11-11 07:43:20: Loss at step 4920: 0.03662960231304169\n",
      "2017-11-11 07:43:22: Loss at step 4921: 0.03678391873836517\n",
      "2017-11-11 07:43:24: Loss at step 4922: 0.036795176565647125\n",
      "2017-11-11 07:43:26: Loss at step 4923: 0.03682904690504074\n",
      "2017-11-11 07:43:28: Loss at step 4924: 0.03678237274289131\n",
      "2017-11-11 07:43:30: Loss at step 4925: 0.03676888346672058\n",
      "2017-11-11 07:43:32: Loss at step 4926: 0.03668069466948509\n",
      "2017-11-11 07:43:35: Loss at step 4927: 0.03673537075519562\n",
      "2017-11-11 07:43:37: Loss at step 4928: 0.03681615740060806\n",
      "2017-11-11 07:43:39: Loss at step 4929: 0.036853283643722534\n",
      "2017-11-11 07:43:41: Loss at step 4930: 0.03684278205037117\n",
      "2017-11-11 07:43:43: Loss at step 4931: 0.036794159561395645\n",
      "2017-11-11 07:43:46: Loss at step 4932: 0.03681926801800728\n",
      "2017-11-11 07:43:48: Loss at step 4933: 0.03672809526324272\n",
      "2017-11-11 07:43:50: Loss at step 4934: 0.03671850636601448\n",
      "2017-11-11 07:43:52: Loss at step 4935: 0.03675739839673042\n",
      "2017-11-11 07:43:55: Loss at step 4936: 0.036789774894714355\n",
      "2017-11-11 07:43:57: Loss at step 4937: 0.03676668182015419\n",
      "2017-11-11 07:43:59: Loss at step 4938: 0.03676663339138031\n",
      "2017-11-11 07:44:02: Loss at step 4939: 0.03679635748267174\n",
      "2017-11-11 07:44:04: Loss at step 4940: 0.03675408288836479\n",
      "2017-11-11 07:44:06: Loss at step 4941: 0.03677836060523987\n",
      "2017-11-11 07:44:09: Loss at step 4942: 0.03674590587615967\n",
      "2017-11-11 07:44:11: Loss at step 4943: 0.036821234971284866\n",
      "2017-11-11 07:44:13: Loss at step 4944: 0.03683086112141609\n",
      "2017-11-11 07:44:16: Loss at step 4945: 0.036803364753723145\n",
      "2017-11-11 07:44:18: Loss at step 4946: 0.03683839738368988\n",
      "2017-11-11 07:44:20: Loss at step 4947: 0.03668021410703659\n",
      "2017-11-11 07:44:22: Loss at step 4948: 0.036674682050943375\n",
      "2017-11-11 07:44:25: Loss at step 4949: 0.036707837134599686\n",
      "2017-11-11 07:44:27: Loss at step 4950: 0.0367249920964241\n",
      "2017-11-11 07:44:29: Loss at step 4951: 0.03673351928591728\n",
      "2017-11-11 07:44:31: Loss at step 4952: 0.03686566650867462\n",
      "2017-11-11 07:44:33: Loss at step 4953: 0.036832068115472794\n",
      "2017-11-11 07:44:35: Loss at step 4954: 0.03678547963500023\n",
      "2017-11-11 07:44:37: Loss at step 4955: 0.0367748998105526\n",
      "2017-11-11 07:44:40: Loss at step 4956: 0.036745838820934296\n",
      "2017-11-11 07:44:42: Loss at step 4957: 0.03683645278215408\n",
      "2017-11-11 07:44:44: Loss at step 4958: 0.03692071884870529\n",
      "2017-11-11 07:44:46: Loss at step 4959: 0.03684001415967941\n",
      "2017-11-11 07:44:48: Loss at step 4960: 0.0367913581430912\n",
      "2017-11-11 07:44:51: Loss at step 4961: 0.036797188222408295\n",
      "2017-11-11 07:44:53: Loss at step 4962: 0.03677823767066002\n",
      "2017-11-11 07:44:55: Loss at step 4963: 0.036753032356500626\n",
      "2017-11-11 07:44:58: Loss at step 4964: 0.03660571947693825\n",
      "2017-11-11 07:45:00: Loss at step 4965: 0.036768704652786255\n",
      "2017-11-11 07:45:02: Loss at step 4966: 0.03682398051023483\n",
      "2017-11-11 07:45:05: Loss at step 4967: 0.0367596298456192\n",
      "2017-11-11 07:45:07: Loss at step 4968: 0.03685026988387108\n",
      "2017-11-11 07:45:09: Loss at step 4969: 0.03676825016736984\n",
      "2017-11-11 07:45:11: Loss at step 4970: 0.0368000790476799\n",
      "2017-11-11 07:45:13: Loss at step 4971: 0.03675470128655434\n",
      "2017-11-11 07:45:15: Loss at step 4972: 0.03679700568318367\n",
      "2017-11-11 07:45:18: Loss at step 4973: 0.03686247020959854\n",
      "2017-11-11 07:45:20: Loss at step 4974: 0.03671201318502426\n",
      "2017-11-11 07:45:22: Loss at step 4975: 0.03679918125271797\n",
      "2017-11-11 07:45:24: Loss at step 4976: 0.03677824139595032\n",
      "2017-11-11 07:45:27: Loss at step 4977: 0.03682582825422287\n",
      "2017-11-11 07:45:29: Loss at step 4978: 0.03669826686382294\n",
      "2017-11-11 07:45:31: Loss at step 4979: 0.036817487329244614\n",
      "2017-11-11 07:45:34: Loss at step 4980: 0.03671420365571976\n",
      "2017-11-11 07:45:36: Loss at step 4981: 0.036822859197854996\n",
      "2017-11-11 07:45:38: Loss at step 4982: 0.03666537627577782\n",
      "2017-11-11 07:45:40: Loss at step 4983: 0.03667778894305229\n",
      "2017-11-11 07:45:42: Loss at step 4984: 0.03686811402440071\n",
      "2017-11-11 07:45:45: Loss at step 4985: 0.036748625338077545\n",
      "2017-11-11 07:45:47: Loss at step 4986: 0.03680937737226486\n",
      "2017-11-11 07:45:49: Loss at step 4987: 0.03684191778302193\n",
      "2017-11-11 07:45:51: Loss at step 4988: 0.03680190443992615\n",
      "2017-11-11 07:45:53: Loss at step 4989: 0.03678010776638985\n",
      "2017-11-11 07:45:55: Loss at step 4990: 0.03672683238983154\n",
      "2017-11-11 07:45:58: Loss at step 4991: 0.03679131716489792\n",
      "2017-11-11 07:46:00: Loss at step 4992: 0.03684132918715477\n",
      "2017-11-11 07:46:02: Loss at step 4993: 0.036738649010658264\n",
      "2017-11-11 07:46:04: Loss at step 4994: 0.036676470190286636\n",
      "2017-11-11 07:46:06: Loss at step 4995: 0.03676220774650574\n",
      "2017-11-11 07:46:09: Loss at step 4996: 0.03678453341126442\n",
      "2017-11-11 07:46:11: Loss at step 4997: 0.03689638525247574\n",
      "2017-11-11 07:46:13: Loss at step 4998: 0.036752428859472275\n",
      "2017-11-11 07:46:15: Loss at step 4999: 0.03683314099907875\n",
      "2017-11-11 07:46:17: Loss at step 5000: 0.03675755113363266\n",
      "2017-11-11 07:46:19: Loss at step 5001: 0.03681758791208267\n",
      "2017-11-11 07:46:22: Loss at step 5002: 0.036730654537677765\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-11-11 07:46:24: Loss at step 5003: 0.03663784638047218\n",
      "2017-11-11 07:46:26: Loss at step 5004: 0.03676796704530716\n",
      "2017-11-11 07:46:28: Loss at step 5005: 0.03672107681632042\n",
      "2017-11-11 07:46:30: Loss at step 5006: 0.03670649230480194\n",
      "2017-11-11 07:46:32: Loss at step 5007: 0.03683760389685631\n",
      "2017-11-11 07:46:35: Loss at step 5008: 0.0367915965616703\n",
      "2017-11-11 07:46:37: Loss at step 5009: 0.0368579626083374\n",
      "2017-11-11 07:46:39: Loss at step 5010: 0.03677348792552948\n",
      "2017-11-11 07:46:41: Loss at step 5011: 0.03686247393488884\n",
      "2017-11-11 07:46:43: Loss at step 5012: 0.036813411861658096\n",
      "2017-11-11 07:46:45: Loss at step 5013: 0.036714885383844376\n",
      "2017-11-11 07:46:48: Loss at step 5014: 0.03671903535723686\n",
      "2017-11-11 07:46:50: Loss at step 5015: 0.036780886352062225\n",
      "2017-11-11 07:46:52: Loss at step 5016: 0.036802131682634354\n",
      "2017-11-11 07:46:54: Loss at step 5017: 0.0368625745177269\n",
      "2017-11-11 07:46:56: Loss at step 5018: 0.036751888692379\n",
      "2017-11-11 07:46:58: Loss at step 5019: 0.03691001608967781\n",
      "2017-11-11 07:47:01: Loss at step 5020: 0.03683234378695488\n",
      "2017-11-11 07:47:03: Loss at step 5021: 0.03686688840389252\n",
      "2017-11-11 07:47:05: Loss at step 5022: 0.036801453679800034\n",
      "2017-11-11 07:47:07: Loss at step 5023: 0.03683094307780266\n",
      "2017-11-11 07:47:09: Loss at step 5024: 0.03687003254890442\n",
      "2017-11-11 07:47:11: Loss at step 5025: 0.036904290318489075\n",
      "2017-11-11 07:47:14: Loss at step 5026: 0.03680259361863136\n",
      "2017-11-11 07:47:16: Loss at step 5027: 0.03675316646695137\n",
      "2017-11-11 07:47:18: Loss at step 5028: 0.036878425627946854\n",
      "2017-11-11 07:47:20: Loss at step 5029: 0.03685261681675911\n",
      "2017-11-11 07:47:22: Loss at step 5030: 0.03680158033967018\n",
      "2017-11-11 07:47:25: Loss at step 5031: 0.036769989877939224\n",
      "2017-11-11 07:47:27: Loss at step 5032: 0.03674955293536186\n",
      "2017-11-11 07:47:29: Loss at step 5033: 0.03682948648929596\n",
      "2017-11-11 07:47:31: Loss at step 5034: 0.0367821529507637\n",
      "2017-11-11 07:47:33: Loss at step 5035: 0.03687320277094841\n",
      "2017-11-11 07:47:35: Loss at step 5036: 0.036862000823020935\n",
      "2017-11-11 07:47:38: Loss at step 5037: 0.03675922751426697\n",
      "2017-11-11 07:47:40: Loss at step 5038: 0.03681240975856781\n",
      "2017-11-11 07:47:42: Loss at step 5039: 0.036771539598703384\n",
      "2017-11-11 07:47:44: Loss at step 5040: 0.0367974191904068\n",
      "2017-11-11 07:47:46: Loss at step 5041: 0.03686060756444931\n",
      "2017-11-11 07:47:48: Loss at step 5042: 0.036795422434806824\n",
      "2017-11-11 07:47:51: Loss at step 5043: 0.03670454025268555\n",
      "2017-11-11 07:47:53: Loss at step 5044: 0.03680867329239845\n",
      "2017-11-11 07:47:55: Loss at step 5045: 0.03675086796283722\n",
      "2017-11-11 07:47:57: Loss at step 5046: 0.0367828905582428\n",
      "2017-11-11 07:47:59: Loss at step 5047: 0.036754362285137177\n",
      "2017-11-11 07:48:01: Loss at step 5048: 0.03681207820773125\n",
      "2017-11-11 07:48:03: Loss at step 5049: 0.036886245012283325\n",
      "2017-11-11 07:48:06: Loss at step 5050: 0.03690535947680473\n",
      "2017-11-11 07:48:08: Loss at step 5051: 0.03678440302610397\n",
      "2017-11-11 07:48:10: Loss at step 5052: 0.03674600273370743\n",
      "2017-11-11 07:48:12: Loss at step 5053: 0.03680277243256569\n",
      "2017-11-11 07:48:14: Loss at step 5054: 0.03682179003953934\n",
      "2017-11-11 07:48:16: Loss at step 5055: 0.03678726777434349\n",
      "2017-11-11 07:48:18: Loss at step 5056: 0.0368005596101284\n",
      "2017-11-11 07:48:21: Loss at step 5057: 0.036768946796655655\n",
      "2017-11-11 07:48:23: Loss at step 5058: 0.03685801848769188\n",
      "2017-11-11 07:48:25: Loss at step 5059: 0.03688444942235947\n",
      "2017-11-11 07:48:27: Loss at step 5060: 0.03678964078426361\n",
      "2017-11-11 07:48:29: Loss at step 5061: 0.03682177886366844\n",
      "2017-11-11 07:48:32: Loss at step 5062: 0.0368543416261673\n",
      "2017-11-11 07:48:34: Loss at step 5063: 0.03687746077775955\n",
      "2017-11-11 07:48:36: Loss at step 5064: 0.0368221178650856\n",
      "2017-11-11 07:48:38: Loss at step 5065: 0.036916583776474\n",
      "2017-11-11 07:48:40: Loss at step 5066: 0.03684884309768677\n",
      "2017-11-11 07:48:42: Loss at step 5067: 0.03689790889620781\n",
      "2017-11-11 07:48:45: Loss at step 5068: 0.03685437887907028\n",
      "2017-11-11 07:48:47: Loss at step 5069: 0.03677825257182121\n",
      "2017-11-11 07:48:49: Loss at step 5070: 0.03675519675016403\n",
      "2017-11-11 07:48:51: Loss at step 5071: 0.03677794709801674\n",
      "2017-11-11 07:48:53: Loss at step 5072: 0.03673543781042099\n",
      "2017-11-11 07:48:55: Loss at step 5073: 0.03684563934803009\n",
      "2017-11-11 07:48:58: Loss at step 5074: 0.03682190552353859\n",
      "2017-11-11 07:49:00: Loss at step 5075: 0.03670431673526764\n",
      "2017-11-11 07:49:02: Loss at step 5076: 0.03673689439892769\n",
      "2017-11-11 07:49:04: Loss at step 5077: 0.03675025701522827\n",
      "2017-11-11 07:49:06: Loss at step 5078: 0.036850787699222565\n",
      "2017-11-11 07:49:08: Loss at step 5079: 0.03677533566951752\n",
      "2017-11-11 07:49:10: Loss at step 5080: 0.036756452172994614\n",
      "2017-11-11 07:49:12: Loss at step 5081: 0.0367138534784317\n",
      "2017-11-11 07:49:15: Loss at step 5082: 0.03681287169456482\n",
      "2017-11-11 07:49:17: Loss at step 5083: 0.03677661716938019\n",
      "2017-11-11 07:49:19: Loss at step 5084: 0.03677782788872719\n",
      "2017-11-11 07:49:21: Loss at step 5085: 0.0367736741900444\n",
      "2017-11-11 07:49:23: Loss at step 5086: 0.03677834942936897\n",
      "2017-11-11 07:49:25: Loss at step 5087: 0.036806587129831314\n",
      "2017-11-11 07:49:27: Loss at step 5088: 0.03670935705304146\n",
      "2017-11-11 07:49:30: Loss at step 5089: 0.036701932549476624\n",
      "2017-11-11 07:49:32: Loss at step 5090: 0.036732371896505356\n",
      "2017-11-11 07:49:34: Loss at step 5091: 0.03674561530351639\n",
      "2017-11-11 07:49:36: Loss at step 5092: 0.03678007796406746\n",
      "2017-11-11 07:49:38: Loss at step 5093: 0.036882899701595306\n",
      "2017-11-11 07:49:40: Loss at step 5094: 0.0367274284362793\n",
      "2017-11-11 07:49:43: Loss at step 5095: 0.03680545464158058\n",
      "2017-11-11 07:49:45: Loss at step 5096: 0.03676455840468407\n",
      "2017-11-11 07:49:47: Loss at step 5097: 0.03680528327822685\n",
      "2017-11-11 07:49:49: Loss at step 5098: 0.03669578954577446\n",
      "2017-11-11 07:49:51: Loss at step 5099: 0.03663548082113266\n",
      "2017-11-11 07:49:54: Loss at step 5100: 0.036680035293102264\n",
      "2017-11-11 07:49:56: Loss at step 5101: 0.03674501180648804\n",
      "2017-11-11 07:49:58: Loss at step 5102: 0.03689168021082878\n",
      "2017-11-11 07:50:00: Loss at step 5103: 0.03677884489297867\n",
      "2017-11-11 07:50:02: Loss at step 5104: 0.036792706698179245\n",
      "2017-11-11 07:50:04: Loss at step 5105: 0.03675127401947975\n",
      "2017-11-11 07:50:07: Loss at step 5106: 0.03680509701371193\n",
      "2017-11-11 07:50:09: Loss at step 5107: 0.03678639978170395\n",
      "2017-11-11 07:50:11: Loss at step 5108: 0.0368649885058403\n",
      "2017-11-11 07:50:13: Loss at step 5109: 0.03685631603002548\n",
      "2017-11-11 07:50:15: Loss at step 5110: 0.036774348467588425\n",
      "2017-11-11 07:50:17: Loss at step 5111: 0.03679172322154045\n",
      "2017-11-11 07:50:20: Loss at step 5112: 0.03666526824235916\n",
      "2017-11-11 07:50:22: Loss at step 5113: 0.036827366799116135\n",
      "2017-11-11 07:50:24: Loss at step 5114: 0.0367591567337513\n",
      "2017-11-11 07:50:26: Loss at step 5115: 0.03679918870329857\n",
      "2017-11-11 07:50:28: Loss at step 5116: 0.036810778081417084\n",
      "2017-11-11 07:50:30: Loss at step 5117: 0.03667616844177246\n",
      "2017-11-11 07:50:33: Loss at step 5118: 0.03673024848103523\n",
      "2017-11-11 07:50:35: Loss at step 5119: 0.03676775097846985\n",
      "2017-11-11 07:50:37: Loss at step 5120: 0.03685936704277992\n",
      "2017-11-11 07:50:39: Loss at step 5121: 0.036793727427721024\n",
      "2017-11-11 07:50:41: Loss at step 5122: 0.0367271713912487\n",
      "2017-11-11 07:50:43: Loss at step 5123: 0.03678005933761597\n",
      "2017-11-11 07:50:45: Loss at step 5124: 0.03679034858942032\n",
      "2017-11-11 07:50:48: Loss at step 5125: 0.03677871823310852\n",
      "2017-11-11 07:50:50: Loss at step 5126: 0.03673788905143738\n",
      "2017-11-11 07:50:52: Loss at step 5127: 0.036760199815034866\n",
      "2017-11-11 07:50:54: Loss at step 5128: 0.036775246262550354\n",
      "2017-11-11 07:50:56: Loss at step 5129: 0.03683824464678764\n",
      "2017-11-11 07:50:58: Loss at step 5130: 0.03680604696273804\n",
      "2017-11-11 07:51:01: Loss at step 5131: 0.036714568734169006\n",
      "2017-11-11 07:51:03: Loss at step 5132: 0.036875203251838684\n",
      "2017-11-11 07:51:05: Loss at step 5133: 0.03685207664966583\n",
      "2017-11-11 07:51:07: Loss at step 5134: 0.036703236401081085\n",
      "2017-11-11 07:51:09: Loss at step 5135: 0.03676922619342804\n",
      "2017-11-11 07:51:11: Loss at step 5136: 0.03676412254571915\n",
      "2017-11-11 07:51:13: Loss at step 5137: 0.03681761026382446\n",
      "2017-11-11 07:51:16: Loss at step 5138: 0.036801502108573914\n",
      "2017-11-11 07:51:18: Loss at step 5139: 0.03677431493997574\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-11-11 07:51:20: Loss at step 5140: 0.03676080331206322\n",
      "2017-11-11 07:51:22: Loss at step 5141: 0.03677816316485405\n",
      "2017-11-11 07:51:24: Loss at step 5142: 0.03675081208348274\n",
      "2017-11-11 07:51:26: Loss at step 5143: 0.03673573583364487\n",
      "2017-11-11 07:51:28: Loss at step 5144: 0.03682028129696846\n",
      "2017-11-11 07:51:31: Loss at step 5145: 0.03674256056547165\n",
      "2017-11-11 07:51:33: Loss at step 5146: 0.03673744574189186\n",
      "2017-11-11 07:51:35: Loss at step 5147: 0.03672629967331886\n",
      "2017-11-11 07:51:37: Loss at step 5148: 0.036629028618335724\n",
      "2017-11-11 07:51:39: Loss at step 5149: 0.03674600273370743\n",
      "2017-11-11 07:51:41: Loss at step 5150: 0.03682996705174446\n",
      "2017-11-11 07:51:43: Loss at step 5151: 0.03682280704379082\n",
      "2017-11-11 07:51:46: Loss at step 5152: 0.03673088550567627\n",
      "2017-11-11 07:51:48: Loss at step 5153: 0.036701176315546036\n",
      "2017-11-11 07:51:50: Loss at step 5154: 0.036726947873830795\n",
      "2017-11-11 07:51:52: Loss at step 5155: 0.03685373812913895\n",
      "2017-11-11 07:51:54: Loss at step 5156: 0.036842938512563705\n",
      "2017-11-11 07:51:56: Loss at step 5157: 0.036693401634693146\n",
      "2017-11-11 07:51:58: Loss at step 5158: 0.03678019344806671\n",
      "2017-11-11 07:52:01: Loss at step 5159: 0.03678928688168526\n",
      "2017-11-11 07:52:03: Loss at step 5160: 0.03687305748462677\n",
      "2017-11-11 07:52:05: Loss at step 5161: 0.036724723875522614\n",
      "2017-11-11 07:52:07: Loss at step 5162: 0.036746323108673096\n",
      "2017-11-11 07:52:09: Loss at step 5163: 0.03680472448468208\n",
      "2017-11-11 07:52:11: Loss at step 5164: 0.036757610738277435\n",
      "2017-11-11 07:52:13: Loss at step 5165: 0.03684238716959953\n",
      "2017-11-11 07:52:16: Loss at step 5166: 0.036731794476509094\n",
      "2017-11-11 07:52:18: Loss at step 5167: 0.03684006631374359\n",
      "2017-11-11 07:52:20: Loss at step 5168: 0.03673046827316284\n",
      "2017-11-11 07:52:22: Loss at step 5169: 0.036754705011844635\n",
      "2017-11-11 07:52:24: Loss at step 5170: 0.03680592402815819\n",
      "2017-11-11 07:52:26: Loss at step 5171: 0.03672144189476967\n",
      "2017-11-11 07:52:29: Loss at step 5172: 0.03675726801156998\n",
      "2017-11-11 07:52:31: Loss at step 5173: 0.036781128495931625\n",
      "2017-11-11 07:52:33: Loss at step 5174: 0.03682240471243858\n",
      "2017-11-11 07:52:35: Loss at step 5175: 0.036770258098840714\n",
      "2017-11-11 07:52:37: Loss at step 5176: 0.03677932918071747\n",
      "2017-11-11 07:52:39: Loss at step 5177: 0.0367584303021431\n",
      "2017-11-11 07:52:41: Loss at step 5178: 0.03668887913227081\n",
      "2017-11-11 07:52:44: Loss at step 5179: 0.0367378368973732\n",
      "2017-11-11 07:52:46: Loss at step 5180: 0.03674731403589249\n",
      "2017-11-11 07:52:48: Loss at step 5181: 0.0367777943611145\n",
      "2017-11-11 07:52:50: Loss at step 5182: 0.03681965172290802\n",
      "2017-11-11 07:52:52: Loss at step 5183: 0.03678678348660469\n",
      "2017-11-11 07:52:54: Loss at step 5184: 0.036837294697761536\n",
      "2017-11-11 07:52:56: Loss at step 5185: 0.036737389862537384\n",
      "2017-11-11 07:52:58: Loss at step 5186: 0.0368223562836647\n",
      "2017-11-11 07:53:01: Loss at step 5187: 0.036719661206007004\n",
      "2017-11-11 07:53:03: Loss at step 5188: 0.03678077459335327\n",
      "2017-11-11 07:53:05: Loss at step 5189: 0.03678738325834274\n",
      "2017-11-11 07:53:07: Loss at step 5190: 0.03678801283240318\n",
      "2017-11-11 07:53:09: Loss at step 5191: 0.03669733926653862\n",
      "2017-11-11 07:53:11: Loss at step 5192: 0.03677421435713768\n",
      "2017-11-11 07:53:13: Loss at step 5193: 0.03679007664322853\n",
      "2017-11-11 07:53:16: Loss at step 5194: 0.03674119710922241\n",
      "2017-11-11 07:53:18: Loss at step 5195: 0.036837611347436905\n",
      "2017-11-11 07:53:20: Loss at step 5196: 0.03675580397248268\n",
      "2017-11-11 07:53:22: Loss at step 5197: 0.03680470213294029\n",
      "2017-11-11 07:53:24: Loss at step 5198: 0.03679472580552101\n",
      "2017-11-11 07:53:26: Loss at step 5199: 0.03673947602510452\n",
      "2017-11-11 07:53:28: Loss at step 5200: 0.03674804046750069\n",
      "2017-11-11 07:53:31: Loss at step 5201: 0.03677479177713394\n",
      "2017-11-11 07:53:33: Loss at step 5202: 0.03671235591173172\n",
      "2017-11-11 07:53:35: Loss at step 5203: 0.036630649119615555\n",
      "2017-11-11 07:53:37: Loss at step 5204: 0.036679960787296295\n",
      "2017-11-11 07:53:39: Loss at step 5205: 0.036795783787965775\n",
      "2017-11-11 07:53:41: Loss at step 5206: 0.03672035411000252\n",
      "2017-11-11 07:53:43: Loss at step 5207: 0.036820124834775925\n",
      "2017-11-11 07:53:46: Loss at step 5208: 0.03673258423805237\n",
      "2017-11-11 07:53:48: Loss at step 5209: 0.036767736077308655\n",
      "2017-11-11 07:53:50: Loss at step 5210: 0.03682288900017738\n",
      "2017-11-11 07:53:52: Loss at step 5211: 0.03678444027900696\n",
      "2017-11-11 07:53:54: Loss at step 5212: 0.03679046034812927\n",
      "2017-11-11 07:53:56: Loss at step 5213: 0.03665817156434059\n",
      "2017-11-11 07:53:58: Loss at step 5214: 0.03671746701002121\n",
      "2017-11-11 07:54:01: Loss at step 5215: 0.03668820112943649\n",
      "2017-11-11 07:54:03: Loss at step 5216: 0.0366329699754715\n",
      "2017-11-11 07:54:05: Loss at step 5217: 0.036746446043252945\n",
      "2017-11-11 07:54:07: Loss at step 5218: 0.03681027516722679\n",
      "2017-11-11 07:54:09: Loss at step 5219: 0.03678829222917557\n",
      "2017-11-11 07:54:11: Loss at step 5220: 0.03683020547032356\n",
      "2017-11-11 07:54:13: Loss at step 5221: 0.036766886711120605\n",
      "2017-11-11 07:54:16: Loss at step 5222: 0.03675388917326927\n",
      "2017-11-11 07:54:18: Loss at step 5223: 0.036767251789569855\n",
      "2017-11-11 07:54:20: Loss at step 5224: 0.03674020618200302\n",
      "2017-11-11 07:54:22: Loss at step 5225: 0.0367463119328022\n",
      "2017-11-11 07:54:24: Loss at step 5226: 0.036774568259716034\n",
      "2017-11-11 07:54:26: Loss at step 5227: 0.03674112632870674\n",
      "2017-11-11 07:54:29: Loss at step 5228: 0.03679198771715164\n",
      "2017-11-11 07:54:31: Loss at step 5229: 0.03683701902627945\n",
      "2017-11-11 07:54:33: Loss at step 5230: 0.036791328340768814\n",
      "2017-11-11 07:54:35: Loss at step 5231: 0.0367782786488533\n",
      "2017-11-11 07:54:37: Loss at step 5232: 0.03676241636276245\n",
      "2017-11-11 07:54:39: Loss at step 5233: 0.03668997809290886\n",
      "2017-11-11 07:54:41: Loss at step 5234: 0.03679346665740013\n",
      "2017-11-11 07:54:44: Loss at step 5235: 0.03670653700828552\n",
      "2017-11-11 07:54:46: Loss at step 5236: 0.036785926669836044\n",
      "2017-11-11 07:54:48: Loss at step 5237: 0.03674128279089928\n",
      "2017-11-11 07:54:50: Loss at step 5238: 0.036740049719810486\n",
      "2017-11-11 07:54:52: Loss at step 5239: 0.03668208047747612\n",
      "2017-11-11 07:54:54: Loss at step 5240: 0.036758776754140854\n",
      "2017-11-11 07:54:56: Loss at step 5241: 0.03678639978170395\n",
      "2017-11-11 07:54:59: Loss at step 5242: 0.036723699420690536\n",
      "2017-11-11 07:55:01: Loss at step 5243: 0.03673157840967178\n",
      "2017-11-11 07:55:03: Loss at step 5244: 0.03671225532889366\n",
      "2017-11-11 07:55:05: Loss at step 5245: 0.036789778620004654\n",
      "2017-11-11 07:55:07: Loss at step 5246: 0.03680208697915077\n",
      "2017-11-11 07:55:09: Loss at step 5247: 0.03667474538087845\n",
      "2017-11-11 07:55:11: Loss at step 5248: 0.036746807396411896\n",
      "2017-11-11 07:55:14: Loss at step 5249: 0.036741454154253006\n",
      "2017-11-11 07:55:16: Loss at step 5250: 0.036823730915784836\n",
      "2017-11-11 07:55:18: Loss at step 5251: 0.0367286391556263\n",
      "2017-11-11 07:55:20: Loss at step 5252: 0.036740925163030624\n",
      "2017-11-11 07:55:22: Loss at step 5253: 0.036825016140937805\n",
      "2017-11-11 07:55:24: Loss at step 5254: 0.03672533482313156\n",
      "2017-11-11 07:55:26: Loss at step 5255: 0.03678300604224205\n",
      "2017-11-11 07:55:29: Loss at step 5256: 0.03673410043120384\n",
      "2017-11-11 07:55:31: Loss at step 5257: 0.03671795874834061\n",
      "2017-11-11 07:55:33: Loss at step 5258: 0.036723144352436066\n",
      "2017-11-11 07:55:35: Loss at step 5259: 0.03677015379071236\n",
      "2017-11-11 07:55:37: Loss at step 5260: 0.03673291578888893\n",
      "2017-11-11 07:55:39: Loss at step 5261: 0.03672051802277565\n",
      "2017-11-11 07:55:41: Loss at step 5262: 0.03679068386554718\n",
      "2017-11-11 07:55:44: Loss at step 5263: 0.03670056164264679\n",
      "2017-11-11 07:55:46: Loss at step 5264: 0.03686020150780678\n",
      "2017-11-11 07:55:48: Loss at step 5265: 0.03666955977678299\n",
      "2017-11-11 07:55:50: Loss at step 5266: 0.036760203540325165\n",
      "2017-11-11 07:55:52: Loss at step 5267: 0.03677933290600777\n",
      "2017-11-11 07:55:54: Loss at step 5268: 0.03674605116248131\n",
      "2017-11-11 07:55:56: Loss at step 5269: 0.0367596261203289\n",
      "2017-11-11 07:55:59: Loss at step 5270: 0.036706071346998215\n",
      "2017-11-11 07:56:01: Loss at step 5271: 0.036674827337265015\n",
      "2017-11-11 07:56:03: Loss at step 5272: 0.036813054233789444\n",
      "2017-11-11 07:56:05: Loss at step 5273: 0.0365871861577034\n",
      "2017-11-11 07:56:07: Loss at step 5274: 0.03678884357213974\n",
      "2017-11-11 07:56:10: Loss at step 5275: 0.0367046557366848\n",
      "2017-11-11 07:56:12: Loss at step 5276: 0.036798182874917984\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-11-11 07:56:14: Loss at step 5277: 0.03683433309197426\n",
      "2017-11-11 07:56:16: Loss at step 5278: 0.03682652488350868\n",
      "2017-11-11 07:56:18: Loss at step 5279: 0.03677448257803917\n",
      "2017-11-11 07:56:20: Loss at step 5280: 0.03676701709628105\n",
      "2017-11-11 07:56:22: Loss at step 5281: 0.03684748709201813\n",
      "2017-11-11 07:56:25: Loss at step 5282: 0.03672650083899498\n",
      "2017-11-11 07:56:27: Loss at step 5283: 0.03678348660469055\n",
      "2017-11-11 07:56:29: Loss at step 5284: 0.03675515577197075\n",
      "2017-11-11 07:56:31: Loss at step 5285: 0.03686431050300598\n",
      "2017-11-11 07:56:33: Loss at step 5286: 0.03676925227046013\n",
      "2017-11-11 07:56:35: Loss at step 5287: 0.03671221435070038\n",
      "2017-11-11 07:56:38: Loss at step 5288: 0.03674933314323425\n",
      "2017-11-11 07:56:40: Loss at step 5289: 0.036709416657686234\n",
      "2017-11-11 07:56:42: Loss at step 5290: 0.036714378744363785\n",
      "2017-11-11 07:56:44: Loss at step 5291: 0.03668693080544472\n",
      "2017-11-11 07:56:46: Loss at step 5292: 0.03683823347091675\n",
      "2017-11-11 07:56:48: Loss at step 5293: 0.03671027719974518\n",
      "2017-11-11 07:56:50: Loss at step 5294: 0.03686247020959854\n",
      "2017-11-11 07:56:53: Loss at step 5295: 0.036905307322740555\n",
      "2017-11-11 07:56:55: Loss at step 5296: 0.036828868091106415\n",
      "2017-11-11 07:56:57: Loss at step 5297: 0.036809131503105164\n",
      "2017-11-11 07:56:59: Loss at step 5298: 0.03680337592959404\n",
      "2017-11-11 07:57:01: Loss at step 5299: 0.03683356195688248\n",
      "2017-11-11 07:57:03: Loss at step 5300: 0.03688674792647362\n",
      "2017-11-11 07:57:05: Loss at step 5301: 0.036859795451164246\n",
      "2017-11-11 07:57:08: Loss at step 5302: 0.036807168275117874\n",
      "2017-11-11 07:57:10: Loss at step 5303: 0.03676529973745346\n",
      "2017-11-11 07:57:12: Loss at step 5304: 0.036811668425798416\n",
      "2017-11-11 07:57:14: Loss at step 5305: 0.03678901493549347\n",
      "2017-11-11 07:57:16: Loss at step 5306: 0.036862559616565704\n",
      "2017-11-11 07:57:18: Loss at step 5307: 0.03682905435562134\n",
      "2017-11-11 07:57:20: Loss at step 5308: 0.03691459819674492\n",
      "2017-11-11 07:57:23: Loss at step 5309: 0.03679467737674713\n",
      "2017-11-11 07:57:25: Loss at step 5310: 0.03683741018176079\n",
      "2017-11-11 07:57:27: Loss at step 5311: 0.036798540502786636\n",
      "2017-11-11 07:57:29: Loss at step 5312: 0.03673071414232254\n",
      "2017-11-11 07:57:31: Loss at step 5313: 0.03680189326405525\n",
      "2017-11-11 07:57:33: Loss at step 5314: 0.03672581911087036\n",
      "2017-11-11 07:57:35: Loss at step 5315: 0.03676062822341919\n",
      "2017-11-11 07:57:38: Loss at step 5316: 0.036721933633089066\n",
      "2017-11-11 07:57:40: Loss at step 5317: 0.036704905331134796\n",
      "2017-11-11 07:57:42: Loss at step 5318: 0.036835551261901855\n",
      "2017-11-11 07:57:44: Loss at step 5319: 0.03674422949552536\n",
      "2017-11-11 07:57:46: Loss at step 5320: 0.03684733808040619\n",
      "2017-11-11 07:57:48: Loss at step 5321: 0.03679998964071274\n",
      "2017-11-11 07:57:50: Loss at step 5322: 0.036905501037836075\n",
      "2017-11-11 07:57:52: Loss at step 5323: 0.03677667677402496\n",
      "2017-11-11 07:57:55: Loss at step 5324: 0.03668184205889702\n",
      "2017-11-11 07:57:57: Loss at step 5325: 0.03678826987743378\n",
      "2017-11-11 07:57:59: Loss at step 5326: 0.03682888299226761\n",
      "2017-11-11 07:58:01: Loss at step 5327: 0.03680668771266937\n",
      "2017-11-11 07:58:03: Loss at step 5328: 0.03682740405201912\n",
      "2017-11-11 07:58:05: Loss at step 5329: 0.03679581731557846\n",
      "2017-11-11 07:58:07: Loss at step 5330: 0.03682710602879524\n",
      "2017-11-11 07:58:10: Loss at step 5331: 0.03680355101823807\n",
      "2017-11-11 07:58:12: Loss at step 5332: 0.036814335733652115\n",
      "2017-11-11 07:58:14: Loss at step 5333: 0.036782748997211456\n",
      "2017-11-11 07:58:16: Loss at step 5334: 0.03681540489196777\n",
      "2017-11-11 07:58:18: Loss at step 5335: 0.03671739622950554\n",
      "2017-11-11 07:58:20: Loss at step 5336: 0.03674297407269478\n",
      "2017-11-11 07:58:22: Loss at step 5337: 0.03678933531045914\n",
      "2017-11-11 07:58:25: Loss at step 5338: 0.03679101541638374\n",
      "2017-11-11 07:58:27: Loss at step 5339: 0.036832649260759354\n",
      "2017-11-11 07:58:29: Loss at step 5340: 0.036784447729587555\n",
      "2017-11-11 07:58:31: Loss at step 5341: 0.036716166883707047\n",
      "2017-11-11 07:58:33: Loss at step 5342: 0.03684326633810997\n",
      "2017-11-11 07:58:35: Loss at step 5343: 0.03682093322277069\n",
      "2017-11-11 07:58:37: Loss at step 5344: 0.036851417273283005\n",
      "2017-11-11 07:58:40: Loss at step 5345: 0.03676304593682289\n",
      "2017-11-11 07:58:42: Loss at step 5346: 0.03681571036577225\n",
      "2017-11-11 07:58:44: Loss at step 5347: 0.03673115745186806\n",
      "2017-11-11 07:58:46: Loss at step 5348: 0.03673990070819855\n",
      "2017-11-11 07:58:48: Loss at step 5349: 0.036801233887672424\n",
      "2017-11-11 07:58:50: Loss at step 5350: 0.036795295774936676\n",
      "2017-11-11 07:58:52: Loss at step 5351: 0.03675414249300957\n",
      "2017-11-11 07:58:55: Loss at step 5352: 0.03672649711370468\n",
      "2017-11-11 07:58:57: Loss at step 5353: 0.03672146424651146\n",
      "2017-11-11 07:58:59: Loss at step 5354: 0.036794982850551605\n",
      "2017-11-11 07:59:01: Loss at step 5355: 0.03674481064081192\n",
      "2017-11-11 07:59:03: Loss at step 5356: 0.036884404718875885\n",
      "2017-11-11 07:59:05: Loss at step 5357: 0.03682009130716324\n",
      "2017-11-11 07:59:07: Loss at step 5358: 0.03680087998509407\n",
      "2017-11-11 07:59:09: Loss at step 5359: 0.03679465502500534\n",
      "2017-11-11 07:59:12: Loss at step 5360: 0.0368197076022625\n",
      "2017-11-11 07:59:14: Loss at step 5361: 0.03673180565237999\n",
      "2017-11-11 07:59:16: Loss at step 5362: 0.036759257316589355\n",
      "2017-11-11 07:59:18: Loss at step 5363: 0.03679662570357323\n",
      "2017-11-11 07:59:20: Loss at step 5364: 0.03683863952755928\n",
      "2017-11-11 07:59:22: Loss at step 5365: 0.036849647760391235\n",
      "2017-11-11 07:59:24: Loss at step 5366: 0.03678043186664581\n",
      "2017-11-11 07:59:27: Loss at step 5367: 0.036820173263549805\n",
      "2017-11-11 07:59:29: Loss at step 5368: 0.03680432587862015\n",
      "2017-11-11 07:59:31: Loss at step 5369: 0.03670678660273552\n",
      "2017-11-11 07:59:33: Loss at step 5370: 0.03677838295698166\n",
      "2017-11-11 07:59:35: Loss at step 5371: 0.03680823743343353\n",
      "2017-11-11 07:59:37: Loss at step 5372: 0.03677165508270264\n",
      "2017-11-11 07:59:39: Loss at step 5373: 0.03684067726135254\n",
      "2017-11-11 07:59:42: Loss at step 5374: 0.036793503910303116\n",
      "2017-11-11 07:59:44: Loss at step 5375: 0.036730267107486725\n",
      "2017-11-11 07:59:46: Loss at step 5376: 0.03683202341198921\n",
      "2017-11-11 07:59:48: Loss at step 5377: 0.03679719939827919\n",
      "2017-11-11 07:59:50: Loss at step 5378: 0.0368865467607975\n",
      "2017-11-11 07:59:52: Loss at step 5379: 0.03679286316037178\n",
      "2017-11-11 07:59:54: Loss at step 5380: 0.036799389868974686\n",
      "2017-11-11 07:59:57: Loss at step 5381: 0.03684346377849579\n",
      "2017-11-11 07:59:59: Loss at step 5382: 0.03677287697792053\n",
      "2017-11-11 08:00:01: Loss at step 5383: 0.03683941811323166\n",
      "2017-11-11 08:00:03: Loss at step 5384: 0.03672851249575615\n",
      "2017-11-11 08:00:05: Loss at step 5385: 0.03685488551855087\n",
      "2017-11-11 08:00:07: Loss at step 5386: 0.03673338145017624\n",
      "2017-11-11 08:00:09: Loss at step 5387: 0.03674064576625824\n",
      "2017-11-11 08:00:12: Loss at step 5388: 0.03679120913147926\n",
      "2017-11-11 08:00:14: Loss at step 5389: 0.03680430352687836\n",
      "2017-11-11 08:00:16: Loss at step 5390: 0.03671708703041077\n",
      "2017-11-11 08:00:18: Loss at step 5391: 0.03674980625510216\n",
      "2017-11-11 08:00:20: Loss at step 5392: 0.03675062954425812\n",
      "2017-11-11 08:00:22: Loss at step 5393: 0.03678347170352936\n",
      "2017-11-11 08:00:24: Loss at step 5394: 0.036658111959695816\n",
      "2017-11-11 08:00:27: Loss at step 5395: 0.03673000633716583\n",
      "2017-11-11 08:00:29: Loss at step 5396: 0.03678110986948013\n",
      "2017-11-11 08:00:31: Loss at step 5397: 0.03674248605966568\n",
      "2017-11-11 08:00:33: Loss at step 5398: 0.03682790696620941\n",
      "2017-11-11 08:00:35: Loss at step 5399: 0.036798786371946335\n",
      "2017-11-11 08:00:38: Loss at step 5400: 0.036714691668748856\n",
      "2017-11-11 08:00:40: Loss at step 5401: 0.036777179688215256\n",
      "2017-11-11 08:00:42: Loss at step 5402: 0.03672010824084282\n",
      "2017-11-11 08:00:44: Loss at step 5403: 0.03684462979435921\n",
      "2017-11-11 08:00:46: Loss at step 5404: 0.03671201691031456\n",
      "2017-11-11 08:00:48: Loss at step 5405: 0.0367247574031353\n",
      "2017-11-11 08:00:50: Loss at step 5406: 0.03679122403264046\n",
      "2017-11-11 08:00:52: Loss at step 5407: 0.036821071058511734\n",
      "2017-11-11 08:00:55: Loss at step 5408: 0.03669092431664467\n",
      "2017-11-11 08:00:57: Loss at step 5409: 0.036759667098522186\n",
      "2017-11-11 08:00:59: Loss at step 5410: 0.03669776767492294\n",
      "2017-11-11 08:01:01: Loss at step 5411: 0.0367671400308609\n",
      "2017-11-11 08:01:03: Loss at step 5412: 0.0368623211979866\n",
      "2017-11-11 08:01:05: Loss at step 5413: 0.036832649260759354\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-11-11 08:01:07: Loss at step 5414: 0.03678181767463684\n",
      "2017-11-11 08:01:10: Loss at step 5415: 0.03680938854813576\n",
      "2017-11-11 08:01:12: Loss at step 5416: 0.03675444796681404\n",
      "2017-11-11 08:01:14: Loss at step 5417: 0.03679803013801575\n",
      "2017-11-11 08:01:16: Loss at step 5418: 0.03680841624736786\n",
      "2017-11-11 08:01:18: Loss at step 5419: 0.03678342327475548\n",
      "2017-11-11 08:01:21: Loss at step 5420: 0.0367349237203598\n",
      "2017-11-11 08:01:23: Loss at step 5421: 0.036759618669748306\n",
      "2017-11-11 08:01:25: Loss at step 5422: 0.036769043654203415\n",
      "2017-11-11 08:01:27: Loss at step 5423: 0.03674799203872681\n",
      "2017-11-11 08:01:29: Loss at step 5424: 0.03675438091158867\n",
      "2017-11-11 08:01:32: Loss at step 5425: 0.03683612868189812\n",
      "2017-11-11 08:01:34: Loss at step 5426: 0.036764197051525116\n",
      "2017-11-11 08:01:36: Loss at step 5427: 0.03680302947759628\n",
      "2017-11-11 08:01:38: Loss at step 5428: 0.036851417273283005\n",
      "2017-11-11 08:01:40: Loss at step 5429: 0.03684091195464134\n",
      "2017-11-11 08:01:43: Loss at step 5430: 0.03673240914940834\n",
      "2017-11-11 08:01:45: Loss at step 5431: 0.03678251430392265\n",
      "2017-11-11 08:01:47: Loss at step 5432: 0.03677034750580788\n",
      "2017-11-11 08:01:49: Loss at step 5433: 0.036713652312755585\n",
      "2017-11-11 08:01:51: Loss at step 5434: 0.0368177630007267\n",
      "2017-11-11 08:01:53: Loss at step 5435: 0.03688018023967743\n",
      "2017-11-11 08:01:56: Loss at step 5436: 0.03679916262626648\n",
      "2017-11-11 08:01:58: Loss at step 5437: 0.036873120814561844\n",
      "2017-11-11 08:02:00: Loss at step 5438: 0.03674539923667908\n",
      "2017-11-11 08:02:02: Loss at step 5439: 0.03684953600168228\n",
      "2017-11-11 08:02:04: Loss at step 5440: 0.036802686750888824\n",
      "2017-11-11 08:02:07: Loss at step 5441: 0.036806464195251465\n",
      "2017-11-11 08:02:09: Loss at step 5442: 0.03679322823882103\n",
      "2017-11-11 08:02:11: Loss at step 5443: 0.036789849400520325\n",
      "2017-11-11 08:02:13: Loss at step 5444: 0.03685294836759567\n",
      "2017-11-11 08:02:15: Loss at step 5445: 0.03677147999405861\n",
      "2017-11-11 08:02:18: Loss at step 5446: 0.03684045374393463\n",
      "2017-11-11 08:02:20: Loss at step 5447: 0.036825187504291534\n",
      "2017-11-11 08:02:22: Loss at step 5448: 0.03682193532586098\n",
      "2017-11-11 08:02:24: Loss at step 5449: 0.03676871210336685\n",
      "2017-11-11 08:02:26: Loss at step 5450: 0.03668951243162155\n",
      "2017-11-11 08:02:29: Loss at step 5451: 0.03670115768909454\n",
      "2017-11-11 08:02:31: Loss at step 5452: 0.03668282926082611\n",
      "2017-11-11 08:02:33: Loss at step 5453: 0.036776915192604065\n",
      "2017-11-11 08:02:35: Loss at step 5454: 0.03675911948084831\n",
      "2017-11-11 08:02:37: Loss at step 5455: 0.036791954189538956\n",
      "2017-11-11 08:02:39: Loss at step 5456: 0.03685496747493744\n",
      "2017-11-11 08:02:41: Loss at step 5457: 0.03686942905187607\n",
      "2017-11-11 08:02:43: Loss at step 5458: 0.036801740527153015\n",
      "2017-11-11 08:02:46: Loss at step 5459: 0.036783382296562195\n",
      "2017-11-11 08:02:48: Loss at step 5460: 0.03677473962306976\n",
      "2017-11-11 08:02:50: Loss at step 5461: 0.036767810583114624\n",
      "2017-11-11 08:02:52: Loss at step 5462: 0.03667641058564186\n",
      "2017-11-11 08:02:54: Loss at step 5463: 0.036746274679899216\n",
      "2017-11-11 08:02:56: Loss at step 5464: 0.036900587379932404\n",
      "2017-11-11 08:02:58: Loss at step 5465: 0.036805398762226105\n",
      "2017-11-11 08:03:01: Loss at step 5466: 0.03667810186743736\n",
      "2017-11-11 08:03:03: Loss at step 5467: 0.03682009130716324\n",
      "2017-11-11 08:03:05: Loss at step 5468: 0.036862727254629135\n",
      "2017-11-11 08:03:07: Loss at step 5469: 0.03678509593009949\n",
      "2017-11-11 08:03:09: Loss at step 5470: 0.036743003875017166\n",
      "2017-11-11 08:03:11: Loss at step 5471: 0.03680036962032318\n",
      "2017-11-11 08:03:13: Loss at step 5472: 0.03676421940326691\n",
      "2017-11-11 08:03:16: Loss at step 5473: 0.036771226674318314\n",
      "2017-11-11 08:03:18: Loss at step 5474: 0.03672516345977783\n",
      "2017-11-11 08:03:20: Loss at step 5475: 0.036771826446056366\n",
      "2017-11-11 08:03:22: Loss at step 5476: 0.03682094067335129\n",
      "2017-11-11 08:03:24: Loss at step 5477: 0.03665436431765556\n",
      "2017-11-11 08:03:26: Loss at step 5478: 0.03674391657114029\n",
      "2017-11-11 08:03:28: Loss at step 5479: 0.03674278408288956\n",
      "2017-11-11 08:03:31: Loss at step 5480: 0.036776103079319\n",
      "2017-11-11 08:03:33: Loss at step 5481: 0.036791130900382996\n",
      "2017-11-11 08:03:35: Loss at step 5482: 0.036675166338682175\n",
      "2017-11-11 08:03:37: Loss at step 5483: 0.0367836132645607\n",
      "2017-11-11 08:03:39: Loss at step 5484: 0.03681066259741783\n",
      "2017-11-11 08:03:41: Loss at step 5485: 0.03680785745382309\n",
      "2017-11-11 08:03:43: Loss at step 5486: 0.03669634461402893\n",
      "2017-11-11 08:03:45: Loss at step 5487: 0.03684172406792641\n",
      "2017-11-11 08:03:48: Loss at step 5488: 0.0367451012134552\n",
      "2017-11-11 08:03:50: Loss at step 5489: 0.036748386919498444\n",
      "2017-11-11 08:03:52: Loss at step 5490: 0.03676531836390495\n",
      "2017-11-11 08:03:54: Loss at step 5491: 0.03680223226547241\n",
      "2017-11-11 08:03:56: Loss at step 5492: 0.03680728003382683\n",
      "2017-11-11 08:03:58: Loss at step 5493: 0.036858879029750824\n",
      "2017-11-11 08:04:00: Loss at step 5494: 0.03675009310245514\n",
      "2017-11-11 08:04:03: Loss at step 5495: 0.03675050288438797\n",
      "2017-11-11 08:04:05: Loss at step 5496: 0.036755647510290146\n",
      "2017-11-11 08:04:07: Loss at step 5497: 0.03673773631453514\n",
      "2017-11-11 08:04:09: Loss at step 5498: 0.03675134479999542\n",
      "2017-11-11 08:04:11: Loss at step 5499: 0.03672624006867409\n",
      "2017-11-11 08:04:13: Loss at step 5500: 0.036775946617126465\n",
      "2017-11-11 08:04:15: Loss at step 5501: 0.03684525191783905\n",
      "2017-11-11 08:04:18: Loss at step 5502: 0.036772578954696655\n",
      "2017-11-11 08:04:20: Loss at step 5503: 0.0367368645966053\n",
      "2017-11-11 08:04:22: Loss at step 5504: 0.03689400479197502\n",
      "2017-11-11 08:04:24: Loss at step 5505: 0.036831408739089966\n",
      "2017-11-11 08:04:26: Loss at step 5506: 0.03676464408636093\n",
      "2017-11-11 08:04:28: Loss at step 5507: 0.03673043102025986\n",
      "2017-11-11 08:04:31: Loss at step 5508: 0.03677539527416229\n",
      "2017-11-11 08:04:33: Loss at step 5509: 0.03682822734117508\n",
      "2017-11-11 08:04:35: Loss at step 5510: 0.03687387704849243\n",
      "2017-11-11 08:04:37: Loss at step 5511: 0.036759499460458755\n",
      "2017-11-11 08:04:39: Loss at step 5512: 0.036861058324575424\n",
      "2017-11-11 08:04:41: Loss at step 5513: 0.0367218554019928\n",
      "2017-11-11 08:04:43: Loss at step 5514: 0.03687397018074989\n",
      "2017-11-11 08:04:45: Loss at step 5515: 0.03677546977996826\n",
      "2017-11-11 08:04:48: Loss at step 5516: 0.03685682266950607\n",
      "2017-11-11 08:04:50: Loss at step 5517: 0.03677918016910553\n",
      "2017-11-11 08:04:52: Loss at step 5518: 0.03686782345175743\n",
      "2017-11-11 08:04:54: Loss at step 5519: 0.036762550473213196\n",
      "2017-11-11 08:04:56: Loss at step 5520: 0.03673391044139862\n",
      "2017-11-11 08:04:58: Loss at step 5521: 0.03675520047545433\n",
      "2017-11-11 08:05:00: Loss at step 5522: 0.03680802136659622\n",
      "2017-11-11 08:05:03: Loss at step 5523: 0.036775246262550354\n",
      "2017-11-11 08:05:05: Loss at step 5524: 0.03669963404536247\n",
      "2017-11-11 08:05:07: Loss at step 5525: 0.036697011440992355\n",
      "2017-11-11 08:05:09: Loss at step 5526: 0.036700185388326645\n",
      "2017-11-11 08:05:11: Loss at step 5527: 0.03682711347937584\n",
      "2017-11-11 08:05:13: Loss at step 5528: 0.0367186963558197\n",
      "2017-11-11 08:05:15: Loss at step 5529: 0.03676830604672432\n",
      "2017-11-11 08:05:18: Loss at step 5530: 0.03672187030315399\n",
      "2017-11-11 08:05:20: Loss at step 5531: 0.036831747740507126\n",
      "2017-11-11 08:05:22: Loss at step 5532: 0.03680478408932686\n",
      "2017-11-11 08:05:24: Loss at step 5533: 0.036837439984083176\n",
      "2017-11-11 08:05:26: Loss at step 5534: 0.03680429607629776\n",
      "2017-11-11 08:05:28: Loss at step 5535: 0.036749467253685\n",
      "2017-11-11 08:05:30: Loss at step 5536: 0.036749567836523056\n",
      "2017-11-11 08:05:33: Loss at step 5537: 0.036686211824417114\n",
      "2017-11-11 08:05:35: Loss at step 5538: 0.036769382655620575\n",
      "2017-11-11 08:05:37: Loss at step 5539: 0.0366760790348053\n",
      "2017-11-11 08:05:39: Loss at step 5540: 0.03666241466999054\n",
      "2017-11-11 08:05:41: Loss at step 5541: 0.03676001727581024\n",
      "2017-11-11 08:05:43: Loss at step 5542: 0.03682524338364601\n",
      "2017-11-11 08:05:46: Loss at step 5543: 0.0367741584777832\n",
      "2017-11-11 08:05:48: Loss at step 5544: 0.036746565252542496\n",
      "2017-11-11 08:05:50: Loss at step 5545: 0.03680209815502167\n",
      "2017-11-11 08:05:52: Loss at step 5546: 0.036762822419404984\n",
      "2017-11-11 08:05:54: Loss at step 5547: 0.0368107333779335\n",
      "2017-11-11 08:05:56: Loss at step 5548: 0.03675464913249016\n",
      "2017-11-11 08:05:58: Loss at step 5549: 0.03678453341126442\n",
      "2017-11-11 08:06:01: Loss at step 5550: 0.036677099764347076\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-11-11 08:06:03: Loss at step 5551: 0.036704663187265396\n",
      "2017-11-11 08:06:05: Loss at step 5552: 0.036715950816869736\n",
      "2017-11-11 08:06:07: Loss at step 5553: 0.036708857864141464\n",
      "2017-11-11 08:06:09: Loss at step 5554: 0.03671044111251831\n",
      "2017-11-11 08:06:11: Loss at step 5555: 0.03673554211854935\n",
      "2017-11-11 08:06:13: Loss at step 5556: 0.03674839437007904\n",
      "2017-11-11 08:06:16: Loss at step 5557: 0.0367605984210968\n",
      "2017-11-11 08:06:18: Loss at step 5558: 0.036808136850595474\n",
      "2017-11-11 08:06:20: Loss at step 5559: 0.036758940666913986\n",
      "2017-11-11 08:06:22: Loss at step 5560: 0.03677215427160263\n",
      "2017-11-11 08:06:24: Loss at step 5561: 0.036749131977558136\n",
      "2017-11-11 08:06:26: Loss at step 5562: 0.036733854562044144\n",
      "2017-11-11 08:06:29: Loss at step 5563: 0.03674313426017761\n",
      "2017-11-11 08:06:31: Loss at step 5564: 0.03674943372607231\n",
      "2017-11-11 08:06:33: Loss at step 5565: 0.03677045926451683\n",
      "2017-11-11 08:06:35: Loss at step 5566: 0.036753296852111816\n",
      "2017-11-11 08:06:37: Loss at step 5567: 0.03674415498971939\n",
      "2017-11-11 08:06:39: Loss at step 5568: 0.03677783161401749\n",
      "2017-11-11 08:06:41: Loss at step 5569: 0.03675990551710129\n",
      "2017-11-11 08:06:44: Loss at step 5570: 0.03664136305451393\n",
      "2017-11-11 08:06:46: Loss at step 5571: 0.03676920011639595\n",
      "2017-11-11 08:06:48: Loss at step 5572: 0.03672562912106514\n",
      "2017-11-11 08:06:50: Loss at step 5573: 0.03670201450586319\n",
      "2017-11-11 08:06:52: Loss at step 5574: 0.03677643835544586\n",
      "2017-11-11 08:06:54: Loss at step 5575: 0.036802440881729126\n",
      "2017-11-11 08:06:57: Loss at step 5576: 0.036653321236371994\n",
      "2017-11-11 08:06:59: Loss at step 5577: 0.03670521825551987\n",
      "2017-11-11 08:07:01: Loss at step 5578: 0.03678479790687561\n",
      "2017-11-11 08:07:03: Loss at step 5579: 0.03667005896568298\n",
      "2017-11-11 08:07:05: Loss at step 5580: 0.03668710216879845\n",
      "2017-11-11 08:07:07: Loss at step 5581: 0.03671763837337494\n",
      "2017-11-11 08:07:10: Loss at step 5582: 0.036726441234350204\n",
      "2017-11-11 08:07:12: Loss at step 5583: 0.036724720150232315\n",
      "2017-11-11 08:07:14: Loss at step 5584: 0.036777064204216\n",
      "2017-11-11 08:07:16: Loss at step 5585: 0.03673578053712845\n",
      "2017-11-11 08:07:18: Loss at step 5586: 0.036807335913181305\n",
      "2017-11-11 08:07:20: Loss at step 5587: 0.03670385852456093\n",
      "2017-11-11 08:07:22: Loss at step 5588: 0.036799103021621704\n",
      "2017-11-11 08:07:25: Loss at step 5589: 0.036803968250751495\n",
      "2017-11-11 08:07:27: Loss at step 5590: 0.03676148131489754\n",
      "2017-11-11 08:07:29: Loss at step 5591: 0.03671599552035332\n",
      "2017-11-11 08:07:31: Loss at step 5592: 0.03679654747247696\n",
      "2017-11-11 08:07:33: Loss at step 5593: 0.03683725371956825\n",
      "2017-11-11 08:07:35: Loss at step 5594: 0.0367487296462059\n",
      "2017-11-11 08:07:38: Loss at step 5595: 0.03670863062143326\n",
      "2017-11-11 08:07:40: Loss at step 5596: 0.03676340728998184\n",
      "2017-11-11 08:07:42: Loss at step 5597: 0.03676125407218933\n",
      "2017-11-11 08:07:44: Loss at step 5598: 0.03684568032622337\n",
      "2017-11-11 08:07:46: Loss at step 5599: 0.03666790947318077\n",
      "2017-11-11 08:07:48: Loss at step 5600: 0.036727793514728546\n",
      "2017-11-11 08:07:51: Loss at step 5601: 0.03674826771020889\n",
      "2017-11-11 08:07:53: Loss at step 5602: 0.03675707429647446\n",
      "2017-11-11 08:07:55: Loss at step 5603: 0.03673906251788139\n",
      "2017-11-11 08:07:57: Loss at step 5604: 0.036763038486242294\n",
      "2017-11-11 08:07:59: Loss at step 5605: 0.03678445890545845\n",
      "2017-11-11 08:08:01: Loss at step 5606: 0.03668863698840141\n",
      "2017-11-11 08:08:04: Loss at step 5607: 0.036807987838983536\n",
      "2017-11-11 08:08:06: Loss at step 5608: 0.03683707118034363\n",
      "2017-11-11 08:08:08: Loss at step 5609: 0.036740776151418686\n",
      "2017-11-11 08:08:10: Loss at step 5610: 0.03681020811200142\n",
      "2017-11-11 08:08:12: Loss at step 5611: 0.03680935502052307\n",
      "2017-11-11 08:08:14: Loss at step 5612: 0.03685489669442177\n",
      "2017-11-11 08:08:16: Loss at step 5613: 0.03678383678197861\n",
      "2017-11-11 08:08:19: Loss at step 5614: 0.036765098571777344\n",
      "2017-11-11 08:08:21: Loss at step 5615: 0.03676613047719002\n",
      "2017-11-11 08:08:23: Loss at step 5616: 0.03675909712910652\n",
      "2017-11-11 08:08:25: Loss at step 5617: 0.03684287145733833\n",
      "2017-11-11 08:08:27: Loss at step 5618: 0.0368240587413311\n",
      "2017-11-11 08:08:30: Loss at step 5619: 0.036876924335956573\n",
      "2017-11-11 08:08:32: Loss at step 5620: 0.03677757456898689\n",
      "2017-11-11 08:08:34: Loss at step 5621: 0.03671211376786232\n",
      "2017-11-11 08:08:36: Loss at step 5622: 0.03685671091079712\n",
      "2017-11-11 08:08:38: Loss at step 5623: 0.03672581911087036\n",
      "2017-11-11 08:08:40: Loss at step 5624: 0.036830224096775055\n",
      "2017-11-11 08:08:43: Loss at step 5625: 0.03678128495812416\n",
      "2017-11-11 08:08:45: Loss at step 5626: 0.036819230765104294\n",
      "2017-11-11 08:08:47: Loss at step 5627: 0.036821674555540085\n",
      "2017-11-11 08:08:49: Loss at step 5628: 0.036779798567295074\n",
      "2017-11-11 08:08:51: Loss at step 5629: 0.03683501482009888\n",
      "2017-11-11 08:08:53: Loss at step 5630: 0.03680667653679848\n",
      "2017-11-11 08:08:55: Loss at step 5631: 0.03677698224782944\n",
      "2017-11-11 08:08:58: Loss at step 5632: 0.03678010776638985\n",
      "2017-11-11 08:09:00: Loss at step 5633: 0.03682740405201912\n",
      "2017-11-11 08:09:02: Loss at step 5634: 0.03679313883185387\n",
      "2017-11-11 08:09:04: Loss at step 5635: 0.036708470433950424\n",
      "2017-11-11 08:09:06: Loss at step 5636: 0.03682165592908859\n",
      "2017-11-11 08:09:08: Loss at step 5637: 0.036759596318006516\n",
      "2017-11-11 08:09:11: Loss at step 5638: 0.03687768429517746\n",
      "2017-11-11 08:09:13: Loss at step 5639: 0.03687041997909546\n",
      "2017-11-11 08:09:15: Loss at step 5640: 0.03678826615214348\n",
      "2017-11-11 08:09:17: Loss at step 5641: 0.03680019453167915\n",
      "2017-11-11 08:09:19: Loss at step 5642: 0.03680286929011345\n",
      "2017-11-11 08:09:22: Loss at step 5643: 0.03689732402563095\n",
      "2017-11-11 08:09:24: Loss at step 5644: 0.03677026927471161\n",
      "2017-11-11 08:09:26: Loss at step 5645: 0.036832116544246674\n",
      "2017-11-11 08:09:28: Loss at step 5646: 0.03678639978170395\n",
      "2017-11-11 08:09:31: Loss at step 5647: 0.036773983389139175\n",
      "2017-11-11 08:09:33: Loss at step 5648: 0.036797016859054565\n",
      "2017-11-11 08:09:35: Loss at step 5649: 0.03678516671061516\n",
      "2017-11-11 08:09:37: Loss at step 5650: 0.03688030317425728\n",
      "2017-11-11 08:09:39: Loss at step 5651: 0.036763180047273636\n",
      "2017-11-11 08:09:41: Loss at step 5652: 0.03681254759430885\n",
      "2017-11-11 08:09:44: Loss at step 5653: 0.03679566830396652\n",
      "2017-11-11 08:09:46: Loss at step 5654: 0.036805473268032074\n",
      "2017-11-11 08:09:48: Loss at step 5655: 0.03677114099264145\n",
      "2017-11-11 08:09:50: Loss at step 5656: 0.036826685070991516\n",
      "2017-11-11 08:09:52: Loss at step 5657: 0.036870237439870834\n",
      "2017-11-11 08:09:54: Loss at step 5658: 0.03683779016137123\n",
      "2017-11-11 08:09:57: Loss at step 5659: 0.036821525543928146\n",
      "2017-11-11 08:09:59: Loss at step 5660: 0.03680982068181038\n",
      "2017-11-11 08:10:01: Loss at step 5661: 0.036773502826690674\n",
      "2017-11-11 08:10:03: Loss at step 5662: 0.03670340031385422\n",
      "2017-11-11 08:10:05: Loss at step 5663: 0.03673935681581497\n",
      "2017-11-11 08:10:08: Loss at step 5664: 0.036801017820835114\n",
      "2017-11-11 08:10:10: Loss at step 5665: 0.03679271042346954\n",
      "2017-11-11 08:10:12: Loss at step 5666: 0.03678647801280022\n",
      "2017-11-11 08:10:14: Loss at step 5667: 0.03672993928194046\n",
      "2017-11-11 08:10:16: Loss at step 5668: 0.03678256645798683\n",
      "2017-11-11 08:10:19: Loss at step 5669: 0.036807116121053696\n",
      "2017-11-11 08:10:21: Loss at step 5670: 0.03680858388543129\n",
      "2017-11-11 08:10:23: Loss at step 5671: 0.036772601306438446\n",
      "2017-11-11 08:10:25: Loss at step 5672: 0.0368739515542984\n",
      "2017-11-11 08:10:28: Loss at step 5673: 0.03678349405527115\n",
      "2017-11-11 08:10:30: Loss at step 5674: 0.03684007748961449\n",
      "2017-11-11 08:10:32: Loss at step 5675: 0.03689979389309883\n",
      "2017-11-11 08:10:34: Loss at step 5676: 0.03681020066142082\n",
      "2017-11-11 08:10:36: Loss at step 5677: 0.03683831915259361\n",
      "2017-11-11 08:10:39: Loss at step 5678: 0.0368368923664093\n",
      "2017-11-11 08:10:41: Loss at step 5679: 0.036797896027565\n",
      "2017-11-11 08:10:43: Loss at step 5680: 0.036860961467027664\n",
      "2017-11-11 08:10:45: Loss at step 5681: 0.03686593100428581\n",
      "2017-11-11 08:10:47: Loss at step 5682: 0.03683322295546532\n",
      "2017-11-11 08:10:49: Loss at step 5683: 0.036869652569293976\n",
      "2017-11-11 08:10:52: Loss at step 5684: 0.03678327053785324\n",
      "2017-11-11 08:10:54: Loss at step 5685: 0.03686157986521721\n",
      "2017-11-11 08:10:56: Loss at step 5686: 0.03683876991271973\n",
      "2017-11-11 08:10:58: Loss at step 5687: 0.036707356572151184\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-11-11 08:11:00: Loss at step 5688: 0.03686915710568428\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-4ebaaf5d30d0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0miteration\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3501\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1000001\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mx_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext_training_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_on_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'{0}: Loss at step {1}: {2}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrftime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"%Y-%m-%d %H:%M:%S\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miteration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'{0}/training_data/x_batch-{1}.npy'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msavePath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miteration\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-be9295578f83>\u001b[0m in \u001b[0;36mnext_training_batch\u001b[0;34m(n)\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mnext_training_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0mboards\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpool\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrandomBoard\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m     \u001b[0mcounts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpool\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mboardPartialMineCounts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mboards\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m     \u001b[0mbatch_xs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpool\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencodeCountsOneHot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcounts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0mbatch_ys\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpool\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalidGuesses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mboards\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcounts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36mmap\u001b[0;34m(self, func, iterable, chunksize)\u001b[0m\n\u001b[1;32m    264\u001b[0m         \u001b[0;32min\u001b[0m \u001b[0ma\u001b[0m \u001b[0mlist\u001b[0m \u001b[0mthat\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mreturned\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m         '''\n\u001b[0;32m--> 266\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_map_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmapstar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunksize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    267\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    268\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstarmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunksize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    637\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 638\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    639\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mready\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    640\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    633\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    634\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 635\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_event\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    637\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    549\u001b[0m             \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flag\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    550\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 551\u001b[0;31m                 \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    552\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    553\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    293\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 295\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    296\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for iteration in range(3501,1000001):\n",
    "    x_batch, y_batch, _ = next_training_batch(10000)\n",
    "    loss = model.train_on_batch(np.array(x_batch), np.array(y_batch))\n",
    "    print('{0}: Loss at step {1}: {2}'.format(dt.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"), iteration, loss))\n",
    "    np.save('{0}/training_data/x_batch-{1}.npy'.format(savePath, iteration), np.array(x_batch))\n",
    "    np.save('{0}/training_data/y_batch-{1}.npy'.format(savePath, iteration), np.array(y_batch))\n",
    "    if iteration % 500 == 0:\n",
    "        model.save('{0}/model-{1}.h5'.format(savePath, iteration))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_training_batch(n):\n",
    "    x_batch = np.load('{0}/training_data/x_batch-{1}.npy'.format(savePath, n))\n",
    "    y_batch = np.load('{0}/training_data/y_batch-{1}.npy'.format(savePath, n))\n",
    "    return (x_batch, y_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-11-11 08:13:21: Loss at step 5689: 0.03686288744211197\n",
      "2017-11-11 08:13:22: Loss at step 5690: 0.036672044545412064\n",
      "2017-11-11 08:13:23: Loss at step 5691: 0.0370478555560112\n",
      "2017-11-11 08:13:23: Loss at step 5692: 0.03694919869303703\n",
      "2017-11-11 08:13:24: Loss at step 5693: 0.03681319206953049\n",
      "2017-11-11 08:13:24: Loss at step 5694: 0.03692269325256348\n",
      "2017-11-11 08:13:25: Loss at step 5695: 0.03690475970506668\n",
      "2017-11-11 08:13:25: Loss at step 5696: 0.03696698695421219\n",
      "2017-11-11 08:13:26: Loss at step 5697: 0.03687051311135292\n",
      "2017-11-11 08:13:26: Loss at step 5698: 0.03680562227964401\n",
      "2017-11-11 08:13:27: Loss at step 5699: 0.03691377490758896\n",
      "2017-11-11 08:13:27: Loss at step 5700: 0.03687459975481033\n",
      "2017-11-11 08:13:28: Loss at step 5701: 0.03696953132748604\n",
      "2017-11-11 08:13:28: Loss at step 5702: 0.0369834341108799\n",
      "2017-11-11 08:13:29: Loss at step 5703: 0.036900438368320465\n",
      "2017-11-11 08:13:29: Loss at step 5704: 0.0368473194539547\n",
      "2017-11-11 08:13:30: Loss at step 5705: 0.0369408018887043\n",
      "2017-11-11 08:13:30: Loss at step 5706: 0.0369722880423069\n",
      "2017-11-11 08:13:31: Loss at step 5707: 0.0368988998234272\n",
      "2017-11-11 08:13:31: Loss at step 5708: 0.03693779930472374\n",
      "2017-11-11 08:13:32: Loss at step 5709: 0.03689481317996979\n",
      "2017-11-11 08:13:32: Loss at step 5710: 0.036865755915641785\n",
      "2017-11-11 08:13:33: Loss at step 5711: 0.036788392812013626\n",
      "2017-11-11 08:13:33: Loss at step 5712: 0.036989327520132065\n",
      "2017-11-11 08:13:34: Loss at step 5713: 0.03696873039007187\n",
      "2017-11-11 08:13:34: Loss at step 5714: 0.03688075393438339\n",
      "2017-11-11 08:13:35: Loss at step 5715: 0.036872681230306625\n",
      "2017-11-11 08:13:35: Loss at step 5716: 0.03690873086452484\n",
      "2017-11-11 08:13:36: Loss at step 5717: 0.03687874227762222\n",
      "2017-11-11 08:13:36: Loss at step 5718: 0.036763016134500504\n",
      "2017-11-11 08:13:37: Loss at step 5719: 0.03694196045398712\n",
      "2017-11-11 08:13:37: Loss at step 5720: 0.03689658269286156\n",
      "2017-11-11 08:13:38: Loss at step 5721: 0.03692753240466118\n",
      "2017-11-11 08:13:38: Loss at step 5722: 0.03694750741124153\n",
      "2017-11-11 08:13:39: Loss at step 5723: 0.0367942750453949\n",
      "2017-11-11 08:13:39: Loss at step 5724: 0.03683285415172577\n",
      "2017-11-11 08:13:40: Loss at step 5725: 0.03687180578708649\n",
      "2017-11-11 08:13:40: Loss at step 5726: 0.03678714111447334\n",
      "2017-11-11 08:13:41: Loss at step 5727: 0.0368400439620018\n",
      "2017-11-11 08:13:41: Loss at step 5728: 0.036968812346458435\n",
      "2017-11-11 08:13:42: Loss at step 5729: 0.03682686761021614\n",
      "2017-11-11 08:13:42: Loss at step 5730: 0.03696451336145401\n",
      "2017-11-11 08:13:43: Loss at step 5731: 0.036890577524900436\n",
      "2017-11-11 08:13:43: Loss at step 5732: 0.03677411004900932\n",
      "2017-11-11 08:13:44: Loss at step 5733: 0.03677870333194733\n",
      "2017-11-11 08:13:44: Loss at step 5734: 0.036796145141124725\n",
      "2017-11-11 08:13:45: Loss at step 5735: 0.0367467999458313\n",
      "2017-11-11 08:13:45: Loss at step 5736: 0.03672822192311287\n",
      "2017-11-11 08:13:46: Loss at step 5737: 0.03672946244478226\n",
      "2017-11-11 08:13:46: Loss at step 5738: 0.036853037774562836\n",
      "2017-11-11 08:13:47: Loss at step 5739: 0.03676074743270874\n",
      "2017-11-11 08:13:47: Loss at step 5740: 0.03677909076213837\n",
      "2017-11-11 08:13:48: Loss at step 5741: 0.03675871342420578\n",
      "2017-11-11 08:13:48: Loss at step 5742: 0.03683329001069069\n",
      "2017-11-11 08:13:49: Loss at step 5743: 0.03680935502052307\n",
      "2017-11-11 08:13:49: Loss at step 5744: 0.036747224628925323\n",
      "2017-11-11 08:13:50: Loss at step 5745: 0.03675027936697006\n",
      "2017-11-11 08:13:50: Loss at step 5746: 0.036728717386722565\n",
      "2017-11-11 08:13:51: Loss at step 5747: 0.036776188760995865\n",
      "2017-11-11 08:13:51: Loss at step 5748: 0.03673359006643295\n",
      "2017-11-11 08:13:52: Loss at step 5749: 0.03678261116147041\n",
      "2017-11-11 08:13:52: Loss at step 5750: 0.036727193742990494\n",
      "2017-11-11 08:13:53: Loss at step 5751: 0.03668581694364548\n",
      "2017-11-11 08:13:53: Loss at step 5752: 0.03679009899497032\n",
      "2017-11-11 08:13:54: Loss at step 5753: 0.03674862161278725\n",
      "2017-11-11 08:13:54: Loss at step 5754: 0.036770280450582504\n",
      "2017-11-11 08:13:55: Loss at step 5755: 0.03669526427984238\n",
      "2017-11-11 08:13:55: Loss at step 5756: 0.03679676353931427\n",
      "2017-11-11 08:13:56: Loss at step 5757: 0.036756232380867004\n",
      "2017-11-11 08:13:56: Loss at step 5758: 0.036727339029312134\n",
      "2017-11-11 08:13:57: Loss at step 5759: 0.03674883022904396\n",
      "2017-11-11 08:13:57: Loss at step 5760: 0.03661199286580086\n",
      "2017-11-11 08:13:58: Loss at step 5761: 0.03677501529455185\n",
      "2017-11-11 08:13:58: Loss at step 5762: 0.03680412471294403\n",
      "2017-11-11 08:13:59: Loss at step 5763: 0.036786921322345734\n",
      "2017-11-11 08:13:59: Loss at step 5764: 0.03670552000403404\n",
      "2017-11-11 08:14:00: Loss at step 5765: 0.03673046827316284\n",
      "2017-11-11 08:14:00: Loss at step 5766: 0.036733631044626236\n",
      "2017-11-11 08:14:01: Loss at step 5767: 0.036702509969472885\n",
      "2017-11-11 08:14:01: Loss at step 5768: 0.03675076737999916\n",
      "2017-11-11 08:14:02: Loss at step 5769: 0.036805056035518646\n",
      "2017-11-11 08:14:02: Loss at step 5770: 0.036702711135149\n",
      "2017-11-11 08:14:03: Loss at step 5771: 0.03667079284787178\n",
      "2017-11-11 08:14:03: Loss at step 5772: 0.03671273589134216\n",
      "2017-11-11 08:14:04: Loss at step 5773: 0.0366617813706398\n",
      "2017-11-11 08:14:04: Loss at step 5774: 0.0366227887570858\n",
      "2017-11-11 08:14:05: Loss at step 5775: 0.036647576838731766\n",
      "2017-11-11 08:14:05: Loss at step 5776: 0.0367274172604084\n",
      "2017-11-11 08:14:06: Loss at step 5777: 0.03673883527517319\n",
      "2017-11-11 08:14:06: Loss at step 5778: 0.03681967034935951\n",
      "2017-11-11 08:14:07: Loss at step 5779: 0.03676968440413475\n",
      "2017-11-11 08:14:07: Loss at step 5780: 0.03683271259069443\n",
      "2017-11-11 08:14:08: Loss at step 5781: 0.036760929971933365\n",
      "2017-11-11 08:14:08: Loss at step 5782: 0.03677571564912796\n",
      "2017-11-11 08:14:09: Loss at step 5783: 0.0366896316409111\n",
      "2017-11-11 08:14:09: Loss at step 5784: 0.03673014044761658\n",
      "2017-11-11 08:14:10: Loss at step 5785: 0.03670518845319748\n",
      "2017-11-11 08:14:10: Loss at step 5786: 0.036602120846509933\n",
      "2017-11-11 08:14:11: Loss at step 5787: 0.03673321381211281\n",
      "2017-11-11 08:14:11: Loss at step 5788: 0.03684303164482117\n",
      "2017-11-11 08:14:12: Loss at step 5789: 0.036897897720336914\n",
      "2017-11-11 08:14:12: Loss at step 5790: 0.03678872063755989\n",
      "2017-11-11 08:14:13: Loss at step 5791: 0.03676421567797661\n",
      "2017-11-11 08:14:13: Loss at step 5792: 0.03685058653354645\n",
      "2017-11-11 08:14:13: Loss at step 5793: 0.036755841225385666\n",
      "2017-11-11 08:14:14: Loss at step 5794: 0.03676069527864456\n",
      "2017-11-11 08:14:14: Loss at step 5795: 0.036805473268032074\n",
      "2017-11-11 08:14:15: Loss at step 5796: 0.03683672472834587\n",
      "2017-11-11 08:14:15: Loss at step 5797: 0.03672697767615318\n",
      "2017-11-11 08:14:16: Loss at step 5798: 0.03670239448547363\n",
      "2017-11-11 08:14:16: Loss at step 5799: 0.03685688227415085\n",
      "2017-11-11 08:14:17: Loss at step 5800: 0.036792926490306854\n",
      "2017-11-11 08:14:17: Loss at step 5801: 0.03669513761997223\n",
      "2017-11-11 08:14:18: Loss at step 5802: 0.03669116646051407\n",
      "2017-11-11 08:14:18: Loss at step 5803: 0.03662542998790741\n",
      "2017-11-11 08:14:19: Loss at step 5804: 0.036675166338682175\n",
      "2017-11-11 08:14:19: Loss at step 5805: 0.03661338612437248\n",
      "2017-11-11 08:14:20: Loss at step 5806: 0.03669653832912445\n",
      "2017-11-11 08:14:20: Loss at step 5807: 0.03673478588461876\n",
      "2017-11-11 08:14:21: Loss at step 5808: 0.03666853904724121\n",
      "2017-11-11 08:14:21: Loss at step 5809: 0.03670434653759003\n",
      "2017-11-11 08:14:22: Loss at step 5810: 0.03664695471525192\n",
      "2017-11-11 08:14:22: Loss at step 5811: 0.03661893308162689\n",
      "2017-11-11 08:14:23: Loss at step 5812: 0.03658832237124443\n",
      "2017-11-11 08:14:23: Loss at step 5813: 0.03670290485024452\n",
      "2017-11-11 08:14:24: Loss at step 5814: 0.03681284934282303\n",
      "2017-11-11 08:14:24: Loss at step 5815: 0.03671060875058174\n",
      "2017-11-11 08:14:25: Loss at step 5816: 0.03667139261960983\n",
      "2017-11-11 08:14:25: Loss at step 5817: 0.03665926679968834\n",
      "2017-11-11 08:14:26: Loss at step 5818: 0.0368136465549469\n",
      "2017-11-11 08:14:27: Loss at step 5819: 0.03678645193576813\n",
      "2017-11-11 08:14:27: Loss at step 5820: 0.03679266199469566\n",
      "2017-11-11 08:14:27: Loss at step 5821: 0.036832090467214584\n",
      "2017-11-11 08:14:28: Loss at step 5822: 0.03680577501654625\n",
      "2017-11-11 08:14:28: Loss at step 5823: 0.03676941618323326\n",
      "2017-11-11 08:14:29: Loss at step 5824: 0.036787860095500946\n",
      "2017-11-11 08:14:29: Loss at step 5825: 0.03676075488328934\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-11-11 08:14:30: Loss at step 5826: 0.03682434558868408\n",
      "2017-11-11 08:14:30: Loss at step 5827: 0.036747876554727554\n",
      "2017-11-11 08:14:31: Loss at step 5828: 0.03680802881717682\n",
      "2017-11-11 08:14:31: Loss at step 5829: 0.03678087890148163\n",
      "2017-11-11 08:14:32: Loss at step 5830: 0.036744508892297745\n",
      "2017-11-11 08:14:33: Loss at step 5831: 0.03661902993917465\n",
      "2017-11-11 08:14:33: Loss at step 5832: 0.036719586700201035\n",
      "2017-11-11 08:14:33: Loss at step 5833: 0.036882203072309494\n",
      "2017-11-11 08:14:34: Loss at step 5834: 0.03679104149341583\n",
      "2017-11-11 08:14:34: Loss at step 5835: 0.03681955114006996\n",
      "2017-11-11 08:14:35: Loss at step 5836: 0.03679773956537247\n",
      "2017-11-11 08:14:35: Loss at step 5837: 0.03674037382006645\n",
      "2017-11-11 08:14:36: Loss at step 5838: 0.03679310157895088\n",
      "2017-11-11 08:14:36: Loss at step 5839: 0.03688318654894829\n",
      "2017-11-11 08:14:37: Loss at step 5840: 0.03688572719693184\n",
      "2017-11-11 08:14:37: Loss at step 5841: 0.036754291504621506\n",
      "2017-11-11 08:14:38: Loss at step 5842: 0.03670056164264679\n",
      "2017-11-11 08:14:39: Loss at step 5843: 0.03667586296796799\n",
      "2017-11-11 08:14:39: Loss at step 5844: 0.03671184554696083\n",
      "2017-11-11 08:14:40: Loss at step 5845: 0.03680852800607681\n",
      "2017-11-11 08:14:40: Loss at step 5846: 0.03684716671705246\n",
      "2017-11-11 08:14:41: Loss at step 5847: 0.036781467497348785\n",
      "2017-11-11 08:14:41: Loss at step 5848: 0.036756254732608795\n",
      "2017-11-11 08:14:41: Loss at step 5849: 0.03675726801156998\n",
      "2017-11-11 08:14:42: Loss at step 5850: 0.03673499450087547\n",
      "2017-11-11 08:14:42: Loss at step 5851: 0.03670571371912956\n",
      "2017-11-11 08:14:43: Loss at step 5852: 0.03675784170627594\n",
      "2017-11-11 08:14:44: Loss at step 5853: 0.03680270165205002\n",
      "2017-11-11 08:14:44: Loss at step 5854: 0.036746665835380554\n",
      "2017-11-11 08:14:45: Loss at step 5855: 0.036660026758909225\n",
      "2017-11-11 08:14:45: Loss at step 5856: 0.03665053844451904\n",
      "2017-11-11 08:14:46: Loss at step 5857: 0.03660952299833298\n",
      "2017-11-11 08:14:46: Loss at step 5858: 0.03670891001820564\n",
      "2017-11-11 08:14:47: Loss at step 5859: 0.0367552749812603\n",
      "2017-11-11 08:14:47: Loss at step 5860: 0.036815181374549866\n",
      "2017-11-11 08:14:47: Loss at step 5861: 0.03675709292292595\n",
      "2017-11-11 08:14:48: Loss at step 5862: 0.036740757524967194\n",
      "2017-11-11 08:14:49: Loss at step 5863: 0.03669246658682823\n",
      "2017-11-11 08:14:49: Loss at step 5864: 0.036695368587970734\n",
      "2017-11-11 08:14:49: Loss at step 5865: 0.03680802881717682\n",
      "2017-11-11 08:14:50: Loss at step 5866: 0.03680013492703438\n",
      "2017-11-11 08:14:50: Loss at step 5867: 0.03681022301316261\n",
      "2017-11-11 08:14:51: Loss at step 5868: 0.03660904988646507\n",
      "2017-11-11 08:14:51: Loss at step 5869: 0.036622583866119385\n",
      "2017-11-11 08:14:52: Loss at step 5870: 0.036826834082603455\n",
      "2017-11-11 08:14:52: Loss at step 5871: 0.036775317043066025\n",
      "2017-11-11 08:14:53: Loss at step 5872: 0.03676663339138031\n",
      "2017-11-11 08:14:53: Loss at step 5873: 0.03669688105583191\n",
      "2017-11-11 08:14:54: Loss at step 5874: 0.03676507622003555\n",
      "2017-11-11 08:14:54: Loss at step 5875: 0.03670470416545868\n",
      "2017-11-11 08:14:55: Loss at step 5876: 0.036709003150463104\n",
      "2017-11-11 08:14:55: Loss at step 5877: 0.03668328374624252\n",
      "2017-11-11 08:14:56: Loss at step 5878: 0.03674168139696121\n",
      "2017-11-11 08:14:56: Loss at step 5879: 0.03674649819731712\n",
      "2017-11-11 08:14:57: Loss at step 5880: 0.03675864636898041\n",
      "2017-11-11 08:14:57: Loss at step 5881: 0.036750759929418564\n",
      "2017-11-11 08:14:58: Loss at step 5882: 0.0366012342274189\n",
      "2017-11-11 08:14:58: Loss at step 5883: 0.03669588267803192\n",
      "2017-11-11 08:14:59: Loss at step 5884: 0.03673533722758293\n",
      "2017-11-11 08:15:00: Loss at step 5885: 0.03674847260117531\n",
      "2017-11-11 08:15:00: Loss at step 5886: 0.03669023513793945\n",
      "2017-11-11 08:15:00: Loss at step 5887: 0.0367339551448822\n",
      "2017-11-11 08:15:01: Loss at step 5888: 0.03675384074449539\n",
      "2017-11-11 08:15:01: Loss at step 5889: 0.036695994436740875\n",
      "2017-11-11 08:15:02: Loss at step 5890: 0.036700598895549774\n",
      "2017-11-11 08:15:02: Loss at step 5891: 0.036736663430929184\n",
      "2017-11-11 08:15:03: Loss at step 5892: 0.036782488226890564\n",
      "2017-11-11 08:15:03: Loss at step 5893: 0.03681214526295662\n",
      "2017-11-11 08:15:04: Loss at step 5894: 0.036777883768081665\n",
      "2017-11-11 08:15:04: Loss at step 5895: 0.036813873797655106\n",
      "2017-11-11 08:15:05: Loss at step 5896: 0.03680416941642761\n",
      "2017-11-11 08:15:05: Loss at step 5897: 0.03680572286248207\n",
      "2017-11-11 08:15:06: Loss at step 5898: 0.036695774644613266\n",
      "2017-11-11 08:15:06: Loss at step 5899: 0.0367744043469429\n",
      "2017-11-11 08:15:07: Loss at step 5900: 0.036814164370298386\n",
      "2017-11-11 08:15:07: Loss at step 5901: 0.03673092648386955\n",
      "2017-11-11 08:15:08: Loss at step 5902: 0.03681247681379318\n",
      "2017-11-11 08:15:08: Loss at step 5903: 0.03681334853172302\n",
      "2017-11-11 08:15:09: Loss at step 5904: 0.03676862642168999\n",
      "2017-11-11 08:15:09: Loss at step 5905: 0.0367015115916729\n",
      "2017-11-11 08:15:10: Loss at step 5906: 0.036734357476234436\n",
      "2017-11-11 08:15:10: Loss at step 5907: 0.03675190359354019\n",
      "2017-11-11 08:15:10: Loss at step 5908: 0.03676612675189972\n",
      "2017-11-11 08:15:11: Loss at step 5909: 0.03676474094390869\n",
      "2017-11-11 08:15:12: Loss at step 5910: 0.03682539612054825\n",
      "2017-11-11 08:15:12: Loss at step 5911: 0.036909572780132294\n",
      "2017-11-11 08:15:13: Loss at step 5912: 0.0369144044816494\n",
      "2017-11-11 08:15:13: Loss at step 5913: 0.03677016496658325\n",
      "2017-11-11 08:15:13: Loss at step 5914: 0.036723438650369644\n",
      "2017-11-11 08:15:14: Loss at step 5915: 0.03670068830251694\n",
      "2017-11-11 08:15:14: Loss at step 5916: 0.03678334876894951\n",
      "2017-11-11 08:15:15: Loss at step 5917: 0.03671487420797348\n",
      "2017-11-11 08:15:15: Loss at step 5918: 0.03679503872990608\n",
      "2017-11-11 08:15:16: Loss at step 5919: 0.03673660755157471\n",
      "2017-11-11 08:15:16: Loss at step 5920: 0.03675883263349533\n",
      "2017-11-11 08:15:17: Loss at step 5921: 0.03676111623644829\n",
      "2017-11-11 08:15:17: Loss at step 5922: 0.03675561398267746\n",
      "2017-11-11 08:15:18: Loss at step 5923: 0.03675761818885803\n",
      "2017-11-11 08:15:18: Loss at step 5924: 0.03672882542014122\n",
      "2017-11-11 08:15:19: Loss at step 5925: 0.03675336390733719\n",
      "2017-11-11 08:15:19: Loss at step 5926: 0.03663507103919983\n",
      "2017-11-11 08:15:20: Loss at step 5927: 0.03666498884558678\n",
      "2017-11-11 08:15:20: Loss at step 5928: 0.03665609285235405\n",
      "2017-11-11 08:15:21: Loss at step 5929: 0.03682119399309158\n",
      "2017-11-11 08:15:21: Loss at step 5930: 0.03681611269712448\n",
      "2017-11-11 08:15:22: Loss at step 5931: 0.03671645373106003\n",
      "2017-11-11 08:15:22: Loss at step 5932: 0.036698661744594574\n",
      "2017-11-11 08:15:23: Loss at step 5933: 0.03675241395831108\n",
      "2017-11-11 08:15:23: Loss at step 5934: 0.03668418526649475\n",
      "2017-11-11 08:15:24: Loss at step 5935: 0.03675619512796402\n",
      "2017-11-11 08:15:24: Loss at step 5936: 0.0367177315056324\n",
      "2017-11-11 08:15:25: Loss at step 5937: 0.03675138205289841\n",
      "2017-11-11 08:15:25: Loss at step 5938: 0.03675832226872444\n",
      "2017-11-11 08:15:26: Loss at step 5939: 0.03669700771570206\n",
      "2017-11-11 08:15:26: Loss at step 5940: 0.03675755485892296\n",
      "2017-11-11 08:15:27: Loss at step 5941: 0.03667359799146652\n",
      "2017-11-11 08:15:27: Loss at step 5942: 0.03670060262084007\n",
      "2017-11-11 08:15:28: Loss at step 5943: 0.03666004538536072\n",
      "2017-11-11 08:15:28: Loss at step 5944: 0.036700572818517685\n",
      "2017-11-11 08:15:29: Loss at step 5945: 0.036716993898153305\n",
      "2017-11-11 08:15:29: Loss at step 5946: 0.03672747313976288\n",
      "2017-11-11 08:15:30: Loss at step 5947: 0.03672109544277191\n",
      "2017-11-11 08:15:30: Loss at step 5948: 0.03672067075967789\n",
      "2017-11-11 08:15:31: Loss at step 5949: 0.03677596524357796\n",
      "2017-11-11 08:15:31: Loss at step 5950: 0.03668056055903435\n",
      "2017-11-11 08:15:32: Loss at step 5951: 0.03666773810982704\n",
      "2017-11-11 08:15:32: Loss at step 5952: 0.03671613708138466\n",
      "2017-11-11 08:15:33: Loss at step 5953: 0.03666794300079346\n",
      "2017-11-11 08:15:33: Loss at step 5954: 0.036802250891923904\n",
      "2017-11-11 08:15:34: Loss at step 5955: 0.03681357577443123\n",
      "2017-11-11 08:15:34: Loss at step 5956: 0.03671515733003616\n",
      "2017-11-11 08:15:35: Loss at step 5957: 0.03674015402793884\n",
      "2017-11-11 08:15:35: Loss at step 5958: 0.0367659367620945\n",
      "2017-11-11 08:15:36: Loss at step 5959: 0.03679758310317993\n",
      "2017-11-11 08:15:36: Loss at step 5960: 0.036786142736673355\n",
      "2017-11-11 08:15:37: Loss at step 5961: 0.0367911197245121\n",
      "2017-11-11 08:15:37: Loss at step 5962: 0.036776959896087646\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-11-11 08:15:38: Loss at step 5963: 0.03674923628568649\n",
      "2017-11-11 08:15:38: Loss at step 5964: 0.03681615740060806\n",
      "2017-11-11 08:15:39: Loss at step 5965: 0.036800771951675415\n",
      "2017-11-11 08:15:39: Loss at step 5966: 0.0368102490901947\n",
      "2017-11-11 08:15:40: Loss at step 5967: 0.03671431168913841\n",
      "2017-11-11 08:15:40: Loss at step 5968: 0.0367400124669075\n",
      "2017-11-11 08:15:41: Loss at step 5969: 0.036740150302648544\n",
      "2017-11-11 08:15:41: Loss at step 5970: 0.03672002628445625\n",
      "2017-11-11 08:15:42: Loss at step 5971: 0.03670274838805199\n",
      "2017-11-11 08:15:42: Loss at step 5972: 0.03671307861804962\n",
      "2017-11-11 08:15:43: Loss at step 5973: 0.03661099076271057\n",
      "2017-11-11 08:15:43: Loss at step 5974: 0.03677491471171379\n",
      "2017-11-11 08:15:44: Loss at step 5975: 0.0366675890982151\n",
      "2017-11-11 08:15:44: Loss at step 5976: 0.03676965832710266\n",
      "2017-11-11 08:15:45: Loss at step 5977: 0.03676033392548561\n",
      "2017-11-11 08:15:45: Loss at step 5978: 0.03670477867126465\n",
      "2017-11-11 08:15:46: Loss at step 5979: 0.03681004047393799\n",
      "2017-11-11 08:15:46: Loss at step 5980: 0.03671128675341606\n",
      "2017-11-11 08:15:47: Loss at step 5981: 0.03665491193532944\n",
      "2017-11-11 08:15:47: Loss at step 5982: 0.03672340512275696\n",
      "2017-11-11 08:15:48: Loss at step 5983: 0.03668699786067009\n",
      "2017-11-11 08:15:48: Loss at step 5984: 0.036720048636198044\n",
      "2017-11-11 08:15:49: Loss at step 5985: 0.036754854023456573\n",
      "2017-11-11 08:15:49: Loss at step 5986: 0.036744628101587296\n",
      "2017-11-11 08:15:50: Loss at step 5987: 0.03678179159760475\n",
      "2017-11-11 08:15:50: Loss at step 5988: 0.03680732846260071\n",
      "2017-11-11 08:15:51: Loss at step 5989: 0.03676748275756836\n",
      "2017-11-11 08:15:51: Loss at step 5990: 0.03681040182709694\n",
      "2017-11-11 08:15:52: Loss at step 5991: 0.036804236471652985\n",
      "2017-11-11 08:15:52: Loss at step 5992: 0.03685402497649193\n",
      "2017-11-11 08:15:53: Loss at step 5993: 0.03673708438873291\n",
      "2017-11-11 08:15:53: Loss at step 5994: 0.03672848269343376\n",
      "2017-11-11 08:15:54: Loss at step 5995: 0.03680793568491936\n",
      "2017-11-11 08:15:54: Loss at step 5996: 0.03681783005595207\n",
      "2017-11-11 08:15:55: Loss at step 5997: 0.03667134419083595\n",
      "2017-11-11 08:15:55: Loss at step 5998: 0.03676347807049751\n",
      "2017-11-11 08:15:56: Loss at step 5999: 0.03671463578939438\n",
      "2017-11-11 08:15:56: Loss at step 6000: 0.036801621317863464\n",
      "2017-11-11 08:15:57: Loss at step 6001: 0.036753252148628235\n",
      "2017-11-11 08:15:57: Loss at step 6002: 0.03681443631649017\n",
      "2017-11-11 08:15:58: Loss at step 6003: 0.03673216700553894\n",
      "2017-11-11 08:15:58: Loss at step 6004: 0.036806538701057434\n",
      "2017-11-11 08:15:59: Loss at step 6005: 0.03682341054081917\n",
      "2017-11-11 08:15:59: Loss at step 6006: 0.036778636276721954\n",
      "2017-11-11 08:16:00: Loss at step 6007: 0.03678852692246437\n",
      "2017-11-11 08:16:00: Loss at step 6008: 0.0367635041475296\n",
      "2017-11-11 08:16:01: Loss at step 6009: 0.036785680800676346\n",
      "2017-11-11 08:16:01: Loss at step 6010: 0.03675520792603493\n",
      "2017-11-11 08:16:02: Loss at step 6011: 0.03679286688566208\n",
      "2017-11-11 08:16:02: Loss at step 6012: 0.03675948455929756\n",
      "2017-11-11 08:16:03: Loss at step 6013: 0.0366964153945446\n",
      "2017-11-11 08:16:03: Loss at step 6014: 0.036833129823207855\n",
      "2017-11-11 08:16:04: Loss at step 6015: 0.03687572106719017\n",
      "2017-11-11 08:16:04: Loss at step 6016: 0.03682678937911987\n",
      "2017-11-11 08:16:05: Loss at step 6017: 0.036769308149814606\n",
      "2017-11-11 08:16:05: Loss at step 6018: 0.03670104220509529\n",
      "2017-11-11 08:16:06: Loss at step 6019: 0.03671390563249588\n",
      "2017-11-11 08:16:06: Loss at step 6020: 0.03674129769206047\n",
      "2017-11-11 08:16:07: Loss at step 6021: 0.03668973222374916\n",
      "2017-11-11 08:16:07: Loss at step 6022: 0.036752983927726746\n",
      "2017-11-11 08:16:08: Loss at step 6023: 0.03673567995429039\n",
      "2017-11-11 08:16:08: Loss at step 6024: 0.036648429930210114\n",
      "2017-11-11 08:16:08: Loss at step 6025: 0.036805447190999985\n",
      "2017-11-11 08:16:09: Loss at step 6026: 0.036762867122888565\n",
      "2017-11-11 08:16:09: Loss at step 6027: 0.03667069599032402\n",
      "2017-11-11 08:16:10: Loss at step 6028: 0.03675569221377373\n",
      "2017-11-11 08:16:11: Loss at step 6029: 0.03673715889453888\n",
      "2017-11-11 08:16:11: Loss at step 6030: 0.036816488951444626\n",
      "2017-11-11 08:16:12: Loss at step 6031: 0.036761485040187836\n",
      "2017-11-11 08:16:12: Loss at step 6032: 0.03680765628814697\n",
      "2017-11-11 08:16:13: Loss at step 6033: 0.03674768656492233\n",
      "2017-11-11 08:16:13: Loss at step 6034: 0.03680849447846413\n",
      "2017-11-11 08:16:13: Loss at step 6035: 0.036693718284368515\n",
      "2017-11-11 08:16:14: Loss at step 6036: 0.036687590181827545\n",
      "2017-11-11 08:16:14: Loss at step 6037: 0.03668161481618881\n",
      "2017-11-11 08:16:15: Loss at step 6038: 0.03672028332948685\n",
      "2017-11-11 08:16:15: Loss at step 6039: 0.036748819053173065\n",
      "2017-11-11 08:16:16: Loss at step 6040: 0.03675074875354767\n",
      "2017-11-11 08:16:16: Loss at step 6041: 0.036775968968868256\n",
      "2017-11-11 08:16:17: Loss at step 6042: 0.03689586743712425\n",
      "2017-11-11 08:16:17: Loss at step 6043: 0.03674282133579254\n",
      "2017-11-11 08:16:18: Loss at step 6044: 0.036806125193834305\n",
      "2017-11-11 08:16:18: Loss at step 6045: 0.0367332324385643\n",
      "2017-11-11 08:16:19: Loss at step 6046: 0.03672316297888756\n",
      "2017-11-11 08:16:19: Loss at step 6047: 0.03660507872700691\n",
      "2017-11-11 08:16:20: Loss at step 6048: 0.03670415282249451\n",
      "2017-11-11 08:16:21: Loss at step 6049: 0.036581218242645264\n",
      "2017-11-11 08:16:21: Loss at step 6050: 0.03676838055253029\n",
      "2017-11-11 08:16:22: Loss at step 6051: 0.036837488412857056\n",
      "2017-11-11 08:16:22: Loss at step 6052: 0.036687303334474564\n",
      "2017-11-11 08:16:22: Loss at step 6053: 0.03677070885896683\n",
      "2017-11-11 08:16:23: Loss at step 6054: 0.036705706268548965\n",
      "2017-11-11 08:16:23: Loss at step 6055: 0.03670391067862511\n",
      "2017-11-11 08:16:24: Loss at step 6056: 0.03672443702816963\n",
      "2017-11-11 08:16:25: Loss at step 6057: 0.03675534576177597\n",
      "2017-11-11 08:16:25: Loss at step 6058: 0.036790840327739716\n",
      "2017-11-11 08:16:26: Loss at step 6059: 0.03676621988415718\n",
      "2017-11-11 08:16:26: Loss at step 6060: 0.03682172670960426\n",
      "2017-11-11 08:16:26: Loss at step 6061: 0.03674585744738579\n",
      "2017-11-11 08:16:27: Loss at step 6062: 0.03678421676158905\n",
      "2017-11-11 08:16:27: Loss at step 6063: 0.03679722920060158\n",
      "2017-11-11 08:16:28: Loss at step 6064: 0.036761488765478134\n",
      "2017-11-11 08:16:28: Loss at step 6065: 0.03680561110377312\n",
      "2017-11-11 08:16:29: Loss at step 6066: 0.036723535507917404\n",
      "2017-11-11 08:16:29: Loss at step 6067: 0.03674519434571266\n",
      "2017-11-11 08:16:30: Loss at step 6068: 0.036778029054403305\n",
      "2017-11-11 08:16:30: Loss at step 6069: 0.03670622408390045\n",
      "2017-11-11 08:16:31: Loss at step 6070: 0.03675150126218796\n",
      "2017-11-11 08:16:31: Loss at step 6071: 0.03677409514784813\n",
      "2017-11-11 08:16:32: Loss at step 6072: 0.036800775676965714\n",
      "2017-11-11 08:16:32: Loss at step 6073: 0.036810252815485\n",
      "2017-11-11 08:16:33: Loss at step 6074: 0.0368211567401886\n",
      "2017-11-11 08:16:33: Loss at step 6075: 0.036832306534051895\n",
      "2017-11-11 08:16:34: Loss at step 6076: 0.0367526113986969\n",
      "2017-11-11 08:16:34: Loss at step 6077: 0.03683080896735191\n",
      "2017-11-11 08:16:35: Loss at step 6078: 0.03675773739814758\n",
      "2017-11-11 08:16:35: Loss at step 6079: 0.03675968199968338\n",
      "2017-11-11 08:16:36: Loss at step 6080: 0.036844298243522644\n",
      "2017-11-11 08:16:36: Loss at step 6081: 0.036817751824855804\n",
      "2017-11-11 08:16:37: Loss at step 6082: 0.036806587129831314\n",
      "2017-11-11 08:16:37: Loss at step 6083: 0.03668075427412987\n",
      "2017-11-11 08:16:38: Loss at step 6084: 0.036700524389743805\n",
      "2017-11-11 08:16:38: Loss at step 6085: 0.0367414727807045\n",
      "2017-11-11 08:16:39: Loss at step 6086: 0.036728136241436005\n",
      "2017-11-11 08:16:39: Loss at step 6087: 0.0367232970893383\n",
      "2017-11-11 08:16:40: Loss at step 6088: 0.036723703145980835\n",
      "2017-11-11 08:16:40: Loss at step 6089: 0.036790959537029266\n",
      "2017-11-11 08:16:41: Loss at step 6090: 0.03674056753516197\n",
      "2017-11-11 08:16:41: Loss at step 6091: 0.03671302646398544\n",
      "2017-11-11 08:16:42: Loss at step 6092: 0.03673891723155975\n",
      "2017-11-11 08:16:42: Loss at step 6093: 0.03670315444469452\n",
      "2017-11-11 08:16:43: Loss at step 6094: 0.036725953221321106\n",
      "2017-11-11 08:16:43: Loss at step 6095: 0.03665636107325554\n",
      "2017-11-11 08:16:44: Loss at step 6096: 0.036673374474048615\n",
      "2017-11-11 08:16:44: Loss at step 6097: 0.03669840097427368\n",
      "2017-11-11 08:16:45: Loss at step 6098: 0.03679344058036804\n",
      "2017-11-11 08:16:45: Loss at step 6099: 0.036674804985523224\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-11-11 08:16:46: Loss at step 6100: 0.036710161715745926\n",
      "2017-11-11 08:16:46: Loss at step 6101: 0.03675812855362892\n",
      "2017-11-11 08:16:47: Loss at step 6102: 0.036810003221035004\n",
      "2017-11-11 08:16:47: Loss at step 6103: 0.036770500242710114\n",
      "2017-11-11 08:16:48: Loss at step 6104: 0.03682725876569748\n",
      "2017-11-11 08:16:48: Loss at step 6105: 0.03666483610868454\n",
      "2017-11-11 08:16:49: Loss at step 6106: 0.036732267588377\n",
      "2017-11-11 08:16:49: Loss at step 6107: 0.03674827143549919\n",
      "2017-11-11 08:16:50: Loss at step 6108: 0.036684323102235794\n",
      "2017-11-11 08:16:50: Loss at step 6109: 0.03669848293066025\n",
      "2017-11-11 08:16:51: Loss at step 6110: 0.03661757707595825\n",
      "2017-11-11 08:16:51: Loss at step 6111: 0.036717675626277924\n",
      "2017-11-11 08:16:52: Loss at step 6112: 0.03685639426112175\n",
      "2017-11-11 08:16:52: Loss at step 6113: 0.03670019283890724\n",
      "2017-11-11 08:16:53: Loss at step 6114: 0.036781225353479385\n",
      "2017-11-11 08:16:53: Loss at step 6115: 0.03671637549996376\n",
      "2017-11-11 08:16:54: Loss at step 6116: 0.03668126091361046\n",
      "2017-11-11 08:16:54: Loss at step 6117: 0.036752913147211075\n",
      "2017-11-11 08:16:55: Loss at step 6118: 0.036824747920036316\n",
      "2017-11-11 08:16:55: Loss at step 6119: 0.03677596151828766\n",
      "2017-11-11 08:16:56: Loss at step 6120: 0.03677554801106453\n",
      "2017-11-11 08:16:56: Loss at step 6121: 0.03675398603081703\n",
      "2017-11-11 08:16:57: Loss at step 6122: 0.03683067485690117\n",
      "2017-11-11 08:16:57: Loss at step 6123: 0.03678427264094353\n",
      "2017-11-11 08:16:58: Loss at step 6124: 0.03669121861457825\n",
      "2017-11-11 08:16:58: Loss at step 6125: 0.03672415018081665\n",
      "2017-11-11 08:16:59: Loss at step 6126: 0.03668978437781334\n",
      "2017-11-11 08:16:59: Loss at step 6127: 0.03677548095583916\n",
      "2017-11-11 08:17:00: Loss at step 6128: 0.036880094558000565\n",
      "2017-11-11 08:17:00: Loss at step 6129: 0.036777351051568985\n",
      "2017-11-11 08:17:01: Loss at step 6130: 0.0368206612765789\n",
      "2017-11-11 08:17:01: Loss at step 6131: 0.03679513558745384\n",
      "2017-11-11 08:17:01: Loss at step 6132: 0.036815229803323746\n",
      "2017-11-11 08:17:02: Loss at step 6133: 0.036769893020391464\n",
      "2017-11-11 08:17:02: Loss at step 6134: 0.036748193204402924\n",
      "2017-11-11 08:17:03: Loss at step 6135: 0.03676575794816017\n",
      "2017-11-11 08:17:03: Loss at step 6136: 0.03680456429719925\n",
      "2017-11-11 08:17:04: Loss at step 6137: 0.036755189299583435\n",
      "2017-11-11 08:17:05: Loss at step 6138: 0.036709196865558624\n",
      "2017-11-11 08:17:05: Loss at step 6139: 0.0367223396897316\n",
      "2017-11-11 08:17:06: Loss at step 6140: 0.03668219968676567\n",
      "2017-11-11 08:17:06: Loss at step 6141: 0.03670838847756386\n",
      "2017-11-11 08:17:07: Loss at step 6142: 0.036767344921827316\n",
      "2017-11-11 08:17:07: Loss at step 6143: 0.03670680150389671\n",
      "2017-11-11 08:17:08: Loss at step 6144: 0.03675125539302826\n",
      "2017-11-11 08:17:08: Loss at step 6145: 0.03666484355926514\n",
      "2017-11-11 08:17:09: Loss at step 6146: 0.03672482445836067\n",
      "2017-11-11 08:17:09: Loss at step 6147: 0.0367584303021431\n",
      "2017-11-11 08:17:10: Loss at step 6148: 0.03669077157974243\n",
      "2017-11-11 08:17:10: Loss at step 6149: 0.03667094558477402\n",
      "2017-11-11 08:17:11: Loss at step 6150: 0.0368417426943779\n",
      "2017-11-11 08:17:11: Loss at step 6151: 0.0367945171892643\n",
      "2017-11-11 08:17:12: Loss at step 6152: 0.03672478720545769\n",
      "2017-11-11 08:17:12: Loss at step 6153: 0.0367552749812603\n",
      "2017-11-11 08:17:13: Loss at step 6154: 0.03671833500266075\n",
      "2017-11-11 08:17:13: Loss at step 6155: 0.036765772849321365\n",
      "2017-11-11 08:17:14: Loss at step 6156: 0.03679078444838524\n",
      "2017-11-11 08:17:14: Loss at step 6157: 0.0368647575378418\n",
      "2017-11-11 08:17:15: Loss at step 6158: 0.03674466535449028\n",
      "2017-11-11 08:17:15: Loss at step 6159: 0.03680354729294777\n",
      "2017-11-11 08:17:16: Loss at step 6160: 0.03677354380488396\n",
      "2017-11-11 08:17:16: Loss at step 6161: 0.03674689680337906\n",
      "2017-11-11 08:17:17: Loss at step 6162: 0.036797817796468735\n",
      "2017-11-11 08:17:17: Loss at step 6163: 0.03667997568845749\n",
      "2017-11-11 08:17:18: Loss at step 6164: 0.0367862842977047\n",
      "2017-11-11 08:17:18: Loss at step 6165: 0.036767538636922836\n",
      "2017-11-11 08:17:19: Loss at step 6166: 0.03676022216677666\n",
      "2017-11-11 08:17:19: Loss at step 6167: 0.0367848202586174\n",
      "2017-11-11 08:17:20: Loss at step 6168: 0.036736175417900085\n",
      "2017-11-11 08:17:20: Loss at step 6169: 0.03673991188406944\n",
      "2017-11-11 08:17:21: Loss at step 6170: 0.03676467761397362\n",
      "2017-11-11 08:17:21: Loss at step 6171: 0.0368160754442215\n",
      "2017-11-11 08:17:22: Loss at step 6172: 0.03674055635929108\n",
      "2017-11-11 08:17:22: Loss at step 6173: 0.03673616796731949\n",
      "2017-11-11 08:17:23: Loss at step 6174: 0.036758046597242355\n",
      "2017-11-11 08:17:23: Loss at step 6175: 0.036769717931747437\n",
      "2017-11-11 08:17:24: Loss at step 6176: 0.036834876984357834\n",
      "2017-11-11 08:17:24: Loss at step 6177: 0.03687300533056259\n",
      "2017-11-11 08:17:25: Loss at step 6178: 0.036828912794589996\n",
      "2017-11-11 08:17:25: Loss at step 6179: 0.03677034750580788\n",
      "2017-11-11 08:17:26: Loss at step 6180: 0.03680533170700073\n",
      "2017-11-11 08:17:26: Loss at step 6181: 0.03666897118091583\n",
      "2017-11-11 08:17:27: Loss at step 6182: 0.03676958754658699\n",
      "2017-11-11 08:17:27: Loss at step 6183: 0.03664417192339897\n",
      "2017-11-11 08:17:28: Loss at step 6184: 0.036720555275678635\n",
      "2017-11-11 08:17:28: Loss at step 6185: 0.03679778426885605\n",
      "2017-11-11 08:17:29: Loss at step 6186: 0.03672376275062561\n",
      "2017-11-11 08:17:29: Loss at step 6187: 0.0367167629301548\n",
      "2017-11-11 08:17:30: Loss at step 6188: 0.036780573427677155\n",
      "2017-11-11 08:17:30: Loss at step 6189: 0.036709535866975784\n",
      "2017-11-11 08:17:31: Loss at step 6190: 0.03669491037726402\n",
      "2017-11-11 08:17:31: Loss at step 6191: 0.03673258796334267\n",
      "2017-11-11 08:17:32: Loss at step 6192: 0.03675447031855583\n",
      "2017-11-11 08:17:32: Loss at step 6193: 0.036656785756349564\n",
      "2017-11-11 08:17:33: Loss at step 6194: 0.03679141402244568\n",
      "2017-11-11 08:17:33: Loss at step 6195: 0.036786023527383804\n",
      "2017-11-11 08:17:34: Loss at step 6196: 0.03681999444961548\n",
      "2017-11-11 08:17:34: Loss at step 6197: 0.036796461790800095\n",
      "2017-11-11 08:17:35: Loss at step 6198: 0.036732934415340424\n",
      "2017-11-11 08:17:35: Loss at step 6199: 0.036740757524967194\n",
      "2017-11-11 08:17:36: Loss at step 6200: 0.036692313849925995\n",
      "2017-11-11 08:17:36: Loss at step 6201: 0.03672698885202408\n",
      "2017-11-11 08:17:37: Loss at step 6202: 0.03672100231051445\n",
      "2017-11-11 08:17:37: Loss at step 6203: 0.03674541413784027\n",
      "2017-11-11 08:17:38: Loss at step 6204: 0.03674881160259247\n",
      "2017-11-11 08:17:38: Loss at step 6205: 0.03678608313202858\n",
      "2017-11-11 08:17:39: Loss at step 6206: 0.03676086291670799\n",
      "2017-11-11 08:17:39: Loss at step 6207: 0.03669130057096481\n",
      "2017-11-11 08:17:40: Loss at step 6208: 0.036668095737695694\n",
      "2017-11-11 08:17:40: Loss at step 6209: 0.03676743060350418\n",
      "2017-11-11 08:17:41: Loss at step 6210: 0.03672588989138603\n",
      "2017-11-11 08:17:41: Loss at step 6211: 0.03672546520829201\n",
      "2017-11-11 08:17:42: Loss at step 6212: 0.0367121547460556\n",
      "2017-11-11 08:17:42: Loss at step 6213: 0.03672877326607704\n",
      "2017-11-11 08:17:43: Loss at step 6214: 0.036732036620378494\n",
      "2017-11-11 08:17:43: Loss at step 6215: 0.03676418587565422\n",
      "2017-11-11 08:17:44: Loss at step 6216: 0.036739178001880646\n",
      "2017-11-11 08:17:44: Loss at step 6217: 0.03669380396604538\n",
      "2017-11-11 08:17:45: Loss at step 6218: 0.03673435002565384\n",
      "2017-11-11 08:17:45: Loss at step 6219: 0.036669306457042694\n",
      "2017-11-11 08:17:46: Loss at step 6220: 0.036757953464984894\n",
      "2017-11-11 08:17:46: Loss at step 6221: 0.03678745776414871\n",
      "2017-11-11 08:17:47: Loss at step 6222: 0.03680971637368202\n",
      "2017-11-11 08:17:47: Loss at step 6223: 0.03680643439292908\n",
      "2017-11-11 08:17:48: Loss at step 6224: 0.03667501360177994\n",
      "2017-11-11 08:17:48: Loss at step 6225: 0.036771032959222794\n",
      "2017-11-11 08:17:49: Loss at step 6226: 0.03680901974439621\n",
      "2017-11-11 08:17:49: Loss at step 6227: 0.03683843836188316\n",
      "2017-11-11 08:17:50: Loss at step 6228: 0.03681734576821327\n",
      "2017-11-11 08:17:50: Loss at step 6229: 0.036741748452186584\n",
      "2017-11-11 08:17:51: Loss at step 6230: 0.03682200238108635\n",
      "2017-11-11 08:17:51: Loss at step 6231: 0.036735210567712784\n",
      "2017-11-11 08:17:52: Loss at step 6232: 0.03683638945221901\n",
      "2017-11-11 08:17:52: Loss at step 6233: 0.03680646792054176\n",
      "2017-11-11 08:17:53: Loss at step 6234: 0.03673199564218521\n",
      "2017-11-11 08:17:53: Loss at step 6235: 0.03685593977570534\n",
      "2017-11-11 08:17:54: Loss at step 6236: 0.03684232011437416\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-11-11 08:17:54: Loss at step 6237: 0.036813538521528244\n",
      "2017-11-11 08:17:55: Loss at step 6238: 0.03673258051276207\n",
      "2017-11-11 08:17:55: Loss at step 6239: 0.036779019981622696\n",
      "2017-11-11 08:17:56: Loss at step 6240: 0.03671501949429512\n",
      "2017-11-11 08:17:56: Loss at step 6241: 0.03672512248158455\n",
      "2017-11-11 08:17:57: Loss at step 6242: 0.036771345883607864\n",
      "2017-11-11 08:17:57: Loss at step 6243: 0.03670337423682213\n",
      "2017-11-11 08:17:58: Loss at step 6244: 0.03675340116024017\n",
      "2017-11-11 08:17:58: Loss at step 6245: 0.03673470392823219\n",
      "2017-11-11 08:17:59: Loss at step 6246: 0.036642566323280334\n",
      "2017-11-11 08:17:59: Loss at step 6247: 0.03675657883286476\n",
      "2017-11-11 08:18:00: Loss at step 6248: 0.03669288754463196\n",
      "2017-11-11 08:18:00: Loss at step 6249: 0.0367446169257164\n",
      "2017-11-11 08:18:01: Loss at step 6250: 0.03671696037054062\n",
      "2017-11-11 08:18:01: Loss at step 6251: 0.03672512248158455\n",
      "2017-11-11 08:18:02: Loss at step 6252: 0.03668314963579178\n",
      "2017-11-11 08:18:02: Loss at step 6253: 0.03669910877943039\n",
      "2017-11-11 08:18:03: Loss at step 6254: 0.03680041432380676\n",
      "2017-11-11 08:18:03: Loss at step 6255: 0.03668129816651344\n",
      "2017-11-11 08:18:04: Loss at step 6256: 0.03676735237240791\n",
      "2017-11-11 08:18:04: Loss at step 6257: 0.03675096482038498\n",
      "2017-11-11 08:18:05: Loss at step 6258: 0.036794718354940414\n",
      "2017-11-11 08:18:05: Loss at step 6259: 0.036690372973680496\n",
      "2017-11-11 08:18:06: Loss at step 6260: 0.03680948168039322\n",
      "2017-11-11 08:18:06: Loss at step 6261: 0.0367223285138607\n",
      "2017-11-11 08:18:07: Loss at step 6262: 0.036865510046482086\n",
      "2017-11-11 08:18:07: Loss at step 6263: 0.03668352589011192\n",
      "2017-11-11 08:18:08: Loss at step 6264: 0.03671496734023094\n",
      "2017-11-11 08:18:08: Loss at step 6265: 0.0368228517472744\n",
      "2017-11-11 08:18:09: Loss at step 6266: 0.036758311092853546\n",
      "2017-11-11 08:18:09: Loss at step 6267: 0.03679893910884857\n",
      "2017-11-11 08:18:10: Loss at step 6268: 0.03672976791858673\n",
      "2017-11-11 08:18:10: Loss at step 6269: 0.036665476858615875\n",
      "2017-11-11 08:18:11: Loss at step 6270: 0.03668421879410744\n",
      "2017-11-11 08:18:11: Loss at step 6271: 0.03679715469479561\n",
      "2017-11-11 08:18:12: Loss at step 6272: 0.03676576167345047\n",
      "2017-11-11 08:18:12: Loss at step 6273: 0.03677743673324585\n",
      "2017-11-11 08:18:13: Loss at step 6274: 0.036768537014722824\n",
      "2017-11-11 08:18:13: Loss at step 6275: 0.03675463795661926\n",
      "2017-11-11 08:18:14: Loss at step 6276: 0.03681301698088646\n",
      "2017-11-11 08:18:14: Loss at step 6277: 0.03678150475025177\n",
      "2017-11-11 08:18:14: Loss at step 6278: 0.03677741065621376\n",
      "2017-11-11 08:18:15: Loss at step 6279: 0.03666876628994942\n",
      "2017-11-11 08:18:15: Loss at step 6280: 0.03671238571405411\n",
      "2017-11-11 08:18:16: Loss at step 6281: 0.03674684837460518\n",
      "2017-11-11 08:18:16: Loss at step 6282: 0.036724358797073364\n",
      "2017-11-11 08:18:17: Loss at step 6283: 0.03674599155783653\n",
      "2017-11-11 08:18:18: Loss at step 6284: 0.036735475063323975\n",
      "2017-11-11 08:18:18: Loss at step 6285: 0.0367942750453949\n",
      "2017-11-11 08:18:19: Loss at step 6286: 0.03682515397667885\n",
      "2017-11-11 08:18:19: Loss at step 6287: 0.036795783787965775\n",
      "2017-11-11 08:18:20: Loss at step 6288: 0.036819782108068466\n",
      "2017-11-11 08:18:20: Loss at step 6289: 0.03683251515030861\n",
      "2017-11-11 08:18:21: Loss at step 6290: 0.03683055564761162\n",
      "2017-11-11 08:18:21: Loss at step 6291: 0.03675783425569534\n",
      "2017-11-11 08:18:22: Loss at step 6292: 0.036822184920310974\n",
      "2017-11-11 08:18:22: Loss at step 6293: 0.036791734397411346\n",
      "2017-11-11 08:18:23: Loss at step 6294: 0.0367998369038105\n",
      "2017-11-11 08:18:23: Loss at step 6295: 0.03666149824857712\n",
      "2017-11-11 08:18:24: Loss at step 6296: 0.036742471158504486\n",
      "2017-11-11 08:18:24: Loss at step 6297: 0.036753688007593155\n",
      "2017-11-11 08:18:25: Loss at step 6298: 0.03664731979370117\n",
      "2017-11-11 08:18:25: Loss at step 6299: 0.03674303740262985\n",
      "2017-11-11 08:18:26: Loss at step 6300: 0.036744099110364914\n",
      "2017-11-11 08:18:26: Loss at step 6301: 0.03680026903748512\n",
      "2017-11-11 08:18:27: Loss at step 6302: 0.03677869215607643\n",
      "2017-11-11 08:18:27: Loss at step 6303: 0.036764565855264664\n",
      "2017-11-11 08:18:28: Loss at step 6304: 0.03679359331727028\n",
      "2017-11-11 08:18:28: Loss at step 6305: 0.03672526404261589\n",
      "2017-11-11 08:18:29: Loss at step 6306: 0.03675493597984314\n",
      "2017-11-11 08:18:29: Loss at step 6307: 0.036912951618433\n",
      "2017-11-11 08:18:30: Loss at step 6308: 0.03672264888882637\n",
      "2017-11-11 08:18:30: Loss at step 6309: 0.03678618744015694\n",
      "2017-11-11 08:18:31: Loss at step 6310: 0.03676943480968475\n",
      "2017-11-11 08:18:31: Loss at step 6311: 0.036724671721458435\n",
      "2017-11-11 08:18:32: Loss at step 6312: 0.036715950816869736\n",
      "2017-11-11 08:18:32: Loss at step 6313: 0.03674415871500969\n",
      "2017-11-11 08:18:33: Loss at step 6314: 0.03667767345905304\n",
      "2017-11-11 08:18:33: Loss at step 6315: 0.036668021231889725\n",
      "2017-11-11 08:18:34: Loss at step 6316: 0.03670360893011093\n",
      "2017-11-11 08:18:34: Loss at step 6317: 0.03684426099061966\n",
      "2017-11-11 08:18:35: Loss at step 6318: 0.03674178943037987\n",
      "2017-11-11 08:18:35: Loss at step 6319: 0.03675417602062225\n",
      "2017-11-11 08:18:36: Loss at step 6320: 0.03680963069200516\n",
      "2017-11-11 08:18:36: Loss at step 6321: 0.03674890473484993\n",
      "2017-11-11 08:18:37: Loss at step 6322: 0.036760613322257996\n",
      "2017-11-11 08:18:37: Loss at step 6323: 0.036755967885255814\n",
      "2017-11-11 08:18:38: Loss at step 6324: 0.03678157180547714\n",
      "2017-11-11 08:18:38: Loss at step 6325: 0.036714810878038406\n",
      "2017-11-11 08:18:39: Loss at step 6326: 0.03676052391529083\n",
      "2017-11-11 08:18:39: Loss at step 6327: 0.03673481568694115\n",
      "2017-11-11 08:18:40: Loss at step 6328: 0.03667565435171127\n",
      "2017-11-11 08:18:40: Loss at step 6329: 0.03676948323845863\n",
      "2017-11-11 08:18:41: Loss at step 6330: 0.03671420365571976\n",
      "2017-11-11 08:18:41: Loss at step 6331: 0.03667883947491646\n",
      "2017-11-11 08:18:42: Loss at step 6332: 0.03670242428779602\n",
      "2017-11-11 08:18:42: Loss at step 6333: 0.03676168993115425\n",
      "2017-11-11 08:18:43: Loss at step 6334: 0.03672148287296295\n",
      "2017-11-11 08:18:43: Loss at step 6335: 0.03677738457918167\n",
      "2017-11-11 08:18:44: Loss at step 6336: 0.03669982776045799\n",
      "2017-11-11 08:18:44: Loss at step 6337: 0.03676696494221687\n",
      "2017-11-11 08:18:45: Loss at step 6338: 0.03673852980136871\n",
      "2017-11-11 08:18:45: Loss at step 6339: 0.03680530935525894\n",
      "2017-11-11 08:18:46: Loss at step 6340: 0.036764826625585556\n",
      "2017-11-11 08:18:46: Loss at step 6341: 0.036706678569316864\n",
      "2017-11-11 08:18:47: Loss at step 6342: 0.03675767034292221\n",
      "2017-11-11 08:18:47: Loss at step 6343: 0.03663754090666771\n",
      "2017-11-11 08:18:48: Loss at step 6344: 0.03672637790441513\n",
      "2017-11-11 08:18:48: Loss at step 6345: 0.03668487071990967\n",
      "2017-11-11 08:18:49: Loss at step 6346: 0.03670957684516907\n",
      "2017-11-11 08:18:49: Loss at step 6347: 0.03674059733748436\n",
      "2017-11-11 08:18:49: Loss at step 6348: 0.03674491122364998\n",
      "2017-11-11 08:18:50: Loss at step 6349: 0.03674750775098801\n",
      "2017-11-11 08:18:51: Loss at step 6350: 0.03671204671263695\n",
      "2017-11-11 08:18:51: Loss at step 6351: 0.03669610992074013\n",
      "2017-11-11 08:18:52: Loss at step 6352: 0.03671995922923088\n",
      "2017-11-11 08:18:52: Loss at step 6353: 0.0368017703294754\n",
      "2017-11-11 08:18:53: Loss at step 6354: 0.03670670464634895\n",
      "2017-11-11 08:18:53: Loss at step 6355: 0.03674764931201935\n",
      "2017-11-11 08:18:54: Loss at step 6356: 0.03672615438699722\n",
      "2017-11-11 08:18:54: Loss at step 6357: 0.03675835579633713\n",
      "2017-11-11 08:18:55: Loss at step 6358: 0.03673609718680382\n",
      "2017-11-11 08:18:55: Loss at step 6359: 0.0367443785071373\n",
      "2017-11-11 08:18:56: Loss at step 6360: 0.036780983209609985\n",
      "2017-11-11 08:18:56: Loss at step 6361: 0.0367402657866478\n",
      "2017-11-11 08:18:56: Loss at step 6362: 0.03678335249423981\n",
      "2017-11-11 08:18:57: Loss at step 6363: 0.03681309148669243\n",
      "2017-11-11 08:18:58: Loss at step 6364: 0.036716386675834656\n",
      "2017-11-11 08:18:58: Loss at step 6365: 0.036785926669836044\n",
      "2017-11-11 08:18:59: Loss at step 6366: 0.036695875227451324\n",
      "2017-11-11 08:18:59: Loss at step 6367: 0.036798130720853806\n",
      "2017-11-11 08:19:00: Loss at step 6368: 0.03674982860684395\n",
      "2017-11-11 08:19:00: Loss at step 6369: 0.036834150552749634\n",
      "2017-11-11 08:19:01: Loss at step 6370: 0.03669893369078636\n",
      "2017-11-11 08:19:01: Loss at step 6371: 0.036790698766708374\n",
      "2017-11-11 08:19:02: Loss at step 6372: 0.03668830171227455\n",
      "2017-11-11 08:19:02: Loss at step 6373: 0.03676663339138031\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-11-11 08:19:03: Loss at step 6374: 0.036744002252817154\n",
      "2017-11-11 08:19:03: Loss at step 6375: 0.03678378835320473\n",
      "2017-11-11 08:19:04: Loss at step 6376: 0.03674374893307686\n",
      "2017-11-11 08:19:04: Loss at step 6377: 0.036700401455163956\n",
      "2017-11-11 08:19:05: Loss at step 6378: 0.03675355389714241\n",
      "2017-11-11 08:19:05: Loss at step 6379: 0.036785803735256195\n",
      "2017-11-11 08:19:06: Loss at step 6380: 0.03674730658531189\n",
      "2017-11-11 08:19:06: Loss at step 6381: 0.03680233657360077\n",
      "2017-11-11 08:19:07: Loss at step 6382: 0.03679421916604042\n",
      "2017-11-11 08:19:07: Loss at step 6383: 0.03674124926328659\n",
      "2017-11-11 08:19:08: Loss at step 6384: 0.03682047501206398\n",
      "2017-11-11 08:19:08: Loss at step 6385: 0.03672010079026222\n",
      "2017-11-11 08:19:09: Loss at step 6386: 0.03671663999557495\n",
      "2017-11-11 08:19:09: Loss at step 6387: 0.03668796271085739\n",
      "2017-11-11 08:19:10: Loss at step 6388: 0.036781035363674164\n",
      "2017-11-11 08:19:10: Loss at step 6389: 0.036798279732465744\n",
      "2017-11-11 08:19:11: Loss at step 6390: 0.036735180765390396\n",
      "2017-11-11 08:19:11: Loss at step 6391: 0.0367555245757103\n",
      "2017-11-11 08:19:12: Loss at step 6392: 0.03676513209939003\n",
      "2017-11-11 08:19:12: Loss at step 6393: 0.036687467247247696\n",
      "2017-11-11 08:19:13: Loss at step 6394: 0.03679269179701805\n",
      "2017-11-11 08:19:13: Loss at step 6395: 0.03679336607456207\n",
      "2017-11-11 08:19:14: Loss at step 6396: 0.03677402436733246\n",
      "2017-11-11 08:19:14: Loss at step 6397: 0.036789897829294205\n",
      "2017-11-11 08:19:15: Loss at step 6398: 0.0367797426879406\n",
      "2017-11-11 08:19:15: Loss at step 6399: 0.036758970469236374\n",
      "2017-11-11 08:19:16: Loss at step 6400: 0.036786917597055435\n",
      "2017-11-11 08:19:16: Loss at step 6401: 0.036717675626277924\n",
      "2017-11-11 08:19:17: Loss at step 6402: 0.036799393594264984\n",
      "2017-11-11 08:19:17: Loss at step 6403: 0.03675023093819618\n",
      "2017-11-11 08:19:18: Loss at step 6404: 0.036754168570041656\n",
      "2017-11-11 08:19:18: Loss at step 6405: 0.036808934062719345\n",
      "2017-11-11 08:19:19: Loss at step 6406: 0.036757439374923706\n",
      "2017-11-11 08:19:19: Loss at step 6407: 0.0366920605301857\n",
      "2017-11-11 08:19:20: Loss at step 6408: 0.03681431710720062\n",
      "2017-11-11 08:19:20: Loss at step 6409: 0.036822233349084854\n",
      "2017-11-11 08:19:21: Loss at step 6410: 0.03686854988336563\n",
      "2017-11-11 08:19:21: Loss at step 6411: 0.03678812086582184\n",
      "2017-11-11 08:19:22: Loss at step 6412: 0.03670395538210869\n",
      "2017-11-11 08:19:22: Loss at step 6413: 0.03677661716938019\n",
      "2017-11-11 08:19:23: Loss at step 6414: 0.036835167557001114\n",
      "2017-11-11 08:19:23: Loss at step 6415: 0.03671947494149208\n",
      "2017-11-11 08:19:24: Loss at step 6416: 0.03677637502551079\n",
      "2017-11-11 08:19:24: Loss at step 6417: 0.03675622493028641\n",
      "2017-11-11 08:19:25: Loss at step 6418: 0.03675289452075958\n",
      "2017-11-11 08:19:25: Loss at step 6419: 0.03677000477910042\n",
      "2017-11-11 08:19:26: Loss at step 6420: 0.03670794144272804\n",
      "2017-11-11 08:19:26: Loss at step 6421: 0.036770641803741455\n",
      "2017-11-11 08:19:27: Loss at step 6422: 0.0366906002163887\n",
      "2017-11-11 08:19:27: Loss at step 6423: 0.036759328097105026\n",
      "2017-11-11 08:19:28: Loss at step 6424: 0.0368354432284832\n",
      "2017-11-11 08:19:28: Loss at step 6425: 0.0367303267121315\n",
      "2017-11-11 08:19:29: Loss at step 6426: 0.036778997629880905\n",
      "2017-11-11 08:19:29: Loss at step 6427: 0.036731548607349396\n",
      "2017-11-11 08:19:30: Loss at step 6428: 0.03682330995798111\n",
      "2017-11-11 08:19:30: Loss at step 6429: 0.03679214045405388\n",
      "2017-11-11 08:19:31: Loss at step 6430: 0.036759648472070694\n",
      "2017-11-11 08:19:31: Loss at step 6431: 0.03674667328596115\n",
      "2017-11-11 08:19:32: Loss at step 6432: 0.03670971840620041\n",
      "2017-11-11 08:19:32: Loss at step 6433: 0.036713097244501114\n",
      "2017-11-11 08:19:33: Loss at step 6434: 0.0367666631937027\n",
      "2017-11-11 08:19:33: Loss at step 6435: 0.036806102842092514\n",
      "2017-11-11 08:19:34: Loss at step 6436: 0.03686775639653206\n",
      "2017-11-11 08:19:34: Loss at step 6437: 0.036744169890880585\n",
      "2017-11-11 08:19:35: Loss at step 6438: 0.0367269292473793\n",
      "2017-11-11 08:19:35: Loss at step 6439: 0.036795780062675476\n",
      "2017-11-11 08:19:36: Loss at step 6440: 0.036750104278326035\n",
      "2017-11-11 08:19:36: Loss at step 6441: 0.03676716238260269\n",
      "2017-11-11 08:19:37: Loss at step 6442: 0.0367218516767025\n",
      "2017-11-11 08:19:37: Loss at step 6443: 0.03676723316311836\n",
      "2017-11-11 08:19:38: Loss at step 6444: 0.03671647980809212\n",
      "2017-11-11 08:19:38: Loss at step 6445: 0.03671317175030708\n",
      "2017-11-11 08:19:39: Loss at step 6446: 0.03671213984489441\n",
      "2017-11-11 08:19:39: Loss at step 6447: 0.036745790392160416\n",
      "2017-11-11 08:19:40: Loss at step 6448: 0.0367901511490345\n",
      "2017-11-11 08:19:40: Loss at step 6449: 0.036757942289114\n",
      "2017-11-11 08:19:41: Loss at step 6450: 0.03670210763812065\n",
      "2017-11-11 08:19:41: Loss at step 6451: 0.03680507093667984\n",
      "2017-11-11 08:19:42: Loss at step 6452: 0.03673849627375603\n",
      "2017-11-11 08:19:42: Loss at step 6453: 0.036737047135829926\n",
      "2017-11-11 08:19:43: Loss at step 6454: 0.03678464889526367\n",
      "2017-11-11 08:19:43: Loss at step 6455: 0.03679857775568962\n",
      "2017-11-11 08:19:44: Loss at step 6456: 0.03668367490172386\n",
      "2017-11-11 08:19:44: Loss at step 6457: 0.03671718016266823\n",
      "2017-11-11 08:19:45: Loss at step 6458: 0.03667650744318962\n",
      "2017-11-11 08:19:45: Loss at step 6459: 0.03678898140788078\n",
      "2017-11-11 08:19:46: Loss at step 6460: 0.03673647344112396\n",
      "2017-11-11 08:19:46: Loss at step 6461: 0.036649227142333984\n",
      "2017-11-11 08:19:47: Loss at step 6462: 0.03673145920038223\n",
      "2017-11-11 08:19:47: Loss at step 6463: 0.03677491471171379\n",
      "2017-11-11 08:19:48: Loss at step 6464: 0.03677056357264519\n",
      "2017-11-11 08:19:48: Loss at step 6465: 0.0367995984852314\n",
      "2017-11-11 08:19:49: Loss at step 6466: 0.03678623214364052\n",
      "2017-11-11 08:19:49: Loss at step 6467: 0.036797307431697845\n",
      "2017-11-11 08:19:50: Loss at step 6468: 0.03678979352116585\n",
      "2017-11-11 08:19:50: Loss at step 6469: 0.036771148443222046\n",
      "2017-11-11 08:19:51: Loss at step 6470: 0.03679819032549858\n",
      "2017-11-11 08:19:51: Loss at step 6471: 0.03678795322775841\n",
      "2017-11-11 08:19:52: Loss at step 6472: 0.036755867302417755\n",
      "2017-11-11 08:19:52: Loss at step 6473: 0.03682853281497955\n",
      "2017-11-11 08:19:53: Loss at step 6474: 0.03683037310838699\n",
      "2017-11-11 08:19:53: Loss at step 6475: 0.03683255612850189\n",
      "2017-11-11 08:19:54: Loss at step 6476: 0.03678447753190994\n",
      "2017-11-11 08:19:54: Loss at step 6477: 0.036839086562395096\n",
      "2017-11-11 08:19:55: Loss at step 6478: 0.03684360533952713\n",
      "2017-11-11 08:19:55: Loss at step 6479: 0.036843523383140564\n",
      "2017-11-11 08:19:56: Loss at step 6480: 0.036803826689720154\n",
      "2017-11-11 08:19:56: Loss at step 6481: 0.036771826446056366\n",
      "2017-11-11 08:19:57: Loss at step 6482: 0.03690953925251961\n",
      "2017-11-11 08:19:57: Loss at step 6483: 0.03685682266950607\n",
      "2017-11-11 08:19:58: Loss at step 6484: 0.03684905543923378\n",
      "2017-11-11 08:19:58: Loss at step 6485: 0.03690205514431\n",
      "2017-11-11 08:19:59: Loss at step 6486: 0.03684445843100548\n",
      "2017-11-11 08:19:59: Loss at step 6487: 0.03684855252504349\n",
      "2017-11-11 08:20:00: Loss at step 6488: 0.03684443607926369\n",
      "2017-11-11 08:20:00: Loss at step 6489: 0.03673252463340759\n",
      "2017-11-11 08:20:01: Loss at step 6490: 0.036791492253541946\n",
      "2017-11-11 08:20:01: Loss at step 6491: 0.036895111203193665\n",
      "2017-11-11 08:20:02: Loss at step 6492: 0.03674955293536186\n",
      "2017-11-11 08:20:02: Loss at step 6493: 0.036896418780088425\n",
      "2017-11-11 08:20:03: Loss at step 6494: 0.03683044761419296\n",
      "2017-11-11 08:20:03: Loss at step 6495: 0.036846887320280075\n",
      "2017-11-11 08:20:04: Loss at step 6496: 0.03681690990924835\n",
      "2017-11-11 08:20:04: Loss at step 6497: 0.03681895509362221\n",
      "2017-11-11 08:20:05: Loss at step 6498: 0.03687475994229317\n",
      "2017-11-11 08:20:05: Loss at step 6499: 0.036866478621959686\n",
      "2017-11-11 08:20:06: Loss at step 6500: 0.036820460110902786\n",
      "2017-11-11 08:20:06: Loss at step 6501: 0.03677886351943016\n",
      "2017-11-11 08:20:07: Loss at step 6502: 0.036852940917015076\n",
      "2017-11-11 08:20:07: Loss at step 6503: 0.03677147254347801\n",
      "2017-11-11 08:20:08: Loss at step 6504: 0.03678670525550842\n",
      "2017-11-11 08:20:08: Loss at step 6505: 0.03686290234327316\n",
      "2017-11-11 08:20:08: Loss at step 6506: 0.03684457391500473\n",
      "2017-11-11 08:20:09: Loss at step 6507: 0.03681575134396553\n",
      "2017-11-11 08:20:09: Loss at step 6508: 0.03674095496535301\n",
      "2017-11-11 08:20:10: Loss at step 6509: 0.036668810993433\n",
      "2017-11-11 08:20:11: Loss at step 6510: 0.036705829203128815\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-11-11 08:20:11: Loss at step 6511: 0.036735162138938904\n",
      "2017-11-11 08:20:12: Loss at step 6512: 0.036749619990587234\n",
      "2017-11-11 08:20:12: Loss at step 6513: 0.036781471222639084\n",
      "2017-11-11 08:20:13: Loss at step 6514: 0.03678300604224205\n",
      "2017-11-11 08:20:13: Loss at step 6515: 0.036817580461502075\n",
      "2017-11-11 08:20:13: Loss at step 6516: 0.0368494987487793\n",
      "2017-11-11 08:20:14: Loss at step 6517: 0.03678204491734505\n",
      "2017-11-11 08:20:15: Loss at step 6518: 0.036831147968769073\n",
      "2017-11-11 08:20:15: Loss at step 6519: 0.03676785156130791\n",
      "2017-11-11 08:20:16: Loss at step 6520: 0.03678525984287262\n",
      "2017-11-11 08:20:16: Loss at step 6521: 0.03675880655646324\n",
      "2017-11-11 08:20:17: Loss at step 6522: 0.0367293506860733\n",
      "2017-11-11 08:20:17: Loss at step 6523: 0.03685639053583145\n",
      "2017-11-11 08:20:18: Loss at step 6524: 0.03677147254347801\n",
      "2017-11-11 08:20:18: Loss at step 6525: 0.03682207688689232\n",
      "2017-11-11 08:20:19: Loss at step 6526: 0.03677143529057503\n",
      "2017-11-11 08:20:19: Loss at step 6527: 0.036722179502248764\n",
      "2017-11-11 08:20:20: Loss at step 6528: 0.03674616664648056\n",
      "2017-11-11 08:20:20: Loss at step 6529: 0.036786194890737534\n",
      "2017-11-11 08:20:21: Loss at step 6530: 0.03670813515782356\n",
      "2017-11-11 08:20:21: Loss at step 6531: 0.03680654242634773\n",
      "2017-11-11 08:20:22: Loss at step 6532: 0.03672834485769272\n",
      "2017-11-11 08:20:22: Loss at step 6533: 0.03683477267622948\n",
      "2017-11-11 08:20:22: Loss at step 6534: 0.03681463003158569\n",
      "2017-11-11 08:20:23: Loss at step 6535: 0.03673921152949333\n",
      "2017-11-11 08:20:23: Loss at step 6536: 0.036667350679636\n",
      "2017-11-11 08:20:24: Loss at step 6537: 0.03673091530799866\n",
      "2017-11-11 08:20:25: Loss at step 6538: 0.036718789488077164\n",
      "2017-11-11 08:20:25: Loss at step 6539: 0.03670590743422508\n",
      "2017-11-11 08:20:26: Loss at step 6540: 0.03671887516975403\n",
      "2017-11-11 08:20:26: Loss at step 6541: 0.0366872139275074\n",
      "2017-11-11 08:20:26: Loss at step 6542: 0.03669462725520134\n",
      "2017-11-11 08:20:27: Loss at step 6543: 0.036700163036584854\n",
      "2017-11-11 08:20:27: Loss at step 6544: 0.036734893918037415\n",
      "2017-11-11 08:20:28: Loss at step 6545: 0.03671785071492195\n",
      "2017-11-11 08:20:28: Loss at step 6546: 0.03680095821619034\n",
      "2017-11-11 08:20:29: Loss at step 6547: 0.036717548966407776\n",
      "2017-11-11 08:20:29: Loss at step 6548: 0.03669389709830284\n",
      "2017-11-11 08:20:30: Loss at step 6549: 0.03670988231897354\n",
      "2017-11-11 08:20:30: Loss at step 6550: 0.03675336390733719\n",
      "2017-11-11 08:20:31: Loss at step 6551: 0.036733537912368774\n",
      "2017-11-11 08:20:31: Loss at step 6552: 0.036734018474817276\n",
      "2017-11-11 08:20:32: Loss at step 6553: 0.03682584688067436\n",
      "2017-11-11 08:20:32: Loss at step 6554: 0.03677745163440704\n",
      "2017-11-11 08:20:33: Loss at step 6555: 0.03677787631750107\n",
      "2017-11-11 08:20:33: Loss at step 6556: 0.03674100339412689\n",
      "2017-11-11 08:20:34: Loss at step 6557: 0.036777276545763016\n",
      "2017-11-11 08:20:34: Loss at step 6558: 0.036829832941293716\n",
      "2017-11-11 08:20:35: Loss at step 6559: 0.036723777651786804\n",
      "2017-11-11 08:20:35: Loss at step 6560: 0.0367010235786438\n",
      "2017-11-11 08:20:36: Loss at step 6561: 0.03673608973622322\n",
      "2017-11-11 08:20:36: Loss at step 6562: 0.03673933073878288\n",
      "2017-11-11 08:20:37: Loss at step 6563: 0.03672456741333008\n",
      "2017-11-11 08:20:37: Loss at step 6564: 0.03675327077507973\n",
      "2017-11-11 08:20:38: Loss at step 6565: 0.03673582896590233\n",
      "2017-11-11 08:20:38: Loss at step 6566: 0.03669803589582443\n",
      "2017-11-11 08:20:39: Loss at step 6567: 0.03673935681581497\n",
      "2017-11-11 08:20:39: Loss at step 6568: 0.03670389577746391\n",
      "2017-11-11 08:20:40: Loss at step 6569: 0.03672734275460243\n",
      "2017-11-11 08:20:40: Loss at step 6570: 0.036636363714933395\n",
      "2017-11-11 08:20:41: Loss at step 6571: 0.03671172633767128\n",
      "2017-11-11 08:20:41: Loss at step 6572: 0.03670966625213623\n",
      "2017-11-11 08:20:42: Loss at step 6573: 0.036749012768268585\n",
      "2017-11-11 08:20:42: Loss at step 6574: 0.03672279790043831\n",
      "2017-11-11 08:20:43: Loss at step 6575: 0.0366952158510685\n",
      "2017-11-11 08:20:43: Loss at step 6576: 0.036688581109046936\n",
      "2017-11-11 08:20:44: Loss at step 6577: 0.03672343119978905\n",
      "2017-11-11 08:20:44: Loss at step 6578: 0.036709897220134735\n",
      "2017-11-11 08:20:45: Loss at step 6579: 0.03667428717017174\n",
      "2017-11-11 08:20:45: Loss at step 6580: 0.0366472490131855\n",
      "2017-11-11 08:20:46: Loss at step 6581: 0.0366746261715889\n",
      "2017-11-11 08:20:46: Loss at step 6582: 0.03671939671039581\n",
      "2017-11-11 08:20:47: Loss at step 6583: 0.036762937903404236\n",
      "2017-11-11 08:20:47: Loss at step 6584: 0.03678399696946144\n",
      "2017-11-11 08:20:48: Loss at step 6585: 0.036671727895736694\n",
      "2017-11-11 08:20:48: Loss at step 6586: 0.03675338253378868\n",
      "2017-11-11 08:20:49: Loss at step 6587: 0.036732267588377\n",
      "2017-11-11 08:20:49: Loss at step 6588: 0.03683990612626076\n",
      "2017-11-11 08:20:50: Loss at step 6589: 0.03678015619516373\n",
      "2017-11-11 08:20:50: Loss at step 6590: 0.036672938615083694\n",
      "2017-11-11 08:20:51: Loss at step 6591: 0.03670978918671608\n",
      "2017-11-11 08:20:51: Loss at step 6592: 0.0366816408932209\n",
      "2017-11-11 08:20:52: Loss at step 6593: 0.03676056116819382\n",
      "2017-11-11 08:20:52: Loss at step 6594: 0.036710791289806366\n",
      "2017-11-11 08:20:53: Loss at step 6595: 0.036628615111112595\n",
      "2017-11-11 08:20:53: Loss at step 6596: 0.03680332005023956\n",
      "2017-11-11 08:20:54: Loss at step 6597: 0.03678875416517258\n",
      "2017-11-11 08:20:54: Loss at step 6598: 0.036685582250356674\n",
      "2017-11-11 08:20:55: Loss at step 6599: 0.03673145920038223\n",
      "2017-11-11 08:20:55: Loss at step 6600: 0.036807864904403687\n",
      "2017-11-11 08:20:56: Loss at step 6601: 0.03670915961265564\n",
      "2017-11-11 08:20:56: Loss at step 6602: 0.03666451573371887\n",
      "2017-11-11 08:20:57: Loss at step 6603: 0.036742135882377625\n",
      "2017-11-11 08:20:57: Loss at step 6604: 0.03665949031710625\n",
      "2017-11-11 08:20:58: Loss at step 6605: 0.03669419512152672\n",
      "2017-11-11 08:20:58: Loss at step 6606: 0.03672795742750168\n",
      "2017-11-11 08:20:59: Loss at step 6607: 0.03678900748491287\n",
      "2017-11-11 08:20:59: Loss at step 6608: 0.03677510470151901\n",
      "2017-11-11 08:21:00: Loss at step 6609: 0.0367477647960186\n",
      "2017-11-11 08:21:00: Loss at step 6610: 0.03671596571803093\n",
      "2017-11-11 08:21:01: Loss at step 6611: 0.036752354353666306\n",
      "2017-11-11 08:21:01: Loss at step 6612: 0.036836136132478714\n",
      "2017-11-11 08:21:02: Loss at step 6613: 0.03674114868044853\n",
      "2017-11-11 08:21:02: Loss at step 6614: 0.03668755665421486\n",
      "2017-11-11 08:21:03: Loss at step 6615: 0.03673204407095909\n",
      "2017-11-11 08:21:03: Loss at step 6616: 0.036770910024642944\n",
      "2017-11-11 08:21:04: Loss at step 6617: 0.03678324446082115\n",
      "2017-11-11 08:21:04: Loss at step 6618: 0.03674684464931488\n",
      "2017-11-11 08:21:05: Loss at step 6619: 0.03683280199766159\n",
      "2017-11-11 08:21:05: Loss at step 6620: 0.036752600222826004\n",
      "2017-11-11 08:21:06: Loss at step 6621: 0.036791540682315826\n",
      "2017-11-11 08:21:06: Loss at step 6622: 0.036783892661333084\n",
      "2017-11-11 08:21:07: Loss at step 6623: 0.036717548966407776\n",
      "2017-11-11 08:21:07: Loss at step 6624: 0.03682815656065941\n",
      "2017-11-11 08:21:08: Loss at step 6625: 0.036794263869524\n",
      "2017-11-11 08:21:08: Loss at step 6626: 0.03674141690135002\n",
      "2017-11-11 08:21:09: Loss at step 6627: 0.03673554211854935\n",
      "2017-11-11 08:21:09: Loss at step 6628: 0.036708470433950424\n",
      "2017-11-11 08:21:10: Loss at step 6629: 0.0367375910282135\n",
      "2017-11-11 08:21:10: Loss at step 6630: 0.036706652492284775\n",
      "2017-11-11 08:21:11: Loss at step 6631: 0.036705341190099716\n",
      "2017-11-11 08:21:11: Loss at step 6632: 0.03665826469659805\n",
      "2017-11-11 08:21:12: Loss at step 6633: 0.0367540568113327\n",
      "2017-11-11 08:21:12: Loss at step 6634: 0.03675057739019394\n",
      "2017-11-11 08:21:13: Loss at step 6635: 0.03669745847582817\n",
      "2017-11-11 08:21:13: Loss at step 6636: 0.03673909977078438\n",
      "2017-11-11 08:21:14: Loss at step 6637: 0.03676571696996689\n",
      "2017-11-11 08:21:14: Loss at step 6638: 0.03679772466421127\n",
      "2017-11-11 08:21:15: Loss at step 6639: 0.03673020005226135\n",
      "2017-11-11 08:21:15: Loss at step 6640: 0.036825623363256454\n",
      "2017-11-11 08:21:16: Loss at step 6641: 0.036783549934625626\n",
      "2017-11-11 08:21:16: Loss at step 6642: 0.0367460697889328\n",
      "2017-11-11 08:21:17: Loss at step 6643: 0.0367315299808979\n",
      "2017-11-11 08:21:17: Loss at step 6644: 0.03661784157156944\n",
      "2017-11-11 08:21:18: Loss at step 6645: 0.0366373285651207\n",
      "2017-11-11 08:21:19: Loss at step 6646: 0.03672021999955177\n",
      "2017-11-11 08:21:19: Loss at step 6647: 0.036650605499744415\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-11-11 08:21:20: Loss at step 6648: 0.03669164329767227\n",
      "2017-11-11 08:21:20: Loss at step 6649: 0.03666210174560547\n",
      "2017-11-11 08:21:20: Loss at step 6650: 0.03676421940326691\n",
      "2017-11-11 08:21:21: Loss at step 6651: 0.03672625496983528\n",
      "2017-11-11 08:21:21: Loss at step 6652: 0.03677033632993698\n",
      "2017-11-11 08:21:22: Loss at step 6653: 0.036694400012493134\n",
      "2017-11-11 08:21:22: Loss at step 6654: 0.036738477647304535\n",
      "2017-11-11 08:21:23: Loss at step 6655: 0.036736469715833664\n",
      "2017-11-11 08:21:23: Loss at step 6656: 0.03675821051001549\n",
      "2017-11-11 08:21:24: Loss at step 6657: 0.03671545907855034\n",
      "2017-11-11 08:21:25: Loss at step 6658: 0.036726076155900955\n",
      "2017-11-11 08:21:25: Loss at step 6659: 0.036726489663124084\n",
      "2017-11-11 08:21:25: Loss at step 6660: 0.03671564534306526\n",
      "2017-11-11 08:21:26: Loss at step 6661: 0.036660484969615936\n",
      "2017-11-11 08:21:26: Loss at step 6662: 0.036722149699926376\n",
      "2017-11-11 08:21:27: Loss at step 6663: 0.0366642102599144\n",
      "2017-11-11 08:21:27: Loss at step 6664: 0.036711085587739944\n",
      "2017-11-11 08:21:28: Loss at step 6665: 0.03672860562801361\n",
      "2017-11-11 08:21:28: Loss at step 6666: 0.03677861765027046\n",
      "2017-11-11 08:21:29: Loss at step 6667: 0.03667373210191727\n",
      "2017-11-11 08:21:29: Loss at step 6668: 0.036770228296518326\n",
      "2017-11-11 08:21:30: Loss at step 6669: 0.03668709844350815\n",
      "2017-11-11 08:21:30: Loss at step 6670: 0.036646515130996704\n",
      "2017-11-11 08:21:31: Loss at step 6671: 0.03668808937072754\n",
      "2017-11-11 08:21:32: Loss at step 6672: 0.0367661751806736\n",
      "2017-11-11 08:21:32: Loss at step 6673: 0.036715276539325714\n",
      "2017-11-11 08:21:33: Loss at step 6674: 0.03665539622306824\n",
      "2017-11-11 08:21:33: Loss at step 6675: 0.036695126444101334\n",
      "2017-11-11 08:21:34: Loss at step 6676: 0.03669331222772598\n",
      "2017-11-11 08:21:34: Loss at step 6677: 0.036728568375110626\n",
      "2017-11-11 08:21:34: Loss at step 6678: 0.03672327101230621\n",
      "2017-11-11 08:21:35: Loss at step 6679: 0.03670816496014595\n",
      "2017-11-11 08:21:35: Loss at step 6680: 0.03668200224637985\n",
      "2017-11-11 08:21:36: Loss at step 6681: 0.036691825836896896\n",
      "2017-11-11 08:21:36: Loss at step 6682: 0.036644406616687775\n",
      "2017-11-11 08:21:37: Loss at step 6683: 0.03675289452075958\n",
      "2017-11-11 08:21:37: Loss at step 6684: 0.036711182445287704\n",
      "2017-11-11 08:21:38: Loss at step 6685: 0.036797814071178436\n",
      "2017-11-11 08:21:38: Loss at step 6686: 0.03664135932922363\n",
      "2017-11-11 08:21:39: Loss at step 6687: 0.03660697117447853\n",
      "2017-11-11 08:21:39: Loss at step 6688: 0.03672325611114502\n",
      "2017-11-11 08:21:40: Loss at step 6689: 0.036669619381427765\n",
      "2017-11-11 08:21:41: Loss at step 6690: 0.03669685870409012\n",
      "2017-11-11 08:21:41: Loss at step 6691: 0.036715053021907806\n",
      "2017-11-11 08:21:42: Loss at step 6692: 0.036820873618125916\n",
      "2017-11-11 08:21:42: Loss at step 6693: 0.036633167415857315\n",
      "2017-11-11 08:21:42: Loss at step 6694: 0.036889854818582535\n",
      "2017-11-11 08:21:43: Loss at step 6695: 0.03670969977974892\n",
      "2017-11-11 08:21:43: Loss at step 6696: 0.03675946220755577\n",
      "2017-11-11 08:21:44: Loss at step 6697: 0.03674578294157982\n",
      "2017-11-11 08:21:45: Loss at step 6698: 0.0367853082716465\n",
      "2017-11-11 08:21:45: Loss at step 6699: 0.03678768128156662\n",
      "2017-11-11 08:21:46: Loss at step 6700: 0.03671887889504433\n",
      "2017-11-11 08:21:46: Loss at step 6701: 0.03683748468756676\n",
      "2017-11-11 08:21:47: Loss at step 6702: 0.03673141822218895\n",
      "2017-11-11 08:21:47: Loss at step 6703: 0.036790959537029266\n",
      "2017-11-11 08:21:48: Loss at step 6704: 0.03684424236416817\n",
      "2017-11-11 08:21:48: Loss at step 6705: 0.036816686391830444\n",
      "2017-11-11 08:21:49: Loss at step 6706: 0.036692019551992416\n",
      "2017-11-11 08:21:49: Loss at step 6707: 0.0367681160569191\n",
      "2017-11-11 08:21:50: Loss at step 6708: 0.03680519759654999\n",
      "2017-11-11 08:21:50: Loss at step 6709: 0.03663444146513939\n",
      "2017-11-11 08:21:51: Loss at step 6710: 0.03671623021364212\n",
      "2017-11-11 08:21:51: Loss at step 6711: 0.03674609959125519\n",
      "2017-11-11 08:21:52: Loss at step 6712: 0.03675096482038498\n",
      "2017-11-11 08:21:52: Loss at step 6713: 0.036833636462688446\n",
      "2017-11-11 08:21:53: Loss at step 6714: 0.036752160638570786\n",
      "2017-11-11 08:21:53: Loss at step 6715: 0.036760199815034866\n",
      "2017-11-11 08:21:54: Loss at step 6716: 0.03675348684191704\n",
      "2017-11-11 08:21:54: Loss at step 6717: 0.036750677973032\n",
      "2017-11-11 08:21:55: Loss at step 6718: 0.03676881268620491\n",
      "2017-11-11 08:21:55: Loss at step 6719: 0.03669818490743637\n",
      "2017-11-11 08:21:56: Loss at step 6720: 0.03669537231326103\n",
      "2017-11-11 08:21:56: Loss at step 6721: 0.036691080778837204\n",
      "2017-11-11 08:21:57: Loss at step 6722: 0.036652885377407074\n",
      "2017-11-11 08:21:57: Loss at step 6723: 0.03673708066344261\n",
      "2017-11-11 08:21:58: Loss at step 6724: 0.03673537075519562\n",
      "2017-11-11 08:21:58: Loss at step 6725: 0.036704108119010925\n",
      "2017-11-11 08:21:59: Loss at step 6726: 0.036844659596681595\n",
      "2017-11-11 08:21:59: Loss at step 6727: 0.03680606186389923\n",
      "2017-11-11 08:22:00: Loss at step 6728: 0.03668166324496269\n",
      "2017-11-11 08:22:00: Loss at step 6729: 0.03673352673649788\n",
      "2017-11-11 08:22:01: Loss at step 6730: 0.03671516850590706\n",
      "2017-11-11 08:22:01: Loss at step 6731: 0.03660758212208748\n",
      "2017-11-11 08:22:02: Loss at step 6732: 0.03672555834054947\n",
      "2017-11-11 08:22:02: Loss at step 6733: 0.036699339747428894\n",
      "2017-11-11 08:22:03: Loss at step 6734: 0.036760248243808746\n",
      "2017-11-11 08:22:03: Loss at step 6735: 0.036681681871414185\n",
      "2017-11-11 08:22:04: Loss at step 6736: 0.036767084151506424\n",
      "2017-11-11 08:22:04: Loss at step 6737: 0.03672473877668381\n",
      "2017-11-11 08:22:05: Loss at step 6738: 0.036683373153209686\n",
      "2017-11-11 08:22:05: Loss at step 6739: 0.036750271916389465\n",
      "2017-11-11 08:22:06: Loss at step 6740: 0.03672286495566368\n",
      "2017-11-11 08:22:06: Loss at step 6741: 0.03668718785047531\n",
      "2017-11-11 08:22:07: Loss at step 6742: 0.03676469996571541\n",
      "2017-11-11 08:22:07: Loss at step 6743: 0.03677048906683922\n",
      "2017-11-11 08:22:08: Loss at step 6744: 0.036637239158153534\n",
      "2017-11-11 08:22:08: Loss at step 6745: 0.03675009682774544\n",
      "2017-11-11 08:22:09: Loss at step 6746: 0.03673412650823593\n",
      "2017-11-11 08:22:09: Loss at step 6747: 0.0367460697889328\n",
      "2017-11-11 08:22:10: Loss at step 6748: 0.03668087720870972\n",
      "2017-11-11 08:22:10: Loss at step 6749: 0.03674854710698128\n",
      "2017-11-11 08:22:11: Loss at step 6750: 0.0367266982793808\n",
      "2017-11-11 08:22:11: Loss at step 6751: 0.03679327666759491\n",
      "2017-11-11 08:22:12: Loss at step 6752: 0.03674163296818733\n",
      "2017-11-11 08:22:12: Loss at step 6753: 0.0366719625890255\n",
      "2017-11-11 08:22:13: Loss at step 6754: 0.03670567646622658\n",
      "2017-11-11 08:22:13: Loss at step 6755: 0.03672470524907112\n",
      "2017-11-11 08:22:14: Loss at step 6756: 0.03670838475227356\n",
      "2017-11-11 08:22:14: Loss at step 6757: 0.03677409887313843\n",
      "2017-11-11 08:22:15: Loss at step 6758: 0.03673955798149109\n",
      "2017-11-11 08:22:15: Loss at step 6759: 0.0367237851023674\n",
      "2017-11-11 08:22:16: Loss at step 6760: 0.03668773174285889\n",
      "2017-11-11 08:22:16: Loss at step 6761: 0.036663301289081573\n",
      "2017-11-11 08:22:17: Loss at step 6762: 0.036755017936229706\n",
      "2017-11-11 08:22:17: Loss at step 6763: 0.03674875944852829\n",
      "2017-11-11 08:22:18: Loss at step 6764: 0.03672649711370468\n",
      "2017-11-11 08:22:18: Loss at step 6765: 0.036821190267801285\n",
      "2017-11-11 08:22:19: Loss at step 6766: 0.036739692091941833\n",
      "2017-11-11 08:22:19: Loss at step 6767: 0.036673132330179214\n",
      "2017-11-11 08:22:20: Loss at step 6768: 0.0367385633289814\n",
      "2017-11-11 08:22:20: Loss at step 6769: 0.03669833391904831\n",
      "2017-11-11 08:22:21: Loss at step 6770: 0.036721404641866684\n",
      "2017-11-11 08:22:21: Loss at step 6771: 0.036761265248060226\n",
      "2017-11-11 08:22:22: Loss at step 6772: 0.0366356335580349\n",
      "2017-11-11 08:22:22: Loss at step 6773: 0.036758702248334885\n",
      "2017-11-11 08:22:23: Loss at step 6774: 0.03664713725447655\n",
      "2017-11-11 08:22:23: Loss at step 6775: 0.036755915731191635\n",
      "2017-11-11 08:22:24: Loss at step 6776: 0.03674697503447533\n",
      "2017-11-11 08:22:24: Loss at step 6777: 0.03673245385289192\n",
      "2017-11-11 08:22:25: Loss at step 6778: 0.03675025701522827\n",
      "2017-11-11 08:22:25: Loss at step 6779: 0.036651283502578735\n",
      "2017-11-11 08:22:26: Loss at step 6780: 0.036715321242809296\n",
      "2017-11-11 08:22:26: Loss at step 6781: 0.036728385835886\n",
      "2017-11-11 08:22:27: Loss at step 6782: 0.0367761105298996\n",
      "2017-11-11 08:22:27: Loss at step 6783: 0.036687351763248444\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-11-11 08:22:28: Loss at step 6784: 0.03667086735367775\n",
      "2017-11-11 08:22:28: Loss at step 6785: 0.03671855479478836\n",
      "2017-11-11 08:22:29: Loss at step 6786: 0.03672421723604202\n",
      "2017-11-11 08:22:29: Loss at step 6787: 0.03674735128879547\n",
      "2017-11-11 08:22:29: Loss at step 6788: 0.036715321242809296\n",
      "2017-11-11 08:22:30: Loss at step 6789: 0.03679710999131203\n",
      "2017-11-11 08:22:30: Loss at step 6790: 0.0366847962141037\n",
      "2017-11-11 08:22:31: Loss at step 6791: 0.03676837310194969\n",
      "2017-11-11 08:22:32: Loss at step 6792: 0.03676086664199829\n",
      "2017-11-11 08:22:32: Loss at step 6793: 0.036741551011800766\n",
      "2017-11-11 08:22:33: Loss at step 6794: 0.03670571744441986\n",
      "2017-11-11 08:22:33: Loss at step 6795: 0.03673532232642174\n",
      "2017-11-11 08:22:33: Loss at step 6796: 0.0367337204515934\n",
      "2017-11-11 08:22:34: Loss at step 6797: 0.03668593615293503\n",
      "2017-11-11 08:22:34: Loss at step 6798: 0.036755796521902084\n",
      "2017-11-11 08:22:35: Loss at step 6799: 0.036696381866931915\n",
      "2017-11-11 08:22:35: Loss at step 6800: 0.03669576346874237\n",
      "2017-11-11 08:22:36: Loss at step 6801: 0.036680325865745544\n",
      "2017-11-11 08:22:36: Loss at step 6802: 0.03666607290506363\n",
      "2017-11-11 08:22:37: Loss at step 6803: 0.03674014285206795\n",
      "2017-11-11 08:22:37: Loss at step 6804: 0.036732111126184464\n",
      "2017-11-11 08:22:38: Loss at step 6805: 0.03672829642891884\n",
      "2017-11-11 08:22:38: Loss at step 6806: 0.03676605224609375\n",
      "2017-11-11 08:22:39: Loss at step 6807: 0.0367540642619133\n",
      "2017-11-11 08:22:39: Loss at step 6808: 0.036763183772563934\n",
      "2017-11-11 08:22:40: Loss at step 6809: 0.03672977164387703\n",
      "2017-11-11 08:22:40: Loss at step 6810: 0.036695994436740875\n",
      "2017-11-11 08:22:41: Loss at step 6811: 0.03671649098396301\n",
      "2017-11-11 08:22:41: Loss at step 6812: 0.036615557968616486\n",
      "2017-11-11 08:22:42: Loss at step 6813: 0.036681968718767166\n",
      "2017-11-11 08:22:42: Loss at step 6814: 0.03672301769256592\n",
      "2017-11-11 08:22:43: Loss at step 6815: 0.03671402111649513\n",
      "2017-11-11 08:22:43: Loss at step 6816: 0.036799535155296326\n",
      "2017-11-11 08:22:44: Loss at step 6817: 0.03674769401550293\n",
      "2017-11-11 08:22:44: Loss at step 6818: 0.03675135597586632\n",
      "2017-11-11 08:22:45: Loss at step 6819: 0.03673164173960686\n",
      "2017-11-11 08:22:45: Loss at step 6820: 0.03667398914694786\n",
      "2017-11-11 08:22:46: Loss at step 6821: 0.03670540824532509\n",
      "2017-11-11 08:22:46: Loss at step 6822: 0.03672926127910614\n",
      "2017-11-11 08:22:47: Loss at step 6823: 0.03669755533337593\n",
      "2017-11-11 08:22:47: Loss at step 6824: 0.03677356615662575\n",
      "2017-11-11 08:22:48: Loss at step 6825: 0.0367601178586483\n",
      "2017-11-11 08:22:48: Loss at step 6826: 0.03672422468662262\n",
      "2017-11-11 08:22:49: Loss at step 6827: 0.036693498492240906\n",
      "2017-11-11 08:22:49: Loss at step 6828: 0.03680316358804703\n",
      "2017-11-11 08:22:50: Loss at step 6829: 0.036823570728302\n",
      "2017-11-11 08:22:50: Loss at step 6830: 0.03680837154388428\n",
      "2017-11-11 08:22:51: Loss at step 6831: 0.0368032231926918\n",
      "2017-11-11 08:22:51: Loss at step 6832: 0.036721862852573395\n",
      "2017-11-11 08:22:52: Loss at step 6833: 0.036743663251399994\n",
      "2017-11-11 08:22:52: Loss at step 6834: 0.03674442693591118\n",
      "2017-11-11 08:22:53: Loss at step 6835: 0.036789607256650925\n",
      "2017-11-11 08:22:53: Loss at step 6836: 0.036805346608161926\n",
      "2017-11-11 08:22:54: Loss at step 6837: 0.03677549958229065\n",
      "2017-11-11 08:22:54: Loss at step 6838: 0.03676336631178856\n",
      "2017-11-11 08:22:55: Loss at step 6839: 0.03683402016758919\n",
      "2017-11-11 08:22:55: Loss at step 6840: 0.03684786707162857\n",
      "2017-11-11 08:22:56: Loss at step 6841: 0.03680881857872009\n",
      "2017-11-11 08:22:56: Loss at step 6842: 0.03673095256090164\n",
      "2017-11-11 08:22:57: Loss at step 6843: 0.03680713102221489\n",
      "2017-11-11 08:22:57: Loss at step 6844: 0.036753326654434204\n",
      "2017-11-11 08:22:58: Loss at step 6845: 0.03675876557826996\n",
      "2017-11-11 08:22:59: Loss at step 6846: 0.03675980120897293\n",
      "2017-11-11 08:22:59: Loss at step 6847: 0.03681834787130356\n",
      "2017-11-11 08:23:00: Loss at step 6848: 0.03679003193974495\n",
      "2017-11-11 08:23:00: Loss at step 6849: 0.03684045746922493\n",
      "2017-11-11 08:23:00: Loss at step 6850: 0.03675679862499237\n",
      "2017-11-11 08:23:01: Loss at step 6851: 0.03683938831090927\n",
      "2017-11-11 08:23:01: Loss at step 6852: 0.03675250709056854\n",
      "2017-11-11 08:23:02: Loss at step 6853: 0.03675856813788414\n",
      "2017-11-11 08:23:02: Loss at step 6854: 0.03682134300470352\n",
      "2017-11-11 08:23:03: Loss at step 6855: 0.03678188845515251\n",
      "2017-11-11 08:23:03: Loss at step 6856: 0.03678732365369797\n",
      "2017-11-11 08:23:04: Loss at step 6857: 0.03688308596611023\n",
      "2017-11-11 08:23:05: Loss at step 6858: 0.036783672869205475\n",
      "2017-11-11 08:23:05: Loss at step 6859: 0.03683805465698242\n",
      "2017-11-11 08:23:06: Loss at step 6860: 0.036836929619312286\n",
      "2017-11-11 08:23:06: Loss at step 6861: 0.036855023354291916\n",
      "2017-11-11 08:23:06: Loss at step 6862: 0.03690127283334732\n",
      "2017-11-11 08:23:07: Loss at step 6863: 0.036848317831754684\n",
      "2017-11-11 08:23:07: Loss at step 6864: 0.0368528850376606\n",
      "2017-11-11 08:23:08: Loss at step 6865: 0.03688865900039673\n",
      "2017-11-11 08:23:08: Loss at step 6866: 0.03674907982349396\n",
      "2017-11-11 08:23:09: Loss at step 6867: 0.03683124855160713\n",
      "2017-11-11 08:23:09: Loss at step 6868: 0.03688914701342583\n",
      "2017-11-11 08:23:10: Loss at step 6869: 0.03686198964715004\n",
      "2017-11-11 08:23:10: Loss at step 6870: 0.0368465818464756\n",
      "2017-11-11 08:23:11: Loss at step 6871: 0.03693016991019249\n",
      "2017-11-11 08:23:12: Loss at step 6872: 0.0369885116815567\n",
      "2017-11-11 08:23:12: Loss at step 6873: 0.03683645650744438\n",
      "2017-11-11 08:23:13: Loss at step 6874: 0.03687916323542595\n",
      "2017-11-11 08:23:13: Loss at step 6875: 0.036834169179201126\n",
      "2017-11-11 08:23:14: Loss at step 6876: 0.03683143109083176\n",
      "2017-11-11 08:23:14: Loss at step 6877: 0.036789704114198685\n",
      "2017-11-11 08:23:14: Loss at step 6878: 0.03690111264586449\n",
      "2017-11-11 08:23:15: Loss at step 6879: 0.036715034395456314\n",
      "2017-11-11 08:23:15: Loss at step 6880: 0.03685035929083824\n",
      "2017-11-11 08:23:16: Loss at step 6881: 0.03698302060365677\n",
      "2017-11-11 08:23:16: Loss at step 6882: 0.036906469613313675\n",
      "2017-11-11 08:23:17: Loss at step 6883: 0.036945756524801254\n",
      "2017-11-11 08:23:17: Loss at step 6884: 0.03696822375059128\n",
      "2017-11-11 08:23:18: Loss at step 6885: 0.03688816353678703\n",
      "2017-11-11 08:23:19: Loss at step 6886: 0.03695499897003174\n",
      "2017-11-11 08:23:19: Loss at step 6887: 0.03706015273928642\n",
      "2017-11-11 08:23:20: Loss at step 6888: 0.03702918440103531\n",
      "2017-11-11 08:23:20: Loss at step 6889: 0.037111297249794006\n",
      "2017-11-11 08:23:21: Loss at step 6890: 0.03717832639813423\n",
      "2017-11-11 08:23:21: Loss at step 6891: 0.03724154084920883\n",
      "2017-11-11 08:23:21: Loss at step 6892: 0.03735436126589775\n",
      "2017-11-11 08:23:22: Loss at step 6893: 0.03719806298613548\n",
      "2017-11-11 08:23:22: Loss at step 6894: 0.037366729229688644\n",
      "2017-11-11 08:23:23: Loss at step 6895: 0.03725200146436691\n",
      "2017-11-11 08:23:23: Loss at step 6896: 0.037230584770441055\n",
      "2017-11-11 08:23:24: Loss at step 6897: 0.037355732172727585\n",
      "2017-11-11 08:23:24: Loss at step 6898: 0.03732077032327652\n",
      "2017-11-11 08:23:25: Loss at step 6899: 0.03727751597762108\n",
      "2017-11-11 08:23:26: Loss at step 6900: 0.03701961785554886\n",
      "2017-11-11 08:23:26: Loss at step 6901: 0.036989085376262665\n",
      "2017-11-11 08:23:27: Loss at step 6902: 0.037297070026397705\n",
      "2017-11-11 08:23:27: Loss at step 6903: 0.03703264892101288\n",
      "2017-11-11 08:23:27: Loss at step 6904: 0.03713187947869301\n",
      "2017-11-11 08:23:28: Loss at step 6905: 0.03725266456604004\n",
      "2017-11-11 08:23:28: Loss at step 6906: 0.037169311195611954\n",
      "2017-11-11 08:23:29: Loss at step 6907: 0.03720958158373833\n",
      "2017-11-11 08:23:29: Loss at step 6908: 0.03710627928376198\n",
      "2017-11-11 08:23:30: Loss at step 6909: 0.03700575977563858\n",
      "2017-11-11 08:23:30: Loss at step 6910: 0.03684433549642563\n",
      "2017-11-11 08:23:31: Loss at step 6911: 0.03720426186919212\n",
      "2017-11-11 08:23:31: Loss at step 6912: 0.03689587861299515\n",
      "2017-11-11 08:23:32: Loss at step 6913: 0.036822088062763214\n",
      "2017-11-11 08:23:32: Loss at step 6914: 0.0368582159280777\n",
      "2017-11-11 08:23:33: Loss at step 6915: 0.03679869323968887\n",
      "2017-11-11 08:23:33: Loss at step 6916: 0.03694769740104675\n",
      "2017-11-11 08:23:34: Loss at step 6917: 0.036819301545619965\n",
      "2017-11-11 08:23:34: Loss at step 6918: 0.03688334301114082\n",
      "2017-11-11 08:23:35: Loss at step 6919: 0.03693524748086929\n",
      "2017-11-11 08:23:35: Loss at step 6920: 0.03678419813513756\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-11-11 08:23:36: Loss at step 6921: 0.03680732473731041\n",
      "2017-11-11 08:23:36: Loss at step 6922: 0.036824990063905716\n",
      "2017-11-11 08:23:37: Loss at step 6923: 0.03686857223510742\n",
      "2017-11-11 08:23:37: Loss at step 6924: 0.036743730306625366\n",
      "2017-11-11 08:23:38: Loss at step 6925: 0.036818619817495346\n",
      "2017-11-11 08:23:38: Loss at step 6926: 0.03678383305668831\n",
      "2017-11-11 08:23:39: Loss at step 6927: 0.03674694150686264\n",
      "2017-11-11 08:23:39: Loss at step 6928: 0.0368051640689373\n",
      "2017-11-11 08:23:40: Loss at step 6929: 0.03677728772163391\n",
      "2017-11-11 08:23:40: Loss at step 6930: 0.036757729947566986\n",
      "2017-11-11 08:23:41: Loss at step 6931: 0.03674453869462013\n",
      "2017-11-11 08:23:41: Loss at step 6932: 0.03677982836961746\n",
      "2017-11-11 08:23:42: Loss at step 6933: 0.036744825541973114\n",
      "2017-11-11 08:23:42: Loss at step 6934: 0.036719515919685364\n",
      "2017-11-11 08:23:43: Loss at step 6935: 0.03671415150165558\n",
      "2017-11-11 08:23:43: Loss at step 6936: 0.03675731271505356\n",
      "2017-11-11 08:23:44: Loss at step 6937: 0.03671114519238472\n",
      "2017-11-11 08:23:44: Loss at step 6938: 0.036786820739507675\n",
      "2017-11-11 08:23:45: Loss at step 6939: 0.036779798567295074\n",
      "2017-11-11 08:23:45: Loss at step 6940: 0.03682834655046463\n",
      "2017-11-11 08:23:46: Loss at step 6941: 0.03671180084347725\n",
      "2017-11-11 08:23:46: Loss at step 6942: 0.036809273064136505\n",
      "2017-11-11 08:23:47: Loss at step 6943: 0.03670119121670723\n",
      "2017-11-11 08:23:47: Loss at step 6944: 0.036772020161151886\n",
      "2017-11-11 08:23:48: Loss at step 6945: 0.03678636997938156\n",
      "2017-11-11 08:23:48: Loss at step 6946: 0.03676911070942879\n",
      "2017-11-11 08:23:49: Loss at step 6947: 0.03673703968524933\n",
      "2017-11-11 08:23:49: Loss at step 6948: 0.03667902946472168\n",
      "2017-11-11 08:23:50: Loss at step 6949: 0.036810509860515594\n",
      "2017-11-11 08:23:50: Loss at step 6950: 0.03669406846165657\n",
      "2017-11-11 08:23:51: Loss at step 6951: 0.03668544441461563\n",
      "2017-11-11 08:23:52: Loss at step 6952: 0.036765217781066895\n",
      "2017-11-11 08:23:52: Loss at step 6953: 0.03670506551861763\n",
      "2017-11-11 08:23:53: Loss at step 6954: 0.03668559342622757\n",
      "2017-11-11 08:23:53: Loss at step 6955: 0.03680118918418884\n",
      "2017-11-11 08:23:53: Loss at step 6956: 0.03663692995905876\n",
      "2017-11-11 08:23:54: Loss at step 6957: 0.03667692095041275\n",
      "2017-11-11 08:23:54: Loss at step 6958: 0.03668953850865364\n",
      "2017-11-11 08:23:55: Loss at step 6959: 0.0367092527449131\n",
      "2017-11-11 08:23:55: Loss at step 6960: 0.03681808337569237\n",
      "2017-11-11 08:23:56: Loss at step 6961: 0.03674212470650673\n",
      "2017-11-11 08:23:56: Loss at step 6962: 0.03679390251636505\n",
      "2017-11-11 08:23:57: Loss at step 6963: 0.0368008017539978\n",
      "2017-11-11 08:23:57: Loss at step 6964: 0.03669234365224838\n",
      "2017-11-11 08:23:58: Loss at step 6965: 0.03673902153968811\n",
      "2017-11-11 08:23:59: Loss at step 6966: 0.036763746291399\n",
      "2017-11-11 08:23:59: Loss at step 6967: 0.03670216724276543\n",
      "2017-11-11 08:24:00: Loss at step 6968: 0.036660924553871155\n",
      "2017-11-11 08:24:00: Loss at step 6969: 0.036752648651599884\n",
      "2017-11-11 08:24:00: Loss at step 6970: 0.036709729582071304\n",
      "2017-11-11 08:24:01: Loss at step 6971: 0.03668438270688057\n",
      "2017-11-11 08:24:01: Loss at step 6972: 0.036873091012239456\n",
      "2017-11-11 08:24:02: Loss at step 6973: 0.03673428297042847\n",
      "2017-11-11 08:24:03: Loss at step 6974: 0.03681306913495064\n",
      "2017-11-11 08:24:03: Loss at step 6975: 0.03672679886221886\n",
      "2017-11-11 08:24:03: Loss at step 6976: 0.036769986152648926\n",
      "2017-11-11 08:24:04: Loss at step 6977: 0.036602068692445755\n",
      "2017-11-11 08:24:05: Loss at step 6978: 0.03671250119805336\n",
      "2017-11-11 08:24:05: Loss at step 6979: 0.036653075367212296\n",
      "2017-11-11 08:24:06: Loss at step 6980: 0.03661638870835304\n",
      "2017-11-11 08:24:06: Loss at step 6981: 0.03670269623398781\n",
      "2017-11-11 08:24:06: Loss at step 6982: 0.03669954091310501\n",
      "2017-11-11 08:24:07: Loss at step 6983: 0.03665917366743088\n",
      "2017-11-11 08:24:07: Loss at step 6984: 0.03675903379917145\n",
      "2017-11-11 08:24:08: Loss at step 6985: 0.036648597568273544\n",
      "2017-11-11 08:24:08: Loss at step 6986: 0.03673850744962692\n",
      "2017-11-11 08:24:09: Loss at step 6987: 0.03677605465054512\n",
      "2017-11-11 08:24:09: Loss at step 6988: 0.03669550269842148\n",
      "2017-11-11 08:24:10: Loss at step 6989: 0.03674968332052231\n",
      "2017-11-11 08:24:10: Loss at step 6990: 0.03669200837612152\n",
      "2017-11-11 08:24:11: Loss at step 6991: 0.036710746586322784\n",
      "2017-11-11 08:24:11: Loss at step 6992: 0.03666939586400986\n",
      "2017-11-11 08:24:12: Loss at step 6993: 0.03676857799291611\n",
      "2017-11-11 08:24:12: Loss at step 6994: 0.03675428032875061\n",
      "2017-11-11 08:24:13: Loss at step 6995: 0.03672393038868904\n",
      "2017-11-11 08:24:14: Loss at step 6996: 0.03667987138032913\n",
      "2017-11-11 08:24:14: Loss at step 6997: 0.036721501499414444\n",
      "2017-11-11 08:24:14: Loss at step 6998: 0.0367114283144474\n",
      "2017-11-11 08:24:15: Loss at step 6999: 0.03670256957411766\n",
      "2017-11-11 08:24:15: Loss at step 7000: 0.03669055923819542\n",
      "2017-11-11 08:24:16: Loss at step 7001: 0.036775700747966766\n",
      "2017-11-11 08:24:16: Loss at step 7002: 0.036771658807992935\n",
      "2017-11-11 08:24:17: Loss at step 7003: 0.036747731268405914\n",
      "2017-11-11 08:24:17: Loss at step 7004: 0.036675430834293365\n",
      "2017-11-11 08:24:18: Loss at step 7005: 0.0367421880364418\n",
      "2017-11-11 08:24:18: Loss at step 7006: 0.03675989434123039\n",
      "2017-11-11 08:24:19: Loss at step 7007: 0.0366814061999321\n",
      "2017-11-11 08:24:19: Loss at step 7008: 0.03677630424499512\n",
      "2017-11-11 08:24:20: Loss at step 7009: 0.036714933812618256\n",
      "2017-11-11 08:24:20: Loss at step 7010: 0.03675392270088196\n",
      "2017-11-11 08:24:21: Loss at step 7011: 0.03680844604969025\n",
      "2017-11-11 08:24:21: Loss at step 7012: 0.036804381757974625\n",
      "2017-11-11 08:24:22: Loss at step 7013: 0.03673823922872543\n",
      "2017-11-11 08:24:22: Loss at step 7014: 0.03679641708731651\n",
      "2017-11-11 08:24:23: Loss at step 7015: 0.03672491014003754\n",
      "2017-11-11 08:24:23: Loss at step 7016: 0.036734797060489655\n",
      "2017-11-11 08:24:24: Loss at step 7017: 0.03671001270413399\n",
      "2017-11-11 08:24:24: Loss at step 7018: 0.03671093285083771\n",
      "2017-11-11 08:24:25: Loss at step 7019: 0.03679736331105232\n",
      "2017-11-11 08:24:25: Loss at step 7020: 0.036740727722644806\n",
      "2017-11-11 08:24:26: Loss at step 7021: 0.03679507598280907\n",
      "2017-11-11 08:24:26: Loss at step 7022: 0.0367126390337944\n",
      "2017-11-11 08:24:26: Loss at step 7023: 0.036707840859889984\n",
      "2017-11-11 08:24:27: Loss at step 7024: 0.03673826530575752\n",
      "2017-11-11 08:24:27: Loss at step 7025: 0.03679099306464195\n",
      "2017-11-11 08:24:28: Loss at step 7026: 0.03675489500164986\n",
      "2017-11-11 08:24:28: Loss at step 7027: 0.03683040291070938\n",
      "2017-11-11 08:24:29: Loss at step 7028: 0.03679348900914192\n",
      "2017-11-11 08:24:29: Loss at step 7029: 0.03675935044884682\n",
      "2017-11-11 08:24:30: Loss at step 7030: 0.03680858761072159\n",
      "2017-11-11 08:24:30: Loss at step 7031: 0.03670559823513031\n",
      "2017-11-11 08:24:31: Loss at step 7032: 0.03673806041479111\n",
      "2017-11-11 08:24:31: Loss at step 7033: 0.036792535334825516\n",
      "2017-11-11 08:24:32: Loss at step 7034: 0.03666909039020538\n",
      "2017-11-11 08:24:32: Loss at step 7035: 0.03676816076040268\n",
      "2017-11-11 08:24:33: Loss at step 7036: 0.036739543080329895\n",
      "2017-11-11 08:24:33: Loss at step 7037: 0.036676183342933655\n",
      "2017-11-11 08:24:34: Loss at step 7038: 0.03678157925605774\n",
      "2017-11-11 08:24:34: Loss at step 7039: 0.036721453070640564\n",
      "2017-11-11 08:24:35: Loss at step 7040: 0.03673413023352623\n",
      "2017-11-11 08:24:35: Loss at step 7041: 0.03677153214812279\n",
      "2017-11-11 08:24:35: Loss at step 7042: 0.03665994107723236\n",
      "2017-11-11 08:24:36: Loss at step 7043: 0.036842528730630875\n",
      "2017-11-11 08:24:37: Loss at step 7044: 0.036787401884794235\n",
      "2017-11-11 08:24:37: Loss at step 7045: 0.03674648329615593\n",
      "2017-11-11 08:24:37: Loss at step 7046: 0.03670167177915573\n",
      "2017-11-11 08:24:38: Loss at step 7047: 0.036726951599121094\n",
      "2017-11-11 08:24:38: Loss at step 7048: 0.03670702502131462\n",
      "2017-11-11 08:24:39: Loss at step 7049: 0.036642368882894516\n",
      "2017-11-11 08:24:39: Loss at step 7050: 0.0366353765130043\n",
      "2017-11-11 08:24:40: Loss at step 7051: 0.03682217374444008\n",
      "2017-11-11 08:24:40: Loss at step 7052: 0.03673715144395828\n",
      "2017-11-11 08:24:41: Loss at step 7053: 0.03671193867921829\n",
      "2017-11-11 08:24:41: Loss at step 7054: 0.03682991489768028\n",
      "2017-11-11 08:24:42: Loss at step 7055: 0.03667481616139412\n",
      "2017-11-11 08:24:42: Loss at step 7056: 0.03672357648611069\n",
      "2017-11-11 08:24:43: Loss at step 7057: 0.03674640879034996\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-11-11 08:24:43: Loss at step 7058: 0.036748554557561874\n",
      "2017-11-11 08:24:44: Loss at step 7059: 0.036788176745176315\n",
      "2017-11-11 08:24:44: Loss at step 7060: 0.036715488880872726\n",
      "2017-11-11 08:24:45: Loss at step 7061: 0.036756183952093124\n",
      "2017-11-11 08:24:45: Loss at step 7062: 0.03668029233813286\n",
      "2017-11-11 08:24:46: Loss at step 7063: 0.03667842596769333\n",
      "2017-11-11 08:24:46: Loss at step 7064: 0.03676141798496246\n",
      "2017-11-11 08:24:47: Loss at step 7065: 0.03674578666687012\n",
      "2017-11-11 08:24:47: Loss at step 7066: 0.03680773451924324\n",
      "2017-11-11 08:24:48: Loss at step 7067: 0.03678474202752113\n",
      "2017-11-11 08:24:48: Loss at step 7068: 0.03679300472140312\n",
      "2017-11-11 08:24:49: Loss at step 7069: 0.036833230406045914\n",
      "2017-11-11 08:24:49: Loss at step 7070: 0.03673684224486351\n",
      "2017-11-11 08:24:50: Loss at step 7071: 0.03676550090312958\n",
      "2017-11-11 08:24:50: Loss at step 7072: 0.03680132329463959\n",
      "2017-11-11 08:24:51: Loss at step 7073: 0.03674548864364624\n",
      "2017-11-11 08:24:51: Loss at step 7074: 0.036785632371902466\n",
      "2017-11-11 08:24:52: Loss at step 7075: 0.036780185997486115\n",
      "2017-11-11 08:24:52: Loss at step 7076: 0.03665371611714363\n",
      "2017-11-11 08:24:53: Loss at step 7077: 0.03673239052295685\n",
      "2017-11-11 08:24:53: Loss at step 7078: 0.03677689656615257\n",
      "2017-11-11 08:24:54: Loss at step 7079: 0.03678980842232704\n",
      "2017-11-11 08:24:54: Loss at step 7080: 0.036731697618961334\n",
      "2017-11-11 08:24:55: Loss at step 7081: 0.036663807928562164\n",
      "2017-11-11 08:24:55: Loss at step 7082: 0.03672229126095772\n",
      "2017-11-11 08:24:56: Loss at step 7083: 0.036687083542346954\n",
      "2017-11-11 08:24:56: Loss at step 7084: 0.036740344017744064\n",
      "2017-11-11 08:24:57: Loss at step 7085: 0.036732129752635956\n",
      "2017-11-11 08:24:57: Loss at step 7086: 0.03673917427659035\n",
      "2017-11-11 08:24:58: Loss at step 7087: 0.03671129047870636\n",
      "2017-11-11 08:24:58: Loss at step 7088: 0.03664112091064453\n",
      "2017-11-11 08:24:59: Loss at step 7089: 0.036585401743650436\n",
      "2017-11-11 08:24:59: Loss at step 7090: 0.03674335405230522\n",
      "2017-11-11 08:25:00: Loss at step 7091: 0.03669305890798569\n",
      "2017-11-11 08:25:00: Loss at step 7092: 0.03673065826296806\n",
      "2017-11-11 08:25:01: Loss at step 7093: 0.03666023164987564\n",
      "2017-11-11 08:25:01: Loss at step 7094: 0.036689676344394684\n",
      "2017-11-11 08:25:02: Loss at step 7095: 0.03666556999087334\n",
      "2017-11-11 08:25:02: Loss at step 7096: 0.036664899438619614\n",
      "2017-11-11 08:25:03: Loss at step 7097: 0.036701057106256485\n",
      "2017-11-11 08:25:03: Loss at step 7098: 0.03672808036208153\n",
      "2017-11-11 08:25:04: Loss at step 7099: 0.03668292984366417\n",
      "2017-11-11 08:25:04: Loss at step 7100: 0.03668789193034172\n",
      "2017-11-11 08:25:05: Loss at step 7101: 0.036763690412044525\n",
      "2017-11-11 08:25:05: Loss at step 7102: 0.03671874850988388\n",
      "2017-11-11 08:25:06: Loss at step 7103: 0.0367741659283638\n",
      "2017-11-11 08:25:06: Loss at step 7104: 0.036686018109321594\n",
      "2017-11-11 08:25:07: Loss at step 7105: 0.03668239712715149\n",
      "2017-11-11 08:25:07: Loss at step 7106: 0.03676474839448929\n",
      "2017-11-11 08:25:08: Loss at step 7107: 0.03670185059309006\n",
      "2017-11-11 08:25:08: Loss at step 7108: 0.036834198981523514\n",
      "2017-11-11 08:25:09: Loss at step 7109: 0.03673078864812851\n",
      "2017-11-11 08:25:09: Loss at step 7110: 0.036687735468149185\n",
      "2017-11-11 08:25:10: Loss at step 7111: 0.036790233105421066\n",
      "2017-11-11 08:25:10: Loss at step 7112: 0.03675316646695137\n",
      "2017-11-11 08:25:11: Loss at step 7113: 0.036689672619104385\n",
      "2017-11-11 08:25:11: Loss at step 7114: 0.03666979819536209\n",
      "2017-11-11 08:25:12: Loss at step 7115: 0.03667312487959862\n",
      "2017-11-11 08:25:12: Loss at step 7116: 0.03684631362557411\n",
      "2017-11-11 08:25:13: Loss at step 7117: 0.03670563921332359\n",
      "2017-11-11 08:25:13: Loss at step 7118: 0.036720555275678635\n",
      "2017-11-11 08:25:14: Loss at step 7119: 0.03673199936747551\n",
      "2017-11-11 08:25:14: Loss at step 7120: 0.036690715700387955\n",
      "2017-11-11 08:25:15: Loss at step 7121: 0.0366966687142849\n",
      "2017-11-11 08:25:15: Loss at step 7122: 0.036697886884212494\n",
      "2017-11-11 08:25:16: Loss at step 7123: 0.03671880438923836\n",
      "2017-11-11 08:25:16: Loss at step 7124: 0.03666125237941742\n",
      "2017-11-11 08:25:17: Loss at step 7125: 0.03673844411969185\n",
      "2017-11-11 08:25:17: Loss at step 7126: 0.03679080680012703\n",
      "2017-11-11 08:25:18: Loss at step 7127: 0.03673429414629936\n",
      "2017-11-11 08:25:18: Loss at step 7128: 0.036644238978624344\n",
      "2017-11-11 08:25:19: Loss at step 7129: 0.03672447428107262\n",
      "2017-11-11 08:25:19: Loss at step 7130: 0.036735642701387405\n",
      "2017-11-11 08:25:20: Loss at step 7131: 0.03666284307837486\n",
      "2017-11-11 08:25:20: Loss at step 7132: 0.036725182086229324\n",
      "2017-11-11 08:25:21: Loss at step 7133: 0.03668414428830147\n",
      "2017-11-11 08:25:21: Loss at step 7134: 0.036810602992773056\n",
      "2017-11-11 08:25:22: Loss at step 7135: 0.036721255630254745\n",
      "2017-11-11 08:25:22: Loss at step 7136: 0.036819249391555786\n",
      "2017-11-11 08:25:23: Loss at step 7137: 0.03674396499991417\n",
      "2017-11-11 08:25:23: Loss at step 7138: 0.036798540502786636\n",
      "2017-11-11 08:25:24: Loss at step 7139: 0.03671092167496681\n",
      "2017-11-11 08:25:24: Loss at step 7140: 0.036774247884750366\n",
      "2017-11-11 08:25:25: Loss at step 7141: 0.036841124296188354\n",
      "2017-11-11 08:25:25: Loss at step 7142: 0.03673481568694115\n",
      "2017-11-11 08:25:26: Loss at step 7143: 0.03672747686505318\n",
      "2017-11-11 08:25:26: Loss at step 7144: 0.036675214767456055\n",
      "2017-11-11 08:25:26: Loss at step 7145: 0.036659516394138336\n",
      "2017-11-11 08:25:27: Loss at step 7146: 0.03672587126493454\n",
      "2017-11-11 08:25:27: Loss at step 7147: 0.03669470176100731\n",
      "2017-11-11 08:25:28: Loss at step 7148: 0.03683171421289444\n",
      "2017-11-11 08:25:28: Loss at step 7149: 0.03672958165407181\n",
      "2017-11-11 08:25:29: Loss at step 7150: 0.03669373691082001\n",
      "2017-11-11 08:25:29: Loss at step 7151: 0.03658650070428848\n",
      "2017-11-11 08:25:30: Loss at step 7152: 0.036710307002067566\n",
      "2017-11-11 08:25:31: Loss at step 7153: 0.0367303341627121\n",
      "2017-11-11 08:25:31: Loss at step 7154: 0.036698658019304276\n",
      "2017-11-11 08:25:31: Loss at step 7155: 0.036689404398202896\n",
      "2017-11-11 08:25:32: Loss at step 7156: 0.03664735332131386\n",
      "2017-11-11 08:25:32: Loss at step 7157: 0.036687202751636505\n",
      "2017-11-11 08:25:33: Loss at step 7158: 0.036786165088415146\n",
      "2017-11-11 08:25:33: Loss at step 7159: 0.036692243069410324\n",
      "2017-11-11 08:25:34: Loss at step 7160: 0.03667251393198967\n",
      "2017-11-11 08:25:34: Loss at step 7161: 0.03676605597138405\n",
      "2017-11-11 08:25:35: Loss at step 7162: 0.03667343780398369\n",
      "2017-11-11 08:25:35: Loss at step 7163: 0.03675280883908272\n",
      "2017-11-11 08:25:36: Loss at step 7164: 0.03670291602611542\n",
      "2017-11-11 08:25:36: Loss at step 7165: 0.03665012866258621\n",
      "2017-11-11 08:25:37: Loss at step 7166: 0.036690693348646164\n",
      "2017-11-11 08:25:37: Loss at step 7167: 0.036692433059215546\n",
      "2017-11-11 08:25:38: Loss at step 7168: 0.03667925298213959\n",
      "2017-11-11 08:25:38: Loss at step 7169: 0.03672482445836067\n",
      "2017-11-11 08:25:39: Loss at step 7170: 0.036625463515520096\n",
      "2017-11-11 08:25:39: Loss at step 7171: 0.03669667989015579\n",
      "2017-11-11 08:25:40: Loss at step 7172: 0.03674975410103798\n",
      "2017-11-11 08:25:40: Loss at step 7173: 0.036682069301605225\n",
      "2017-11-11 08:25:41: Loss at step 7174: 0.03671636804938316\n",
      "2017-11-11 08:25:41: Loss at step 7175: 0.036659251898527145\n",
      "2017-11-11 08:25:42: Loss at step 7176: 0.03667151927947998\n",
      "2017-11-11 08:25:42: Loss at step 7177: 0.0367264524102211\n",
      "2017-11-11 08:25:43: Loss at step 7178: 0.03665722534060478\n",
      "2017-11-11 08:25:43: Loss at step 7179: 0.03666352108120918\n",
      "2017-11-11 08:25:44: Loss at step 7180: 0.03662903979420662\n",
      "2017-11-11 08:25:44: Loss at step 7181: 0.03656758740544319\n",
      "2017-11-11 08:25:45: Loss at step 7182: 0.03674529865384102\n",
      "2017-11-11 08:25:45: Loss at step 7183: 0.036697130650281906\n",
      "2017-11-11 08:25:46: Loss at step 7184: 0.03660522773861885\n",
      "2017-11-11 08:25:46: Loss at step 7185: 0.03666025772690773\n",
      "2017-11-11 08:25:47: Loss at step 7186: 0.036708757281303406\n",
      "2017-11-11 08:25:47: Loss at step 7187: 0.036640558391809464\n",
      "2017-11-11 08:25:48: Loss at step 7188: 0.036688245832920074\n",
      "2017-11-11 08:25:48: Loss at step 7189: 0.03664449602365494\n",
      "2017-11-11 08:25:49: Loss at step 7190: 0.03667658194899559\n",
      "2017-11-11 08:25:49: Loss at step 7191: 0.036713507026433945\n",
      "2017-11-11 08:25:50: Loss at step 7192: 0.03677360713481903\n",
      "2017-11-11 08:25:50: Loss at step 7193: 0.03669741377234459\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-11-11 08:25:51: Loss at step 7194: 0.03671667352318764\n",
      "2017-11-11 08:25:51: Loss at step 7195: 0.03665193170309067\n",
      "2017-11-11 08:25:52: Loss at step 7196: 0.036745477467775345\n",
      "2017-11-11 08:25:52: Loss at step 7197: 0.03667376935482025\n",
      "2017-11-11 08:25:53: Loss at step 7198: 0.03679492324590683\n",
      "2017-11-11 08:25:53: Loss at step 7199: 0.036698102951049805\n",
      "2017-11-11 08:25:54: Loss at step 7200: 0.03682214021682739\n",
      "2017-11-11 08:25:54: Loss at step 7201: 0.03666223585605621\n",
      "2017-11-11 08:25:55: Loss at step 7202: 0.03673491254448891\n",
      "2017-11-11 08:25:55: Loss at step 7203: 0.03675815463066101\n",
      "2017-11-11 08:25:56: Loss at step 7204: 0.03675059974193573\n",
      "2017-11-11 08:25:56: Loss at step 7205: 0.036755144596099854\n",
      "2017-11-11 08:25:57: Loss at step 7206: 0.03672146797180176\n",
      "2017-11-11 08:25:57: Loss at step 7207: 0.03680805116891861\n",
      "2017-11-11 08:25:58: Loss at step 7208: 0.03667980805039406\n",
      "2017-11-11 08:25:58: Loss at step 7209: 0.036746084690093994\n",
      "2017-11-11 08:25:59: Loss at step 7210: 0.03672245517373085\n",
      "2017-11-11 08:25:59: Loss at step 7211: 0.0367874801158905\n",
      "2017-11-11 08:26:00: Loss at step 7212: 0.03674665093421936\n",
      "2017-11-11 08:26:00: Loss at step 7213: 0.03667459264397621\n",
      "2017-11-11 08:26:01: Loss at step 7214: 0.03677646443247795\n",
      "2017-11-11 08:26:01: Loss at step 7215: 0.03675734996795654\n",
      "2017-11-11 08:26:02: Loss at step 7216: 0.03680986538529396\n",
      "2017-11-11 08:26:02: Loss at step 7217: 0.036788374185562134\n",
      "2017-11-11 08:26:03: Loss at step 7218: 0.03674747794866562\n",
      "2017-11-11 08:26:03: Loss at step 7219: 0.03671634569764137\n",
      "2017-11-11 08:26:04: Loss at step 7220: 0.03679197281599045\n",
      "2017-11-11 08:26:04: Loss at step 7221: 0.03681139647960663\n",
      "2017-11-11 08:26:05: Loss at step 7222: 0.03680451586842537\n",
      "2017-11-11 08:26:05: Loss at step 7223: 0.03680099919438362\n",
      "2017-11-11 08:26:06: Loss at step 7224: 0.036808278411626816\n",
      "2017-11-11 08:26:06: Loss at step 7225: 0.036817241460084915\n",
      "2017-11-11 08:26:07: Loss at step 7226: 0.03678623586893082\n",
      "2017-11-11 08:26:07: Loss at step 7227: 0.03666176274418831\n",
      "2017-11-11 08:26:08: Loss at step 7228: 0.03667266294360161\n",
      "2017-11-11 08:26:08: Loss at step 7229: 0.03676869347691536\n",
      "2017-11-11 08:26:09: Loss at step 7230: 0.036813464015722275\n",
      "2017-11-11 08:26:09: Loss at step 7231: 0.03678186237812042\n",
      "2017-11-11 08:26:10: Loss at step 7232: 0.03670031949877739\n",
      "2017-11-11 08:26:10: Loss at step 7233: 0.03683764487504959\n",
      "2017-11-11 08:26:11: Loss at step 7234: 0.036822251975536346\n",
      "2017-11-11 08:26:11: Loss at step 7235: 0.03672914206981659\n",
      "2017-11-11 08:26:12: Loss at step 7236: 0.03675505891442299\n",
      "2017-11-11 08:26:12: Loss at step 7237: 0.0367223359644413\n",
      "2017-11-11 08:26:13: Loss at step 7238: 0.03675190359354019\n",
      "2017-11-11 08:26:13: Loss at step 7239: 0.03675513342022896\n",
      "2017-11-11 08:26:14: Loss at step 7240: 0.036735065281391144\n",
      "2017-11-11 08:26:14: Loss at step 7241: 0.03663613274693489\n",
      "2017-11-11 08:26:15: Loss at step 7242: 0.03675913065671921\n",
      "2017-11-11 08:26:15: Loss at step 7243: 0.036755479872226715\n",
      "2017-11-11 08:26:16: Loss at step 7244: 0.03675386309623718\n",
      "2017-11-11 08:26:16: Loss at step 7245: 0.03665756806731224\n",
      "2017-11-11 08:26:17: Loss at step 7246: 0.03661218285560608\n",
      "2017-11-11 08:26:17: Loss at step 7247: 0.03675215318799019\n",
      "2017-11-11 08:26:18: Loss at step 7248: 0.03670831397175789\n",
      "2017-11-11 08:26:18: Loss at step 7249: 0.03669239580631256\n",
      "2017-11-11 08:26:19: Loss at step 7250: 0.03673386201262474\n",
      "2017-11-11 08:26:19: Loss at step 7251: 0.03670342266559601\n",
      "2017-11-11 08:26:20: Loss at step 7252: 0.03675446659326553\n",
      "2017-11-11 08:26:20: Loss at step 7253: 0.03669201210141182\n",
      "2017-11-11 08:26:21: Loss at step 7254: 0.036786653101444244\n",
      "2017-11-11 08:26:21: Loss at step 7255: 0.03673775494098663\n",
      "2017-11-11 08:26:22: Loss at step 7256: 0.03677649423480034\n",
      "2017-11-11 08:26:22: Loss at step 7257: 0.03673199191689491\n",
      "2017-11-11 08:26:23: Loss at step 7258: 0.03672926872968674\n",
      "2017-11-11 08:26:23: Loss at step 7259: 0.036786578595638275\n",
      "2017-11-11 08:26:24: Loss at step 7260: 0.03676256537437439\n",
      "2017-11-11 08:26:24: Loss at step 7261: 0.036641381680965424\n",
      "2017-11-11 08:26:25: Loss at step 7262: 0.03674996271729469\n",
      "2017-11-11 08:26:25: Loss at step 7263: 0.03675292804837227\n",
      "2017-11-11 08:26:26: Loss at step 7264: 0.036755725741386414\n",
      "2017-11-11 08:26:26: Loss at step 7265: 0.036698706448078156\n",
      "2017-11-11 08:26:27: Loss at step 7266: 0.03669270500540733\n",
      "2017-11-11 08:26:27: Loss at step 7267: 0.03667338937520981\n",
      "2017-11-11 08:26:28: Loss at step 7268: 0.036691877990961075\n",
      "2017-11-11 08:26:28: Loss at step 7269: 0.03666699677705765\n",
      "2017-11-11 08:26:29: Loss at step 7270: 0.0367329940199852\n",
      "2017-11-11 08:26:29: Loss at step 7271: 0.036780375987291336\n",
      "2017-11-11 08:26:30: Loss at step 7272: 0.0367533341050148\n",
      "2017-11-11 08:26:30: Loss at step 7273: 0.03666485473513603\n",
      "2017-11-11 08:26:31: Loss at step 7274: 0.03667309135198593\n",
      "2017-11-11 08:26:31: Loss at step 7275: 0.03673891723155975\n",
      "2017-11-11 08:26:32: Loss at step 7276: 0.03675433248281479\n",
      "2017-11-11 08:26:32: Loss at step 7277: 0.03661677986383438\n",
      "2017-11-11 08:26:33: Loss at step 7278: 0.03664229437708855\n",
      "2017-11-11 08:26:33: Loss at step 7279: 0.0367017462849617\n",
      "2017-11-11 08:26:34: Loss at step 7280: 0.03670884296298027\n",
      "2017-11-11 08:26:34: Loss at step 7281: 0.03666619211435318\n",
      "2017-11-11 08:26:35: Loss at step 7282: 0.036777742207050323\n",
      "2017-11-11 08:26:35: Loss at step 7283: 0.036716993898153305\n",
      "2017-11-11 08:26:36: Loss at step 7284: 0.036835331469774246\n",
      "2017-11-11 08:26:36: Loss at step 7285: 0.03671678528189659\n",
      "2017-11-11 08:26:37: Loss at step 7286: 0.036713048815727234\n",
      "2017-11-11 08:26:37: Loss at step 7287: 0.036733172833919525\n",
      "2017-11-11 08:26:38: Loss at step 7288: 0.03672901168465614\n",
      "2017-11-11 08:26:38: Loss at step 7289: 0.036708202213048935\n",
      "2017-11-11 08:26:39: Loss at step 7290: 0.036716654896736145\n",
      "2017-11-11 08:26:39: Loss at step 7291: 0.0367128849029541\n",
      "2017-11-11 08:26:40: Loss at step 7292: 0.03676094487309456\n",
      "2017-11-11 08:26:40: Loss at step 7293: 0.03670208901166916\n",
      "2017-11-11 08:26:41: Loss at step 7294: 0.036767445504665375\n",
      "2017-11-11 08:26:41: Loss at step 7295: 0.03673607110977173\n",
      "2017-11-11 08:26:42: Loss at step 7296: 0.03678005188703537\n",
      "2017-11-11 08:26:42: Loss at step 7297: 0.03673451021313667\n",
      "2017-11-11 08:26:43: Loss at step 7298: 0.03664637356996536\n",
      "2017-11-11 08:26:43: Loss at step 7299: 0.03671512007713318\n",
      "2017-11-11 08:26:44: Loss at step 7300: 0.036801207810640335\n",
      "2017-11-11 08:26:44: Loss at step 7301: 0.03667563572525978\n",
      "2017-11-11 08:26:45: Loss at step 7302: 0.03671695664525032\n",
      "2017-11-11 08:26:45: Loss at step 7303: 0.0367315299808979\n",
      "2017-11-11 08:26:46: Loss at step 7304: 0.03678460791707039\n",
      "2017-11-11 08:26:46: Loss at step 7305: 0.03666029870510101\n",
      "2017-11-11 08:26:46: Loss at step 7306: 0.036672770977020264\n",
      "2017-11-11 08:26:47: Loss at step 7307: 0.03669505566358566\n",
      "2017-11-11 08:26:47: Loss at step 7308: 0.03674757853150368\n",
      "2017-11-11 08:26:48: Loss at step 7309: 0.03669344633817673\n",
      "2017-11-11 08:26:48: Loss at step 7310: 0.03666859492659569\n",
      "2017-11-11 08:26:49: Loss at step 7311: 0.036720942705869675\n",
      "2017-11-11 08:26:49: Loss at step 7312: 0.03676799684762955\n",
      "2017-11-11 08:26:50: Loss at step 7313: 0.03675507381558418\n",
      "2017-11-11 08:26:51: Loss at step 7314: 0.03686017915606499\n",
      "2017-11-11 08:26:51: Loss at step 7315: 0.036746442317962646\n",
      "2017-11-11 08:26:52: Loss at step 7316: 0.0367133654654026\n",
      "2017-11-11 08:26:52: Loss at step 7317: 0.03680244833230972\n",
      "2017-11-11 08:26:52: Loss at step 7318: 0.03675030544400215\n",
      "2017-11-11 08:26:53: Loss at step 7319: 0.03676072880625725\n",
      "2017-11-11 08:26:53: Loss at step 7320: 0.036784857511520386\n",
      "2017-11-11 08:26:54: Loss at step 7321: 0.03671221807599068\n",
      "2017-11-11 08:26:54: Loss at step 7322: 0.03681868687272072\n",
      "2017-11-11 08:26:55: Loss at step 7323: 0.03676154837012291\n",
      "2017-11-11 08:26:55: Loss at step 7324: 0.03685978427529335\n",
      "2017-11-11 08:26:56: Loss at step 7325: 0.036708638072013855\n",
      "2017-11-11 08:26:57: Loss at step 7326: 0.03684502840042114\n",
      "2017-11-11 08:26:57: Loss at step 7327: 0.03673795610666275\n",
      "2017-11-11 08:26:58: Loss at step 7328: 0.03668820485472679\n",
      "2017-11-11 08:26:58: Loss at step 7329: 0.036723542958498\n",
      "2017-11-11 08:26:58: Loss at step 7330: 0.03675084561109543\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-11-11 08:26:59: Loss at step 7331: 0.03671199828386307\n",
      "2017-11-11 08:26:59: Loss at step 7332: 0.03669697418808937\n",
      "2017-11-11 08:27:00: Loss at step 7333: 0.036702290177345276\n",
      "2017-11-11 08:27:00: Loss at step 7334: 0.03667759522795677\n",
      "2017-11-11 08:27:01: Loss at step 7335: 0.036807831376791\n",
      "2017-11-11 08:27:01: Loss at step 7336: 0.03678993880748749\n",
      "2017-11-11 08:27:02: Loss at step 7337: 0.03671285882592201\n",
      "2017-11-11 08:27:03: Loss at step 7338: 0.03675207123160362\n",
      "2017-11-11 08:27:03: Loss at step 7339: 0.03678765147924423\n",
      "2017-11-11 08:27:04: Loss at step 7340: 0.036770857870578766\n",
      "2017-11-11 08:27:04: Loss at step 7341: 0.03685525059700012\n",
      "2017-11-11 08:27:04: Loss at step 7342: 0.0367622897028923\n",
      "2017-11-11 08:27:05: Loss at step 7343: 0.0366816408932209\n",
      "2017-11-11 08:27:05: Loss at step 7344: 0.036737821996212006\n",
      "2017-11-11 08:27:06: Loss at step 7345: 0.03676309064030647\n",
      "2017-11-11 08:27:06: Loss at step 7346: 0.03667153790593147\n",
      "2017-11-11 08:27:07: Loss at step 7347: 0.036689337342977524\n",
      "2017-11-11 08:27:07: Loss at step 7348: 0.03668898344039917\n",
      "2017-11-11 08:27:08: Loss at step 7349: 0.03674204275012016\n",
      "2017-11-11 08:27:08: Loss at step 7350: 0.036746613681316376\n",
      "2017-11-11 08:27:09: Loss at step 7351: 0.036753300577402115\n",
      "2017-11-11 08:27:09: Loss at step 7352: 0.03679735213518143\n",
      "2017-11-11 08:27:10: Loss at step 7353: 0.036751873791217804\n",
      "2017-11-11 08:27:10: Loss at step 7354: 0.03675932437181473\n",
      "2017-11-11 08:27:11: Loss at step 7355: 0.03676967695355415\n",
      "2017-11-11 08:27:11: Loss at step 7356: 0.036728598177433014\n",
      "2017-11-11 08:27:12: Loss at step 7357: 0.03673292696475983\n",
      "2017-11-11 08:27:12: Loss at step 7358: 0.036719195544719696\n",
      "2017-11-11 08:27:13: Loss at step 7359: 0.036772020161151886\n",
      "2017-11-11 08:27:13: Loss at step 7360: 0.036636702716350555\n",
      "2017-11-11 08:27:14: Loss at step 7361: 0.03672488406300545\n",
      "2017-11-11 08:27:14: Loss at step 7362: 0.03677681088447571\n",
      "2017-11-11 08:27:15: Loss at step 7363: 0.03676409274339676\n",
      "2017-11-11 08:27:15: Loss at step 7364: 0.03670799732208252\n",
      "2017-11-11 08:27:16: Loss at step 7365: 0.03682149201631546\n",
      "2017-11-11 08:27:16: Loss at step 7366: 0.03675083816051483\n",
      "2017-11-11 08:27:17: Loss at step 7367: 0.036726247519254684\n",
      "2017-11-11 08:27:17: Loss at step 7368: 0.0366850420832634\n",
      "2017-11-11 08:27:18: Loss at step 7369: 0.03675374388694763\n",
      "2017-11-11 08:27:18: Loss at step 7370: 0.03678090125322342\n",
      "2017-11-11 08:27:19: Loss at step 7371: 0.036738235503435135\n",
      "2017-11-11 08:27:19: Loss at step 7372: 0.03668377548456192\n",
      "2017-11-11 08:27:20: Loss at step 7373: 0.03682325407862663\n",
      "2017-11-11 08:27:20: Loss at step 7374: 0.03675147518515587\n",
      "2017-11-11 08:27:21: Loss at step 7375: 0.03668999671936035\n",
      "2017-11-11 08:27:21: Loss at step 7376: 0.03664393723011017\n",
      "2017-11-11 08:27:22: Loss at step 7377: 0.03673245385289192\n",
      "2017-11-11 08:27:22: Loss at step 7378: 0.03667314350605011\n",
      "2017-11-11 08:27:23: Loss at step 7379: 0.03670492023229599\n",
      "2017-11-11 08:27:23: Loss at step 7380: 0.03676823154091835\n",
      "2017-11-11 08:27:24: Loss at step 7381: 0.036824487149715424\n",
      "2017-11-11 08:27:24: Loss at step 7382: 0.03671517223119736\n",
      "2017-11-11 08:27:25: Loss at step 7383: 0.036784715950489044\n",
      "2017-11-11 08:27:25: Loss at step 7384: 0.0367186963558197\n",
      "2017-11-11 08:27:26: Loss at step 7385: 0.036735810339450836\n",
      "2017-11-11 08:27:26: Loss at step 7386: 0.03674213960766792\n",
      "2017-11-11 08:27:27: Loss at step 7387: 0.036742325872182846\n",
      "2017-11-11 08:27:27: Loss at step 7388: 0.03672359511256218\n",
      "2017-11-11 08:27:28: Loss at step 7389: 0.03677712380886078\n",
      "2017-11-11 08:27:28: Loss at step 7390: 0.036681536585092545\n",
      "2017-11-11 08:27:29: Loss at step 7391: 0.036747369915246964\n",
      "2017-11-11 08:27:29: Loss at step 7392: 0.03678089752793312\n",
      "2017-11-11 08:27:30: Loss at step 7393: 0.03672339394688606\n",
      "2017-11-11 08:27:30: Loss at step 7394: 0.03680530562996864\n",
      "2017-11-11 08:27:31: Loss at step 7395: 0.036687690764665604\n",
      "2017-11-11 08:27:31: Loss at step 7396: 0.03677882254123688\n",
      "2017-11-11 08:27:32: Loss at step 7397: 0.03670291230082512\n",
      "2017-11-11 08:27:32: Loss at step 7398: 0.03668242692947388\n",
      "2017-11-11 08:27:33: Loss at step 7399: 0.03677128255367279\n",
      "2017-11-11 08:27:33: Loss at step 7400: 0.03655081242322922\n",
      "2017-11-11 08:27:34: Loss at step 7401: 0.03673522546887398\n",
      "2017-11-11 08:27:34: Loss at step 7402: 0.03676922246813774\n",
      "2017-11-11 08:27:35: Loss at step 7403: 0.03664444014430046\n",
      "2017-11-11 08:27:35: Loss at step 7404: 0.03669432923197746\n",
      "2017-11-11 08:27:36: Loss at step 7405: 0.03673861175775528\n",
      "2017-11-11 08:27:36: Loss at step 7406: 0.03669777885079384\n",
      "2017-11-11 08:27:37: Loss at step 7407: 0.03668242320418358\n",
      "2017-11-11 08:27:37: Loss at step 7408: 0.03666915372014046\n",
      "2017-11-11 08:27:38: Loss at step 7409: 0.03675041347742081\n",
      "2017-11-11 08:27:38: Loss at step 7410: 0.03674707189202309\n",
      "2017-11-11 08:27:39: Loss at step 7411: 0.03671766817569733\n",
      "2017-11-11 08:27:39: Loss at step 7412: 0.03673432022333145\n",
      "2017-11-11 08:27:40: Loss at step 7413: 0.03667960688471794\n",
      "2017-11-11 08:27:40: Loss at step 7414: 0.03669187054038048\n",
      "2017-11-11 08:27:41: Loss at step 7415: 0.03675317391753197\n",
      "2017-11-11 08:27:41: Loss at step 7416: 0.03676518052816391\n",
      "2017-11-11 08:27:42: Loss at step 7417: 0.036684922873973846\n",
      "2017-11-11 08:27:42: Loss at step 7418: 0.03682710975408554\n",
      "2017-11-11 08:27:43: Loss at step 7419: 0.03662106767296791\n",
      "2017-11-11 08:27:43: Loss at step 7420: 0.036704424768686295\n",
      "2017-11-11 08:27:44: Loss at step 7421: 0.036746472120285034\n",
      "2017-11-11 08:27:44: Loss at step 7422: 0.0367179811000824\n",
      "2017-11-11 08:27:45: Loss at step 7423: 0.036862194538116455\n",
      "2017-11-11 08:27:45: Loss at step 7424: 0.03670214116573334\n",
      "2017-11-11 08:27:46: Loss at step 7425: 0.036732133477926254\n",
      "2017-11-11 08:27:46: Loss at step 7426: 0.03667793050408363\n",
      "2017-11-11 08:27:47: Loss at step 7427: 0.03672294318675995\n",
      "2017-11-11 08:27:47: Loss at step 7428: 0.036711253225803375\n",
      "2017-11-11 08:27:48: Loss at step 7429: 0.036721765995025635\n",
      "2017-11-11 08:27:48: Loss at step 7430: 0.036749597638845444\n",
      "2017-11-11 08:27:49: Loss at step 7431: 0.036799438297748566\n",
      "2017-11-11 08:27:49: Loss at step 7432: 0.036771923303604126\n",
      "2017-11-11 08:27:50: Loss at step 7433: 0.03670366108417511\n",
      "2017-11-11 08:27:50: Loss at step 7434: 0.036804284900426865\n",
      "2017-11-11 08:27:51: Loss at step 7435: 0.036690495908260345\n",
      "2017-11-11 08:27:51: Loss at step 7436: 0.036736972630023956\n",
      "2017-11-11 08:27:52: Loss at step 7437: 0.03669968619942665\n",
      "2017-11-11 08:27:52: Loss at step 7438: 0.03675417602062225\n",
      "2017-11-11 08:27:52: Loss at step 7439: 0.03684527426958084\n",
      "2017-11-11 08:27:53: Loss at step 7440: 0.03671689331531525\n",
      "2017-11-11 08:27:53: Loss at step 7441: 0.03668438270688057\n",
      "2017-11-11 08:27:54: Loss at step 7442: 0.03662485256791115\n",
      "2017-11-11 08:27:54: Loss at step 7443: 0.03674386441707611\n",
      "2017-11-11 08:27:55: Loss at step 7444: 0.03670346736907959\n",
      "2017-11-11 08:27:56: Loss at step 7445: 0.036664463579654694\n",
      "2017-11-11 08:27:56: Loss at step 7446: 0.03673279657959938\n",
      "2017-11-11 08:27:57: Loss at step 7447: 0.03662814572453499\n",
      "2017-11-11 08:27:57: Loss at step 7448: 0.0367448590695858\n",
      "2017-11-11 08:27:58: Loss at step 7449: 0.036718107759952545\n",
      "2017-11-11 08:27:58: Loss at step 7450: 0.03667812421917915\n",
      "2017-11-11 08:27:59: Loss at step 7451: 0.03667562082409859\n",
      "2017-11-11 08:27:59: Loss at step 7452: 0.03676685690879822\n",
      "2017-11-11 08:27:59: Loss at step 7453: 0.03664137050509453\n",
      "2017-11-11 08:28:00: Loss at step 7454: 0.03667154535651207\n",
      "2017-11-11 08:28:00: Loss at step 7455: 0.036668021231889725\n",
      "2017-11-11 08:28:01: Loss at step 7456: 0.036602120846509933\n",
      "2017-11-11 08:28:01: Loss at step 7457: 0.03673951327800751\n",
      "2017-11-11 08:28:02: Loss at step 7458: 0.03668642416596413\n",
      "2017-11-11 08:28:03: Loss at step 7459: 0.0367729589343071\n",
      "2017-11-11 08:28:03: Loss at step 7460: 0.0367494598031044\n",
      "2017-11-11 08:28:04: Loss at step 7461: 0.0367363840341568\n",
      "2017-11-11 08:28:04: Loss at step 7462: 0.03671761974692345\n",
      "2017-11-11 08:28:04: Loss at step 7463: 0.036672238260507584\n",
      "2017-11-11 08:28:05: Loss at step 7464: 0.03675278276205063\n",
      "2017-11-11 08:28:05: Loss at step 7465: 0.03675166890025139\n",
      "2017-11-11 08:28:06: Loss at step 7466: 0.0367317795753479\n",
      "2017-11-11 08:28:06: Loss at step 7467: 0.036793384701013565\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-11-11 08:28:07: Loss at step 7468: 0.03675857186317444\n",
      "2017-11-11 08:28:07: Loss at step 7469: 0.03667903319001198\n",
      "2017-11-11 08:28:08: Loss at step 7470: 0.03671545535326004\n",
      "2017-11-11 08:28:08: Loss at step 7471: 0.03665834665298462\n",
      "2017-11-11 08:28:09: Loss at step 7472: 0.03669390827417374\n",
      "2017-11-11 08:28:09: Loss at step 7473: 0.0366973914206028\n",
      "2017-11-11 08:28:10: Loss at step 7474: 0.03670676797628403\n",
      "2017-11-11 08:28:10: Loss at step 7475: 0.03674517944455147\n",
      "2017-11-11 08:28:11: Loss at step 7476: 0.03678610920906067\n",
      "2017-11-11 08:28:11: Loss at step 7477: 0.03680284321308136\n",
      "2017-11-11 08:28:12: Loss at step 7478: 0.03676287457346916\n",
      "2017-11-11 08:28:12: Loss at step 7479: 0.036788348108530045\n",
      "2017-11-11 08:28:13: Loss at step 7480: 0.03673504292964935\n",
      "2017-11-11 08:28:13: Loss at step 7481: 0.03674565628170967\n",
      "2017-11-11 08:28:14: Loss at step 7482: 0.03675226867198944\n",
      "2017-11-11 08:28:14: Loss at step 7483: 0.03676672279834747\n",
      "2017-11-11 08:28:15: Loss at step 7484: 0.03671497851610184\n",
      "2017-11-11 08:28:15: Loss at step 7485: 0.036736633628606796\n",
      "2017-11-11 08:28:16: Loss at step 7486: 0.036758244037628174\n",
      "2017-11-11 08:28:16: Loss at step 7487: 0.03674158826470375\n",
      "2017-11-11 08:28:17: Loss at step 7488: 0.0367412343621254\n",
      "2017-11-11 08:28:17: Loss at step 7489: 0.03674622252583504\n",
      "2017-11-11 08:28:18: Loss at step 7490: 0.03674062341451645\n",
      "2017-11-11 08:28:18: Loss at step 7491: 0.03668125718832016\n",
      "2017-11-11 08:28:19: Loss at step 7492: 0.03669263795018196\n",
      "2017-11-11 08:28:19: Loss at step 7493: 0.03673934191465378\n",
      "2017-11-11 08:28:20: Loss at step 7494: 0.03675394132733345\n",
      "2017-11-11 08:28:20: Loss at step 7495: 0.03670725226402283\n",
      "2017-11-11 08:28:21: Loss at step 7496: 0.03673763945698738\n",
      "2017-11-11 08:28:21: Loss at step 7497: 0.03674740344285965\n",
      "2017-11-11 08:28:22: Loss at step 7498: 0.03678600490093231\n",
      "2017-11-11 08:28:22: Loss at step 7499: 0.03672059252858162\n",
      "2017-11-11 08:28:23: Loss at step 7500: 0.0366828478872776\n",
      "2017-11-11 08:28:23: Loss at step 7501: 0.036806341260671616\n",
      "2017-11-11 08:28:24: Loss at step 7502: 0.03678378462791443\n",
      "2017-11-11 08:28:24: Loss at step 7503: 0.03679840639233589\n",
      "2017-11-11 08:28:25: Loss at step 7504: 0.03663961961865425\n",
      "2017-11-11 08:28:25: Loss at step 7505: 0.036732420325279236\n",
      "2017-11-11 08:28:26: Loss at step 7506: 0.03678141534328461\n",
      "2017-11-11 08:28:26: Loss at step 7507: 0.03671923652291298\n",
      "2017-11-11 08:28:27: Loss at step 7508: 0.03673278167843819\n",
      "2017-11-11 08:28:27: Loss at step 7509: 0.03678290545940399\n",
      "2017-11-11 08:28:28: Loss at step 7510: 0.03672407194972038\n",
      "2017-11-11 08:28:28: Loss at step 7511: 0.03665347397327423\n",
      "2017-11-11 08:28:29: Loss at step 7512: 0.03662687912583351\n",
      "2017-11-11 08:28:29: Loss at step 7513: 0.036748602986335754\n",
      "2017-11-11 08:28:30: Loss at step 7514: 0.03671365976333618\n",
      "2017-11-11 08:28:30: Loss at step 7515: 0.0366927795112133\n",
      "2017-11-11 08:28:31: Loss at step 7516: 0.03668025881052017\n",
      "2017-11-11 08:28:31: Loss at step 7517: 0.036659277975559235\n",
      "2017-11-11 08:28:32: Loss at step 7518: 0.036724403500556946\n",
      "2017-11-11 08:28:32: Loss at step 7519: 0.03673091530799866\n",
      "2017-11-11 08:28:33: Loss at step 7520: 0.036661986261606216\n",
      "2017-11-11 08:28:33: Loss at step 7521: 0.036756034940481186\n",
      "2017-11-11 08:28:33: Loss at step 7522: 0.03674055635929108\n",
      "2017-11-11 08:28:34: Loss at step 7523: 0.036726318299770355\n",
      "2017-11-11 08:28:34: Loss at step 7524: 0.0367487370967865\n",
      "2017-11-11 08:28:35: Loss at step 7525: 0.036845579743385315\n",
      "2017-11-11 08:28:36: Loss at step 7526: 0.036738988012075424\n",
      "2017-11-11 08:28:36: Loss at step 7527: 0.036775317043066025\n",
      "2017-11-11 08:28:36: Loss at step 7528: 0.036716997623443604\n",
      "2017-11-11 08:28:37: Loss at step 7529: 0.036774635314941406\n",
      "2017-11-11 08:28:37: Loss at step 7530: 0.03680402785539627\n",
      "2017-11-11 08:28:38: Loss at step 7531: 0.036731645464897156\n",
      "2017-11-11 08:28:38: Loss at step 7532: 0.03677438199520111\n",
      "2017-11-11 08:28:39: Loss at step 7533: 0.03673938661813736\n",
      "2017-11-11 08:28:39: Loss at step 7534: 0.03667616844177246\n",
      "2017-11-11 08:28:40: Loss at step 7535: 0.03671560809016228\n",
      "2017-11-11 08:28:40: Loss at step 7536: 0.0367167666554451\n",
      "2017-11-11 08:28:41: Loss at step 7537: 0.03674096241593361\n",
      "2017-11-11 08:28:41: Loss at step 7538: 0.036740563809871674\n",
      "2017-11-11 08:28:42: Loss at step 7539: 0.03669692575931549\n",
      "2017-11-11 08:28:43: Loss at step 7540: 0.03671370446681976\n",
      "2017-11-11 08:28:43: Loss at step 7541: 0.03665732964873314\n",
      "2017-11-11 08:28:43: Loss at step 7542: 0.03668995574116707\n",
      "2017-11-11 08:28:44: Loss at step 7543: 0.03666466102004051\n",
      "2017-11-11 08:28:45: Loss at step 7544: 0.036729615181684494\n",
      "2017-11-11 08:28:45: Loss at step 7545: 0.03676309064030647\n",
      "2017-11-11 08:28:45: Loss at step 7546: 0.03673364594578743\n",
      "2017-11-11 08:28:46: Loss at step 7547: 0.03677352890372276\n",
      "2017-11-11 08:28:46: Loss at step 7548: 0.03681985288858414\n",
      "2017-11-11 08:28:47: Loss at step 7549: 0.03667536750435829\n",
      "2017-11-11 08:28:47: Loss at step 7550: 0.036705948412418365\n",
      "2017-11-11 08:28:48: Loss at step 7551: 0.036706436425447464\n",
      "2017-11-11 08:28:48: Loss at step 7552: 0.036732908338308334\n",
      "2017-11-11 08:28:49: Loss at step 7553: 0.036785226315259933\n",
      "2017-11-11 08:28:49: Loss at step 7554: 0.036731209605932236\n",
      "2017-11-11 08:28:50: Loss at step 7555: 0.03674206882715225\n",
      "2017-11-11 08:28:51: Loss at step 7556: 0.036743536591529846\n",
      "2017-11-11 08:28:51: Loss at step 7557: 0.03673316910862923\n",
      "2017-11-11 08:28:51: Loss at step 7558: 0.03668655827641487\n",
      "2017-11-11 08:28:52: Loss at step 7559: 0.036786653101444244\n",
      "2017-11-11 08:28:52: Loss at step 7560: 0.036768097430467606\n",
      "2017-11-11 08:28:53: Loss at step 7561: 0.03678283840417862\n",
      "2017-11-11 08:28:53: Loss at step 7562: 0.03674093633890152\n",
      "2017-11-11 08:28:54: Loss at step 7563: 0.03680436313152313\n",
      "2017-11-11 08:28:54: Loss at step 7564: 0.03672841563820839\n",
      "2017-11-11 08:28:55: Loss at step 7565: 0.03679012507200241\n",
      "2017-11-11 08:28:56: Loss at step 7566: 0.03684109076857567\n",
      "2017-11-11 08:28:56: Loss at step 7567: 0.03677242994308472\n",
      "2017-11-11 08:28:57: Loss at step 7568: 0.03675228729844093\n",
      "2017-11-11 08:28:57: Loss at step 7569: 0.03671476989984512\n",
      "2017-11-11 08:28:58: Loss at step 7570: 0.03681471571326256\n",
      "2017-11-11 08:28:58: Loss at step 7571: 0.036843299865722656\n",
      "2017-11-11 08:28:59: Loss at step 7572: 0.03682725504040718\n",
      "2017-11-11 08:28:59: Loss at step 7573: 0.03678523376584053\n",
      "2017-11-11 08:28:59: Loss at step 7574: 0.03682703152298927\n",
      "2017-11-11 08:29:00: Loss at step 7575: 0.036828406155109406\n",
      "2017-11-11 08:29:00: Loss at step 7576: 0.036715295165777206\n",
      "2017-11-11 08:29:01: Loss at step 7577: 0.03671304136514664\n",
      "2017-11-11 08:29:02: Loss at step 7578: 0.03672666475176811\n",
      "2017-11-11 08:29:02: Loss at step 7579: 0.03674870729446411\n",
      "2017-11-11 08:29:03: Loss at step 7580: 0.036728572100400925\n",
      "2017-11-11 08:29:03: Loss at step 7581: 0.036753714084625244\n",
      "2017-11-11 08:29:04: Loss at step 7582: 0.036754120141267776\n",
      "2017-11-11 08:29:04: Loss at step 7583: 0.0367269329726696\n",
      "2017-11-11 08:29:04: Loss at step 7584: 0.036774326115846634\n",
      "2017-11-11 08:29:05: Loss at step 7585: 0.03670591488480568\n",
      "2017-11-11 08:29:05: Loss at step 7586: 0.036787230521440506\n",
      "2017-11-11 08:29:06: Loss at step 7587: 0.03681838512420654\n",
      "2017-11-11 08:29:06: Loss at step 7588: 0.036721449345350266\n",
      "2017-11-11 08:29:07: Loss at step 7589: 0.03674352541565895\n",
      "2017-11-11 08:29:07: Loss at step 7590: 0.036840155720710754\n",
      "2017-11-11 08:29:08: Loss at step 7591: 0.036844272166490555\n",
      "2017-11-11 08:29:08: Loss at step 7592: 0.036886878311634064\n",
      "2017-11-11 08:29:09: Loss at step 7593: 0.03686695918440819\n",
      "2017-11-11 08:29:09: Loss at step 7594: 0.03668712079524994\n",
      "2017-11-11 08:29:10: Loss at step 7595: 0.03670297935605049\n",
      "2017-11-11 08:29:10: Loss at step 7596: 0.036723602563142776\n",
      "2017-11-11 08:29:11: Loss at step 7597: 0.03670952841639519\n",
      "2017-11-11 08:29:11: Loss at step 7598: 0.03675280883908272\n",
      "2017-11-11 08:29:12: Loss at step 7599: 0.036721810698509216\n",
      "2017-11-11 08:29:12: Loss at step 7600: 0.03669910132884979\n",
      "2017-11-11 08:29:13: Loss at step 7601: 0.03671572357416153\n",
      "2017-11-11 08:29:13: Loss at step 7602: 0.03669440746307373\n",
      "2017-11-11 08:29:14: Loss at step 7603: 0.0366959311068058\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-11-11 08:29:14: Loss at step 7604: 0.03678401932120323\n",
      "2017-11-11 08:29:15: Loss at step 7605: 0.036731284111738205\n",
      "2017-11-11 08:29:15: Loss at step 7606: 0.036660369485616684\n",
      "2017-11-11 08:29:16: Loss at step 7607: 0.03672026842832565\n",
      "2017-11-11 08:29:16: Loss at step 7608: 0.036705829203128815\n",
      "2017-11-11 08:29:17: Loss at step 7609: 0.03666425868868828\n",
      "2017-11-11 08:29:17: Loss at step 7610: 0.0367414616048336\n",
      "2017-11-11 08:29:18: Loss at step 7611: 0.036573078483343124\n",
      "2017-11-11 08:29:18: Loss at step 7612: 0.03667614609003067\n",
      "2017-11-11 08:29:19: Loss at step 7613: 0.036781035363674164\n",
      "2017-11-11 08:29:19: Loss at step 7614: 0.036695607006549835\n",
      "2017-11-11 08:29:20: Loss at step 7615: 0.03675542399287224\n",
      "2017-11-11 08:29:20: Loss at step 7616: 0.036727555096149445\n",
      "2017-11-11 08:29:21: Loss at step 7617: 0.036714453250169754\n",
      "2017-11-11 08:29:21: Loss at step 7618: 0.03665854036808014\n",
      "2017-11-11 08:29:22: Loss at step 7619: 0.03665832057595253\n",
      "2017-11-11 08:29:22: Loss at step 7620: 0.036728695034980774\n",
      "2017-11-11 08:29:23: Loss at step 7621: 0.03688628226518631\n",
      "2017-11-11 08:29:23: Loss at step 7622: 0.036807890981435776\n",
      "2017-11-11 08:29:24: Loss at step 7623: 0.036736343055963516\n",
      "2017-11-11 08:29:24: Loss at step 7624: 0.0367734394967556\n",
      "2017-11-11 08:29:25: Loss at step 7625: 0.03668868914246559\n",
      "2017-11-11 08:29:25: Loss at step 7626: 0.03674635291099548\n",
      "2017-11-11 08:29:26: Loss at step 7627: 0.03670203685760498\n",
      "2017-11-11 08:29:26: Loss at step 7628: 0.036803364753723145\n",
      "2017-11-11 08:29:27: Loss at step 7629: 0.036811865866184235\n",
      "2017-11-11 08:29:27: Loss at step 7630: 0.03674465790390968\n",
      "2017-11-11 08:29:28: Loss at step 7631: 0.03674767538905144\n",
      "2017-11-11 08:29:29: Loss at step 7632: 0.0366910882294178\n",
      "2017-11-11 08:29:29: Loss at step 7633: 0.03675124794244766\n",
      "2017-11-11 08:29:30: Loss at step 7634: 0.036706630140542984\n",
      "2017-11-11 08:29:30: Loss at step 7635: 0.03675307705998421\n",
      "2017-11-11 08:29:30: Loss at step 7636: 0.03676604852080345\n",
      "2017-11-11 08:29:31: Loss at step 7637: 0.03674373775720596\n",
      "2017-11-11 08:29:31: Loss at step 7638: 0.03682965040206909\n",
      "2017-11-11 08:29:32: Loss at step 7639: 0.03678515553474426\n",
      "2017-11-11 08:29:32: Loss at step 7640: 0.036717142909765244\n",
      "2017-11-11 08:29:33: Loss at step 7641: 0.036795832216739655\n",
      "2017-11-11 08:29:33: Loss at step 7642: 0.036752521991729736\n",
      "2017-11-11 08:29:34: Loss at step 7643: 0.036868128925561905\n",
      "2017-11-11 08:29:34: Loss at step 7644: 0.03671712800860405\n",
      "2017-11-11 08:29:35: Loss at step 7645: 0.03678296506404877\n",
      "2017-11-11 08:29:36: Loss at step 7646: 0.0366826169192791\n",
      "2017-11-11 08:29:36: Loss at step 7647: 0.036746636033058167\n",
      "2017-11-11 08:29:37: Loss at step 7648: 0.036803022027015686\n",
      "2017-11-11 08:29:37: Loss at step 7649: 0.0366523452103138\n",
      "2017-11-11 08:29:38: Loss at step 7650: 0.03673851490020752\n",
      "2017-11-11 08:29:38: Loss at step 7651: 0.036717113107442856\n",
      "2017-11-11 08:29:39: Loss at step 7652: 0.03675289824604988\n",
      "2017-11-11 08:29:39: Loss at step 7653: 0.03666789084672928\n",
      "2017-11-11 08:29:40: Loss at step 7654: 0.03675222024321556\n",
      "2017-11-11 08:29:40: Loss at step 7655: 0.03676177188754082\n",
      "2017-11-11 08:29:41: Loss at step 7656: 0.036698099225759506\n",
      "2017-11-11 08:29:41: Loss at step 7657: 0.03669100999832153\n",
      "2017-11-11 08:29:42: Loss at step 7658: 0.03673868998885155\n",
      "2017-11-11 08:29:42: Loss at step 7659: 0.03668070212006569\n",
      "2017-11-11 08:29:43: Loss at step 7660: 0.03672628849744797\n",
      "2017-11-11 08:29:43: Loss at step 7661: 0.03670086711645126\n",
      "2017-11-11 08:29:44: Loss at step 7662: 0.03677480295300484\n",
      "2017-11-11 08:29:44: Loss at step 7663: 0.03675585240125656\n",
      "2017-11-11 08:29:45: Loss at step 7664: 0.03672924265265465\n",
      "2017-11-11 08:29:45: Loss at step 7665: 0.036733195185661316\n",
      "2017-11-11 08:29:46: Loss at step 7666: 0.03678012639284134\n",
      "2017-11-11 08:29:46: Loss at step 7667: 0.036722369492053986\n",
      "2017-11-11 08:29:47: Loss at step 7668: 0.03674241900444031\n",
      "2017-11-11 08:29:47: Loss at step 7669: 0.03670746460556984\n",
      "2017-11-11 08:29:48: Loss at step 7670: 0.03670341894030571\n",
      "2017-11-11 08:29:48: Loss at step 7671: 0.03671463578939438\n",
      "2017-11-11 08:29:49: Loss at step 7672: 0.03677938133478165\n",
      "2017-11-11 08:29:49: Loss at step 7673: 0.03674611821770668\n",
      "2017-11-11 08:29:50: Loss at step 7674: 0.03669487312436104\n",
      "2017-11-11 08:29:50: Loss at step 7675: 0.03667636215686798\n",
      "2017-11-11 08:29:51: Loss at step 7676: 0.036765094846487045\n",
      "2017-11-11 08:29:51: Loss at step 7677: 0.036731939762830734\n",
      "2017-11-11 08:29:52: Loss at step 7678: 0.03671324625611305\n",
      "2017-11-11 08:29:52: Loss at step 7679: 0.03676903247833252\n",
      "2017-11-11 08:29:53: Loss at step 7680: 0.036755841225385666\n",
      "2017-11-11 08:29:53: Loss at step 7681: 0.0368005745112896\n",
      "2017-11-11 08:29:54: Loss at step 7682: 0.036715634167194366\n",
      "2017-11-11 08:29:54: Loss at step 7683: 0.036678288131952286\n",
      "2017-11-11 08:29:55: Loss at step 7684: 0.036817461252212524\n",
      "2017-11-11 08:29:55: Loss at step 7685: 0.03672783076763153\n",
      "2017-11-11 08:29:56: Loss at step 7686: 0.0368037223815918\n",
      "2017-11-11 08:29:56: Loss at step 7687: 0.03678593039512634\n",
      "2017-11-11 08:29:57: Loss at step 7688: 0.036668311804533005\n",
      "2017-11-11 08:29:57: Loss at step 7689: 0.036755193024873734\n",
      "2017-11-11 08:29:58: Loss at step 7690: 0.036757249385118484\n",
      "2017-11-11 08:29:58: Loss at step 7691: 0.03670421242713928\n",
      "2017-11-11 08:29:59: Loss at step 7692: 0.03676484525203705\n",
      "2017-11-11 08:29:59: Loss at step 7693: 0.03670014068484306\n",
      "2017-11-11 08:30:00: Loss at step 7694: 0.036773040890693665\n",
      "2017-11-11 08:30:00: Loss at step 7695: 0.036718983203172684\n",
      "2017-11-11 08:30:01: Loss at step 7696: 0.03667538985610008\n",
      "2017-11-11 08:30:01: Loss at step 7697: 0.036738261580467224\n",
      "2017-11-11 08:30:02: Loss at step 7698: 0.036779388785362244\n",
      "2017-11-11 08:30:02: Loss at step 7699: 0.03678277134895325\n",
      "2017-11-11 08:30:03: Loss at step 7700: 0.03680171072483063\n",
      "2017-11-11 08:30:03: Loss at step 7701: 0.03671982139348984\n",
      "2017-11-11 08:30:04: Loss at step 7702: 0.03677349165081978\n",
      "2017-11-11 08:30:04: Loss at step 7703: 0.03691832721233368\n",
      "2017-11-11 08:30:05: Loss at step 7704: 0.03676977381110191\n",
      "2017-11-11 08:30:05: Loss at step 7705: 0.03686153143644333\n",
      "2017-11-11 08:30:06: Loss at step 7706: 0.036807335913181305\n",
      "2017-11-11 08:30:06: Loss at step 7707: 0.03676297515630722\n",
      "2017-11-11 08:30:07: Loss at step 7708: 0.036711301654577255\n",
      "2017-11-11 08:30:07: Loss at step 7709: 0.03683803975582123\n",
      "2017-11-11 08:30:08: Loss at step 7710: 0.03681529313325882\n",
      "2017-11-11 08:30:08: Loss at step 7711: 0.03679323196411133\n",
      "2017-11-11 08:30:09: Loss at step 7712: 0.03681526333093643\n",
      "2017-11-11 08:30:09: Loss at step 7713: 0.03667982667684555\n",
      "2017-11-11 08:30:10: Loss at step 7714: 0.03678353503346443\n",
      "2017-11-11 08:30:10: Loss at step 7715: 0.03670686483383179\n",
      "2017-11-11 08:30:11: Loss at step 7716: 0.036660559475421906\n",
      "2017-11-11 08:30:11: Loss at step 7717: 0.03678246587514877\n",
      "2017-11-11 08:30:12: Loss at step 7718: 0.036769457161426544\n",
      "2017-11-11 08:30:12: Loss at step 7719: 0.03676978871226311\n",
      "2017-11-11 08:30:13: Loss at step 7720: 0.03672204539179802\n",
      "2017-11-11 08:30:13: Loss at step 7721: 0.03691030293703079\n",
      "2017-11-11 08:30:14: Loss at step 7722: 0.036835603415966034\n",
      "2017-11-11 08:30:14: Loss at step 7723: 0.03672110661864281\n",
      "2017-11-11 08:30:15: Loss at step 7724: 0.03680961951613426\n",
      "2017-11-11 08:30:15: Loss at step 7725: 0.0367765948176384\n",
      "2017-11-11 08:30:16: Loss at step 7726: 0.03674304857850075\n",
      "2017-11-11 08:30:16: Loss at step 7727: 0.036732494831085205\n",
      "2017-11-11 08:30:17: Loss at step 7728: 0.0367196649312973\n",
      "2017-11-11 08:30:17: Loss at step 7729: 0.03669403865933418\n",
      "2017-11-11 08:30:18: Loss at step 7730: 0.03665886074304581\n",
      "2017-11-11 08:30:18: Loss at step 7731: 0.03679857775568962\n",
      "2017-11-11 08:30:19: Loss at step 7732: 0.036720991134643555\n",
      "2017-11-11 08:30:19: Loss at step 7733: 0.03674875944852829\n",
      "2017-11-11 08:30:20: Loss at step 7734: 0.036673158407211304\n",
      "2017-11-11 08:30:20: Loss at step 7735: 0.03679107129573822\n",
      "2017-11-11 08:30:21: Loss at step 7736: 0.03670968487858772\n",
      "2017-11-11 08:30:21: Loss at step 7737: 0.03674811124801636\n",
      "2017-11-11 08:30:22: Loss at step 7738: 0.03667917102575302\n",
      "2017-11-11 08:30:22: Loss at step 7739: 0.03666846826672554\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-11-11 08:30:23: Loss at step 7740: 0.03679892420768738\n",
      "2017-11-11 08:30:23: Loss at step 7741: 0.03673817217350006\n",
      "2017-11-11 08:30:24: Loss at step 7742: 0.03661319240927696\n",
      "2017-11-11 08:30:24: Loss at step 7743: 0.0367865227162838\n",
      "2017-11-11 08:30:25: Loss at step 7744: 0.036715585738420486\n",
      "2017-11-11 08:30:25: Loss at step 7745: 0.03670116513967514\n",
      "2017-11-11 08:30:26: Loss at step 7746: 0.036699388176202774\n",
      "2017-11-11 08:30:26: Loss at step 7747: 0.03672569617629051\n",
      "2017-11-11 08:30:27: Loss at step 7748: 0.03667034953832626\n",
      "2017-11-11 08:30:27: Loss at step 7749: 0.03678663820028305\n",
      "2017-11-11 08:30:28: Loss at step 7750: 0.03681493550539017\n",
      "2017-11-11 08:30:28: Loss at step 7751: 0.0367826484143734\n",
      "2017-11-11 08:30:29: Loss at step 7752: 0.036732666194438934\n",
      "2017-11-11 08:30:29: Loss at step 7753: 0.03667183965444565\n",
      "2017-11-11 08:30:30: Loss at step 7754: 0.03672123700380325\n",
      "2017-11-11 08:30:30: Loss at step 7755: 0.036788422614336014\n",
      "2017-11-11 08:30:31: Loss at step 7756: 0.03677087277173996\n",
      "2017-11-11 08:30:31: Loss at step 7757: 0.036690182983875275\n",
      "2017-11-11 08:30:32: Loss at step 7758: 0.036751728504896164\n",
      "2017-11-11 08:30:32: Loss at step 7759: 0.036666516214609146\n",
      "2017-11-11 08:30:32: Loss at step 7760: 0.036698728799819946\n",
      "2017-11-11 08:30:33: Loss at step 7761: 0.03671368584036827\n",
      "2017-11-11 08:30:33: Loss at step 7762: 0.03678590804338455\n",
      "2017-11-11 08:30:34: Loss at step 7763: 0.03678629919886589\n",
      "2017-11-11 08:30:35: Loss at step 7764: 0.03676556050777435\n",
      "2017-11-11 08:30:35: Loss at step 7765: 0.036791618913412094\n",
      "2017-11-11 08:30:36: Loss at step 7766: 0.036698199808597565\n",
      "2017-11-11 08:30:36: Loss at step 7767: 0.036743663251399994\n",
      "2017-11-11 08:30:37: Loss at step 7768: 0.03674587979912758\n",
      "2017-11-11 08:30:37: Loss at step 7769: 0.03671574220061302\n",
      "2017-11-11 08:30:38: Loss at step 7770: 0.03673231974244118\n",
      "2017-11-11 08:30:38: Loss at step 7771: 0.03675617650151253\n",
      "2017-11-11 08:30:39: Loss at step 7772: 0.03670104965567589\n",
      "2017-11-11 08:30:39: Loss at step 7773: 0.03677624836564064\n",
      "2017-11-11 08:30:40: Loss at step 7774: 0.03683322295546532\n",
      "2017-11-11 08:30:40: Loss at step 7775: 0.03674289211630821\n",
      "2017-11-11 08:30:41: Loss at step 7776: 0.0367782786488533\n",
      "2017-11-11 08:30:41: Loss at step 7777: 0.036766111850738525\n",
      "2017-11-11 08:30:42: Loss at step 7778: 0.036819539964199066\n",
      "2017-11-11 08:30:42: Loss at step 7779: 0.03678756207227707\n",
      "2017-11-11 08:30:43: Loss at step 7780: 0.036745261400938034\n",
      "2017-11-11 08:30:43: Loss at step 7781: 0.03676040098071098\n",
      "2017-11-11 08:30:44: Loss at step 7782: 0.03673277795314789\n",
      "2017-11-11 08:30:44: Loss at step 7783: 0.03667040541768074\n",
      "2017-11-11 08:30:45: Loss at step 7784: 0.036646902561187744\n",
      "2017-11-11 08:30:45: Loss at step 7785: 0.036725688725709915\n",
      "2017-11-11 08:30:46: Loss at step 7786: 0.03672156482934952\n",
      "2017-11-11 08:30:46: Loss at step 7787: 0.036622222512960434\n",
      "2017-11-11 08:30:47: Loss at step 7788: 0.03666146099567413\n",
      "2017-11-11 08:30:47: Loss at step 7789: 0.03672943264245987\n",
      "2017-11-11 08:30:48: Loss at step 7790: 0.03673088550567627\n",
      "2017-11-11 08:30:48: Loss at step 7791: 0.03680422157049179\n",
      "2017-11-11 08:30:49: Loss at step 7792: 0.03665238618850708\n",
      "2017-11-11 08:30:49: Loss at step 7793: 0.03671512380242348\n",
      "2017-11-11 08:30:50: Loss at step 7794: 0.036612171679735184\n",
      "2017-11-11 08:30:50: Loss at step 7795: 0.03671776130795479\n",
      "2017-11-11 08:30:51: Loss at step 7796: 0.036688316613435745\n",
      "2017-11-11 08:30:51: Loss at step 7797: 0.0366714671254158\n",
      "2017-11-11 08:30:52: Loss at step 7798: 0.036694493144750595\n",
      "2017-11-11 08:30:52: Loss at step 7799: 0.03668707609176636\n",
      "2017-11-11 08:30:53: Loss at step 7800: 0.036749113351106644\n",
      "2017-11-11 08:30:53: Loss at step 7801: 0.036666784435510635\n",
      "2017-11-11 08:30:54: Loss at step 7802: 0.036701519042253494\n",
      "2017-11-11 08:30:54: Loss at step 7803: 0.03664719685912132\n",
      "2017-11-11 08:30:55: Loss at step 7804: 0.036763645708560944\n",
      "2017-11-11 08:30:55: Loss at step 7805: 0.036698758602142334\n",
      "2017-11-11 08:30:56: Loss at step 7806: 0.036786045879125595\n",
      "2017-11-11 08:30:56: Loss at step 7807: 0.036791250109672546\n",
      "2017-11-11 08:30:57: Loss at step 7808: 0.03674216568470001\n",
      "2017-11-11 08:30:57: Loss at step 7809: 0.03676567226648331\n",
      "2017-11-11 08:30:58: Loss at step 7810: 0.03667488321661949\n",
      "2017-11-11 08:30:58: Loss at step 7811: 0.036747392266988754\n",
      "2017-11-11 08:30:59: Loss at step 7812: 0.03670409694314003\n",
      "2017-11-11 08:30:59: Loss at step 7813: 0.036731090396642685\n",
      "2017-11-11 08:30:59: Loss at step 7814: 0.03668927773833275\n",
      "2017-11-11 08:31:00: Loss at step 7815: 0.03666934370994568\n",
      "2017-11-11 08:31:00: Loss at step 7816: 0.036691658198833466\n",
      "2017-11-11 08:31:01: Loss at step 7817: 0.03667121008038521\n",
      "2017-11-11 08:31:02: Loss at step 7818: 0.03670560196042061\n",
      "2017-11-11 08:31:02: Loss at step 7819: 0.03667949140071869\n",
      "2017-11-11 08:31:03: Loss at step 7820: 0.03674471005797386\n",
      "2017-11-11 08:31:03: Loss at step 7821: 0.03662985935807228\n",
      "2017-11-11 08:31:03: Loss at step 7822: 0.03677801042795181\n",
      "2017-11-11 08:31:04: Loss at step 7823: 0.036737482994794846\n",
      "2017-11-11 08:31:04: Loss at step 7824: 0.03665945306420326\n",
      "2017-11-11 08:31:05: Loss at step 7825: 0.036747101694345474\n",
      "2017-11-11 08:31:05: Loss at step 7826: 0.03662687540054321\n",
      "2017-11-11 08:31:06: Loss at step 7827: 0.036707762628793716\n",
      "2017-11-11 08:31:06: Loss at step 7828: 0.036739036440849304\n",
      "2017-11-11 08:31:07: Loss at step 7829: 0.03667277842760086\n",
      "2017-11-11 08:31:07: Loss at step 7830: 0.03673984482884407\n",
      "2017-11-11 08:31:08: Loss at step 7831: 0.03670068830251694\n",
      "2017-11-11 08:31:08: Loss at step 7832: 0.03670429810881615\n",
      "2017-11-11 08:31:09: Loss at step 7833: 0.036670513451099396\n",
      "2017-11-11 08:31:09: Loss at step 7834: 0.0367148220539093\n",
      "2017-11-11 08:31:10: Loss at step 7835: 0.03677540272474289\n",
      "2017-11-11 08:31:10: Loss at step 7836: 0.036686625331640244\n",
      "2017-11-11 08:31:11: Loss at step 7837: 0.036779433488845825\n",
      "2017-11-11 08:31:11: Loss at step 7838: 0.03670085594058037\n",
      "2017-11-11 08:31:12: Loss at step 7839: 0.03678120672702789\n",
      "2017-11-11 08:31:12: Loss at step 7840: 0.036725714802742004\n",
      "2017-11-11 08:31:13: Loss at step 7841: 0.03667837753891945\n",
      "2017-11-11 08:31:13: Loss at step 7842: 0.036647822707891464\n",
      "2017-11-11 08:31:14: Loss at step 7843: 0.03672007471323013\n",
      "2017-11-11 08:31:14: Loss at step 7844: 0.03668439760804176\n",
      "2017-11-11 08:31:15: Loss at step 7845: 0.03663318604230881\n",
      "2017-11-11 08:31:15: Loss at step 7846: 0.03678666800260544\n",
      "2017-11-11 08:31:16: Loss at step 7847: 0.03670608252286911\n",
      "2017-11-11 08:31:16: Loss at step 7848: 0.036731358617544174\n",
      "2017-11-11 08:31:17: Loss at step 7849: 0.03674296289682388\n",
      "2017-11-11 08:31:17: Loss at step 7850: 0.03684233874082565\n",
      "2017-11-11 08:31:18: Loss at step 7851: 0.03667520731687546\n",
      "2017-11-11 08:31:18: Loss at step 7852: 0.03675190359354019\n",
      "2017-11-11 08:31:19: Loss at step 7853: 0.03673547878861427\n",
      "2017-11-11 08:31:19: Loss at step 7854: 0.03669339418411255\n",
      "2017-11-11 08:31:20: Loss at step 7855: 0.03675016015768051\n",
      "2017-11-11 08:31:20: Loss at step 7856: 0.036761365830898285\n",
      "2017-11-11 08:31:21: Loss at step 7857: 0.03671160712838173\n",
      "2017-11-11 08:31:21: Loss at step 7858: 0.03680190443992615\n",
      "2017-11-11 08:31:22: Loss at step 7859: 0.036692310124635696\n",
      "2017-11-11 08:31:22: Loss at step 7860: 0.036654070019721985\n",
      "2017-11-11 08:31:23: Loss at step 7861: 0.03663526102900505\n",
      "2017-11-11 08:31:23: Loss at step 7862: 0.036759547889232635\n",
      "2017-11-11 08:31:24: Loss at step 7863: 0.036743804812431335\n",
      "2017-11-11 08:31:24: Loss at step 7864: 0.036762531846761703\n",
      "2017-11-11 08:31:24: Loss at step 7865: 0.03679875656962395\n",
      "2017-11-11 08:31:25: Loss at step 7866: 0.03670526295900345\n",
      "2017-11-11 08:31:25: Loss at step 7867: 0.03676822409033775\n",
      "2017-11-11 08:31:26: Loss at step 7868: 0.03675913065671921\n",
      "2017-11-11 08:31:26: Loss at step 7869: 0.03676535189151764\n",
      "2017-11-11 08:31:27: Loss at step 7870: 0.03675825893878937\n",
      "2017-11-11 08:31:27: Loss at step 7871: 0.03680165857076645\n",
      "2017-11-11 08:31:28: Loss at step 7872: 0.036761052906513214\n",
      "2017-11-11 08:31:28: Loss at step 7873: 0.03676861524581909\n",
      "2017-11-11 08:31:29: Loss at step 7874: 0.03673122450709343\n",
      "2017-11-11 08:31:29: Loss at step 7875: 0.036733392626047134\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-11-11 08:31:30: Loss at step 7876: 0.036844655871391296\n",
      "2017-11-11 08:31:30: Loss at step 7877: 0.036789052188396454\n",
      "2017-11-11 08:31:31: Loss at step 7878: 0.03679678216576576\n",
      "2017-11-11 08:31:31: Loss at step 7879: 0.036822956055402756\n",
      "2017-11-11 08:31:32: Loss at step 7880: 0.03676116466522217\n",
      "2017-11-11 08:31:32: Loss at step 7881: 0.03676964342594147\n",
      "2017-11-11 08:31:33: Loss at step 7882: 0.0367630310356617\n",
      "2017-11-11 08:31:33: Loss at step 7883: 0.03674433007836342\n",
      "2017-11-11 08:31:34: Loss at step 7884: 0.036782849580049515\n",
      "2017-11-11 08:31:34: Loss at step 7885: 0.03673717752099037\n",
      "2017-11-11 08:31:35: Loss at step 7886: 0.03664730489253998\n",
      "2017-11-11 08:31:35: Loss at step 7887: 0.036684300750494\n",
      "2017-11-11 08:31:36: Loss at step 7888: 0.03672676905989647\n",
      "2017-11-11 08:31:36: Loss at step 7889: 0.036665916442871094\n",
      "2017-11-11 08:31:37: Loss at step 7890: 0.036749694496393204\n",
      "2017-11-11 08:31:37: Loss at step 7891: 0.03669951111078262\n",
      "2017-11-11 08:31:38: Loss at step 7892: 0.03673610836267471\n",
      "2017-11-11 08:31:38: Loss at step 7893: 0.03668316826224327\n",
      "2017-11-11 08:31:39: Loss at step 7894: 0.03685973212122917\n",
      "2017-11-11 08:31:39: Loss at step 7895: 0.03680542856454849\n",
      "2017-11-11 08:31:40: Loss at step 7896: 0.03674335777759552\n",
      "2017-11-11 08:31:40: Loss at step 7897: 0.03675323352217674\n",
      "2017-11-11 08:31:41: Loss at step 7898: 0.036814965307712555\n",
      "2017-11-11 08:31:41: Loss at step 7899: 0.03673333674669266\n",
      "2017-11-11 08:31:42: Loss at step 7900: 0.0368032269179821\n",
      "2017-11-11 08:31:42: Loss at step 7901: 0.03672719746828079\n",
      "2017-11-11 08:31:43: Loss at step 7902: 0.03677082061767578\n",
      "2017-11-11 08:31:43: Loss at step 7903: 0.036733802407979965\n",
      "2017-11-11 08:31:44: Loss at step 7904: 0.03670111298561096\n",
      "2017-11-11 08:31:44: Loss at step 7905: 0.03675572946667671\n",
      "2017-11-11 08:31:45: Loss at step 7906: 0.036732420325279236\n",
      "2017-11-11 08:31:45: Loss at step 7907: 0.03671971336007118\n",
      "2017-11-11 08:31:46: Loss at step 7908: 0.03676023706793785\n",
      "2017-11-11 08:31:46: Loss at step 7909: 0.03666134178638458\n",
      "2017-11-11 08:31:47: Loss at step 7910: 0.0368189811706543\n",
      "2017-11-11 08:31:47: Loss at step 7911: 0.03670058026909828\n",
      "2017-11-11 08:31:48: Loss at step 7912: 0.03672616556286812\n",
      "2017-11-11 08:31:48: Loss at step 7913: 0.03685767948627472\n",
      "2017-11-11 08:31:49: Loss at step 7914: 0.03674132749438286\n",
      "2017-11-11 08:31:49: Loss at step 7915: 0.03674529865384102\n",
      "2017-11-11 08:31:50: Loss at step 7916: 0.03672792762517929\n",
      "2017-11-11 08:31:50: Loss at step 7917: 0.03677592799067497\n",
      "2017-11-11 08:31:51: Loss at step 7918: 0.036726612597703934\n",
      "2017-11-11 08:31:51: Loss at step 7919: 0.03675233945250511\n",
      "2017-11-11 08:31:51: Loss at step 7920: 0.036767326295375824\n",
      "2017-11-11 08:31:52: Loss at step 7921: 0.03672808036208153\n",
      "2017-11-11 08:31:52: Loss at step 7922: 0.03678455948829651\n",
      "2017-11-11 08:31:53: Loss at step 7923: 0.03674149140715599\n",
      "2017-11-11 08:31:54: Loss at step 7924: 0.03671576455235481\n",
      "2017-11-11 08:31:54: Loss at step 7925: 0.03678485006093979\n",
      "2017-11-11 08:31:55: Loss at step 7926: 0.0367998406291008\n",
      "2017-11-11 08:31:55: Loss at step 7927: 0.03671885281801224\n",
      "2017-11-11 08:31:56: Loss at step 7928: 0.036792635917663574\n",
      "2017-11-11 08:31:56: Loss at step 7929: 0.03676452487707138\n",
      "2017-11-11 08:31:57: Loss at step 7930: 0.036807212978601456\n",
      "2017-11-11 08:31:57: Loss at step 7931: 0.03670569509267807\n",
      "2017-11-11 08:31:57: Loss at step 7932: 0.03670641407370567\n",
      "2017-11-11 08:31:58: Loss at step 7933: 0.0367351770401001\n",
      "2017-11-11 08:31:58: Loss at step 7934: 0.036722760647535324\n",
      "2017-11-11 08:31:59: Loss at step 7935: 0.03667984530329704\n",
      "2017-11-11 08:31:59: Loss at step 7936: 0.03674083203077316\n",
      "2017-11-11 08:32:00: Loss at step 7937: 0.03671450912952423\n",
      "2017-11-11 08:32:01: Loss at step 7938: 0.036744505167007446\n",
      "2017-11-11 08:32:01: Loss at step 7939: 0.03666066750884056\n",
      "2017-11-11 08:32:02: Loss at step 7940: 0.03673487529158592\n",
      "2017-11-11 08:32:02: Loss at step 7941: 0.03664862737059593\n",
      "2017-11-11 08:32:03: Loss at step 7942: 0.03674480319023132\n",
      "2017-11-11 08:32:03: Loss at step 7943: 0.03678442910313606\n",
      "2017-11-11 08:32:03: Loss at step 7944: 0.03684034198522568\n",
      "2017-11-11 08:32:04: Loss at step 7945: 0.03672729432582855\n",
      "2017-11-11 08:32:04: Loss at step 7946: 0.036862894892692566\n",
      "2017-11-11 08:32:05: Loss at step 7947: 0.03670646995306015\n",
      "2017-11-11 08:32:05: Loss at step 7948: 0.03662963584065437\n",
      "2017-11-11 08:32:06: Loss at step 7949: 0.036754801869392395\n",
      "2017-11-11 08:32:06: Loss at step 7950: 0.03677808493375778\n",
      "2017-11-11 08:32:07: Loss at step 7951: 0.03684491291642189\n",
      "2017-11-11 08:32:08: Loss at step 7952: 0.036751873791217804\n",
      "2017-11-11 08:32:08: Loss at step 7953: 0.036683589220047\n",
      "2017-11-11 08:32:08: Loss at step 7954: 0.036713358014822006\n",
      "2017-11-11 08:32:09: Loss at step 7955: 0.03673231974244118\n",
      "2017-11-11 08:32:09: Loss at step 7956: 0.036751046776771545\n",
      "2017-11-11 08:32:10: Loss at step 7957: 0.03679799661040306\n",
      "2017-11-11 08:32:10: Loss at step 7958: 0.03677460923790932\n",
      "2017-11-11 08:32:11: Loss at step 7959: 0.036722972989082336\n",
      "2017-11-11 08:32:11: Loss at step 7960: 0.03664563596248627\n",
      "2017-11-11 08:32:12: Loss at step 7961: 0.03671852871775627\n",
      "2017-11-11 08:32:12: Loss at step 7962: 0.03669898957014084\n",
      "2017-11-11 08:32:13: Loss at step 7963: 0.036713093519210815\n",
      "2017-11-11 08:32:13: Loss at step 7964: 0.0367157943546772\n",
      "2017-11-11 08:32:14: Loss at step 7965: 0.03672214224934578\n",
      "2017-11-11 08:32:14: Loss at step 7966: 0.036803893744945526\n",
      "2017-11-11 08:32:15: Loss at step 7967: 0.03667555749416351\n",
      "2017-11-11 08:32:15: Loss at step 7968: 0.036738310009241104\n",
      "2017-11-11 08:32:16: Loss at step 7969: 0.036716122180223465\n",
      "2017-11-11 08:32:16: Loss at step 7970: 0.036649759858846664\n",
      "2017-11-11 08:32:17: Loss at step 7971: 0.036606963723897934\n",
      "2017-11-11 08:32:17: Loss at step 7972: 0.03675999864935875\n",
      "2017-11-11 08:32:18: Loss at step 7973: 0.036749571561813354\n",
      "2017-11-11 08:32:18: Loss at step 7974: 0.0366966538131237\n",
      "2017-11-11 08:32:19: Loss at step 7975: 0.036698002368211746\n",
      "2017-11-11 08:32:19: Loss at step 7976: 0.03668505698442459\n",
      "2017-11-11 08:32:20: Loss at step 7977: 0.03683626279234886\n",
      "2017-11-11 08:32:20: Loss at step 7978: 0.036836061626672745\n",
      "2017-11-11 08:32:21: Loss at step 7979: 0.03676123917102814\n",
      "2017-11-11 08:32:21: Loss at step 7980: 0.03678217902779579\n",
      "2017-11-11 08:32:22: Loss at step 7981: 0.03678873926401138\n",
      "2017-11-11 08:32:22: Loss at step 7982: 0.03677033632993698\n",
      "2017-11-11 08:32:23: Loss at step 7983: 0.036789849400520325\n",
      "2017-11-11 08:32:23: Loss at step 7984: 0.036779262125492096\n",
      "2017-11-11 08:32:23: Loss at step 7985: 0.036772582679986954\n",
      "2017-11-11 08:32:24: Loss at step 7986: 0.03668224439024925\n",
      "2017-11-11 08:32:24: Loss at step 7987: 0.036764536052942276\n",
      "2017-11-11 08:32:25: Loss at step 7988: 0.03677436709403992\n",
      "2017-11-11 08:32:25: Loss at step 7989: 0.036726225167512894\n",
      "2017-11-11 08:32:26: Loss at step 7990: 0.036816053092479706\n",
      "2017-11-11 08:32:26: Loss at step 7991: 0.036731328815221786\n",
      "2017-11-11 08:32:27: Loss at step 7992: 0.0366879440844059\n",
      "2017-11-11 08:32:27: Loss at step 7993: 0.036692094057798386\n",
      "2017-11-11 08:32:28: Loss at step 7994: 0.03674772009253502\n",
      "2017-11-11 08:32:28: Loss at step 7995: 0.03667180612683296\n",
      "2017-11-11 08:32:29: Loss at step 7996: 0.03670356422662735\n",
      "2017-11-11 08:32:29: Loss at step 7997: 0.03677820786833763\n",
      "2017-11-11 08:32:30: Loss at step 7998: 0.03671254217624664\n",
      "2017-11-11 08:32:30: Loss at step 7999: 0.036805566400289536\n",
      "2017-11-11 08:32:31: Loss at step 8000: 0.036678895354270935\n",
      "2017-11-11 08:32:31: Loss at step 8001: 0.03677217289805412\n",
      "2017-11-11 08:32:32: Loss at step 8002: 0.03666916489601135\n",
      "2017-11-11 08:32:32: Loss at step 8003: 0.036670882254838943\n",
      "2017-11-11 08:32:33: Loss at step 8004: 0.03670822083950043\n",
      "2017-11-11 08:32:33: Loss at step 8005: 0.03664800897240639\n",
      "2017-11-11 08:32:34: Loss at step 8006: 0.036674171686172485\n",
      "2017-11-11 08:32:34: Loss at step 8007: 0.03674856573343277\n",
      "2017-11-11 08:32:35: Loss at step 8008: 0.03675974905490875\n",
      "2017-11-11 08:32:35: Loss at step 8009: 0.036675117909908295\n",
      "2017-11-11 08:32:36: Loss at step 8010: 0.036649372428655624\n",
      "2017-11-11 08:32:36: Loss at step 8011: 0.03674858435988426\n",
      "2017-11-11 08:32:37: Loss at step 8012: 0.0367753729224205\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-11-11 08:32:37: Loss at step 8013: 0.03676389157772064\n",
      "2017-11-11 08:32:38: Loss at step 8014: 0.03669204190373421\n",
      "2017-11-11 08:32:38: Loss at step 8015: 0.036760132759809494\n",
      "2017-11-11 08:32:39: Loss at step 8016: 0.03667723387479782\n",
      "2017-11-11 08:32:39: Loss at step 8017: 0.03679732233285904\n",
      "2017-11-11 08:32:40: Loss at step 8018: 0.03686932474374771\n",
      "2017-11-11 08:32:41: Loss at step 8019: 0.03678896650671959\n",
      "2017-11-11 08:32:41: Loss at step 8020: 0.036752186715602875\n",
      "2017-11-11 08:32:41: Loss at step 8021: 0.03669309616088867\n",
      "2017-11-11 08:32:42: Loss at step 8022: 0.03669178485870361\n",
      "2017-11-11 08:32:42: Loss at step 8023: 0.03671658784151077\n",
      "2017-11-11 08:32:43: Loss at step 8024: 0.03675549477338791\n",
      "2017-11-11 08:32:43: Loss at step 8025: 0.036705952137708664\n",
      "2017-11-11 08:32:44: Loss at step 8026: 0.03662361949682236\n",
      "2017-11-11 08:32:44: Loss at step 8027: 0.03674456104636192\n",
      "2017-11-11 08:32:45: Loss at step 8028: 0.03669855371117592\n",
      "2017-11-11 08:32:45: Loss at step 8029: 0.03668989986181259\n",
      "2017-11-11 08:32:46: Loss at step 8030: 0.03675704449415207\n",
      "2017-11-11 08:32:47: Loss at step 8031: 0.03677378594875336\n",
      "2017-11-11 08:32:47: Loss at step 8032: 0.036770086735486984\n",
      "2017-11-11 08:32:48: Loss at step 8033: 0.03675919026136398\n",
      "2017-11-11 08:32:48: Loss at step 8034: 0.0367310494184494\n",
      "2017-11-11 08:32:49: Loss at step 8035: 0.036791447550058365\n",
      "2017-11-11 08:32:49: Loss at step 8036: 0.036781903356313705\n",
      "2017-11-11 08:32:50: Loss at step 8037: 0.03675838187336922\n",
      "2017-11-11 08:32:50: Loss at step 8038: 0.03672730177640915\n",
      "2017-11-11 08:32:50: Loss at step 8039: 0.03686767444014549\n",
      "2017-11-11 08:32:51: Loss at step 8040: 0.03675120696425438\n",
      "2017-11-11 08:32:51: Loss at step 8041: 0.03678909316658974\n",
      "2017-11-11 08:32:52: Loss at step 8042: 0.03683432191610336\n",
      "2017-11-11 08:32:53: Loss at step 8043: 0.03694688901305199\n",
      "2017-11-11 08:32:53: Loss at step 8044: 0.03678727522492409\n",
      "2017-11-11 08:32:54: Loss at step 8045: 0.036825187504291534\n",
      "2017-11-11 08:32:54: Loss at step 8046: 0.03686818853020668\n",
      "2017-11-11 08:32:55: Loss at step 8047: 0.036896344274282455\n",
      "2017-11-11 08:32:55: Loss at step 8048: 0.03691718727350235\n",
      "2017-11-11 08:32:56: Loss at step 8049: 0.03691515326499939\n",
      "2017-11-11 08:32:56: Loss at step 8050: 0.03685979172587395\n",
      "2017-11-11 08:32:57: Loss at step 8051: 0.03690160810947418\n",
      "2017-11-11 08:32:57: Loss at step 8052: 0.03693196550011635\n",
      "2017-11-11 08:32:58: Loss at step 8053: 0.036879319697618484\n",
      "2017-11-11 08:32:58: Loss at step 8054: 0.03697153925895691\n",
      "2017-11-11 08:32:59: Loss at step 8055: 0.036881037056446075\n",
      "2017-11-11 08:32:59: Loss at step 8056: 0.03705412521958351\n",
      "2017-11-11 08:33:00: Loss at step 8057: 0.03708622232079506\n",
      "2017-11-11 08:33:00: Loss at step 8058: 0.03698410466313362\n",
      "2017-11-11 08:33:01: Loss at step 8059: 0.0369381420314312\n",
      "2017-11-11 08:33:01: Loss at step 8060: 0.03710150346159935\n",
      "2017-11-11 08:33:02: Loss at step 8061: 0.037177056074142456\n",
      "2017-11-11 08:33:02: Loss at step 8062: 0.037105806171894073\n",
      "2017-11-11 08:33:03: Loss at step 8063: 0.03695473447442055\n",
      "2017-11-11 08:33:03: Loss at step 8064: 0.0370500311255455\n",
      "2017-11-11 08:33:04: Loss at step 8065: 0.037131208926439285\n",
      "2017-11-11 08:33:04: Loss at step 8066: 0.03714580088853836\n",
      "2017-11-11 08:33:05: Loss at step 8067: 0.03709081560373306\n",
      "2017-11-11 08:33:05: Loss at step 8068: 0.037121232599020004\n",
      "2017-11-11 08:33:06: Loss at step 8069: 0.03720088675618172\n",
      "2017-11-11 08:33:06: Loss at step 8070: 0.03723881021142006\n",
      "2017-11-11 08:33:07: Loss at step 8071: 0.0371374748647213\n",
      "2017-11-11 08:33:07: Loss at step 8072: 0.037186216562986374\n",
      "2017-11-11 08:33:08: Loss at step 8073: 0.037144627422094345\n",
      "2017-11-11 08:33:08: Loss at step 8074: 0.037179578095674515\n",
      "2017-11-11 08:33:09: Loss at step 8075: 0.0369824655354023\n",
      "2017-11-11 08:33:09: Loss at step 8076: 0.03712321072816849\n",
      "2017-11-11 08:33:10: Loss at step 8077: 0.036916930228471756\n",
      "2017-11-11 08:33:10: Loss at step 8078: 0.0368976928293705\n",
      "2017-11-11 08:33:11: Loss at step 8079: 0.03708721324801445\n",
      "2017-11-11 08:33:11: Loss at step 8080: 0.0368494838476181\n",
      "2017-11-11 08:33:12: Loss at step 8081: 0.0369604229927063\n",
      "2017-11-11 08:33:12: Loss at step 8082: 0.036937642842531204\n",
      "2017-11-11 08:33:13: Loss at step 8083: 0.03691408038139343\n",
      "2017-11-11 08:33:13: Loss at step 8084: 0.03688516840338707\n",
      "2017-11-11 08:33:14: Loss at step 8085: 0.03693350404500961\n",
      "2017-11-11 08:33:14: Loss at step 8086: 0.03683513030409813\n",
      "2017-11-11 08:33:15: Loss at step 8087: 0.03687899559736252\n",
      "2017-11-11 08:33:15: Loss at step 8088: 0.03692396730184555\n",
      "2017-11-11 08:33:16: Loss at step 8089: 0.03680194169282913\n",
      "2017-11-11 08:33:16: Loss at step 8090: 0.03690562769770622\n",
      "2017-11-11 08:33:17: Loss at step 8091: 0.03681075572967529\n",
      "2017-11-11 08:33:17: Loss at step 8092: 0.036845847964286804\n",
      "2017-11-11 08:33:18: Loss at step 8093: 0.036765508353710175\n",
      "2017-11-11 08:33:18: Loss at step 8094: 0.03677622601389885\n",
      "2017-11-11 08:33:19: Loss at step 8095: 0.036803144961595535\n",
      "2017-11-11 08:33:19: Loss at step 8096: 0.03679095581173897\n",
      "2017-11-11 08:33:20: Loss at step 8097: 0.03671324998140335\n",
      "2017-11-11 08:33:20: Loss at step 8098: 0.03676096349954605\n",
      "2017-11-11 08:33:21: Loss at step 8099: 0.03675556927919388\n",
      "2017-11-11 08:33:21: Loss at step 8100: 0.0366547517478466\n",
      "2017-11-11 08:33:22: Loss at step 8101: 0.03677917644381523\n",
      "2017-11-11 08:33:22: Loss at step 8102: 0.036755435168743134\n",
      "2017-11-11 08:33:23: Loss at step 8103: 0.03678487613797188\n",
      "2017-11-11 08:33:23: Loss at step 8104: 0.03674023970961571\n",
      "2017-11-11 08:33:24: Loss at step 8105: 0.036733247339725494\n",
      "2017-11-11 08:33:24: Loss at step 8106: 0.03671960532665253\n",
      "2017-11-11 08:33:25: Loss at step 8107: 0.036767810583114624\n",
      "2017-11-11 08:33:25: Loss at step 8108: 0.036757830530405045\n",
      "2017-11-11 08:33:26: Loss at step 8109: 0.03669102117419243\n",
      "2017-11-11 08:33:26: Loss at step 8110: 0.03672032430768013\n",
      "2017-11-11 08:33:27: Loss at step 8111: 0.03671363368630409\n",
      "2017-11-11 08:33:27: Loss at step 8112: 0.03672938421368599\n",
      "2017-11-11 08:33:28: Loss at step 8113: 0.036741044372320175\n",
      "2017-11-11 08:33:28: Loss at step 8114: 0.036875855177640915\n",
      "2017-11-11 08:33:29: Loss at step 8115: 0.036775749176740646\n",
      "2017-11-11 08:33:29: Loss at step 8116: 0.036784760653972626\n",
      "2017-11-11 08:33:30: Loss at step 8117: 0.036739010363817215\n",
      "2017-11-11 08:33:30: Loss at step 8118: 0.03668304532766342\n",
      "2017-11-11 08:33:31: Loss at step 8119: 0.03678928315639496\n",
      "2017-11-11 08:33:31: Loss at step 8120: 0.036700110882520676\n",
      "2017-11-11 08:33:32: Loss at step 8121: 0.036705370992422104\n",
      "2017-11-11 08:33:32: Loss at step 8122: 0.036736249923706055\n",
      "2017-11-11 08:33:33: Loss at step 8123: 0.036609794944524765\n",
      "2017-11-11 08:33:33: Loss at step 8124: 0.036644596606492996\n",
      "2017-11-11 08:33:34: Loss at step 8125: 0.03670547530055046\n",
      "2017-11-11 08:33:34: Loss at step 8126: 0.036755308508872986\n",
      "2017-11-11 08:33:35: Loss at step 8127: 0.03661279007792473\n",
      "2017-11-11 08:33:35: Loss at step 8128: 0.03670905530452728\n",
      "2017-11-11 08:33:36: Loss at step 8129: 0.03667070344090462\n",
      "2017-11-11 08:33:36: Loss at step 8130: 0.03673155605792999\n",
      "2017-11-11 08:33:37: Loss at step 8131: 0.0366375707089901\n",
      "2017-11-11 08:33:37: Loss at step 8132: 0.03669509291648865\n",
      "2017-11-11 08:33:38: Loss at step 8133: 0.03670518100261688\n",
      "2017-11-11 08:33:38: Loss at step 8134: 0.036639727652072906\n",
      "2017-11-11 08:33:39: Loss at step 8135: 0.036685485392808914\n",
      "2017-11-11 08:33:39: Loss at step 8136: 0.03669370338320732\n",
      "2017-11-11 08:33:40: Loss at step 8137: 0.03673970326781273\n",
      "2017-11-11 08:33:40: Loss at step 8138: 0.036735981702804565\n",
      "2017-11-11 08:33:41: Loss at step 8139: 0.03667784482240677\n",
      "2017-11-11 08:33:41: Loss at step 8140: 0.03667781502008438\n",
      "2017-11-11 08:33:42: Loss at step 8141: 0.03673508018255234\n",
      "2017-11-11 08:33:42: Loss at step 8142: 0.036718953400850296\n",
      "2017-11-11 08:33:43: Loss at step 8143: 0.03672883287072182\n",
      "2017-11-11 08:33:43: Loss at step 8144: 0.036749787628650665\n",
      "2017-11-11 08:33:44: Loss at step 8145: 0.03670526295900345\n",
      "2017-11-11 08:33:44: Loss at step 8146: 0.036723099648952484\n",
      "2017-11-11 08:33:45: Loss at step 8147: 0.03665069118142128\n",
      "2017-11-11 08:33:45: Loss at step 8148: 0.036761146038770676\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-11-11 08:33:46: Loss at step 8149: 0.03676912188529968\n",
      "2017-11-11 08:33:46: Loss at step 8150: 0.036703553050756454\n",
      "2017-11-11 08:33:47: Loss at step 8151: 0.036720603704452515\n",
      "2017-11-11 08:33:47: Loss at step 8152: 0.036776043474674225\n",
      "2017-11-11 08:33:48: Loss at step 8153: 0.03669659420847893\n",
      "2017-11-11 08:33:48: Loss at step 8154: 0.0366264171898365\n",
      "2017-11-11 08:33:49: Loss at step 8155: 0.036731380969285965\n",
      "2017-11-11 08:33:49: Loss at step 8156: 0.03667949140071869\n",
      "2017-11-11 08:33:50: Loss at step 8157: 0.03660658746957779\n",
      "2017-11-11 08:33:50: Loss at step 8158: 0.036839526146650314\n",
      "2017-11-11 08:33:51: Loss at step 8159: 0.03677617385983467\n",
      "2017-11-11 08:33:51: Loss at step 8160: 0.03669426217675209\n",
      "2017-11-11 08:33:52: Loss at step 8161: 0.03674071654677391\n",
      "2017-11-11 08:33:52: Loss at step 8162: 0.03679097071290016\n",
      "2017-11-11 08:33:53: Loss at step 8163: 0.03671618178486824\n",
      "2017-11-11 08:33:53: Loss at step 8164: 0.0366542711853981\n",
      "2017-11-11 08:33:54: Loss at step 8165: 0.03671029210090637\n",
      "2017-11-11 08:33:54: Loss at step 8166: 0.03672127425670624\n",
      "2017-11-11 08:33:55: Loss at step 8167: 0.03677104786038399\n",
      "2017-11-11 08:33:55: Loss at step 8168: 0.03670413792133331\n",
      "2017-11-11 08:33:56: Loss at step 8169: 0.03671971336007118\n",
      "2017-11-11 08:33:56: Loss at step 8170: 0.03673578426241875\n",
      "2017-11-11 08:33:57: Loss at step 8171: 0.036778565496206284\n",
      "2017-11-11 08:33:57: Loss at step 8172: 0.03672176972031593\n",
      "2017-11-11 08:33:58: Loss at step 8173: 0.036755044013261795\n",
      "2017-11-11 08:33:59: Loss at step 8174: 0.03669089451432228\n",
      "2017-11-11 08:33:59: Loss at step 8175: 0.03674042224884033\n",
      "2017-11-11 08:34:00: Loss at step 8176: 0.03672533482313156\n",
      "2017-11-11 08:34:00: Loss at step 8177: 0.03672480955719948\n",
      "2017-11-11 08:34:01: Loss at step 8178: 0.03679479658603668\n",
      "2017-11-11 08:34:01: Loss at step 8179: 0.03677874058485031\n",
      "2017-11-11 08:34:02: Loss at step 8180: 0.036743756383657455\n",
      "2017-11-11 08:34:02: Loss at step 8181: 0.036690689623355865\n",
      "2017-11-11 08:34:03: Loss at step 8182: 0.036690399050712585\n",
      "2017-11-11 08:34:03: Loss at step 8183: 0.03670636564493179\n",
      "2017-11-11 08:34:04: Loss at step 8184: 0.036732953041791916\n",
      "2017-11-11 08:34:04: Loss at step 8185: 0.03675125911831856\n",
      "2017-11-11 08:34:05: Loss at step 8186: 0.036674004048109055\n",
      "2017-11-11 08:34:05: Loss at step 8187: 0.03677714988589287\n",
      "2017-11-11 08:34:06: Loss at step 8188: 0.036719102412462234\n",
      "2017-11-11 08:34:06: Loss at step 8189: 0.036769840866327286\n",
      "2017-11-11 08:34:07: Loss at step 8190: 0.036707304418087006\n",
      "2017-11-11 08:34:07: Loss at step 8191: 0.03669891506433487\n",
      "2017-11-11 08:34:08: Loss at step 8192: 0.036720115691423416\n",
      "2017-11-11 08:34:08: Loss at step 8193: 0.0368024967610836\n",
      "2017-11-11 08:34:09: Loss at step 8194: 0.036679502576589584\n",
      "2017-11-11 08:34:09: Loss at step 8195: 0.03671517223119736\n",
      "2017-11-11 08:34:10: Loss at step 8196: 0.03676243871450424\n",
      "2017-11-11 08:34:10: Loss at step 8197: 0.0367266945540905\n",
      "2017-11-11 08:34:11: Loss at step 8198: 0.03674057126045227\n",
      "2017-11-11 08:34:11: Loss at step 8199: 0.036775462329387665\n",
      "2017-11-11 08:34:12: Loss at step 8200: 0.03668173775076866\n",
      "2017-11-11 08:34:12: Loss at step 8201: 0.0367666631937027\n",
      "2017-11-11 08:34:13: Loss at step 8202: 0.03670818358659744\n",
      "2017-11-11 08:34:13: Loss at step 8203: 0.03674381971359253\n",
      "2017-11-11 08:34:14: Loss at step 8204: 0.036697085946798325\n",
      "2017-11-11 08:34:14: Loss at step 8205: 0.036762092262506485\n",
      "2017-11-11 08:34:15: Loss at step 8206: 0.03673340380191803\n",
      "2017-11-11 08:34:15: Loss at step 8207: 0.03671460598707199\n",
      "2017-11-11 08:34:16: Loss at step 8208: 0.03671848028898239\n",
      "2017-11-11 08:34:16: Loss at step 8209: 0.03670990467071533\n",
      "2017-11-11 08:34:17: Loss at step 8210: 0.03672074154019356\n",
      "2017-11-11 08:34:17: Loss at step 8211: 0.03672443702816963\n",
      "2017-11-11 08:34:18: Loss at step 8212: 0.03675859794020653\n",
      "2017-11-11 08:34:18: Loss at step 8213: 0.03675491362810135\n",
      "2017-11-11 08:34:19: Loss at step 8214: 0.03672498092055321\n",
      "2017-11-11 08:34:19: Loss at step 8215: 0.03670451045036316\n",
      "2017-11-11 08:34:20: Loss at step 8216: 0.036718934774398804\n",
      "2017-11-11 08:34:20: Loss at step 8217: 0.03658856078982353\n",
      "2017-11-11 08:34:21: Loss at step 8218: 0.03674132004380226\n",
      "2017-11-11 08:34:21: Loss at step 8219: 0.036723461002111435\n",
      "2017-11-11 08:34:22: Loss at step 8220: 0.03670881688594818\n",
      "2017-11-11 08:34:22: Loss at step 8221: 0.036668457090854645\n",
      "2017-11-11 08:34:23: Loss at step 8222: 0.036712102591991425\n",
      "2017-11-11 08:34:23: Loss at step 8223: 0.03668561577796936\n",
      "2017-11-11 08:34:24: Loss at step 8224: 0.03669539466500282\n",
      "2017-11-11 08:34:24: Loss at step 8225: 0.03666265308856964\n",
      "2017-11-11 08:34:25: Loss at step 8226: 0.0367618165910244\n",
      "2017-11-11 08:34:25: Loss at step 8227: 0.03665268421173096\n",
      "2017-11-11 08:34:26: Loss at step 8228: 0.03666119650006294\n",
      "2017-11-11 08:34:26: Loss at step 8229: 0.03675548732280731\n",
      "2017-11-11 08:34:27: Loss at step 8230: 0.036781683564186096\n",
      "2017-11-11 08:34:27: Loss at step 8231: 0.036665815860033035\n",
      "2017-11-11 08:34:28: Loss at step 8232: 0.03666890785098076\n",
      "2017-11-11 08:34:28: Loss at step 8233: 0.036674197763204575\n",
      "2017-11-11 08:34:29: Loss at step 8234: 0.03669458627700806\n",
      "2017-11-11 08:34:29: Loss at step 8235: 0.03672575205564499\n",
      "2017-11-11 08:34:30: Loss at step 8236: 0.036661963909864426\n",
      "2017-11-11 08:34:30: Loss at step 8237: 0.036687709391117096\n",
      "2017-11-11 08:34:31: Loss at step 8238: 0.036776307970285416\n",
      "2017-11-11 08:34:31: Loss at step 8239: 0.03672479838132858\n",
      "2017-11-11 08:34:32: Loss at step 8240: 0.036754608154296875\n",
      "2017-11-11 08:34:32: Loss at step 8241: 0.03678300231695175\n",
      "2017-11-11 08:34:33: Loss at step 8242: 0.03664945065975189\n",
      "2017-11-11 08:34:33: Loss at step 8243: 0.03672347590327263\n",
      "2017-11-11 08:34:34: Loss at step 8244: 0.03673175349831581\n",
      "2017-11-11 08:34:34: Loss at step 8245: 0.03671470284461975\n",
      "2017-11-11 08:34:35: Loss at step 8246: 0.03667543828487396\n",
      "2017-11-11 08:34:35: Loss at step 8247: 0.03680861368775368\n",
      "2017-11-11 08:34:36: Loss at step 8248: 0.03673706576228142\n",
      "2017-11-11 08:34:36: Loss at step 8249: 0.03678277134895325\n",
      "2017-11-11 08:34:37: Loss at step 8250: 0.036674290895462036\n",
      "2017-11-11 08:34:37: Loss at step 8251: 0.036743901669979095\n",
      "2017-11-11 08:34:38: Loss at step 8252: 0.03675578162074089\n",
      "2017-11-11 08:34:38: Loss at step 8253: 0.03677292913198471\n",
      "2017-11-11 08:34:39: Loss at step 8254: 0.03663906082510948\n",
      "2017-11-11 08:34:39: Loss at step 8255: 0.03680896759033203\n",
      "2017-11-11 08:34:40: Loss at step 8256: 0.03668944537639618\n",
      "2017-11-11 08:34:40: Loss at step 8257: 0.03672921657562256\n",
      "2017-11-11 08:34:41: Loss at step 8258: 0.03668277710676193\n",
      "2017-11-11 08:34:41: Loss at step 8259: 0.03676392883062363\n",
      "2017-11-11 08:34:42: Loss at step 8260: 0.03671928122639656\n",
      "2017-11-11 08:34:42: Loss at step 8261: 0.03669506311416626\n",
      "2017-11-11 08:34:43: Loss at step 8262: 0.03679782897233963\n",
      "2017-11-11 08:34:43: Loss at step 8263: 0.03670933097600937\n",
      "2017-11-11 08:34:44: Loss at step 8264: 0.036734338849782944\n",
      "2017-11-11 08:34:44: Loss at step 8265: 0.036761559545993805\n",
      "2017-11-11 08:34:45: Loss at step 8266: 0.03676235303282738\n",
      "2017-11-11 08:34:45: Loss at step 8267: 0.03668101504445076\n",
      "2017-11-11 08:34:46: Loss at step 8268: 0.036625079810619354\n",
      "2017-11-11 08:34:46: Loss at step 8269: 0.03680945560336113\n",
      "2017-11-11 08:34:47: Loss at step 8270: 0.036672674119472504\n",
      "2017-11-11 08:34:47: Loss at step 8271: 0.03674452006816864\n",
      "2017-11-11 08:34:48: Loss at step 8272: 0.03672414645552635\n",
      "2017-11-11 08:34:48: Loss at step 8273: 0.03671683371067047\n",
      "2017-11-11 08:34:49: Loss at step 8274: 0.03665989264845848\n",
      "2017-11-11 08:34:49: Loss at step 8275: 0.03677139803767204\n",
      "2017-11-11 08:34:50: Loss at step 8276: 0.03678126260638237\n",
      "2017-11-11 08:34:50: Loss at step 8277: 0.036709263920784\n",
      "2017-11-11 08:34:51: Loss at step 8278: 0.036794863641262054\n",
      "2017-11-11 08:34:51: Loss at step 8279: 0.03671998903155327\n",
      "2017-11-11 08:34:52: Loss at step 8280: 0.0367647148668766\n",
      "2017-11-11 08:34:52: Loss at step 8281: 0.03672761470079422\n",
      "2017-11-11 08:34:53: Loss at step 8282: 0.03671804815530777\n",
      "2017-11-11 08:34:54: Loss at step 8283: 0.03678033873438835\n",
      "2017-11-11 08:34:54: Loss at step 8284: 0.03677894175052643\n",
      "2017-11-11 08:34:55: Loss at step 8285: 0.03675474226474762\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-11-11 08:34:55: Loss at step 8286: 0.03668900951743126\n",
      "2017-11-11 08:34:55: Loss at step 8287: 0.036739520728588104\n",
      "2017-11-11 08:34:56: Loss at step 8288: 0.036796797066926956\n",
      "2017-11-11 08:34:56: Loss at step 8289: 0.036724403500556946\n",
      "2017-11-11 08:34:57: Loss at step 8290: 0.036724794656038284\n",
      "2017-11-11 08:34:57: Loss at step 8291: 0.03666212409734726\n",
      "2017-11-11 08:34:58: Loss at step 8292: 0.03676777333021164\n",
      "2017-11-11 08:34:58: Loss at step 8293: 0.036691974848508835\n",
      "2017-11-11 08:34:59: Loss at step 8294: 0.03674515336751938\n",
      "2017-11-11 08:34:59: Loss at step 8295: 0.03673502057790756\n",
      "2017-11-11 08:35:00: Loss at step 8296: 0.03679182007908821\n",
      "2017-11-11 08:35:00: Loss at step 8297: 0.03671470284461975\n",
      "2017-11-11 08:35:01: Loss at step 8298: 0.036667194217443466\n",
      "2017-11-11 08:35:01: Loss at step 8299: 0.03679712861776352\n",
      "2017-11-11 08:35:02: Loss at step 8300: 0.0367363877594471\n",
      "2017-11-11 08:35:02: Loss at step 8301: 0.0367012694478035\n",
      "2017-11-11 08:35:03: Loss at step 8302: 0.036609966307878494\n",
      "2017-11-11 08:35:03: Loss at step 8303: 0.036691419780254364\n",
      "2017-11-11 08:35:04: Loss at step 8304: 0.03673241659998894\n",
      "2017-11-11 08:35:04: Loss at step 8305: 0.036672767251729965\n",
      "2017-11-11 08:35:05: Loss at step 8306: 0.036739129573106766\n",
      "2017-11-11 08:35:05: Loss at step 8307: 0.036786504089832306\n",
      "2017-11-11 08:35:06: Loss at step 8308: 0.03669652342796326\n",
      "2017-11-11 08:35:06: Loss at step 8309: 0.03676050901412964\n",
      "2017-11-11 08:35:07: Loss at step 8310: 0.03678441792726517\n",
      "2017-11-11 08:35:07: Loss at step 8311: 0.03660617023706436\n",
      "2017-11-11 08:35:08: Loss at step 8312: 0.0367201529443264\n",
      "2017-11-11 08:35:08: Loss at step 8313: 0.03674739971756935\n",
      "2017-11-11 08:35:09: Loss at step 8314: 0.03674319386482239\n",
      "2017-11-11 08:35:09: Loss at step 8315: 0.03668487071990967\n",
      "2017-11-11 08:35:10: Loss at step 8316: 0.036701008677482605\n",
      "2017-11-11 08:35:10: Loss at step 8317: 0.036733124405145645\n",
      "2017-11-11 08:35:11: Loss at step 8318: 0.036739006638526917\n",
      "2017-11-11 08:35:11: Loss at step 8319: 0.036667969077825546\n",
      "2017-11-11 08:35:12: Loss at step 8320: 0.036740437150001526\n",
      "2017-11-11 08:35:12: Loss at step 8321: 0.036776427179574966\n",
      "2017-11-11 08:35:13: Loss at step 8322: 0.03671129047870636\n",
      "2017-11-11 08:35:13: Loss at step 8323: 0.03671024739742279\n",
      "2017-11-11 08:35:14: Loss at step 8324: 0.036674052476882935\n",
      "2017-11-11 08:35:14: Loss at step 8325: 0.03675822913646698\n",
      "2017-11-11 08:35:15: Loss at step 8326: 0.03670424968004227\n",
      "2017-11-11 08:35:15: Loss at step 8327: 0.036789026111364365\n",
      "2017-11-11 08:35:16: Loss at step 8328: 0.03671881556510925\n",
      "2017-11-11 08:35:16: Loss at step 8329: 0.0366462804377079\n",
      "2017-11-11 08:35:17: Loss at step 8330: 0.036701008677482605\n",
      "2017-11-11 08:35:17: Loss at step 8331: 0.03674627095460892\n",
      "2017-11-11 08:35:18: Loss at step 8332: 0.03663508594036102\n",
      "2017-11-11 08:35:18: Loss at step 8333: 0.03674869239330292\n",
      "2017-11-11 08:35:19: Loss at step 8334: 0.0366847962141037\n",
      "2017-11-11 08:35:20: Loss at step 8335: 0.03670496121048927\n",
      "2017-11-11 08:35:20: Loss at step 8336: 0.03675631061196327\n",
      "2017-11-11 08:35:21: Loss at step 8337: 0.0367511548101902\n",
      "2017-11-11 08:35:21: Loss at step 8338: 0.03677605092525482\n",
      "2017-11-11 08:35:22: Loss at step 8339: 0.036769263446331024\n",
      "2017-11-11 08:35:22: Loss at step 8340: 0.036720070987939835\n",
      "2017-11-11 08:35:23: Loss at step 8341: 0.036652784794569016\n",
      "2017-11-11 08:35:23: Loss at step 8342: 0.036744482815265656\n",
      "2017-11-11 08:35:24: Loss at step 8343: 0.03669741749763489\n",
      "2017-11-11 08:35:24: Loss at step 8344: 0.03666910529136658\n",
      "2017-11-11 08:35:25: Loss at step 8345: 0.0367802195250988\n",
      "2017-11-11 08:35:25: Loss at step 8346: 0.03676319494843483\n",
      "2017-11-11 08:35:26: Loss at step 8347: 0.03675595670938492\n",
      "2017-11-11 08:35:26: Loss at step 8348: 0.03675380349159241\n",
      "2017-11-11 08:35:27: Loss at step 8349: 0.03674422577023506\n",
      "2017-11-11 08:35:27: Loss at step 8350: 0.036765679717063904\n",
      "2017-11-11 08:35:28: Loss at step 8351: 0.03666062653064728\n",
      "2017-11-11 08:35:28: Loss at step 8352: 0.03670395538210869\n",
      "2017-11-11 08:35:29: Loss at step 8353: 0.03681576997041702\n",
      "2017-11-11 08:35:29: Loss at step 8354: 0.03667086735367775\n",
      "2017-11-11 08:35:30: Loss at step 8355: 0.03668169677257538\n",
      "2017-11-11 08:35:30: Loss at step 8356: 0.03676987439393997\n",
      "2017-11-11 08:35:31: Loss at step 8357: 0.03672286868095398\n",
      "2017-11-11 08:35:31: Loss at step 8358: 0.036669258028268814\n",
      "2017-11-11 08:35:32: Loss at step 8359: 0.03671681508421898\n",
      "2017-11-11 08:35:32: Loss at step 8360: 0.03671078011393547\n",
      "2017-11-11 08:35:33: Loss at step 8361: 0.03671852871775627\n",
      "2017-11-11 08:35:33: Loss at step 8362: 0.03669821843504906\n",
      "2017-11-11 08:35:34: Loss at step 8363: 0.036693278700113297\n",
      "2017-11-11 08:35:34: Loss at step 8364: 0.036693181842565536\n",
      "2017-11-11 08:35:35: Loss at step 8365: 0.03667653352022171\n",
      "2017-11-11 08:35:35: Loss at step 8366: 0.03664178028702736\n",
      "2017-11-11 08:35:36: Loss at step 8367: 0.03663510084152222\n",
      "2017-11-11 08:35:36: Loss at step 8368: 0.036634013056755066\n",
      "2017-11-11 08:35:37: Loss at step 8369: 0.03670407086610794\n",
      "2017-11-11 08:35:37: Loss at step 8370: 0.036712754517793655\n",
      "2017-11-11 08:35:38: Loss at step 8371: 0.036751050502061844\n",
      "2017-11-11 08:35:38: Loss at step 8372: 0.036712877452373505\n",
      "2017-11-11 08:35:39: Loss at step 8373: 0.036719098687171936\n",
      "2017-11-11 08:35:39: Loss at step 8374: 0.03676735982298851\n",
      "2017-11-11 08:35:40: Loss at step 8375: 0.03668190911412239\n",
      "2017-11-11 08:35:40: Loss at step 8376: 0.036665234714746475\n",
      "2017-11-11 08:35:41: Loss at step 8377: 0.03675369918346405\n",
      "2017-11-11 08:35:41: Loss at step 8378: 0.03659683093428612\n",
      "2017-11-11 08:35:42: Loss at step 8379: 0.036687351763248444\n",
      "2017-11-11 08:35:42: Loss at step 8380: 0.036700647324323654\n",
      "2017-11-11 08:35:43: Loss at step 8381: 0.0366816408932209\n",
      "2017-11-11 08:35:43: Loss at step 8382: 0.03667106106877327\n",
      "2017-11-11 08:35:44: Loss at step 8383: 0.03672180324792862\n",
      "2017-11-11 08:35:44: Loss at step 8384: 0.036735519766807556\n",
      "2017-11-11 08:35:45: Loss at step 8385: 0.03669745475053787\n",
      "2017-11-11 08:35:45: Loss at step 8386: 0.03669903427362442\n",
      "2017-11-11 08:35:46: Loss at step 8387: 0.03673860430717468\n",
      "2017-11-11 08:35:46: Loss at step 8388: 0.03672899305820465\n",
      "2017-11-11 08:35:47: Loss at step 8389: 0.03674536570906639\n",
      "2017-11-11 08:35:47: Loss at step 8390: 0.03663572296500206\n",
      "2017-11-11 08:35:48: Loss at step 8391: 0.036707665771245956\n",
      "2017-11-11 08:35:48: Loss at step 8392: 0.03673199564218521\n",
      "2017-11-11 08:35:49: Loss at step 8393: 0.036730218678712845\n",
      "2017-11-11 08:35:49: Loss at step 8394: 0.036745984107255936\n",
      "2017-11-11 08:35:50: Loss at step 8395: 0.03664640337228775\n",
      "2017-11-11 08:35:50: Loss at step 8396: 0.036750007420778275\n",
      "2017-11-11 08:35:51: Loss at step 8397: 0.03674822300672531\n",
      "2017-11-11 08:35:51: Loss at step 8398: 0.03670639172196388\n",
      "2017-11-11 08:35:52: Loss at step 8399: 0.0367438979446888\n",
      "2017-11-11 08:35:52: Loss at step 8400: 0.03671615943312645\n",
      "2017-11-11 08:35:53: Loss at step 8401: 0.03667328506708145\n",
      "2017-11-11 08:35:53: Loss at step 8402: 0.036776941269636154\n",
      "2017-11-11 08:35:54: Loss at step 8403: 0.03671353682875633\n",
      "2017-11-11 08:35:54: Loss at step 8404: 0.036792390048503876\n",
      "2017-11-11 08:35:55: Loss at step 8405: 0.03679431229829788\n",
      "2017-11-11 08:35:55: Loss at step 8406: 0.036785826086997986\n",
      "2017-11-11 08:35:56: Loss at step 8407: 0.03679373860359192\n",
      "2017-11-11 08:35:56: Loss at step 8408: 0.03669794648885727\n",
      "2017-11-11 08:35:57: Loss at step 8409: 0.036731090396642685\n",
      "2017-11-11 08:35:57: Loss at step 8410: 0.036693911999464035\n",
      "2017-11-11 08:35:58: Loss at step 8411: 0.036674775183200836\n",
      "2017-11-11 08:35:58: Loss at step 8412: 0.03674454987049103\n",
      "2017-11-11 08:35:59: Loss at step 8413: 0.036745697259902954\n",
      "2017-11-11 08:35:59: Loss at step 8414: 0.03678310662508011\n",
      "2017-11-11 08:36:00: Loss at step 8415: 0.036665819585323334\n",
      "2017-11-11 08:36:00: Loss at step 8416: 0.03675030544400215\n",
      "2017-11-11 08:36:01: Loss at step 8417: 0.03671444579958916\n",
      "2017-11-11 08:36:01: Loss at step 8418: 0.03673284128308296\n",
      "2017-11-11 08:36:02: Loss at step 8419: 0.03672313690185547\n",
      "2017-11-11 08:36:02: Loss at step 8420: 0.036731041967868805\n",
      "2017-11-11 08:36:03: Loss at step 8421: 0.03668558970093727\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-11-11 08:36:03: Loss at step 8422: 0.03667769953608513\n",
      "2017-11-11 08:36:04: Loss at step 8423: 0.03667525202035904\n",
      "2017-11-11 08:36:04: Loss at step 8424: 0.03665494546294212\n",
      "2017-11-11 08:36:05: Loss at step 8425: 0.03671516478061676\n",
      "2017-11-11 08:36:05: Loss at step 8426: 0.036654651165008545\n",
      "2017-11-11 08:36:06: Loss at step 8427: 0.036697808653116226\n",
      "2017-11-11 08:36:06: Loss at step 8428: 0.03669967129826546\n",
      "2017-11-11 08:36:07: Loss at step 8429: 0.03669123724102974\n",
      "2017-11-11 08:36:07: Loss at step 8430: 0.03672577440738678\n",
      "2017-11-11 08:36:08: Loss at step 8431: 0.036668188869953156\n",
      "2017-11-11 08:36:08: Loss at step 8432: 0.036756861954927444\n",
      "2017-11-11 08:36:09: Loss at step 8433: 0.03672261908650398\n",
      "2017-11-11 08:36:09: Loss at step 8434: 0.03668731823563576\n",
      "2017-11-11 08:36:10: Loss at step 8435: 0.03674345836043358\n",
      "2017-11-11 08:36:10: Loss at step 8436: 0.03673679754137993\n",
      "2017-11-11 08:36:11: Loss at step 8437: 0.036689337342977524\n",
      "2017-11-11 08:36:11: Loss at step 8438: 0.0367109552025795\n",
      "2017-11-11 08:36:12: Loss at step 8439: 0.036728084087371826\n",
      "2017-11-11 08:36:12: Loss at step 8440: 0.03672574460506439\n",
      "2017-11-11 08:36:13: Loss at step 8441: 0.03677951544523239\n",
      "2017-11-11 08:36:13: Loss at step 8442: 0.036743342876434326\n",
      "2017-11-11 08:36:14: Loss at step 8443: 0.03668893873691559\n",
      "2017-11-11 08:36:15: Loss at step 8444: 0.036730412393808365\n",
      "2017-11-11 08:36:15: Loss at step 8445: 0.03673945367336273\n",
      "2017-11-11 08:36:16: Loss at step 8446: 0.036781195551157\n",
      "2017-11-11 08:36:16: Loss at step 8447: 0.03683030977845192\n",
      "2017-11-11 08:36:17: Loss at step 8448: 0.03672070428729057\n",
      "2017-11-11 08:36:17: Loss at step 8449: 0.03670284524559975\n",
      "2017-11-11 08:36:18: Loss at step 8450: 0.03682433068752289\n",
      "2017-11-11 08:36:18: Loss at step 8451: 0.036671485751867294\n",
      "2017-11-11 08:36:19: Loss at step 8452: 0.03682101517915726\n",
      "2017-11-11 08:36:19: Loss at step 8453: 0.03678499162197113\n",
      "2017-11-11 08:36:20: Loss at step 8454: 0.03664927929639816\n",
      "2017-11-11 08:36:20: Loss at step 8455: 0.03677668422460556\n",
      "2017-11-11 08:36:21: Loss at step 8456: 0.036674950271844864\n",
      "2017-11-11 08:36:21: Loss at step 8457: 0.03667261824011803\n",
      "2017-11-11 08:36:22: Loss at step 8458: 0.03666124492883682\n",
      "2017-11-11 08:36:22: Loss at step 8459: 0.0367184579372406\n",
      "2017-11-11 08:36:23: Loss at step 8460: 0.03676808625459671\n",
      "2017-11-11 08:36:23: Loss at step 8461: 0.036688439548015594\n",
      "2017-11-11 08:36:24: Loss at step 8462: 0.03673774376511574\n",
      "2017-11-11 08:36:24: Loss at step 8463: 0.03673030808568001\n",
      "2017-11-11 08:36:25: Loss at step 8464: 0.03672465682029724\n",
      "2017-11-11 08:36:25: Loss at step 8465: 0.03676155209541321\n",
      "2017-11-11 08:36:26: Loss at step 8466: 0.0366985909640789\n",
      "2017-11-11 08:36:26: Loss at step 8467: 0.036766212433576584\n",
      "2017-11-11 08:36:27: Loss at step 8468: 0.03670554980635643\n",
      "2017-11-11 08:36:27: Loss at step 8469: 0.036798182874917984\n",
      "2017-11-11 08:36:28: Loss at step 8470: 0.03674868866801262\n",
      "2017-11-11 08:36:28: Loss at step 8471: 0.036741435527801514\n",
      "2017-11-11 08:36:29: Loss at step 8472: 0.0366944745182991\n",
      "2017-11-11 08:36:29: Loss at step 8473: 0.03677608072757721\n",
      "2017-11-11 08:36:30: Loss at step 8474: 0.036647748202085495\n",
      "2017-11-11 08:36:30: Loss at step 8475: 0.03664016351103783\n",
      "2017-11-11 08:36:31: Loss at step 8476: 0.03671915456652641\n",
      "2017-11-11 08:36:31: Loss at step 8477: 0.03679005801677704\n",
      "2017-11-11 08:36:32: Loss at step 8478: 0.03666462376713753\n",
      "2017-11-11 08:36:32: Loss at step 8479: 0.036814358085393906\n",
      "2017-11-11 08:36:33: Loss at step 8480: 0.03659915179014206\n",
      "2017-11-11 08:36:33: Loss at step 8481: 0.036694854497909546\n",
      "2017-11-11 08:36:34: Loss at step 8482: 0.03668443113565445\n",
      "2017-11-11 08:36:34: Loss at step 8483: 0.0367267020046711\n",
      "2017-11-11 08:36:35: Loss at step 8484: 0.036658961325883865\n",
      "2017-11-11 08:36:35: Loss at step 8485: 0.036656010895967484\n",
      "2017-11-11 08:36:36: Loss at step 8486: 0.03662798926234245\n",
      "2017-11-11 08:36:36: Loss at step 8487: 0.036803003400564194\n",
      "2017-11-11 08:36:37: Loss at step 8488: 0.036642253398895264\n",
      "2017-11-11 08:36:37: Loss at step 8489: 0.03670130670070648\n",
      "2017-11-11 08:36:38: Loss at step 8490: 0.03672407567501068\n",
      "2017-11-11 08:36:38: Loss at step 8491: 0.03666648641228676\n",
      "2017-11-11 08:36:39: Loss at step 8492: 0.036771006882190704\n",
      "2017-11-11 08:36:39: Loss at step 8493: 0.03673627972602844\n",
      "2017-11-11 08:36:40: Loss at step 8494: 0.036623165011405945\n",
      "2017-11-11 08:36:41: Loss at step 8495: 0.03678208589553833\n",
      "2017-11-11 08:36:41: Loss at step 8496: 0.03677213937044144\n",
      "2017-11-11 08:36:42: Loss at step 8497: 0.03665046766400337\n",
      "2017-11-11 08:36:42: Loss at step 8498: 0.036744069308042526\n",
      "2017-11-11 08:36:43: Loss at step 8499: 0.0367303267121315\n",
      "2017-11-11 08:36:43: Loss at step 8500: 0.03665877506136894\n",
      "2017-11-11 08:36:43: Loss at step 8501: 0.03664018586277962\n",
      "2017-11-11 08:36:44: Loss at step 8502: 0.036653850227594376\n",
      "2017-11-11 08:36:44: Loss at step 8503: 0.03671056404709816\n",
      "2017-11-11 08:36:45: Loss at step 8504: 0.03672049194574356\n",
      "2017-11-11 08:36:45: Loss at step 8505: 0.03669396787881851\n",
      "2017-11-11 08:36:46: Loss at step 8506: 0.03662049397826195\n",
      "2017-11-11 08:36:47: Loss at step 8507: 0.036731138825416565\n",
      "2017-11-11 08:36:47: Loss at step 8508: 0.03674175962805748\n",
      "2017-11-11 08:36:48: Loss at step 8509: 0.03676651045680046\n",
      "2017-11-11 08:36:48: Loss at step 8510: 0.03671294450759888\n",
      "2017-11-11 08:36:49: Loss at step 8511: 0.03666534274816513\n",
      "2017-11-11 08:36:49: Loss at step 8512: 0.03676779195666313\n",
      "2017-11-11 08:36:50: Loss at step 8513: 0.03667303919792175\n",
      "2017-11-11 08:36:50: Loss at step 8514: 0.036755528301000595\n",
      "2017-11-11 08:36:51: Loss at step 8515: 0.03661451116204262\n",
      "2017-11-11 08:36:51: Loss at step 8516: 0.03667052090167999\n",
      "2017-11-11 08:36:52: Loss at step 8517: 0.03674020990729332\n",
      "2017-11-11 08:36:52: Loss at step 8518: 0.03669219836592674\n",
      "2017-11-11 08:36:53: Loss at step 8519: 0.03670203685760498\n",
      "2017-11-11 08:36:53: Loss at step 8520: 0.036728814244270325\n",
      "2017-11-11 08:36:54: Loss at step 8521: 0.03679080307483673\n",
      "2017-11-11 08:36:54: Loss at step 8522: 0.03672289475798607\n",
      "2017-11-11 08:36:55: Loss at step 8523: 0.03670559450984001\n",
      "2017-11-11 08:36:55: Loss at step 8524: 0.03669153153896332\n",
      "2017-11-11 08:36:56: Loss at step 8525: 0.0367707759141922\n",
      "2017-11-11 08:36:56: Loss at step 8526: 0.03667588531970978\n",
      "2017-11-11 08:36:57: Loss at step 8527: 0.03670889139175415\n",
      "2017-11-11 08:36:57: Loss at step 8528: 0.03671687841415405\n",
      "2017-11-11 08:36:58: Loss at step 8529: 0.03673286363482475\n",
      "2017-11-11 08:36:58: Loss at step 8530: 0.03669045493006706\n",
      "2017-11-11 08:36:59: Loss at step 8531: 0.036761943250894547\n",
      "2017-11-11 08:36:59: Loss at step 8532: 0.0366569384932518\n",
      "2017-11-11 08:37:00: Loss at step 8533: 0.03673461452126503\n",
      "2017-11-11 08:37:00: Loss at step 8534: 0.036733776330947876\n",
      "2017-11-11 08:37:01: Loss at step 8535: 0.036660999059677124\n",
      "2017-11-11 08:37:01: Loss at step 8536: 0.03668678179383278\n",
      "2017-11-11 08:37:02: Loss at step 8537: 0.03669397905468941\n",
      "2017-11-11 08:37:02: Loss at step 8538: 0.03671886771917343\n",
      "2017-11-11 08:37:03: Loss at step 8539: 0.03670518845319748\n",
      "2017-11-11 08:37:03: Loss at step 8540: 0.03682491183280945\n",
      "2017-11-11 08:37:04: Loss at step 8541: 0.03679034113883972\n",
      "2017-11-11 08:37:04: Loss at step 8542: 0.03668495640158653\n",
      "2017-11-11 08:37:05: Loss at step 8543: 0.03683333843946457\n",
      "2017-11-11 08:37:05: Loss at step 8544: 0.03669276833534241\n",
      "2017-11-11 08:37:06: Loss at step 8545: 0.03670823201537132\n",
      "2017-11-11 08:37:06: Loss at step 8546: 0.03681008890271187\n",
      "2017-11-11 08:37:07: Loss at step 8547: 0.03672207519412041\n",
      "2017-11-11 08:37:07: Loss at step 8548: 0.03674367815256119\n",
      "2017-11-11 08:37:08: Loss at step 8549: 0.036772631108760834\n",
      "2017-11-11 08:37:08: Loss at step 8550: 0.03676682710647583\n",
      "2017-11-11 08:37:09: Loss at step 8551: 0.03669076785445213\n",
      "2017-11-11 08:37:09: Loss at step 8552: 0.036774322390556335\n",
      "2017-11-11 08:37:10: Loss at step 8553: 0.03676281124353409\n",
      "2017-11-11 08:37:10: Loss at step 8554: 0.036728933453559875\n",
      "2017-11-11 08:37:11: Loss at step 8555: 0.036781877279281616\n",
      "2017-11-11 08:37:11: Loss at step 8556: 0.03675676882266998\n",
      "2017-11-11 08:37:12: Loss at step 8557: 0.03665481507778168\n",
      "2017-11-11 08:37:13: Loss at step 8558: 0.03667996823787689\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-11-11 08:37:13: Loss at step 8559: 0.03674912080168724\n",
      "2017-11-11 08:37:14: Loss at step 8560: 0.03670467436313629\n",
      "2017-11-11 08:37:14: Loss at step 8561: 0.03681572154164314\n",
      "2017-11-11 08:37:15: Loss at step 8562: 0.03669620305299759\n",
      "2017-11-11 08:37:15: Loss at step 8563: 0.036752186715602875\n",
      "2017-11-11 08:37:16: Loss at step 8564: 0.03679221123456955\n",
      "2017-11-11 08:37:16: Loss at step 8565: 0.03669903427362442\n",
      "2017-11-11 08:37:17: Loss at step 8566: 0.03667479380965233\n",
      "2017-11-11 08:37:17: Loss at step 8567: 0.036692485213279724\n",
      "2017-11-11 08:37:18: Loss at step 8568: 0.036792442202568054\n",
      "2017-11-11 08:37:18: Loss at step 8569: 0.036782220005989075\n",
      "2017-11-11 08:37:19: Loss at step 8570: 0.03676873818039894\n",
      "2017-11-11 08:37:19: Loss at step 8571: 0.03677671402692795\n",
      "2017-11-11 08:37:20: Loss at step 8572: 0.03667524456977844\n",
      "2017-11-11 08:37:20: Loss at step 8573: 0.03679352253675461\n",
      "2017-11-11 08:37:21: Loss at step 8574: 0.036710161715745926\n",
      "2017-11-11 08:37:21: Loss at step 8575: 0.03680603578686714\n",
      "2017-11-11 08:37:22: Loss at step 8576: 0.036710504442453384\n",
      "2017-11-11 08:37:22: Loss at step 8577: 0.03679286316037178\n",
      "2017-11-11 08:37:23: Loss at step 8578: 0.03667570278048515\n",
      "2017-11-11 08:37:23: Loss at step 8579: 0.03672359138727188\n",
      "2017-11-11 08:37:24: Loss at step 8580: 0.036728955805301666\n",
      "2017-11-11 08:37:24: Loss at step 8581: 0.03669620305299759\n",
      "2017-11-11 08:37:25: Loss at step 8582: 0.036736760288476944\n",
      "2017-11-11 08:37:25: Loss at step 8583: 0.03678933531045914\n",
      "2017-11-11 08:37:26: Loss at step 8584: 0.036697302013635635\n",
      "2017-11-11 08:37:26: Loss at step 8585: 0.036681562662124634\n",
      "2017-11-11 08:37:27: Loss at step 8586: 0.03674185276031494\n",
      "2017-11-11 08:37:27: Loss at step 8587: 0.03673763573169708\n",
      "2017-11-11 08:37:28: Loss at step 8588: 0.03675917536020279\n",
      "2017-11-11 08:37:28: Loss at step 8589: 0.03672604262828827\n",
      "2017-11-11 08:37:29: Loss at step 8590: 0.036714136600494385\n",
      "2017-11-11 08:37:29: Loss at step 8591: 0.036678701639175415\n",
      "2017-11-11 08:37:30: Loss at step 8592: 0.036773234605789185\n",
      "2017-11-11 08:37:30: Loss at step 8593: 0.03667185828089714\n",
      "2017-11-11 08:37:31: Loss at step 8594: 0.036650415509939194\n",
      "2017-11-11 08:37:31: Loss at step 8595: 0.036700550466775894\n",
      "2017-11-11 08:37:32: Loss at step 8596: 0.036808207631111145\n",
      "2017-11-11 08:37:32: Loss at step 8597: 0.03678670525550842\n",
      "2017-11-11 08:37:33: Loss at step 8598: 0.03666113317012787\n",
      "2017-11-11 08:37:33: Loss at step 8599: 0.03679581731557846\n",
      "2017-11-11 08:37:34: Loss at step 8600: 0.03668515011668205\n",
      "2017-11-11 08:37:34: Loss at step 8601: 0.0366688035428524\n",
      "2017-11-11 08:37:35: Loss at step 8602: 0.036767881363630295\n",
      "2017-11-11 08:37:35: Loss at step 8603: 0.03679375350475311\n",
      "2017-11-11 08:37:36: Loss at step 8604: 0.036644499748945236\n",
      "2017-11-11 08:37:36: Loss at step 8605: 0.03668683394789696\n",
      "2017-11-11 08:37:37: Loss at step 8606: 0.036729663610458374\n",
      "2017-11-11 08:37:37: Loss at step 8607: 0.03661845251917839\n",
      "2017-11-11 08:37:38: Loss at step 8608: 0.03671422600746155\n",
      "2017-11-11 08:37:38: Loss at step 8609: 0.03675505518913269\n",
      "2017-11-11 08:37:39: Loss at step 8610: 0.0366678312420845\n",
      "2017-11-11 08:37:39: Loss at step 8611: 0.036618079990148544\n",
      "2017-11-11 08:37:40: Loss at step 8612: 0.03672340512275696\n",
      "2017-11-11 08:37:41: Loss at step 8613: 0.0366557277739048\n",
      "2017-11-11 08:37:41: Loss at step 8614: 0.036673467606306076\n",
      "2017-11-11 08:37:42: Loss at step 8615: 0.036673061549663544\n",
      "2017-11-11 08:37:42: Loss at step 8616: 0.03671633079648018\n",
      "2017-11-11 08:37:43: Loss at step 8617: 0.03674808144569397\n",
      "2017-11-11 08:37:43: Loss at step 8618: 0.03681043162941933\n",
      "2017-11-11 08:37:44: Loss at step 8619: 0.03672710061073303\n",
      "2017-11-11 08:37:44: Loss at step 8620: 0.036827314645051956\n",
      "2017-11-11 08:37:45: Loss at step 8621: 0.036744799464941025\n",
      "2017-11-11 08:37:45: Loss at step 8622: 0.036752693355083466\n",
      "2017-11-11 08:37:46: Loss at step 8623: 0.03672406077384949\n",
      "2017-11-11 08:37:46: Loss at step 8624: 0.036778923124074936\n",
      "2017-11-11 08:37:47: Loss at step 8625: 0.036671075969934464\n",
      "2017-11-11 08:37:47: Loss at step 8626: 0.03674345463514328\n",
      "2017-11-11 08:37:48: Loss at step 8627: 0.0366840735077858\n",
      "2017-11-11 08:37:48: Loss at step 8628: 0.036656226962804794\n",
      "2017-11-11 08:37:49: Loss at step 8629: 0.03678397089242935\n",
      "2017-11-11 08:37:49: Loss at step 8630: 0.036662377417087555\n",
      "2017-11-11 08:37:50: Loss at step 8631: 0.03672385215759277\n",
      "2017-11-11 08:37:50: Loss at step 8632: 0.03672614321112633\n",
      "2017-11-11 08:37:51: Loss at step 8633: 0.03672589734196663\n",
      "2017-11-11 08:37:51: Loss at step 8634: 0.03674400970339775\n",
      "2017-11-11 08:37:52: Loss at step 8635: 0.036649223417043686\n",
      "2017-11-11 08:37:52: Loss at step 8636: 0.036730121821165085\n",
      "2017-11-11 08:37:53: Loss at step 8637: 0.03679319843649864\n",
      "2017-11-11 08:37:53: Loss at step 8638: 0.0367896743118763\n",
      "2017-11-11 08:37:54: Loss at step 8639: 0.036690112203359604\n",
      "2017-11-11 08:37:54: Loss at step 8640: 0.03674269840121269\n",
      "2017-11-11 08:37:55: Loss at step 8641: 0.03679005801677704\n",
      "2017-11-11 08:37:55: Loss at step 8642: 0.0367487296462059\n",
      "2017-11-11 08:37:56: Loss at step 8643: 0.03670850396156311\n",
      "2017-11-11 08:37:56: Loss at step 8644: 0.03662947565317154\n",
      "2017-11-11 08:37:57: Loss at step 8645: 0.03672042116522789\n",
      "2017-11-11 08:37:57: Loss at step 8646: 0.03676202893257141\n",
      "2017-11-11 08:37:58: Loss at step 8647: 0.0367116704583168\n",
      "2017-11-11 08:37:58: Loss at step 8648: 0.036708105355501175\n",
      "2017-11-11 08:37:59: Loss at step 8649: 0.0367039255797863\n",
      "2017-11-11 08:37:59: Loss at step 8650: 0.0367385558784008\n",
      "2017-11-11 08:38:00: Loss at step 8651: 0.03671753406524658\n",
      "2017-11-11 08:38:01: Loss at step 8652: 0.036764394491910934\n",
      "2017-11-11 08:38:01: Loss at step 8653: 0.03672444075345993\n",
      "2017-11-11 08:38:02: Loss at step 8654: 0.03672988712787628\n",
      "2017-11-11 08:38:02: Loss at step 8655: 0.03670414537191391\n",
      "2017-11-11 08:38:03: Loss at step 8656: 0.036707375198602676\n",
      "2017-11-11 08:38:03: Loss at step 8657: 0.03672465682029724\n",
      "2017-11-11 08:38:04: Loss at step 8658: 0.03670860454440117\n",
      "2017-11-11 08:38:04: Loss at step 8659: 0.036730390042066574\n",
      "2017-11-11 08:38:05: Loss at step 8660: 0.03667546436190605\n",
      "2017-11-11 08:38:05: Loss at step 8661: 0.03669597953557968\n",
      "2017-11-11 08:38:06: Loss at step 8662: 0.03674802929162979\n",
      "2017-11-11 08:38:06: Loss at step 8663: 0.03672517091035843\n",
      "2017-11-11 08:38:07: Loss at step 8664: 0.03671199455857277\n",
      "2017-11-11 08:38:07: Loss at step 8665: 0.0367538183927536\n",
      "2017-11-11 08:38:08: Loss at step 8666: 0.03676651045680046\n",
      "2017-11-11 08:38:08: Loss at step 8667: 0.03659059479832649\n",
      "2017-11-11 08:38:09: Loss at step 8668: 0.03673810511827469\n",
      "2017-11-11 08:38:09: Loss at step 8669: 0.036672692745923996\n",
      "2017-11-11 08:38:10: Loss at step 8670: 0.036765530705451965\n",
      "2017-11-11 08:38:10: Loss at step 8671: 0.036660127341747284\n",
      "2017-11-11 08:38:11: Loss at step 8672: 0.03657223656773567\n",
      "2017-11-11 08:38:11: Loss at step 8673: 0.03673544153571129\n",
      "2017-11-11 08:38:12: Loss at step 8674: 0.036591771990060806\n",
      "2017-11-11 08:38:12: Loss at step 8675: 0.03668363764882088\n",
      "2017-11-11 08:38:13: Loss at step 8676: 0.03670189157128334\n",
      "2017-11-11 08:38:13: Loss at step 8677: 0.03672531619668007\n",
      "2017-11-11 08:38:14: Loss at step 8678: 0.0367070771753788\n",
      "2017-11-11 08:38:14: Loss at step 8679: 0.036743778735399246\n",
      "2017-11-11 08:38:15: Loss at step 8680: 0.03663904219865799\n",
      "2017-11-11 08:38:15: Loss at step 8681: 0.03676930442452431\n",
      "2017-11-11 08:38:16: Loss at step 8682: 0.03671544790267944\n",
      "2017-11-11 08:38:16: Loss at step 8683: 0.03673478215932846\n",
      "2017-11-11 08:38:17: Loss at step 8684: 0.03678858280181885\n",
      "2017-11-11 08:38:17: Loss at step 8685: 0.036665815860033035\n",
      "2017-11-11 08:38:18: Loss at step 8686: 0.036683857440948486\n",
      "2017-11-11 08:38:18: Loss at step 8687: 0.0366901233792305\n",
      "2017-11-11 08:38:19: Loss at step 8688: 0.036708611994981766\n",
      "2017-11-11 08:38:19: Loss at step 8689: 0.03666150942444801\n",
      "2017-11-11 08:38:20: Loss at step 8690: 0.03667886182665825\n",
      "2017-11-11 08:38:20: Loss at step 8691: 0.036668382585048676\n",
      "2017-11-11 08:38:21: Loss at step 8692: 0.03672138229012489\n",
      "2017-11-11 08:38:22: Loss at step 8693: 0.03664160519838333\n",
      "2017-11-11 08:38:22: Loss at step 8694: 0.036690667271614075\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-11-11 08:38:23: Loss at step 8695: 0.036737408488988876\n",
      "2017-11-11 08:38:23: Loss at step 8696: 0.03674701601266861\n",
      "2017-11-11 08:38:23: Loss at step 8697: 0.03671083226799965\n",
      "2017-11-11 08:38:24: Loss at step 8698: 0.036684803664684296\n",
      "2017-11-11 08:38:24: Loss at step 8699: 0.03677690029144287\n",
      "2017-11-11 08:38:25: Loss at step 8700: 0.03670870512723923\n",
      "2017-11-11 08:38:25: Loss at step 8701: 0.03678637370467186\n",
      "2017-11-11 08:38:26: Loss at step 8702: 0.03675498813390732\n",
      "2017-11-11 08:38:26: Loss at step 8703: 0.03673948347568512\n",
      "2017-11-11 08:38:27: Loss at step 8704: 0.036718908697366714\n",
      "2017-11-11 08:38:28: Loss at step 8705: 0.03676292300224304\n",
      "2017-11-11 08:38:28: Loss at step 8706: 0.03675127401947975\n",
      "2017-11-11 08:38:29: Loss at step 8707: 0.03678654134273529\n",
      "2017-11-11 08:38:29: Loss at step 8708: 0.036768414080142975\n",
      "2017-11-11 08:38:30: Loss at step 8709: 0.036712877452373505\n",
      "2017-11-11 08:38:30: Loss at step 8710: 0.036669377237558365\n",
      "2017-11-11 08:38:31: Loss at step 8711: 0.03672858700156212\n",
      "2017-11-11 08:38:31: Loss at step 8712: 0.0366683155298233\n",
      "2017-11-11 08:38:32: Loss at step 8713: 0.03671792149543762\n",
      "2017-11-11 08:38:32: Loss at step 8714: 0.03664012998342514\n",
      "2017-11-11 08:38:33: Loss at step 8715: 0.03670736402273178\n",
      "2017-11-11 08:38:33: Loss at step 8716: 0.036695972084999084\n",
      "2017-11-11 08:38:34: Loss at step 8717: 0.03673223778605461\n",
      "2017-11-11 08:38:34: Loss at step 8718: 0.036674316972494125\n",
      "2017-11-11 08:38:35: Loss at step 8719: 0.03669349104166031\n",
      "2017-11-11 08:38:35: Loss at step 8720: 0.03674374893307686\n",
      "2017-11-11 08:38:36: Loss at step 8721: 0.03677675873041153\n",
      "2017-11-11 08:38:36: Loss at step 8722: 0.03680930659174919\n",
      "2017-11-11 08:38:37: Loss at step 8723: 0.036690112203359604\n",
      "2017-11-11 08:38:37: Loss at step 8724: 0.03663375973701477\n",
      "2017-11-11 08:38:38: Loss at step 8725: 0.036738913506269455\n",
      "2017-11-11 08:38:38: Loss at step 8726: 0.03669643774628639\n",
      "2017-11-11 08:38:39: Loss at step 8727: 0.036744143813848495\n",
      "2017-11-11 08:38:39: Loss at step 8728: 0.03671452775597572\n",
      "2017-11-11 08:38:40: Loss at step 8729: 0.03672769293189049\n",
      "2017-11-11 08:38:40: Loss at step 8730: 0.0367315411567688\n",
      "2017-11-11 08:38:41: Loss at step 8731: 0.0367334708571434\n",
      "2017-11-11 08:38:41: Loss at step 8732: 0.036760363727808\n",
      "2017-11-11 08:38:42: Loss at step 8733: 0.03674136474728584\n",
      "2017-11-11 08:38:42: Loss at step 8734: 0.036788471043109894\n",
      "2017-11-11 08:38:43: Loss at step 8735: 0.03675386309623718\n",
      "2017-11-11 08:38:43: Loss at step 8736: 0.03676694259047508\n",
      "2017-11-11 08:38:44: Loss at step 8737: 0.03675632178783417\n",
      "2017-11-11 08:38:44: Loss at step 8738: 0.036746665835380554\n",
      "2017-11-11 08:38:45: Loss at step 8739: 0.036722972989082336\n",
      "2017-11-11 08:38:45: Loss at step 8740: 0.03677564114332199\n",
      "2017-11-11 08:38:46: Loss at step 8741: 0.03674875572323799\n",
      "2017-11-11 08:38:46: Loss at step 8742: 0.03669557347893715\n",
      "2017-11-11 08:38:47: Loss at step 8743: 0.03669043630361557\n",
      "2017-11-11 08:38:47: Loss at step 8744: 0.036701612174510956\n",
      "2017-11-11 08:38:48: Loss at step 8745: 0.03672793507575989\n",
      "2017-11-11 08:38:48: Loss at step 8746: 0.036652807146310806\n",
      "2017-11-11 08:38:49: Loss at step 8747: 0.0367717482149601\n",
      "2017-11-11 08:38:50: Loss at step 8748: 0.03670601174235344\n",
      "2017-11-11 08:38:50: Loss at step 8749: 0.0367811843752861\n",
      "2017-11-11 08:38:51: Loss at step 8750: 0.03683669492602348\n",
      "2017-11-11 08:38:51: Loss at step 8751: 0.03676164522767067\n",
      "2017-11-11 08:38:52: Loss at step 8752: 0.03677043318748474\n",
      "2017-11-11 08:38:52: Loss at step 8753: 0.036718059331178665\n",
      "2017-11-11 08:38:53: Loss at step 8754: 0.036748066544532776\n",
      "2017-11-11 08:38:53: Loss at step 8755: 0.03670759126543999\n",
      "2017-11-11 08:38:54: Loss at step 8756: 0.03667531907558441\n",
      "2017-11-11 08:38:54: Loss at step 8757: 0.03672006353735924\n",
      "2017-11-11 08:38:55: Loss at step 8758: 0.0367213636636734\n",
      "2017-11-11 08:38:55: Loss at step 8759: 0.03671204671263695\n",
      "2017-11-11 08:38:56: Loss at step 8760: 0.03665757179260254\n",
      "2017-11-11 08:38:56: Loss at step 8761: 0.036601658910512924\n",
      "2017-11-11 08:38:57: Loss at step 8762: 0.03669023886322975\n",
      "2017-11-11 08:38:57: Loss at step 8763: 0.03672726824879646\n",
      "2017-11-11 08:38:58: Loss at step 8764: 0.03675997257232666\n",
      "2017-11-11 08:38:58: Loss at step 8765: 0.036655765026807785\n",
      "2017-11-11 08:38:59: Loss at step 8766: 0.03672159090638161\n",
      "2017-11-11 08:38:59: Loss at step 8767: 0.03676239401102066\n",
      "2017-11-11 08:39:00: Loss at step 8768: 0.036635253578424454\n",
      "2017-11-11 08:39:00: Loss at step 8769: 0.03671136125922203\n",
      "2017-11-11 08:39:01: Loss at step 8770: 0.03672358766198158\n",
      "2017-11-11 08:39:01: Loss at step 8771: 0.03671493008732796\n",
      "2017-11-11 08:39:02: Loss at step 8772: 0.03677543252706528\n",
      "2017-11-11 08:39:02: Loss at step 8773: 0.036682575941085815\n",
      "2017-11-11 08:39:03: Loss at step 8774: 0.03673149272799492\n",
      "2017-11-11 08:39:03: Loss at step 8775: 0.0366692990064621\n",
      "2017-11-11 08:39:04: Loss at step 8776: 0.03678444027900696\n",
      "2017-11-11 08:39:04: Loss at step 8777: 0.036677032709121704\n",
      "2017-11-11 08:39:05: Loss at step 8778: 0.036738503724336624\n",
      "2017-11-11 08:39:05: Loss at step 8779: 0.0367257334291935\n",
      "2017-11-11 08:39:06: Loss at step 8780: 0.03684175759553909\n",
      "2017-11-11 08:39:06: Loss at step 8781: 0.0368366464972496\n",
      "2017-11-11 08:39:07: Loss at step 8782: 0.03671034425497055\n",
      "2017-11-11 08:39:07: Loss at step 8783: 0.036679644137620926\n",
      "2017-11-11 08:39:08: Loss at step 8784: 0.0367705374956131\n",
      "2017-11-11 08:39:08: Loss at step 8785: 0.036711085587739944\n",
      "2017-11-11 08:39:09: Loss at step 8786: 0.036789655685424805\n",
      "2017-11-11 08:39:09: Loss at step 8787: 0.036722101271152496\n",
      "2017-11-11 08:39:10: Loss at step 8788: 0.03667939454317093\n",
      "2017-11-11 08:39:10: Loss at step 8789: 0.03675326704978943\n",
      "2017-11-11 08:39:11: Loss at step 8790: 0.0367424376308918\n",
      "2017-11-11 08:39:11: Loss at step 8791: 0.03664107993245125\n",
      "2017-11-11 08:39:12: Loss at step 8792: 0.03678813949227333\n",
      "2017-11-11 08:39:13: Loss at step 8793: 0.0367310494184494\n",
      "2017-11-11 08:39:13: Loss at step 8794: 0.03680681809782982\n",
      "2017-11-11 08:39:14: Loss at step 8795: 0.03667423874139786\n",
      "2017-11-11 08:39:14: Loss at step 8796: 0.03678504750132561\n",
      "2017-11-11 08:39:15: Loss at step 8797: 0.03677808865904808\n",
      "2017-11-11 08:39:15: Loss at step 8798: 0.036746952682733536\n",
      "2017-11-11 08:39:16: Loss at step 8799: 0.03679516166448593\n",
      "2017-11-11 08:39:16: Loss at step 8800: 0.03670378401875496\n",
      "2017-11-11 08:39:17: Loss at step 8801: 0.036702897399663925\n",
      "2017-11-11 08:39:17: Loss at step 8802: 0.03674272447824478\n",
      "2017-11-11 08:39:18: Loss at step 8803: 0.036759838461875916\n",
      "2017-11-11 08:39:18: Loss at step 8804: 0.036762215197086334\n",
      "2017-11-11 08:39:19: Loss at step 8805: 0.036810502409935\n",
      "2017-11-11 08:39:19: Loss at step 8806: 0.03689436614513397\n",
      "2017-11-11 08:39:20: Loss at step 8807: 0.03680089861154556\n",
      "2017-11-11 08:39:20: Loss at step 8808: 0.03682665154337883\n",
      "2017-11-11 08:39:21: Loss at step 8809: 0.036792684346437454\n",
      "2017-11-11 08:39:21: Loss at step 8810: 0.03673918917775154\n",
      "2017-11-11 08:39:22: Loss at step 8811: 0.03682727739214897\n",
      "2017-11-11 08:39:22: Loss at step 8812: 0.03674030303955078\n",
      "2017-11-11 08:39:23: Loss at step 8813: 0.03677516058087349\n",
      "2017-11-11 08:39:23: Loss at step 8814: 0.036779046058654785\n",
      "2017-11-11 08:39:24: Loss at step 8815: 0.036865320056676865\n",
      "2017-11-11 08:39:24: Loss at step 8816: 0.03681236132979393\n",
      "2017-11-11 08:39:25: Loss at step 8817: 0.03673309460282326\n",
      "2017-11-11 08:39:25: Loss at step 8818: 0.036721259355545044\n",
      "2017-11-11 08:39:26: Loss at step 8819: 0.03676803782582283\n",
      "2017-11-11 08:39:26: Loss at step 8820: 0.036845237016677856\n",
      "2017-11-11 08:39:27: Loss at step 8821: 0.036731209605932236\n",
      "2017-11-11 08:39:27: Loss at step 8822: 0.03671623393893242\n",
      "2017-11-11 08:39:28: Loss at step 8823: 0.03671739995479584\n",
      "2017-11-11 08:39:28: Loss at step 8824: 0.03670540079474449\n",
      "2017-11-11 08:39:29: Loss at step 8825: 0.03667999431490898\n",
      "2017-11-11 08:39:29: Loss at step 8826: 0.036737699061632156\n",
      "2017-11-11 08:39:30: Loss at step 8827: 0.03668733686208725\n",
      "2017-11-11 08:39:30: Loss at step 8828: 0.036700330674648285\n",
      "2017-11-11 08:39:31: Loss at step 8829: 0.036763325333595276\n",
      "2017-11-11 08:39:31: Loss at step 8830: 0.03668738529086113\n",
      "2017-11-11 08:39:32: Loss at step 8831: 0.03660360723733902\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-11-11 08:39:32: Loss at step 8832: 0.036805592477321625\n",
      "2017-11-11 08:39:33: Loss at step 8833: 0.036721501499414444\n",
      "2017-11-11 08:39:34: Loss at step 8834: 0.03666277602314949\n",
      "2017-11-11 08:39:34: Loss at step 8835: 0.036702629178762436\n",
      "2017-11-11 08:39:35: Loss at step 8836: 0.036709800362586975\n",
      "2017-11-11 08:39:35: Loss at step 8837: 0.03669178485870361\n",
      "2017-11-11 08:39:36: Loss at step 8838: 0.03670436888933182\n",
      "2017-11-11 08:39:36: Loss at step 8839: 0.03671184554696083\n",
      "2017-11-11 08:39:37: Loss at step 8840: 0.03675302863121033\n",
      "2017-11-11 08:39:37: Loss at step 8841: 0.03675039857625961\n",
      "2017-11-11 08:39:38: Loss at step 8842: 0.036776743829250336\n",
      "2017-11-11 08:39:38: Loss at step 8843: 0.03672385960817337\n",
      "2017-11-11 08:39:39: Loss at step 8844: 0.03669503703713417\n",
      "2017-11-11 08:39:39: Loss at step 8845: 0.03678461164236069\n",
      "2017-11-11 08:39:40: Loss at step 8846: 0.0366891548037529\n",
      "2017-11-11 08:39:40: Loss at step 8847: 0.03668694943189621\n",
      "2017-11-11 08:39:41: Loss at step 8848: 0.03664712980389595\n",
      "2017-11-11 08:39:41: Loss at step 8849: 0.03682015463709831\n",
      "2017-11-11 08:39:42: Loss at step 8850: 0.03676767647266388\n",
      "2017-11-11 08:39:42: Loss at step 8851: 0.03672023117542267\n",
      "2017-11-11 08:39:43: Loss at step 8852: 0.03674355521798134\n",
      "2017-11-11 08:39:43: Loss at step 8853: 0.03672206029295921\n",
      "2017-11-11 08:39:44: Loss at step 8854: 0.03666582703590393\n",
      "2017-11-11 08:39:44: Loss at step 8855: 0.03666097670793533\n",
      "2017-11-11 08:39:45: Loss at step 8856: 0.03678057715296745\n",
      "2017-11-11 08:39:45: Loss at step 8857: 0.03665167838335037\n",
      "2017-11-11 08:39:46: Loss at step 8858: 0.03669862821698189\n",
      "2017-11-11 08:39:46: Loss at step 8859: 0.036704517900943756\n",
      "2017-11-11 08:39:47: Loss at step 8860: 0.03678908199071884\n",
      "2017-11-11 08:39:47: Loss at step 8861: 0.03668399900197983\n",
      "2017-11-11 08:39:48: Loss at step 8862: 0.03672178462147713\n",
      "2017-11-11 08:39:48: Loss at step 8863: 0.03664914146065712\n",
      "2017-11-11 08:39:49: Loss at step 8864: 0.036797210574150085\n",
      "2017-11-11 08:39:49: Loss at step 8865: 0.036751408129930496\n",
      "2017-11-11 08:39:50: Loss at step 8866: 0.03669038042426109\n",
      "2017-11-11 08:39:50: Loss at step 8867: 0.03669172525405884\n",
      "2017-11-11 08:39:51: Loss at step 8868: 0.03668303042650223\n",
      "2017-11-11 08:39:51: Loss at step 8869: 0.03671890124678612\n",
      "2017-11-11 08:39:52: Loss at step 8870: 0.0366775207221508\n",
      "2017-11-11 08:39:52: Loss at step 8871: 0.036749131977558136\n",
      "2017-11-11 08:39:53: Loss at step 8872: 0.0366896353662014\n",
      "2017-11-11 08:39:54: Loss at step 8873: 0.03673137351870537\n",
      "2017-11-11 08:39:54: Loss at step 8874: 0.036728862673044205\n",
      "2017-11-11 08:39:55: Loss at step 8875: 0.03667653724551201\n",
      "2017-11-11 08:39:55: Loss at step 8876: 0.03679969906806946\n",
      "2017-11-11 08:39:56: Loss at step 8877: 0.036673545837402344\n",
      "2017-11-11 08:39:56: Loss at step 8878: 0.03668368607759476\n",
      "2017-11-11 08:39:57: Loss at step 8879: 0.03664537891745567\n",
      "2017-11-11 08:39:57: Loss at step 8880: 0.03666751831769943\n",
      "2017-11-11 08:39:58: Loss at step 8881: 0.03669063746929169\n",
      "2017-11-11 08:39:58: Loss at step 8882: 0.036681462079286575\n",
      "2017-11-11 08:39:59: Loss at step 8883: 0.036699675023555756\n",
      "2017-11-11 08:39:59: Loss at step 8884: 0.03671039268374443\n",
      "2017-11-11 08:40:00: Loss at step 8885: 0.03671766817569733\n",
      "2017-11-11 08:40:00: Loss at step 8886: 0.03674133121967316\n",
      "2017-11-11 08:40:01: Loss at step 8887: 0.0367356576025486\n",
      "2017-11-11 08:40:01: Loss at step 8888: 0.03671250492334366\n",
      "2017-11-11 08:40:02: Loss at step 8889: 0.03671794757246971\n",
      "2017-11-11 08:40:02: Loss at step 8890: 0.036751639097929\n",
      "2017-11-11 08:40:03: Loss at step 8891: 0.03667345643043518\n",
      "2017-11-11 08:40:03: Loss at step 8892: 0.036696966737508774\n",
      "2017-11-11 08:40:04: Loss at step 8893: 0.036685314029455185\n",
      "2017-11-11 08:40:04: Loss at step 8894: 0.036721959710121155\n",
      "2017-11-11 08:40:05: Loss at step 8895: 0.0367230586707592\n",
      "2017-11-11 08:40:05: Loss at step 8896: 0.036772485822439194\n",
      "2017-11-11 08:40:06: Loss at step 8897: 0.036711134016513824\n",
      "2017-11-11 08:40:06: Loss at step 8898: 0.036674924194812775\n",
      "2017-11-11 08:40:07: Loss at step 8899: 0.03679806366562843\n",
      "2017-11-11 08:40:07: Loss at step 8900: 0.036697015166282654\n",
      "2017-11-11 08:40:08: Loss at step 8901: 0.036723725497722626\n",
      "2017-11-11 08:40:08: Loss at step 8902: 0.036743491888046265\n",
      "2017-11-11 08:40:09: Loss at step 8903: 0.03676968812942505\n",
      "2017-11-11 08:40:09: Loss at step 8904: 0.0366993173956871\n",
      "2017-11-11 08:40:10: Loss at step 8905: 0.036709364503622055\n",
      "2017-11-11 08:40:10: Loss at step 8906: 0.036788325756788254\n",
      "2017-11-11 08:40:11: Loss at step 8907: 0.036670878529548645\n",
      "2017-11-11 08:40:11: Loss at step 8908: 0.03675340488553047\n",
      "2017-11-11 08:40:12: Loss at step 8909: 0.036711834371089935\n",
      "2017-11-11 08:40:13: Loss at step 8910: 0.03670042008161545\n",
      "2017-11-11 08:40:13: Loss at step 8911: 0.036779046058654785\n",
      "2017-11-11 08:40:14: Loss at step 8912: 0.03673326596617699\n",
      "2017-11-11 08:40:14: Loss at step 8913: 0.03672850504517555\n",
      "2017-11-11 08:40:15: Loss at step 8914: 0.03667755797505379\n",
      "2017-11-11 08:40:15: Loss at step 8915: 0.03672747313976288\n",
      "2017-11-11 08:40:16: Loss at step 8916: 0.036754120141267776\n",
      "2017-11-11 08:40:16: Loss at step 8917: 0.036744438111782074\n",
      "2017-11-11 08:40:17: Loss at step 8918: 0.036721400916576385\n",
      "2017-11-11 08:40:17: Loss at step 8919: 0.036683015525341034\n",
      "2017-11-11 08:40:18: Loss at step 8920: 0.0366983637213707\n",
      "2017-11-11 08:40:18: Loss at step 8921: 0.03674931824207306\n",
      "2017-11-11 08:40:19: Loss at step 8922: 0.03664620220661163\n",
      "2017-11-11 08:40:19: Loss at step 8923: 0.03670433908700943\n",
      "2017-11-11 08:40:20: Loss at step 8924: 0.03664843365550041\n",
      "2017-11-11 08:40:20: Loss at step 8925: 0.036669302731752396\n",
      "2017-11-11 08:40:21: Loss at step 8926: 0.036650314927101135\n",
      "2017-11-11 08:40:21: Loss at step 8927: 0.036663588136434555\n",
      "2017-11-11 08:40:22: Loss at step 8928: 0.036725226789712906\n",
      "2017-11-11 08:40:22: Loss at step 8929: 0.036638788878917694\n",
      "2017-11-11 08:40:23: Loss at step 8930: 0.036661162972450256\n",
      "2017-11-11 08:40:23: Loss at step 8931: 0.03680207580327988\n",
      "2017-11-11 08:40:24: Loss at step 8932: 0.03669843077659607\n",
      "2017-11-11 08:40:24: Loss at step 8933: 0.036706238985061646\n",
      "2017-11-11 08:40:25: Loss at step 8934: 0.036712951958179474\n",
      "2017-11-11 08:40:25: Loss at step 8935: 0.03680117055773735\n",
      "2017-11-11 08:40:26: Loss at step 8936: 0.036757465451955795\n",
      "2017-11-11 08:40:26: Loss at step 8937: 0.03669852763414383\n",
      "2017-11-11 08:40:27: Loss at step 8938: 0.03673500195145607\n",
      "2017-11-11 08:40:27: Loss at step 8939: 0.036715902388095856\n",
      "2017-11-11 08:40:28: Loss at step 8940: 0.03675168752670288\n",
      "2017-11-11 08:40:28: Loss at step 8941: 0.03668143227696419\n",
      "2017-11-11 08:40:29: Loss at step 8942: 0.03681956231594086\n",
      "2017-11-11 08:40:29: Loss at step 8943: 0.036753006279468536\n",
      "2017-11-11 08:40:30: Loss at step 8944: 0.0367019958794117\n",
      "2017-11-11 08:40:30: Loss at step 8945: 0.03677282854914665\n",
      "2017-11-11 08:40:31: Loss at step 8946: 0.03669323772192001\n",
      "2017-11-11 08:40:31: Loss at step 8947: 0.03681943193078041\n",
      "2017-11-11 08:40:32: Loss at step 8948: 0.036701787263154984\n",
      "2017-11-11 08:40:32: Loss at step 8949: 0.03669712319970131\n",
      "2017-11-11 08:40:33: Loss at step 8950: 0.036748480051755905\n",
      "2017-11-11 08:40:34: Loss at step 8951: 0.03669856861233711\n",
      "2017-11-11 08:40:34: Loss at step 8952: 0.03670716658234596\n",
      "2017-11-11 08:40:35: Loss at step 8953: 0.03670335188508034\n",
      "2017-11-11 08:40:35: Loss at step 8954: 0.036721184849739075\n",
      "2017-11-11 08:40:36: Loss at step 8955: 0.03665241226553917\n",
      "2017-11-11 08:40:36: Loss at step 8956: 0.0367383249104023\n",
      "2017-11-11 08:40:37: Loss at step 8957: 0.03674823418259621\n",
      "2017-11-11 08:40:37: Loss at step 8958: 0.036754000931978226\n",
      "2017-11-11 08:40:38: Loss at step 8959: 0.036718375980854034\n",
      "2017-11-11 08:40:38: Loss at step 8960: 0.0367354080080986\n",
      "2017-11-11 08:40:39: Loss at step 8961: 0.036699265241622925\n",
      "2017-11-11 08:40:39: Loss at step 8962: 0.03669465705752373\n",
      "2017-11-11 08:40:40: Loss at step 8963: 0.03664863109588623\n",
      "2017-11-11 08:40:40: Loss at step 8964: 0.03673192113637924\n",
      "2017-11-11 08:40:41: Loss at step 8965: 0.03670531138777733\n",
      "2017-11-11 08:40:41: Loss at step 8966: 0.03667880967259407\n",
      "2017-11-11 08:40:42: Loss at step 8967: 0.03667491301894188\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-11-11 08:40:42: Loss at step 8968: 0.03669235482811928\n",
      "2017-11-11 08:40:43: Loss at step 8969: 0.03673074394464493\n",
      "2017-11-11 08:40:43: Loss at step 8970: 0.03668839856982231\n",
      "2017-11-11 08:40:44: Loss at step 8971: 0.0367707833647728\n",
      "2017-11-11 08:40:44: Loss at step 8972: 0.03672398254275322\n",
      "2017-11-11 08:40:45: Loss at step 8973: 0.0367676317691803\n",
      "2017-11-11 08:40:45: Loss at step 8974: 0.03675040975213051\n",
      "2017-11-11 08:40:46: Loss at step 8975: 0.036797624081373215\n",
      "2017-11-11 08:40:46: Loss at step 8976: 0.03673847019672394\n",
      "2017-11-11 08:40:47: Loss at step 8977: 0.03675273805856705\n",
      "2017-11-11 08:40:47: Loss at step 8978: 0.036670587956905365\n",
      "2017-11-11 08:40:48: Loss at step 8979: 0.03674101084470749\n",
      "2017-11-11 08:40:48: Loss at step 8980: 0.03676643595099449\n",
      "2017-11-11 08:40:49: Loss at step 8981: 0.03675631433725357\n",
      "2017-11-11 08:40:49: Loss at step 8982: 0.036773622035980225\n",
      "2017-11-11 08:40:50: Loss at step 8983: 0.03669775277376175\n",
      "2017-11-11 08:40:50: Loss at step 8984: 0.036698758602142334\n",
      "2017-11-11 08:40:51: Loss at step 8985: 0.03683571144938469\n",
      "2017-11-11 08:40:51: Loss at step 8986: 0.03676565736532211\n",
      "2017-11-11 08:40:52: Loss at step 8987: 0.03667595982551575\n",
      "2017-11-11 08:40:52: Loss at step 8988: 0.03672756999731064\n",
      "2017-11-11 08:40:53: Loss at step 8989: 0.036699023097753525\n",
      "2017-11-11 08:40:54: Loss at step 8990: 0.03669784590601921\n",
      "2017-11-11 08:40:54: Loss at step 8991: 0.03674721717834473\n",
      "2017-11-11 08:40:55: Loss at step 8992: 0.036658283323049545\n",
      "2017-11-11 08:40:55: Loss at step 8993: 0.03674166277050972\n",
      "2017-11-11 08:40:56: Loss at step 8994: 0.03668338060379028\n",
      "2017-11-11 08:40:56: Loss at step 8995: 0.03682897239923477\n",
      "2017-11-11 08:40:57: Loss at step 8996: 0.03672495484352112\n",
      "2017-11-11 08:40:57: Loss at step 8997: 0.03659646585583687\n",
      "2017-11-11 08:40:58: Loss at step 8998: 0.03670536354184151\n",
      "2017-11-11 08:40:58: Loss at step 8999: 0.03673577308654785\n",
      "2017-11-11 08:40:59: Loss at step 9000: 0.036780137568712234\n",
      "2017-11-11 08:40:59: Loss at step 9001: 0.03680756315588951\n",
      "2017-11-11 08:41:00: Loss at step 9002: 0.03679756075143814\n",
      "2017-11-11 08:41:00: Loss at step 9003: 0.036745622754096985\n",
      "2017-11-11 08:41:01: Loss at step 9004: 0.03678888827562332\n",
      "2017-11-11 08:41:01: Loss at step 9005: 0.0367223285138607\n",
      "2017-11-11 08:41:02: Loss at step 9006: 0.036738038063049316\n",
      "2017-11-11 08:41:02: Loss at step 9007: 0.036718156188726425\n",
      "2017-11-11 08:41:03: Loss at step 9008: 0.03664689511060715\n",
      "2017-11-11 08:41:03: Loss at step 9009: 0.03679990768432617\n",
      "2017-11-11 08:41:04: Loss at step 9010: 0.03676155209541321\n",
      "2017-11-11 08:41:04: Loss at step 9011: 0.0367816723883152\n",
      "2017-11-11 08:41:05: Loss at step 9012: 0.03670965135097504\n",
      "2017-11-11 08:41:05: Loss at step 9013: 0.03672810643911362\n",
      "2017-11-11 08:41:06: Loss at step 9014: 0.03674602508544922\n",
      "2017-11-11 08:41:06: Loss at step 9015: 0.03671059012413025\n",
      "2017-11-11 08:41:07: Loss at step 9016: 0.036769330501556396\n",
      "2017-11-11 08:41:07: Loss at step 9017: 0.03674351051449776\n",
      "2017-11-11 08:41:08: Loss at step 9018: 0.03671440854668617\n",
      "2017-11-11 08:41:08: Loss at step 9019: 0.03663504496216774\n",
      "2017-11-11 08:41:09: Loss at step 9020: 0.03671838343143463\n",
      "2017-11-11 08:41:09: Loss at step 9021: 0.03666522353887558\n",
      "2017-11-11 08:41:10: Loss at step 9022: 0.03669142350554466\n",
      "2017-11-11 08:41:10: Loss at step 9023: 0.03672056272625923\n",
      "2017-11-11 08:41:11: Loss at step 9024: 0.03666001185774803\n",
      "2017-11-11 08:41:11: Loss at step 9025: 0.03676106780767441\n",
      "2017-11-11 08:41:12: Loss at step 9026: 0.03672370687127113\n",
      "2017-11-11 08:41:12: Loss at step 9027: 0.03668120130896568\n",
      "2017-11-11 08:41:13: Loss at step 9028: 0.036691538989543915\n",
      "2017-11-11 08:41:14: Loss at step 9029: 0.036780402064323425\n",
      "2017-11-11 08:41:14: Loss at step 9030: 0.036710284650325775\n",
      "2017-11-11 08:41:15: Loss at step 9031: 0.036630284041166306\n",
      "2017-11-11 08:41:15: Loss at step 9032: 0.036686964333057404\n",
      "2017-11-11 08:41:16: Loss at step 9033: 0.03668500483036041\n",
      "2017-11-11 08:41:16: Loss at step 9034: 0.03668360412120819\n",
      "2017-11-11 08:41:17: Loss at step 9035: 0.03665652498602867\n",
      "2017-11-11 08:41:17: Loss at step 9036: 0.03671383485198021\n",
      "2017-11-11 08:41:18: Loss at step 9037: 0.03668922185897827\n",
      "2017-11-11 08:41:18: Loss at step 9038: 0.03671692684292793\n",
      "2017-11-11 08:41:19: Loss at step 9039: 0.036677420139312744\n",
      "2017-11-11 08:41:19: Loss at step 9040: 0.036673467606306076\n",
      "2017-11-11 08:41:20: Loss at step 9041: 0.03669601306319237\n",
      "2017-11-11 08:41:20: Loss at step 9042: 0.03674480319023132\n",
      "2017-11-11 08:41:21: Loss at step 9043: 0.03674022853374481\n",
      "2017-11-11 08:41:21: Loss at step 9044: 0.036714959889650345\n",
      "2017-11-11 08:41:22: Loss at step 9045: 0.03672075644135475\n",
      "2017-11-11 08:41:22: Loss at step 9046: 0.03665235638618469\n",
      "2017-11-11 08:41:23: Loss at step 9047: 0.03663759306073189\n",
      "2017-11-11 08:41:23: Loss at step 9048: 0.03681683912873268\n",
      "2017-11-11 08:41:24: Loss at step 9049: 0.03669585660099983\n",
      "2017-11-11 08:41:24: Loss at step 9050: 0.03671668842434883\n",
      "2017-11-11 08:41:25: Loss at step 9051: 0.03664141148328781\n",
      "2017-11-11 08:41:25: Loss at step 9052: 0.03674115985631943\n",
      "2017-11-11 08:41:26: Loss at step 9053: 0.03669692203402519\n",
      "2017-11-11 08:41:26: Loss at step 9054: 0.0367080383002758\n",
      "2017-11-11 08:41:27: Loss at step 9055: 0.036698780953884125\n",
      "2017-11-11 08:41:27: Loss at step 9056: 0.036691997200250626\n",
      "2017-11-11 08:41:28: Loss at step 9057: 0.036692265421152115\n",
      "2017-11-11 08:41:28: Loss at step 9058: 0.03670087456703186\n",
      "2017-11-11 08:41:29: Loss at step 9059: 0.03674221411347389\n",
      "2017-11-11 08:41:30: Loss at step 9060: 0.03676161542534828\n",
      "2017-11-11 08:41:30: Loss at step 9061: 0.03678518161177635\n",
      "2017-11-11 08:41:31: Loss at step 9062: 0.03672638535499573\n",
      "2017-11-11 08:41:31: Loss at step 9063: 0.03673147037625313\n",
      "2017-11-11 08:41:32: Loss at step 9064: 0.0366748608648777\n",
      "2017-11-11 08:41:32: Loss at step 9065: 0.03673636168241501\n",
      "2017-11-11 08:41:33: Loss at step 9066: 0.036689210683107376\n",
      "2017-11-11 08:41:33: Loss at step 9067: 0.03669186681509018\n",
      "2017-11-11 08:41:34: Loss at step 9068: 0.03675234317779541\n",
      "2017-11-11 08:41:34: Loss at step 9069: 0.036741096526384354\n",
      "2017-11-11 08:41:35: Loss at step 9070: 0.036784783005714417\n",
      "2017-11-11 08:41:35: Loss at step 9071: 0.03680582344532013\n",
      "2017-11-11 08:41:36: Loss at step 9072: 0.036716900765895844\n",
      "2017-11-11 08:41:36: Loss at step 9073: 0.03679998219013214\n",
      "2017-11-11 08:41:37: Loss at step 9074: 0.036776766180992126\n",
      "2017-11-11 08:41:37: Loss at step 9075: 0.036817796528339386\n",
      "2017-11-11 08:41:38: Loss at step 9076: 0.03686417639255524\n",
      "2017-11-11 08:41:38: Loss at step 9077: 0.03676098585128784\n",
      "2017-11-11 08:41:39: Loss at step 9078: 0.03679821267724037\n",
      "2017-11-11 08:41:39: Loss at step 9079: 0.03682776913046837\n",
      "2017-11-11 08:41:40: Loss at step 9080: 0.03672831505537033\n",
      "2017-11-11 08:41:40: Loss at step 9081: 0.036754053086042404\n",
      "2017-11-11 08:41:41: Loss at step 9082: 0.03678649291396141\n",
      "2017-11-11 08:41:41: Loss at step 9083: 0.03671399503946304\n",
      "2017-11-11 08:41:42: Loss at step 9084: 0.03676696866750717\n",
      "2017-11-11 08:41:42: Loss at step 9085: 0.03675480931997299\n",
      "2017-11-11 08:41:43: Loss at step 9086: 0.03671763092279434\n",
      "2017-11-11 08:41:43: Loss at step 9087: 0.03671557456254959\n",
      "2017-11-11 08:41:44: Loss at step 9088: 0.036651067435741425\n",
      "2017-11-11 08:41:44: Loss at step 9089: 0.036684032529592514\n",
      "2017-11-11 08:41:45: Loss at step 9090: 0.036743178963661194\n",
      "2017-11-11 08:41:45: Loss at step 9091: 0.0366850346326828\n",
      "2017-11-11 08:41:46: Loss at step 9092: 0.036746107041835785\n",
      "2017-11-11 08:41:46: Loss at step 9093: 0.03678322583436966\n",
      "2017-11-11 08:41:47: Loss at step 9094: 0.0367620624601841\n",
      "2017-11-11 08:41:47: Loss at step 9095: 0.03674449399113655\n",
      "2017-11-11 08:41:48: Loss at step 9096: 0.036729954183101654\n",
      "2017-11-11 08:41:49: Loss at step 9097: 0.036716967821121216\n",
      "2017-11-11 08:41:49: Loss at step 9098: 0.036741796880960464\n",
      "2017-11-11 08:41:50: Loss at step 9099: 0.03680264949798584\n",
      "2017-11-11 08:41:50: Loss at step 9100: 0.03676356375217438\n",
      "2017-11-11 08:41:51: Loss at step 9101: 0.036748286336660385\n",
      "2017-11-11 08:41:51: Loss at step 9102: 0.03684220463037491\n",
      "2017-11-11 08:41:52: Loss at step 9103: 0.03674265369772911\n",
      "2017-11-11 08:41:52: Loss at step 9104: 0.03675974905490875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-11-11 08:41:53: Loss at step 9105: 0.036796025931835175\n",
      "2017-11-11 08:41:53: Loss at step 9106: 0.03677298128604889\n",
      "2017-11-11 08:41:54: Loss at step 9107: 0.03676246479153633\n",
      "2017-11-11 08:41:54: Loss at step 9108: 0.03677172586321831\n",
      "2017-11-11 08:41:55: Loss at step 9109: 0.036700449883937836\n",
      "2017-11-11 08:41:55: Loss at step 9110: 0.03672441467642784\n",
      "2017-11-11 08:41:56: Loss at step 9111: 0.036787714809179306\n",
      "2017-11-11 08:41:56: Loss at step 9112: 0.03670695051550865\n",
      "2017-11-11 08:41:57: Loss at step 9113: 0.036751482635736465\n",
      "2017-11-11 08:41:57: Loss at step 9114: 0.03681028261780739\n",
      "2017-11-11 08:41:58: Loss at step 9115: 0.03683573752641678\n",
      "2017-11-11 08:41:58: Loss at step 9116: 0.03681596741080284\n",
      "2017-11-11 08:41:59: Loss at step 9117: 0.03670094534754753\n",
      "2017-11-11 08:41:59: Loss at step 9118: 0.03674550727009773\n",
      "2017-11-11 08:42:00: Loss at step 9119: 0.03668754920363426\n",
      "2017-11-11 08:42:00: Loss at step 9120: 0.03676090016961098\n",
      "2017-11-11 08:42:01: Loss at step 9121: 0.036673545837402344\n",
      "2017-11-11 08:42:01: Loss at step 9122: 0.03668631240725517\n",
      "2017-11-11 08:42:02: Loss at step 9123: 0.03666335344314575\n",
      "2017-11-11 08:42:02: Loss at step 9124: 0.03667077794671059\n",
      "2017-11-11 08:42:03: Loss at step 9125: 0.036757294088602066\n",
      "2017-11-11 08:42:03: Loss at step 9126: 0.036672819405794144\n",
      "2017-11-11 08:42:04: Loss at step 9127: 0.03661772608757019\n",
      "2017-11-11 08:42:04: Loss at step 9128: 0.036643266677856445\n",
      "2017-11-11 08:42:05: Loss at step 9129: 0.03670722618699074\n",
      "2017-11-11 08:42:05: Loss at step 9130: 0.03665925934910774\n",
      "2017-11-11 08:42:06: Loss at step 9131: 0.036691948771476746\n",
      "2017-11-11 08:42:06: Loss at step 9132: 0.036646075546741486\n",
      "2017-11-11 08:42:07: Loss at step 9133: 0.03665563464164734\n",
      "2017-11-11 08:42:07: Loss at step 9134: 0.036731086671352386\n",
      "2017-11-11 08:42:08: Loss at step 9135: 0.036708660423755646\n",
      "2017-11-11 08:42:08: Loss at step 9136: 0.03673282638192177\n",
      "2017-11-11 08:42:09: Loss at step 9137: 0.036717578768730164\n",
      "2017-11-11 08:42:09: Loss at step 9138: 0.03671189397573471\n",
      "2017-11-11 08:42:10: Loss at step 9139: 0.03673122823238373\n",
      "2017-11-11 08:42:10: Loss at step 9140: 0.03676762804389\n",
      "2017-11-11 08:42:11: Loss at step 9141: 0.03677809610962868\n",
      "2017-11-11 08:42:11: Loss at step 9142: 0.036668580025434494\n",
      "2017-11-11 08:42:12: Loss at step 9143: 0.03669624775648117\n",
      "2017-11-11 08:42:12: Loss at step 9144: 0.036724116653203964\n",
      "2017-11-11 08:42:13: Loss at step 9145: 0.0366838201880455\n",
      "2017-11-11 08:42:14: Loss at step 9146: 0.0366729199886322\n",
      "2017-11-11 08:42:14: Loss at step 9147: 0.03666551038622856\n",
      "2017-11-11 08:42:15: Loss at step 9148: 0.03669050335884094\n",
      "2017-11-11 08:42:15: Loss at step 9149: 0.03672328218817711\n",
      "2017-11-11 08:42:16: Loss at step 9150: 0.036689966917037964\n",
      "2017-11-11 08:42:16: Loss at step 9151: 0.03684065118432045\n",
      "2017-11-11 08:42:17: Loss at step 9152: 0.036743633449077606\n",
      "2017-11-11 08:42:17: Loss at step 9153: 0.03675225377082825\n",
      "2017-11-11 08:42:18: Loss at step 9154: 0.03671848028898239\n",
      "2017-11-11 08:42:18: Loss at step 9155: 0.03675257787108421\n",
      "2017-11-11 08:42:19: Loss at step 9156: 0.036777935922145844\n",
      "2017-11-11 08:42:19: Loss at step 9157: 0.03676581382751465\n",
      "2017-11-11 08:42:20: Loss at step 9158: 0.03677666187286377\n",
      "2017-11-11 08:42:20: Loss at step 9159: 0.03679284825921059\n",
      "2017-11-11 08:42:21: Loss at step 9160: 0.036693017929792404\n",
      "2017-11-11 08:42:21: Loss at step 9161: 0.036684755235910416\n",
      "2017-11-11 08:42:22: Loss at step 9162: 0.03674408420920372\n",
      "2017-11-11 08:42:22: Loss at step 9163: 0.03672255948185921\n",
      "2017-11-11 08:42:23: Loss at step 9164: 0.03669487312436104\n",
      "2017-11-11 08:42:23: Loss at step 9165: 0.03671026602387428\n",
      "2017-11-11 08:42:24: Loss at step 9166: 0.03678444027900696\n",
      "2017-11-11 08:42:24: Loss at step 9167: 0.036655671894550323\n",
      "2017-11-11 08:42:25: Loss at step 9168: 0.036690764129161835\n",
      "2017-11-11 08:42:25: Loss at step 9169: 0.03664349392056465\n",
      "2017-11-11 08:42:26: Loss at step 9170: 0.0366596020758152\n",
      "2017-11-11 08:42:26: Loss at step 9171: 0.03674161806702614\n",
      "2017-11-11 08:42:27: Loss at step 9172: 0.03670281544327736\n",
      "2017-11-11 08:42:27: Loss at step 9173: 0.03666367009282112\n",
      "2017-11-11 08:42:28: Loss at step 9174: 0.03668154776096344\n",
      "2017-11-11 08:42:28: Loss at step 9175: 0.03674944490194321\n",
      "2017-11-11 08:42:29: Loss at step 9176: 0.036729924380779266\n",
      "2017-11-11 08:42:29: Loss at step 9177: 0.03672018274664879\n",
      "2017-11-11 08:42:30: Loss at step 9178: 0.03668416664004326\n",
      "2017-11-11 08:42:30: Loss at step 9179: 0.03670608624815941\n",
      "2017-11-11 08:42:31: Loss at step 9180: 0.03668439760804176\n",
      "2017-11-11 08:42:31: Loss at step 9181: 0.03668225556612015\n",
      "2017-11-11 08:42:32: Loss at step 9182: 0.03667055815458298\n",
      "2017-11-11 08:42:32: Loss at step 9183: 0.03674609959125519\n",
      "2017-11-11 08:42:33: Loss at step 9184: 0.03674014285206795\n",
      "2017-11-11 08:42:33: Loss at step 9185: 0.036702610552310944\n",
      "2017-11-11 08:42:34: Loss at step 9186: 0.0367361344397068\n",
      "2017-11-11 08:42:34: Loss at step 9187: 0.03678349032998085\n",
      "2017-11-11 08:42:35: Loss at step 9188: 0.036749646067619324\n",
      "2017-11-11 08:42:35: Loss at step 9189: 0.03671986609697342\n",
      "2017-11-11 08:42:36: Loss at step 9190: 0.036813728511333466\n",
      "2017-11-11 08:42:36: Loss at step 9191: 0.036662932485342026\n",
      "2017-11-11 08:42:37: Loss at step 9192: 0.03683767467737198\n",
      "2017-11-11 08:42:37: Loss at step 9193: 0.0368720106780529\n",
      "2017-11-11 08:42:38: Loss at step 9194: 0.0366704948246479\n",
      "2017-11-11 08:42:38: Loss at step 9195: 0.0366915799677372\n",
      "2017-11-11 08:42:39: Loss at step 9196: 0.03677121177315712\n",
      "2017-11-11 08:42:39: Loss at step 9197: 0.03680744767189026\n",
      "2017-11-11 08:42:40: Loss at step 9198: 0.036847904324531555\n",
      "2017-11-11 08:42:40: Loss at step 9199: 0.03677533566951752\n",
      "2017-11-11 08:42:41: Loss at step 9200: 0.03658729046583176\n",
      "2017-11-11 08:42:41: Loss at step 9201: 0.03671782836318016\n",
      "2017-11-11 08:42:42: Loss at step 9202: 0.036640509963035583\n",
      "2017-11-11 08:42:42: Loss at step 9203: 0.03671331703662872\n",
      "2017-11-11 08:42:43: Loss at step 9204: 0.03668288141489029\n",
      "2017-11-11 08:42:43: Loss at step 9205: 0.03667318820953369\n",
      "2017-11-11 08:42:44: Loss at step 9206: 0.036711134016513824\n",
      "2017-11-11 08:42:44: Loss at step 9207: 0.03677259758114815\n",
      "2017-11-11 08:42:45: Loss at step 9208: 0.036727529019117355\n",
      "2017-11-11 08:42:45: Loss at step 9209: 0.03674128279089928\n",
      "2017-11-11 08:42:46: Loss at step 9210: 0.0367656946182251\n",
      "2017-11-11 08:42:46: Loss at step 9211: 0.03664382919669151\n",
      "2017-11-11 08:42:47: Loss at step 9212: 0.03673029690980911\n",
      "2017-11-11 08:42:47: Loss at step 9213: 0.03667424991726875\n",
      "2017-11-11 08:42:48: Loss at step 9214: 0.03671221435070038\n",
      "2017-11-11 08:42:48: Loss at step 9215: 0.036793798208236694\n",
      "2017-11-11 08:42:49: Loss at step 9216: 0.03669288754463196\n",
      "2017-11-11 08:42:49: Loss at step 9217: 0.036586467176675797\n",
      "2017-11-11 08:42:50: Loss at step 9218: 0.03665078803896904\n",
      "2017-11-11 08:42:50: Loss at step 9219: 0.03664849326014519\n",
      "2017-11-11 08:42:51: Loss at step 9220: 0.036714088171720505\n",
      "2017-11-11 08:42:51: Loss at step 9221: 0.03667780011892319\n",
      "2017-11-11 08:42:52: Loss at step 9222: 0.036671705543994904\n",
      "2017-11-11 08:42:52: Loss at step 9223: 0.0367341972887516\n",
      "2017-11-11 08:42:53: Loss at step 9224: 0.036649271845817566\n",
      "2017-11-11 08:42:53: Loss at step 9225: 0.03681257367134094\n",
      "2017-11-11 08:42:54: Loss at step 9226: 0.03681677207350731\n",
      "2017-11-11 08:42:54: Loss at step 9227: 0.036718133836984634\n",
      "2017-11-11 08:42:55: Loss at step 9228: 0.03671224042773247\n",
      "2017-11-11 08:42:55: Loss at step 9229: 0.036765795201063156\n",
      "2017-11-11 08:42:56: Loss at step 9230: 0.03668367490172386\n",
      "2017-11-11 08:42:56: Loss at step 9231: 0.036861106753349304\n",
      "2017-11-11 08:42:57: Loss at step 9232: 0.03675644099712372\n",
      "2017-11-11 08:42:57: Loss at step 9233: 0.03666702285408974\n",
      "2017-11-11 08:42:58: Loss at step 9234: 0.036648016422986984\n",
      "2017-11-11 08:42:58: Loss at step 9235: 0.036667097359895706\n",
      "2017-11-11 08:42:59: Loss at step 9236: 0.03669300302863121\n",
      "2017-11-11 08:42:59: Loss at step 9237: 0.036701880395412445\n",
      "2017-11-11 08:43:00: Loss at step 9238: 0.03668623045086861\n",
      "2017-11-11 08:43:00: Loss at step 9239: 0.03678315877914429\n",
      "2017-11-11 08:43:01: Loss at step 9240: 0.03668703883886337\n",
      "2017-11-11 08:43:01: Loss at step 9241: 0.0368802472949028\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-11-11 08:43:02: Loss at step 9242: 0.0368177555501461\n",
      "2017-11-11 08:43:02: Loss at step 9243: 0.036857720464468\n",
      "2017-11-11 08:43:03: Loss at step 9244: 0.03664369508624077\n",
      "2017-11-11 08:43:03: Loss at step 9245: 0.03659699484705925\n",
      "2017-11-11 08:43:04: Loss at step 9246: 0.03684882074594498\n",
      "2017-11-11 08:43:04: Loss at step 9247: 0.03668053075671196\n",
      "2017-11-11 08:43:05: Loss at step 9248: 0.03676558658480644\n",
      "2017-11-11 08:43:05: Loss at step 9249: 0.03682871535420418\n",
      "2017-11-11 08:43:06: Loss at step 9250: 0.036805152893066406\n",
      "2017-11-11 08:43:06: Loss at step 9251: 0.03673221915960312\n",
      "2017-11-11 08:43:06: Loss at step 9252: 0.0366397462785244\n",
      "2017-11-11 08:43:07: Loss at step 9253: 0.036598797887563705\n",
      "2017-11-11 08:43:07: Loss at step 9254: 0.03669608011841774\n",
      "2017-11-11 08:43:08: Loss at step 9255: 0.036610446870326996\n",
      "2017-11-11 08:43:08: Loss at step 9256: 0.03674149885773659\n",
      "2017-11-11 08:43:09: Loss at step 9257: 0.036772288382053375\n",
      "2017-11-11 08:43:09: Loss at step 9258: 0.03678909316658974\n",
      "2017-11-11 08:43:10: Loss at step 9259: 0.036646049469709396\n",
      "2017-11-11 08:43:10: Loss at step 9260: 0.036665696650743484\n",
      "2017-11-11 08:43:11: Loss at step 9261: 0.03674987331032753\n",
      "2017-11-11 08:43:11: Loss at step 9262: 0.036681536585092545\n",
      "2017-11-11 08:43:12: Loss at step 9263: 0.036679573357105255\n",
      "2017-11-11 08:43:12: Loss at step 9264: 0.03666218742728233\n",
      "2017-11-11 08:43:13: Loss at step 9265: 0.036589961498975754\n",
      "2017-11-11 08:43:13: Loss at step 9266: 0.03670923411846161\n",
      "2017-11-11 08:43:14: Loss at step 9267: 0.03678791597485542\n",
      "2017-11-11 08:43:14: Loss at step 9268: 0.03668293356895447\n",
      "2017-11-11 08:43:15: Loss at step 9269: 0.036726437509059906\n",
      "2017-11-11 08:43:15: Loss at step 9270: 0.03662944957613945\n",
      "2017-11-11 08:43:16: Loss at step 9271: 0.03667357191443443\n",
      "2017-11-11 08:43:16: Loss at step 9272: 0.03672852739691734\n",
      "2017-11-11 08:43:17: Loss at step 9273: 0.03679946810007095\n",
      "2017-11-11 08:43:17: Loss at step 9274: 0.03669425845146179\n",
      "2017-11-11 08:43:18: Loss at step 9275: 0.03673389181494713\n",
      "2017-11-11 08:43:18: Loss at step 9276: 0.036733053624629974\n",
      "2017-11-11 08:43:19: Loss at step 9277: 0.03669624775648117\n",
      "2017-11-11 08:43:19: Loss at step 9278: 0.036649543792009354\n",
      "2017-11-11 08:43:19: Loss at step 9279: 0.036649566143751144\n",
      "2017-11-11 08:43:20: Loss at step 9280: 0.03682856261730194\n",
      "2017-11-11 08:43:20: Loss at step 9281: 0.036696258932352066\n",
      "2017-11-11 08:43:21: Loss at step 9282: 0.03670943155884743\n",
      "2017-11-11 08:43:21: Loss at step 9283: 0.036728277802467346\n",
      "2017-11-11 08:43:22: Loss at step 9284: 0.03683926910161972\n",
      "2017-11-11 08:43:22: Loss at step 9285: 0.03674160689115524\n",
      "2017-11-11 08:43:23: Loss at step 9286: 0.03677899017930031\n",
      "2017-11-11 08:43:23: Loss at step 9287: 0.03669332340359688\n",
      "2017-11-11 08:43:24: Loss at step 9288: 0.0367773100733757\n",
      "2017-11-11 08:43:24: Loss at step 9289: 0.036845482885837555\n",
      "2017-11-11 08:43:25: Loss at step 9290: 0.036790575832128525\n",
      "2017-11-11 08:43:25: Loss at step 9291: 0.03675378859043121\n",
      "2017-11-11 08:43:26: Loss at step 9292: 0.0368509516119957\n",
      "2017-11-11 08:43:26: Loss at step 9293: 0.03678665682673454\n",
      "2017-11-11 08:43:27: Loss at step 9294: 0.03671887144446373\n",
      "2017-11-11 08:43:27: Loss at step 9295: 0.036681342869997025\n",
      "2017-11-11 08:43:28: Loss at step 9296: 0.03675806149840355\n",
      "2017-11-11 08:43:28: Loss at step 9297: 0.036621082574129105\n",
      "2017-11-11 08:43:29: Loss at step 9298: 0.03665446862578392\n",
      "2017-11-11 08:43:29: Loss at step 9299: 0.036768585443496704\n",
      "2017-11-11 08:43:30: Loss at step 9300: 0.03670040890574455\n",
      "2017-11-11 08:43:30: Loss at step 9301: 0.036747608333826065\n",
      "2017-11-11 08:43:31: Loss at step 9302: 0.03672364354133606\n",
      "2017-11-11 08:43:31: Loss at step 9303: 0.036645833402872086\n",
      "2017-11-11 08:43:32: Loss at step 9304: 0.036663781851530075\n",
      "2017-11-11 08:43:32: Loss at step 9305: 0.036586835980415344\n",
      "2017-11-11 08:43:32: Loss at step 9306: 0.03676837682723999\n",
      "2017-11-11 08:43:33: Loss at step 9307: 0.03673502802848816\n",
      "2017-11-11 08:43:33: Loss at step 9308: 0.036729950457811356\n",
      "2017-11-11 08:43:34: Loss at step 9309: 0.03670628368854523\n",
      "2017-11-11 08:43:34: Loss at step 9310: 0.036735571920871735\n",
      "2017-11-11 08:43:35: Loss at step 9311: 0.03667823225259781\n",
      "2017-11-11 08:43:35: Loss at step 9312: 0.036684662103652954\n",
      "2017-11-11 08:43:36: Loss at step 9313: 0.03671959787607193\n",
      "2017-11-11 08:43:36: Loss at step 9314: 0.0366763211786747\n",
      "2017-11-11 08:43:37: Loss at step 9315: 0.036657530814409256\n",
      "2017-11-11 08:43:37: Loss at step 9316: 0.03665367513895035\n",
      "2017-11-11 08:43:38: Loss at step 9317: 0.036718547344207764\n",
      "2017-11-11 08:43:38: Loss at step 9318: 0.03670850023627281\n",
      "2017-11-11 08:43:39: Loss at step 9319: 0.03669261932373047\n",
      "2017-11-11 08:43:39: Loss at step 9320: 0.03661702573299408\n",
      "2017-11-11 08:43:40: Loss at step 9321: 0.036803241819143295\n",
      "2017-11-11 08:43:40: Loss at step 9322: 0.03666399046778679\n",
      "2017-11-11 08:43:41: Loss at step 9323: 0.03664650395512581\n",
      "2017-11-11 08:43:41: Loss at step 9324: 0.0367003008723259\n",
      "2017-11-11 08:43:42: Loss at step 9325: 0.03678170591592789\n",
      "2017-11-11 08:43:42: Loss at step 9326: 0.0366966612637043\n",
      "2017-11-11 08:43:43: Loss at step 9327: 0.03676459193229675\n",
      "2017-11-11 08:43:43: Loss at step 9328: 0.036733586341142654\n",
      "2017-11-11 08:43:44: Loss at step 9329: 0.03669121488928795\n",
      "2017-11-11 08:43:44: Loss at step 9330: 0.03675329312682152\n",
      "2017-11-11 08:43:45: Loss at step 9331: 0.03669486567378044\n",
      "2017-11-11 08:43:45: Loss at step 9332: 0.03674517571926117\n",
      "2017-11-11 08:43:46: Loss at step 9333: 0.036667656153440475\n",
      "2017-11-11 08:43:46: Loss at step 9334: 0.03680877760052681\n",
      "2017-11-11 08:43:46: Loss at step 9335: 0.036800310015678406\n",
      "2017-11-11 08:43:47: Loss at step 9336: 0.036718614399433136\n",
      "2017-11-11 08:43:47: Loss at step 9337: 0.0367213599383831\n",
      "2017-11-11 08:43:48: Loss at step 9338: 0.036751776933670044\n",
      "2017-11-11 08:43:48: Loss at step 9339: 0.03670424968004227\n",
      "2017-11-11 08:43:49: Loss at step 9340: 0.03677316755056381\n",
      "2017-11-11 08:43:49: Loss at step 9341: 0.03665006533265114\n",
      "2017-11-11 08:43:50: Loss at step 9342: 0.03669106960296631\n",
      "2017-11-11 08:43:50: Loss at step 9343: 0.03667213022708893\n",
      "2017-11-11 08:43:51: Loss at step 9344: 0.03669685125350952\n",
      "2017-11-11 08:43:51: Loss at step 9345: 0.03662784397602081\n",
      "2017-11-11 08:43:52: Loss at step 9346: 0.03672062233090401\n",
      "2017-11-11 08:43:53: Loss at step 9347: 0.036658771336078644\n",
      "2017-11-11 08:43:53: Loss at step 9348: 0.036672260612249374\n",
      "2017-11-11 08:43:54: Loss at step 9349: 0.036670781672000885\n",
      "2017-11-11 08:43:54: Loss at step 9350: 0.03677036240696907\n",
      "2017-11-11 08:43:55: Loss at step 9351: 0.03668014705181122\n",
      "2017-11-11 08:43:55: Loss at step 9352: 0.036725979298353195\n",
      "2017-11-11 08:43:56: Loss at step 9353: 0.03674132004380226\n",
      "2017-11-11 08:43:56: Loss at step 9354: 0.03665180504322052\n",
      "2017-11-11 08:43:57: Loss at step 9355: 0.03677664324641228\n",
      "2017-11-11 08:43:57: Loss at step 9356: 0.0367448590695858\n",
      "2017-11-11 08:43:58: Loss at step 9357: 0.03675515577197075\n",
      "2017-11-11 08:43:58: Loss at step 9358: 0.03668588399887085\n",
      "2017-11-11 08:43:59: Loss at step 9359: 0.03666391596198082\n",
      "2017-11-11 08:43:59: Loss at step 9360: 0.036751605570316315\n",
      "2017-11-11 08:44:00: Loss at step 9361: 0.036712415516376495\n",
      "2017-11-11 08:44:00: Loss at step 9362: 0.036645855754613876\n",
      "2017-11-11 08:44:01: Loss at step 9363: 0.036743421107530594\n",
      "2017-11-11 08:44:01: Loss at step 9364: 0.03671128675341606\n",
      "2017-11-11 08:44:02: Loss at step 9365: 0.03674514591693878\n",
      "2017-11-11 08:44:02: Loss at step 9366: 0.036763448268175125\n",
      "2017-11-11 08:44:03: Loss at step 9367: 0.036825377494096756\n",
      "2017-11-11 08:44:03: Loss at step 9368: 0.03673507645726204\n",
      "2017-11-11 08:44:04: Loss at step 9369: 0.036705438047647476\n",
      "2017-11-11 08:44:04: Loss at step 9370: 0.03663413226604462\n",
      "2017-11-11 08:44:05: Loss at step 9371: 0.036738354712724686\n",
      "2017-11-11 08:44:05: Loss at step 9372: 0.036603040993213654\n",
      "2017-11-11 08:44:06: Loss at step 9373: 0.03662984073162079\n",
      "2017-11-11 08:44:06: Loss at step 9374: 0.036751266568899155\n",
      "2017-11-11 08:44:07: Loss at step 9375: 0.03680059686303139\n",
      "2017-11-11 08:44:07: Loss at step 9376: 0.036717962473630905\n",
      "2017-11-11 08:44:08: Loss at step 9377: 0.03672587126493454\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-11-11 08:44:08: Loss at step 9378: 0.03666071221232414\n",
      "2017-11-11 08:44:09: Loss at step 9379: 0.03665674850344658\n",
      "2017-11-11 08:44:09: Loss at step 9380: 0.03659289702773094\n",
      "2017-11-11 08:44:10: Loss at step 9381: 0.036778274923563004\n",
      "2017-11-11 08:44:10: Loss at step 9382: 0.03665296733379364\n",
      "2017-11-11 08:44:11: Loss at step 9383: 0.03676224499940872\n",
      "2017-11-11 08:44:11: Loss at step 9384: 0.036749694496393204\n",
      "2017-11-11 08:44:12: Loss at step 9385: 0.03677020221948624\n",
      "2017-11-11 08:44:12: Loss at step 9386: 0.03672400489449501\n",
      "2017-11-11 08:44:12: Loss at step 9387: 0.0366288423538208\n",
      "2017-11-11 08:44:13: Loss at step 9388: 0.03665906935930252\n",
      "2017-11-11 08:44:13: Loss at step 9389: 0.036664802581071854\n",
      "2017-11-11 08:44:14: Loss at step 9390: 0.036642301827669144\n",
      "2017-11-11 08:44:15: Loss at step 9391: 0.03673902153968811\n",
      "2017-11-11 08:44:15: Loss at step 9392: 0.03672318905591965\n",
      "2017-11-11 08:44:16: Loss at step 9393: 0.036722175776958466\n",
      "2017-11-11 08:44:17: Loss at step 9394: 0.03664365038275719\n",
      "2017-11-11 08:44:17: Loss at step 9395: 0.036713726818561554\n",
      "2017-11-11 08:44:17: Loss at step 9396: 0.036700379103422165\n",
      "2017-11-11 08:44:18: Loss at step 9397: 0.03674129769206047\n",
      "2017-11-11 08:44:18: Loss at step 9398: 0.036742329597473145\n",
      "2017-11-11 08:44:19: Loss at step 9399: 0.0366574265062809\n",
      "2017-11-11 08:44:20: Loss at step 9400: 0.036655426025390625\n",
      "2017-11-11 08:44:20: Loss at step 9401: 0.03669619932770729\n",
      "2017-11-11 08:44:21: Loss at step 9402: 0.036730825901031494\n",
      "2017-11-11 08:44:21: Loss at step 9403: 0.03685057535767555\n",
      "2017-11-11 08:44:22: Loss at step 9404: 0.03661040961742401\n",
      "2017-11-11 08:44:22: Loss at step 9405: 0.036689940840005875\n",
      "2017-11-11 08:44:23: Loss at step 9406: 0.036676619201898575\n",
      "2017-11-11 08:44:23: Loss at step 9407: 0.036683790385723114\n",
      "2017-11-11 08:44:24: Loss at step 9408: 0.03668680787086487\n",
      "2017-11-11 08:44:24: Loss at step 9409: 0.03664626553654671\n",
      "2017-11-11 08:44:25: Loss at step 9410: 0.03675797954201698\n",
      "2017-11-11 08:44:26: Loss at step 9411: 0.03667423129081726\n",
      "2017-11-11 08:44:26: Loss at step 9412: 0.03672514483332634\n",
      "2017-11-11 08:44:27: Loss at step 9413: 0.036723535507917404\n",
      "2017-11-11 08:44:27: Loss at step 9414: 0.036741890013217926\n",
      "2017-11-11 08:44:28: Loss at step 9415: 0.03675628453493118\n",
      "2017-11-11 08:44:28: Loss at step 9416: 0.03675389289855957\n",
      "2017-11-11 08:44:29: Loss at step 9417: 0.03666193410754204\n",
      "2017-11-11 08:44:29: Loss at step 9418: 0.03666970133781433\n",
      "2017-11-11 08:44:30: Loss at step 9419: 0.036632951349020004\n",
      "2017-11-11 08:44:30: Loss at step 9420: 0.03669029474258423\n",
      "2017-11-11 08:44:31: Loss at step 9421: 0.03670476749539375\n",
      "2017-11-11 08:44:31: Loss at step 9422: 0.03667091205716133\n",
      "2017-11-11 08:44:32: Loss at step 9423: 0.03677351772785187\n",
      "2017-11-11 08:44:32: Loss at step 9424: 0.03676992654800415\n",
      "2017-11-11 08:44:33: Loss at step 9425: 0.036706261336803436\n",
      "2017-11-11 08:44:33: Loss at step 9426: 0.036823686212301254\n",
      "2017-11-11 08:44:34: Loss at step 9427: 0.036755409091711044\n",
      "2017-11-11 08:44:34: Loss at step 9428: 0.03675909340381622\n",
      "2017-11-11 08:44:35: Loss at step 9429: 0.03671105578541756\n",
      "2017-11-11 08:44:35: Loss at step 9430: 0.03673046827316284\n",
      "2017-11-11 08:44:36: Loss at step 9431: 0.03673982992768288\n",
      "2017-11-11 08:44:37: Loss at step 9432: 0.03657238185405731\n",
      "2017-11-11 08:44:37: Loss at step 9433: 0.036699872463941574\n",
      "2017-11-11 08:44:38: Loss at step 9434: 0.03669184446334839\n",
      "2017-11-11 08:44:38: Loss at step 9435: 0.036774005740880966\n",
      "2017-11-11 08:44:39: Loss at step 9436: 0.03670135512948036\n",
      "2017-11-11 08:44:39: Loss at step 9437: 0.036634739488363266\n",
      "2017-11-11 08:44:39: Loss at step 9438: 0.036825694143772125\n",
      "2017-11-11 08:44:40: Loss at step 9439: 0.036753468215465546\n",
      "2017-11-11 08:44:40: Loss at step 9440: 0.03677245229482651\n",
      "2017-11-11 08:44:41: Loss at step 9441: 0.036750126630067825\n",
      "2017-11-11 08:44:42: Loss at step 9442: 0.03672560304403305\n",
      "2017-11-11 08:44:42: Loss at step 9443: 0.03678807243704796\n",
      "2017-11-11 08:44:43: Loss at step 9444: 0.03679591417312622\n",
      "2017-11-11 08:44:43: Loss at step 9445: 0.03666301444172859\n",
      "2017-11-11 08:44:44: Loss at step 9446: 0.036622997373342514\n",
      "2017-11-11 08:44:44: Loss at step 9447: 0.03675858676433563\n",
      "2017-11-11 08:44:45: Loss at step 9448: 0.03663228079676628\n",
      "2017-11-11 08:44:45: Loss at step 9449: 0.0367363803088665\n",
      "2017-11-11 08:44:46: Loss at step 9450: 0.036708325147628784\n",
      "2017-11-11 08:44:46: Loss at step 9451: 0.036754533648490906\n",
      "2017-11-11 08:44:47: Loss at step 9452: 0.03668421506881714\n",
      "2017-11-11 08:44:47: Loss at step 9453: 0.036663416773080826\n",
      "2017-11-11 08:44:48: Loss at step 9454: 0.036713384091854095\n",
      "2017-11-11 08:44:48: Loss at step 9455: 0.036776408553123474\n",
      "2017-11-11 08:44:49: Loss at step 9456: 0.03668484836816788\n",
      "2017-11-11 08:44:49: Loss at step 9457: 0.03670070320367813\n",
      "2017-11-11 08:44:50: Loss at step 9458: 0.036733951419591904\n",
      "2017-11-11 08:44:50: Loss at step 9459: 0.03681043162941933\n",
      "2017-11-11 08:44:51: Loss at step 9460: 0.03678145632147789\n",
      "2017-11-11 08:44:51: Loss at step 9461: 0.03681855648756027\n",
      "2017-11-11 08:44:52: Loss at step 9462: 0.03671799227595329\n",
      "2017-11-11 08:44:53: Loss at step 9463: 0.03670286759734154\n",
      "2017-11-11 08:44:53: Loss at step 9464: 0.03661663085222244\n",
      "2017-11-11 08:44:54: Loss at step 9465: 0.0367087759077549\n",
      "2017-11-11 08:44:54: Loss at step 9466: 0.03676993399858475\n",
      "2017-11-11 08:44:55: Loss at step 9467: 0.03677035868167877\n",
      "2017-11-11 08:44:55: Loss at step 9468: 0.036795131862163544\n",
      "2017-11-11 08:44:56: Loss at step 9469: 0.0368337444961071\n",
      "2017-11-11 08:44:56: Loss at step 9470: 0.03672410920262337\n",
      "2017-11-11 08:44:57: Loss at step 9471: 0.0366818830370903\n",
      "2017-11-11 08:44:57: Loss at step 9472: 0.03663642704486847\n",
      "2017-11-11 08:44:58: Loss at step 9473: 0.03673919290304184\n",
      "2017-11-11 08:44:58: Loss at step 9474: 0.03674989938735962\n",
      "2017-11-11 08:44:59: Loss at step 9475: 0.0367811918258667\n",
      "2017-11-11 08:44:59: Loss at step 9476: 0.036642834544181824\n",
      "2017-11-11 08:45:00: Loss at step 9477: 0.036700788885354996\n",
      "2017-11-11 08:45:00: Loss at step 9478: 0.03665284812450409\n",
      "2017-11-11 08:45:01: Loss at step 9479: 0.036636341363191605\n",
      "2017-11-11 08:45:01: Loss at step 9480: 0.03674350678920746\n",
      "2017-11-11 08:45:02: Loss at step 9481: 0.03675800934433937\n",
      "2017-11-11 08:45:02: Loss at step 9482: 0.03668767213821411\n",
      "2017-11-11 08:45:03: Loss at step 9483: 0.03684644028544426\n",
      "2017-11-11 08:45:03: Loss at step 9484: 0.036767102777957916\n",
      "2017-11-11 08:45:04: Loss at step 9485: 0.036629218608140945\n",
      "2017-11-11 08:45:04: Loss at step 9486: 0.036566417664289474\n",
      "2017-11-11 08:45:05: Loss at step 9487: 0.036722443997859955\n",
      "2017-11-11 08:45:05: Loss at step 9488: 0.036594029515981674\n",
      "2017-11-11 08:45:06: Loss at step 9489: 0.03689581900835037\n",
      "2017-11-11 08:45:06: Loss at step 9490: 0.03674936667084694\n",
      "2017-11-11 08:45:07: Loss at step 9491: 0.036709774285554886\n",
      "2017-11-11 08:45:07: Loss at step 9492: 0.036616645753383636\n",
      "2017-11-11 08:45:08: Loss at step 9493: 0.03669600188732147\n",
      "2017-11-11 08:45:08: Loss at step 9494: 0.03661509230732918\n",
      "2017-11-11 08:45:09: Loss at step 9495: 0.036628276109695435\n",
      "2017-11-11 08:45:09: Loss at step 9496: 0.03668911010026932\n",
      "2017-11-11 08:45:10: Loss at step 9497: 0.03674864396452904\n",
      "2017-11-11 08:45:11: Loss at step 9498: 0.03675742819905281\n",
      "2017-11-11 08:45:11: Loss at step 9499: 0.0366666279733181\n",
      "2017-11-11 08:45:12: Loss at step 9500: 0.03661929443478584\n",
      "2017-11-11 08:45:12: Loss at step 9501: 0.03665613383054733\n",
      "2017-11-11 08:45:13: Loss at step 9502: 0.03670133650302887\n",
      "2017-11-11 08:45:13: Loss at step 9503: 0.036769188940525055\n",
      "2017-11-11 08:45:14: Loss at step 9504: 0.03675585240125656\n",
      "2017-11-11 08:45:14: Loss at step 9505: 0.03681746870279312\n",
      "2017-11-11 08:45:15: Loss at step 9506: 0.03665977343916893\n",
      "2017-11-11 08:45:15: Loss at step 9507: 0.03666407987475395\n",
      "2017-11-11 08:45:16: Loss at step 9508: 0.03672662377357483\n",
      "2017-11-11 08:45:16: Loss at step 9509: 0.03666919469833374\n",
      "2017-11-11 08:45:17: Loss at step 9510: 0.036745332181453705\n",
      "2017-11-11 08:45:17: Loss at step 9511: 0.036740679293870926\n",
      "2017-11-11 08:45:18: Loss at step 9512: 0.03671909123659134\n",
      "2017-11-11 08:45:18: Loss at step 9513: 0.036736540496349335\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-11-11 08:45:19: Loss at step 9514: 0.036742113530635834\n",
      "2017-11-11 08:45:19: Loss at step 9515: 0.036646854132413864\n",
      "2017-11-11 08:45:20: Loss at step 9516: 0.03672979399561882\n",
      "2017-11-11 08:45:20: Loss at step 9517: 0.036715440452098846\n",
      "2017-11-11 08:45:21: Loss at step 9518: 0.03671601787209511\n",
      "2017-11-11 08:45:21: Loss at step 9519: 0.03675935044884682\n",
      "2017-11-11 08:45:22: Loss at step 9520: 0.03672705590724945\n",
      "2017-11-11 08:45:22: Loss at step 9521: 0.03665910288691521\n",
      "2017-11-11 08:45:23: Loss at step 9522: 0.03670187294483185\n",
      "2017-11-11 08:45:23: Loss at step 9523: 0.03675390034914017\n",
      "2017-11-11 08:45:24: Loss at step 9524: 0.036757808178663254\n",
      "2017-11-11 08:45:24: Loss at step 9525: 0.03674820065498352\n",
      "2017-11-11 08:45:25: Loss at step 9526: 0.03675178810954094\n",
      "2017-11-11 08:45:25: Loss at step 9527: 0.036686576902866364\n",
      "2017-11-11 08:45:26: Loss at step 9528: 0.036741502583026886\n",
      "2017-11-11 08:45:26: Loss at step 9529: 0.03664395585656166\n",
      "2017-11-11 08:45:27: Loss at step 9530: 0.03665737807750702\n",
      "2017-11-11 08:45:27: Loss at step 9531: 0.03670211881399155\n",
      "2017-11-11 08:45:28: Loss at step 9532: 0.03679019957780838\n",
      "2017-11-11 08:45:28: Loss at step 9533: 0.0367448553442955\n",
      "2017-11-11 08:45:29: Loss at step 9534: 0.03681431710720062\n",
      "2017-11-11 08:45:29: Loss at step 9535: 0.0368322879076004\n",
      "2017-11-11 08:45:30: Loss at step 9536: 0.03681909292936325\n",
      "2017-11-11 08:45:30: Loss at step 9537: 0.03677254170179367\n",
      "2017-11-11 08:45:31: Loss at step 9538: 0.03676217049360275\n",
      "2017-11-11 08:45:31: Loss at step 9539: 0.036791883409023285\n",
      "2017-11-11 08:45:32: Loss at step 9540: 0.03675227612257004\n",
      "2017-11-11 08:45:32: Loss at step 9541: 0.03681090101599693\n",
      "2017-11-11 08:45:33: Loss at step 9542: 0.03673678636550903\n",
      "2017-11-11 08:45:33: Loss at step 9543: 0.0367196723818779\n",
      "2017-11-11 08:45:34: Loss at step 9544: 0.03670268878340721\n",
      "2017-11-11 08:45:34: Loss at step 9545: 0.03674706444144249\n",
      "2017-11-11 08:45:35: Loss at step 9546: 0.036604512482881546\n",
      "2017-11-11 08:45:35: Loss at step 9547: 0.03674476593732834\n",
      "2017-11-11 08:45:36: Loss at step 9548: 0.03672811761498451\n",
      "2017-11-11 08:45:37: Loss at step 9549: 0.036746796220541\n",
      "2017-11-11 08:45:37: Loss at step 9550: 0.036785926669836044\n",
      "2017-11-11 08:45:38: Loss at step 9551: 0.03679720684885979\n",
      "2017-11-11 08:45:38: Loss at step 9552: 0.0368015319108963\n",
      "2017-11-11 08:45:39: Loss at step 9553: 0.03675031661987305\n",
      "2017-11-11 08:45:39: Loss at step 9554: 0.03678189218044281\n",
      "2017-11-11 08:45:40: Loss at step 9555: 0.03670943155884743\n",
      "2017-11-11 08:45:40: Loss at step 9556: 0.036714471876621246\n",
      "2017-11-11 08:45:40: Loss at step 9557: 0.03671769052743912\n",
      "2017-11-11 08:45:41: Loss at step 9558: 0.03666551038622856\n",
      "2017-11-11 08:45:41: Loss at step 9559: 0.03673925623297691\n",
      "2017-11-11 08:45:42: Loss at step 9560: 0.03670935332775116\n",
      "2017-11-11 08:45:43: Loss at step 9561: 0.03671202436089516\n",
      "2017-11-11 08:45:43: Loss at step 9562: 0.03675992414355278\n",
      "2017-11-11 08:45:44: Loss at step 9563: 0.036798760294914246\n",
      "2017-11-11 08:45:44: Loss at step 9564: 0.03670620545744896\n",
      "2017-11-11 08:45:45: Loss at step 9565: 0.03675494343042374\n",
      "2017-11-11 08:45:45: Loss at step 9566: 0.036558836698532104\n",
      "2017-11-11 08:45:46: Loss at step 9567: 0.036654531955718994\n",
      "2017-11-11 08:45:46: Loss at step 9568: 0.036661215126514435\n",
      "2017-11-11 08:45:47: Loss at step 9569: 0.036645833402872086\n",
      "2017-11-11 08:45:47: Loss at step 9570: 0.03665754944086075\n",
      "2017-11-11 08:45:48: Loss at step 9571: 0.03666277974843979\n",
      "2017-11-11 08:45:48: Loss at step 9572: 0.03672824800014496\n",
      "2017-11-11 08:45:49: Loss at step 9573: 0.036687977612018585\n",
      "2017-11-11 08:45:49: Loss at step 9574: 0.0366847962141037\n",
      "2017-11-11 08:45:50: Loss at step 9575: 0.03667983412742615\n",
      "2017-11-11 08:45:50: Loss at step 9576: 0.036744244396686554\n",
      "2017-11-11 08:45:51: Loss at step 9577: 0.03669383376836777\n",
      "2017-11-11 08:45:51: Loss at step 9578: 0.036661382764577866\n",
      "2017-11-11 08:45:52: Loss at step 9579: 0.03671327233314514\n",
      "2017-11-11 08:45:52: Loss at step 9580: 0.03667603060603142\n",
      "2017-11-11 08:45:53: Loss at step 9581: 0.03666326031088829\n",
      "2017-11-11 08:45:53: Loss at step 9582: 0.03661227598786354\n",
      "2017-11-11 08:45:54: Loss at step 9583: 0.03662426024675369\n",
      "2017-11-11 08:45:54: Loss at step 9584: 0.036588702350854874\n",
      "2017-11-11 08:45:55: Loss at step 9585: 0.036679912358522415\n",
      "2017-11-11 08:45:55: Loss at step 9586: 0.036750972270965576\n",
      "2017-11-11 08:45:56: Loss at step 9587: 0.03674573451280594\n",
      "2017-11-11 08:45:56: Loss at step 9588: 0.03664745017886162\n",
      "2017-11-11 08:45:57: Loss at step 9589: 0.036804184317588806\n",
      "2017-11-11 08:45:57: Loss at step 9590: 0.03668088838458061\n",
      "2017-11-11 08:45:58: Loss at step 9591: 0.036734454333782196\n",
      "2017-11-11 08:45:58: Loss at step 9592: 0.03659488260746002\n",
      "2017-11-11 08:45:59: Loss at step 9593: 0.036688294261693954\n",
      "2017-11-11 08:45:59: Loss at step 9594: 0.03673284500837326\n",
      "2017-11-11 08:46:00: Loss at step 9595: 0.03684303164482117\n",
      "2017-11-11 08:46:00: Loss at step 9596: 0.0366891548037529\n",
      "2017-11-11 08:46:01: Loss at step 9597: 0.0366995744407177\n",
      "2017-11-11 08:46:01: Loss at step 9598: 0.036737922579050064\n",
      "2017-11-11 08:46:02: Loss at step 9599: 0.03664907068014145\n",
      "2017-11-11 08:46:02: Loss at step 9600: 0.036617711186409\n",
      "2017-11-11 08:46:03: Loss at step 9601: 0.03658132255077362\n",
      "2017-11-11 08:46:03: Loss at step 9602: 0.03669977933168411\n",
      "2017-11-11 08:46:04: Loss at step 9603: 0.036607325077056885\n",
      "2017-11-11 08:46:04: Loss at step 9604: 0.036625176668167114\n",
      "2017-11-11 08:46:05: Loss at step 9605: 0.03665189817547798\n",
      "2017-11-11 08:46:05: Loss at step 9606: 0.03665802255272865\n",
      "2017-11-11 08:46:06: Loss at step 9607: 0.03676879033446312\n",
      "2017-11-11 08:46:06: Loss at step 9608: 0.036650270223617554\n",
      "2017-11-11 08:46:07: Loss at step 9609: 0.036725349724292755\n",
      "2017-11-11 08:46:07: Loss at step 9610: 0.03667694702744484\n",
      "2017-11-11 08:46:08: Loss at step 9611: 0.03671161085367203\n",
      "2017-11-11 08:46:08: Loss at step 9612: 0.036656685173511505\n",
      "2017-11-11 08:46:09: Loss at step 9613: 0.03666432946920395\n",
      "2017-11-11 08:46:09: Loss at step 9614: 0.03676392138004303\n",
      "2017-11-11 08:46:10: Loss at step 9615: 0.03667733073234558\n",
      "2017-11-11 08:46:11: Loss at step 9616: 0.03666669502854347\n",
      "2017-11-11 08:46:11: Loss at step 9617: 0.036708343774080276\n",
      "2017-11-11 08:46:12: Loss at step 9618: 0.036674872040748596\n",
      "2017-11-11 08:46:12: Loss at step 9619: 0.036719948053359985\n",
      "2017-11-11 08:46:13: Loss at step 9620: 0.03670002892613411\n",
      "2017-11-11 08:46:13: Loss at step 9621: 0.036577269434928894\n",
      "2017-11-11 08:46:13: Loss at step 9622: 0.036769427359104156\n",
      "2017-11-11 08:46:14: Loss at step 9623: 0.036856334656476974\n",
      "2017-11-11 08:46:14: Loss at step 9624: 0.036597710102796555\n",
      "2017-11-11 08:46:15: Loss at step 9625: 0.036635130643844604\n",
      "2017-11-11 08:46:15: Loss at step 9626: 0.036778852343559265\n",
      "2017-11-11 08:46:16: Loss at step 9627: 0.03675679489970207\n",
      "2017-11-11 08:46:17: Loss at step 9628: 0.03675226494669914\n",
      "2017-11-11 08:46:17: Loss at step 9629: 0.03674967959523201\n",
      "2017-11-11 08:46:18: Loss at step 9630: 0.0367397665977478\n",
      "2017-11-11 08:46:18: Loss at step 9631: 0.03671865537762642\n",
      "2017-11-11 08:46:18: Loss at step 9632: 0.03675052151083946\n",
      "2017-11-11 08:46:19: Loss at step 9633: 0.03671863302588463\n",
      "2017-11-11 08:46:19: Loss at step 9634: 0.036642976105213165\n",
      "2017-11-11 08:46:20: Loss at step 9635: 0.03667532280087471\n",
      "2017-11-11 08:46:20: Loss at step 9636: 0.03667648509144783\n",
      "2017-11-11 08:46:21: Loss at step 9637: 0.036608412861824036\n",
      "2017-11-11 08:46:22: Loss at step 9638: 0.03672020137310028\n",
      "2017-11-11 08:46:22: Loss at step 9639: 0.03669296205043793\n",
      "2017-11-11 08:46:23: Loss at step 9640: 0.03666815534234047\n",
      "2017-11-11 08:46:23: Loss at step 9641: 0.03668387979269028\n",
      "2017-11-11 08:46:24: Loss at step 9642: 0.03667241334915161\n",
      "2017-11-11 08:46:24: Loss at step 9643: 0.03658255189657211\n",
      "2017-11-11 08:46:25: Loss at step 9644: 0.03662652149796486\n",
      "2017-11-11 08:46:25: Loss at step 9645: 0.03670543059706688\n",
      "2017-11-11 08:46:26: Loss at step 9646: 0.03672035411000252\n",
      "2017-11-11 08:46:26: Loss at step 9647: 0.036761343479156494\n",
      "2017-11-11 08:46:27: Loss at step 9648: 0.03668058291077614\n",
      "2017-11-11 08:46:27: Loss at step 9649: 0.036706071346998215\n",
      "2017-11-11 08:46:28: Loss at step 9650: 0.036796461790800095\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-11-11 08:46:28: Loss at step 9651: 0.03674515336751938\n",
      "2017-11-11 08:46:28: Loss at step 9652: 0.03674190491437912\n",
      "2017-11-11 08:46:29: Loss at step 9653: 0.036667291074991226\n",
      "2017-11-11 08:46:30: Loss at step 9654: 0.036752380430698395\n",
      "2017-11-11 08:46:30: Loss at step 9655: 0.036631837487220764\n",
      "2017-11-11 08:46:31: Loss at step 9656: 0.03655282407999039\n",
      "2017-11-11 08:46:31: Loss at step 9657: 0.03665540739893913\n",
      "2017-11-11 08:46:32: Loss at step 9658: 0.03671044483780861\n",
      "2017-11-11 08:46:32: Loss at step 9659: 0.03669571503996849\n",
      "2017-11-11 08:46:33: Loss at step 9660: 0.03678267076611519\n",
      "2017-11-11 08:46:33: Loss at step 9661: 0.03671453148126602\n",
      "2017-11-11 08:46:34: Loss at step 9662: 0.03674957528710365\n",
      "2017-11-11 08:46:34: Loss at step 9663: 0.036727506667375565\n",
      "2017-11-11 08:46:34: Loss at step 9664: 0.036727145314216614\n",
      "2017-11-11 08:46:35: Loss at step 9665: 0.03665906935930252\n",
      "2017-11-11 08:46:36: Loss at step 9666: 0.03668366000056267\n",
      "2017-11-11 08:46:36: Loss at step 9667: 0.03678157180547714\n",
      "2017-11-11 08:46:37: Loss at step 9668: 0.03677303344011307\n",
      "2017-11-11 08:46:37: Loss at step 9669: 0.03668815642595291\n",
      "2017-11-11 08:46:38: Loss at step 9670: 0.036684904247522354\n",
      "2017-11-11 08:46:38: Loss at step 9671: 0.036674391478300095\n",
      "2017-11-11 08:46:39: Loss at step 9672: 0.0366961807012558\n",
      "2017-11-11 08:46:39: Loss at step 9673: 0.03672002628445625\n",
      "2017-11-11 08:46:39: Loss at step 9674: 0.03674729913473129\n",
      "2017-11-11 08:46:40: Loss at step 9675: 0.03667038679122925\n",
      "2017-11-11 08:46:40: Loss at step 9676: 0.03676745295524597\n",
      "2017-11-11 08:46:41: Loss at step 9677: 0.03682473301887512\n",
      "2017-11-11 08:46:41: Loss at step 9678: 0.03669058904051781\n",
      "2017-11-11 08:46:42: Loss at step 9679: 0.03666038438677788\n",
      "2017-11-11 08:46:42: Loss at step 9680: 0.03671060875058174\n",
      "2017-11-11 08:46:43: Loss at step 9681: 0.03668409585952759\n",
      "2017-11-11 08:46:44: Loss at step 9682: 0.03670613095164299\n",
      "2017-11-11 08:46:44: Loss at step 9683: 0.03675283491611481\n",
      "2017-11-11 08:46:44: Loss at step 9684: 0.0366750992834568\n",
      "2017-11-11 08:46:45: Loss at step 9685: 0.036677341908216476\n",
      "2017-11-11 08:46:45: Loss at step 9686: 0.0366750992834568\n",
      "2017-11-11 08:46:46: Loss at step 9687: 0.03660178557038307\n",
      "2017-11-11 08:46:46: Loss at step 9688: 0.036718036979436874\n",
      "2017-11-11 08:46:47: Loss at step 9689: 0.03676310554146767\n",
      "2017-11-11 08:46:47: Loss at step 9690: 0.036639608442783356\n",
      "2017-11-11 08:46:48: Loss at step 9691: 0.03675628826022148\n",
      "2017-11-11 08:46:48: Loss at step 9692: 0.03673834726214409\n",
      "2017-11-11 08:46:49: Loss at step 9693: 0.036777887493371964\n",
      "2017-11-11 08:46:49: Loss at step 9694: 0.03677147999405861\n",
      "2017-11-11 08:46:50: Loss at step 9695: 0.03683098033070564\n",
      "2017-11-11 08:46:50: Loss at step 9696: 0.03666054457426071\n",
      "2017-11-11 08:46:51: Loss at step 9697: 0.03672037273645401\n",
      "2017-11-11 08:46:51: Loss at step 9698: 0.036640144884586334\n",
      "2017-11-11 08:46:52: Loss at step 9699: 0.036722246557474136\n",
      "2017-11-11 08:46:52: Loss at step 9700: 0.036676324903964996\n",
      "2017-11-11 08:46:53: Loss at step 9701: 0.036756694316864014\n",
      "2017-11-11 08:46:53: Loss at step 9702: 0.03680262342095375\n",
      "2017-11-11 08:46:54: Loss at step 9703: 0.03681005910038948\n",
      "2017-11-11 08:46:54: Loss at step 9704: 0.036725372076034546\n",
      "2017-11-11 08:46:55: Loss at step 9705: 0.03666596859693527\n",
      "2017-11-11 08:46:55: Loss at step 9706: 0.03676098585128784\n",
      "2017-11-11 08:46:56: Loss at step 9707: 0.036782294511795044\n",
      "2017-11-11 08:46:56: Loss at step 9708: 0.03679478168487549\n",
      "2017-11-11 08:46:57: Loss at step 9709: 0.03680488467216492\n",
      "2017-11-11 08:46:57: Loss at step 9710: 0.03676799312233925\n",
      "2017-11-11 08:46:58: Loss at step 9711: 0.036597490310668945\n",
      "2017-11-11 08:46:58: Loss at step 9712: 0.03675030916929245\n",
      "2017-11-11 08:46:59: Loss at step 9713: 0.036759715527296066\n",
      "2017-11-11 08:46:59: Loss at step 9714: 0.03670651465654373\n",
      "2017-11-11 08:47:00: Loss at step 9715: 0.03674164414405823\n",
      "2017-11-11 08:47:00: Loss at step 9716: 0.03681645542383194\n",
      "2017-11-11 08:47:01: Loss at step 9717: 0.036792244762182236\n",
      "2017-11-11 08:47:01: Loss at step 9718: 0.036840226501226425\n",
      "2017-11-11 08:47:02: Loss at step 9719: 0.03668448328971863\n",
      "2017-11-11 08:47:02: Loss at step 9720: 0.0367928110063076\n",
      "2017-11-11 08:47:03: Loss at step 9721: 0.03679833933711052\n",
      "2017-11-11 08:47:03: Loss at step 9722: 0.03678348287940025\n",
      "2017-11-11 08:47:04: Loss at step 9723: 0.03682056814432144\n",
      "2017-11-11 08:47:04: Loss at step 9724: 0.03681669756770134\n",
      "2017-11-11 08:47:05: Loss at step 9725: 0.03691190108656883\n",
      "2017-11-11 08:47:05: Loss at step 9726: 0.03686632588505745\n",
      "2017-11-11 08:47:06: Loss at step 9727: 0.03685009852051735\n",
      "2017-11-11 08:47:06: Loss at step 9728: 0.036988090723752975\n",
      "2017-11-11 08:47:07: Loss at step 9729: 0.03701682388782501\n",
      "2017-11-11 08:47:07: Loss at step 9730: 0.03707226738333702\n",
      "2017-11-11 08:47:08: Loss at step 9731: 0.03713064640760422\n",
      "2017-11-11 08:47:08: Loss at step 9732: 0.03711625188589096\n",
      "2017-11-11 08:47:09: Loss at step 9733: 0.037195563316345215\n",
      "2017-11-11 08:47:09: Loss at step 9734: 0.03724510967731476\n",
      "2017-11-11 08:47:10: Loss at step 9735: 0.03718485310673714\n",
      "2017-11-11 08:47:10: Loss at step 9736: 0.037362463772296906\n",
      "2017-11-11 08:47:11: Loss at step 9737: 0.03723515197634697\n",
      "2017-11-11 08:47:11: Loss at step 9738: 0.0372503362596035\n",
      "2017-11-11 08:47:12: Loss at step 9739: 0.03738771751523018\n",
      "2017-11-11 08:47:12: Loss at step 9740: 0.03750697150826454\n",
      "2017-11-11 08:47:13: Loss at step 9741: 0.03755546361207962\n",
      "2017-11-11 08:47:13: Loss at step 9742: 0.038003213703632355\n",
      "2017-11-11 08:47:14: Loss at step 9743: 0.03787469491362572\n",
      "2017-11-11 08:47:14: Loss at step 9744: 0.03799805790185928\n",
      "2017-11-11 08:47:15: Loss at step 9745: 0.03804754093289375\n",
      "2017-11-11 08:47:15: Loss at step 9746: 0.03774509206414223\n",
      "2017-11-11 08:47:16: Loss at step 9747: 0.03759104758501053\n",
      "2017-11-11 08:47:16: Loss at step 9748: 0.03725593909621239\n",
      "2017-11-11 08:47:17: Loss at step 9749: 0.038510020822286606\n",
      "2017-11-11 08:47:17: Loss at step 9750: 0.03784794360399246\n",
      "2017-11-11 08:47:18: Loss at step 9751: 0.03822933882474899\n",
      "2017-11-11 08:47:18: Loss at step 9752: 0.03837451711297035\n",
      "2017-11-11 08:47:19: Loss at step 9753: 0.03828168287873268\n",
      "2017-11-11 08:47:19: Loss at step 9754: 0.03843415901064873\n",
      "2017-11-11 08:47:20: Loss at step 9755: 0.03824605792760849\n",
      "2017-11-11 08:47:20: Loss at step 9756: 0.03827982768416405\n",
      "2017-11-11 08:47:21: Loss at step 9757: 0.03828957676887512\n",
      "2017-11-11 08:47:21: Loss at step 9758: 0.03819160908460617\n",
      "2017-11-11 08:47:22: Loss at step 9759: 0.03806515410542488\n",
      "2017-11-11 08:47:22: Loss at step 9760: 0.038127601146698\n",
      "2017-11-11 08:47:23: Loss at step 9761: 0.03814341500401497\n",
      "2017-11-11 08:47:23: Loss at step 9762: 0.038104038685560226\n",
      "2017-11-11 08:47:24: Loss at step 9763: 0.03800312429666519\n",
      "2017-11-11 08:47:24: Loss at step 9764: 0.03799516335129738\n",
      "2017-11-11 08:47:25: Loss at step 9765: 0.037982091307640076\n",
      "2017-11-11 08:47:25: Loss at step 9766: 0.037973519414663315\n",
      "2017-11-11 08:47:26: Loss at step 9767: 0.037946075201034546\n",
      "2017-11-11 08:47:26: Loss at step 9768: 0.03795731067657471\n",
      "2017-11-11 08:47:27: Loss at step 9769: 0.03777936473488808\n",
      "2017-11-11 08:47:27: Loss at step 9770: 0.037932414561510086\n",
      "2017-11-11 08:47:28: Loss at step 9771: 0.037778254598379135\n",
      "2017-11-11 08:47:28: Loss at step 9772: 0.037705425173044205\n",
      "2017-11-11 08:47:29: Loss at step 9773: 0.037714894860982895\n",
      "2017-11-11 08:47:29: Loss at step 9774: 0.037790678441524506\n",
      "2017-11-11 08:47:30: Loss at step 9775: 0.03783607855439186\n",
      "2017-11-11 08:47:30: Loss at step 9776: 0.037861358374357224\n",
      "2017-11-11 08:47:31: Loss at step 9777: 0.03778477758169174\n",
      "2017-11-11 08:47:31: Loss at step 9778: 0.03783964738249779\n",
      "2017-11-11 08:47:32: Loss at step 9779: 0.037741973996162415\n",
      "2017-11-11 08:47:32: Loss at step 9780: 0.03776774927973747\n",
      "2017-11-11 08:47:33: Loss at step 9781: 0.037768810987472534\n",
      "2017-11-11 08:47:33: Loss at step 9782: 0.03764154762029648\n",
      "2017-11-11 08:47:34: Loss at step 9783: 0.03778604790568352\n",
      "2017-11-11 08:47:34: Loss at step 9784: 0.037707287818193436\n",
      "2017-11-11 08:47:35: Loss at step 9785: 0.037699371576309204\n",
      "2017-11-11 08:47:35: Loss at step 9786: 0.03773576393723488\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-11-11 08:47:36: Loss at step 9787: 0.03765013441443443\n",
      "2017-11-11 08:47:36: Loss at step 9788: 0.03776150196790695\n",
      "2017-11-11 08:47:37: Loss at step 9789: 0.037738390266895294\n",
      "2017-11-11 08:47:37: Loss at step 9790: 0.03766133263707161\n",
      "2017-11-11 08:47:38: Loss at step 9791: 0.03773337975144386\n",
      "2017-11-11 08:47:38: Loss at step 9792: 0.03766143321990967\n",
      "2017-11-11 08:47:39: Loss at step 9793: 0.03772230073809624\n",
      "2017-11-11 08:47:39: Loss at step 9794: 0.03766864165663719\n",
      "2017-11-11 08:47:40: Loss at step 9795: 0.037688735872507095\n",
      "2017-11-11 08:47:40: Loss at step 9796: 0.03761937841773033\n",
      "2017-11-11 08:47:41: Loss at step 9797: 0.037730034440755844\n",
      "2017-11-11 08:47:41: Loss at step 9798: 0.03766990825533867\n",
      "2017-11-11 08:47:42: Loss at step 9799: 0.037709422409534454\n",
      "2017-11-11 08:47:42: Loss at step 9800: 0.03770731762051582\n",
      "2017-11-11 08:47:43: Loss at step 9801: 0.03764345124363899\n",
      "2017-11-11 08:47:43: Loss at step 9802: 0.03765358403325081\n",
      "2017-11-11 08:47:44: Loss at step 9803: 0.03764427453279495\n",
      "2017-11-11 08:47:44: Loss at step 9804: 0.037590332329273224\n",
      "2017-11-11 08:47:45: Loss at step 9805: 0.03756605088710785\n",
      "2017-11-11 08:47:45: Loss at step 9806: 0.03767470270395279\n",
      "2017-11-11 08:47:46: Loss at step 9807: 0.03762079402804375\n",
      "2017-11-11 08:47:46: Loss at step 9808: 0.037625525146722794\n",
      "2017-11-11 08:47:47: Loss at step 9809: 0.037563953548669815\n",
      "2017-11-11 08:47:47: Loss at step 9810: 0.03767850995063782\n",
      "2017-11-11 08:47:48: Loss at step 9811: 0.03759055957198143\n",
      "2017-11-11 08:47:48: Loss at step 9812: 0.037628527730703354\n",
      "2017-11-11 08:47:49: Loss at step 9813: 0.03763614594936371\n",
      "2017-11-11 08:47:49: Loss at step 9814: 0.037748198956251144\n",
      "2017-11-11 08:47:50: Loss at step 9815: 0.03772779926657677\n",
      "2017-11-11 08:47:50: Loss at step 9816: 0.03762686252593994\n",
      "2017-11-11 08:47:51: Loss at step 9817: 0.037749774754047394\n",
      "2017-11-11 08:47:51: Loss at step 9818: 0.03764183446764946\n",
      "2017-11-11 08:47:52: Loss at step 9819: 0.037661660462617874\n",
      "2017-11-11 08:47:52: Loss at step 9820: 0.037651531398296356\n",
      "2017-11-11 08:47:53: Loss at step 9821: 0.037621431052684784\n",
      "2017-11-11 08:47:53: Loss at step 9822: 0.03762400895357132\n",
      "2017-11-11 08:47:54: Loss at step 9823: 0.03772842884063721\n",
      "2017-11-11 08:47:54: Loss at step 9824: 0.03768004849553108\n",
      "2017-11-11 08:47:55: Loss at step 9825: 0.03769176825881004\n",
      "2017-11-11 08:47:55: Loss at step 9826: 0.03764870762825012\n",
      "2017-11-11 08:47:56: Loss at step 9827: 0.03762033209204674\n",
      "2017-11-11 08:47:56: Loss at step 9828: 0.03752419725060463\n",
      "2017-11-11 08:47:57: Loss at step 9829: 0.03763793781399727\n",
      "2017-11-11 08:47:57: Loss at step 9830: 0.037686821073293686\n",
      "2017-11-11 08:47:58: Loss at step 9831: 0.03765760362148285\n",
      "2017-11-11 08:47:58: Loss at step 9832: 0.037574298679828644\n",
      "2017-11-11 08:47:59: Loss at step 9833: 0.03765009716153145\n",
      "2017-11-11 08:47:59: Loss at step 9834: 0.03762800619006157\n",
      "2017-11-11 08:48:00: Loss at step 9835: 0.037594541907310486\n",
      "2017-11-11 08:48:00: Loss at step 9836: 0.03764423727989197\n",
      "2017-11-11 08:48:00: Loss at step 9837: 0.03762754425406456\n",
      "2017-11-11 08:48:01: Loss at step 9838: 0.03764329105615616\n",
      "2017-11-11 08:48:01: Loss at step 9839: 0.037562109529972076\n",
      "2017-11-11 08:48:02: Loss at step 9840: 0.0375746451318264\n",
      "2017-11-11 08:48:03: Loss at step 9841: 0.0376625619828701\n",
      "2017-11-11 08:48:03: Loss at step 9842: 0.037562403827905655\n",
      "2017-11-11 08:48:03: Loss at step 9843: 0.037559568881988525\n",
      "2017-11-11 08:48:04: Loss at step 9844: 0.037604667246341705\n",
      "2017-11-11 08:48:04: Loss at step 9845: 0.03772810101509094\n",
      "2017-11-11 08:48:05: Loss at step 9846: 0.03761552274227142\n",
      "2017-11-11 08:48:05: Loss at step 9847: 0.03753422200679779\n",
      "2017-11-11 08:48:06: Loss at step 9848: 0.03762444481253624\n",
      "2017-11-11 08:48:06: Loss at step 9849: 0.03754561021924019\n",
      "2017-11-11 08:48:07: Loss at step 9850: 0.03764202445745468\n",
      "2017-11-11 08:48:07: Loss at step 9851: 0.03761524707078934\n",
      "2017-11-11 08:48:08: Loss at step 9852: 0.03764317184686661\n",
      "2017-11-11 08:48:08: Loss at step 9853: 0.03754822909832001\n",
      "2017-11-11 08:48:09: Loss at step 9854: 0.03762335702776909\n",
      "2017-11-11 08:48:09: Loss at step 9855: 0.037692125886678696\n",
      "2017-11-11 08:48:10: Loss at step 9856: 0.03761695325374603\n",
      "2017-11-11 08:48:10: Loss at step 9857: 0.03764087334275246\n",
      "2017-11-11 08:48:11: Loss at step 9858: 0.037562739104032516\n",
      "2017-11-11 08:48:11: Loss at step 9859: 0.037646424025297165\n",
      "2017-11-11 08:48:12: Loss at step 9860: 0.0376298613846302\n",
      "2017-11-11 08:48:12: Loss at step 9861: 0.03766128420829773\n",
      "2017-11-11 08:48:13: Loss at step 9862: 0.037518806755542755\n",
      "2017-11-11 08:48:13: Loss at step 9863: 0.03768206015229225\n",
      "2017-11-11 08:48:14: Loss at step 9864: 0.0376206710934639\n",
      "2017-11-11 08:48:14: Loss at step 9865: 0.037591755390167236\n",
      "2017-11-11 08:48:15: Loss at step 9866: 0.03761346638202667\n",
      "2017-11-11 08:48:15: Loss at step 9867: 0.037662260234355927\n",
      "2017-11-11 08:48:16: Loss at step 9868: 0.037679072469472885\n",
      "2017-11-11 08:48:16: Loss at step 9869: 0.037599194794893265\n",
      "2017-11-11 08:48:17: Loss at step 9870: 0.03773107752203941\n",
      "2017-11-11 08:48:17: Loss at step 9871: 0.03760474920272827\n",
      "2017-11-11 08:48:18: Loss at step 9872: 0.03761252388358116\n",
      "2017-11-11 08:48:18: Loss at step 9873: 0.03763863071799278\n",
      "2017-11-11 08:48:19: Loss at step 9874: 0.03766113519668579\n",
      "2017-11-11 08:48:19: Loss at step 9875: 0.037623438984155655\n",
      "2017-11-11 08:48:20: Loss at step 9876: 0.03772649168968201\n",
      "2017-11-11 08:48:20: Loss at step 9877: 0.03773149102926254\n",
      "2017-11-11 08:48:21: Loss at step 9878: 0.037581585347652435\n",
      "2017-11-11 08:48:21: Loss at step 9879: 0.03765418007969856\n",
      "2017-11-11 08:48:22: Loss at step 9880: 0.037600114941596985\n",
      "2017-11-11 08:48:22: Loss at step 9881: 0.037574682384729385\n",
      "2017-11-11 08:48:23: Loss at step 9882: 0.03759758174419403\n",
      "2017-11-11 08:48:23: Loss at step 9883: 0.0377223938703537\n",
      "2017-11-11 08:48:24: Loss at step 9884: 0.03772052749991417\n",
      "2017-11-11 08:48:24: Loss at step 9885: 0.037608761340379715\n",
      "2017-11-11 08:48:25: Loss at step 9886: 0.03771156817674637\n",
      "2017-11-11 08:48:25: Loss at step 9887: 0.037646833807229996\n",
      "2017-11-11 08:48:26: Loss at step 9888: 0.03765074536204338\n",
      "2017-11-11 08:48:26: Loss at step 9889: 0.037750739604234695\n",
      "2017-11-11 08:48:27: Loss at step 9890: 0.03768911212682724\n",
      "2017-11-11 08:48:27: Loss at step 9891: 0.03758925199508667\n",
      "2017-11-11 08:48:28: Loss at step 9892: 0.03748856857419014\n",
      "2017-11-11 08:48:28: Loss at step 9893: 0.03768052160739899\n",
      "2017-11-11 08:48:29: Loss at step 9894: 0.037640657275915146\n",
      "2017-11-11 08:48:29: Loss at step 9895: 0.03763704374432564\n",
      "2017-11-11 08:48:30: Loss at step 9896: 0.03775493800640106\n",
      "2017-11-11 08:48:30: Loss at step 9897: 0.0377253033220768\n",
      "2017-11-11 08:48:31: Loss at step 9898: 0.037774644792079926\n",
      "2017-11-11 08:48:31: Loss at step 9899: 0.03759061545133591\n",
      "2017-11-11 08:48:32: Loss at step 9900: 0.03760824725031853\n",
      "2017-11-11 08:48:32: Loss at step 9901: 0.037670381367206573\n",
      "2017-11-11 08:48:33: Loss at step 9902: 0.03764476999640465\n",
      "2017-11-11 08:48:33: Loss at step 9903: 0.037564318627119064\n",
      "2017-11-11 08:48:34: Loss at step 9904: 0.037681907415390015\n",
      "2017-11-11 08:48:34: Loss at step 9905: 0.037695951759815216\n",
      "2017-11-11 08:48:35: Loss at step 9906: 0.037567224353551865\n",
      "2017-11-11 08:48:35: Loss at step 9907: 0.03754222393035889\n",
      "2017-11-11 08:48:36: Loss at step 9908: 0.03766825050115585\n",
      "2017-11-11 08:48:36: Loss at step 9909: 0.037652403116226196\n",
      "2017-11-11 08:48:37: Loss at step 9910: 0.03762994334101677\n",
      "2017-11-11 08:48:37: Loss at step 9911: 0.037661563605070114\n",
      "2017-11-11 08:48:38: Loss at step 9912: 0.03762051835656166\n",
      "2017-11-11 08:48:38: Loss at step 9913: 0.037617772817611694\n",
      "2017-11-11 08:48:39: Loss at step 9914: 0.03762829303741455\n",
      "2017-11-11 08:48:39: Loss at step 9915: 0.037716034799814224\n",
      "2017-11-11 08:48:40: Loss at step 9916: 0.03756248205900192\n",
      "2017-11-11 08:48:40: Loss at step 9917: 0.037595394998788834\n",
      "2017-11-11 08:48:41: Loss at step 9918: 0.037660643458366394\n",
      "2017-11-11 08:48:41: Loss at step 9919: 0.03764519467949867\n",
      "2017-11-11 08:48:42: Loss at step 9920: 0.037558507174253464\n",
      "2017-11-11 08:48:42: Loss at step 9921: 0.03760681301355362\n",
      "2017-11-11 08:48:43: Loss at step 9922: 0.03759033605456352\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-11-11 08:48:43: Loss at step 9923: 0.037624064832925797\n",
      "2017-11-11 08:48:44: Loss at step 9924: 0.037611719220876694\n",
      "2017-11-11 08:48:44: Loss at step 9925: 0.03780515864491463\n",
      "2017-11-11 08:48:45: Loss at step 9926: 0.03762705251574516\n",
      "2017-11-11 08:48:45: Loss at step 9927: 0.03761802241206169\n",
      "2017-11-11 08:48:46: Loss at step 9928: 0.03768565505743027\n",
      "2017-11-11 08:48:46: Loss at step 9929: 0.037607625126838684\n",
      "2017-11-11 08:48:47: Loss at step 9930: 0.03766242414712906\n",
      "2017-11-11 08:48:47: Loss at step 9931: 0.037658631801605225\n",
      "2017-11-11 08:48:48: Loss at step 9932: 0.03759294003248215\n",
      "2017-11-11 08:48:48: Loss at step 9933: 0.037520881742239\n",
      "2017-11-11 08:48:49: Loss at step 9934: 0.03774036839604378\n",
      "2017-11-11 08:48:49: Loss at step 9935: 0.0376502126455307\n",
      "2017-11-11 08:48:50: Loss at step 9936: 0.03775206208229065\n",
      "2017-11-11 08:48:50: Loss at step 9937: 0.0377604141831398\n",
      "2017-11-11 08:48:51: Loss at step 9938: 0.03756864368915558\n",
      "2017-11-11 08:48:51: Loss at step 9939: 0.03760524466633797\n",
      "2017-11-11 08:48:52: Loss at step 9940: 0.03765159845352173\n",
      "2017-11-11 08:48:52: Loss at step 9941: 0.03772684186697006\n",
      "2017-11-11 08:48:53: Loss at step 9942: 0.03760609030723572\n",
      "2017-11-11 08:48:53: Loss at step 9943: 0.037632573395967484\n",
      "2017-11-11 08:48:54: Loss at step 9944: 0.03761470317840576\n",
      "2017-11-11 08:48:54: Loss at step 9945: 0.037596940994262695\n",
      "2017-11-11 08:48:55: Loss at step 9946: 0.037683866918087006\n",
      "2017-11-11 08:48:55: Loss at step 9947: 0.03766152262687683\n",
      "2017-11-11 08:48:56: Loss at step 9948: 0.03763549029827118\n",
      "2017-11-11 08:48:56: Loss at step 9949: 0.03754783794283867\n",
      "2017-11-11 08:48:57: Loss at step 9950: 0.03769403696060181\n",
      "2017-11-11 08:48:57: Loss at step 9951: 0.03766712546348572\n",
      "2017-11-11 08:48:58: Loss at step 9952: 0.03768587112426758\n",
      "2017-11-11 08:48:58: Loss at step 9953: 0.037591978907585144\n",
      "2017-11-11 08:48:59: Loss at step 9954: 0.037589166313409805\n",
      "2017-11-11 08:48:59: Loss at step 9955: 0.037680502980947495\n",
      "2017-11-11 08:49:00: Loss at step 9956: 0.03759824112057686\n",
      "2017-11-11 08:49:00: Loss at step 9957: 0.03763168305158615\n",
      "2017-11-11 08:49:01: Loss at step 9958: 0.03759525716304779\n",
      "2017-11-11 08:49:01: Loss at step 9959: 0.037606339901685715\n",
      "2017-11-11 08:49:02: Loss at step 9960: 0.03762853518128395\n",
      "2017-11-11 08:49:02: Loss at step 9961: 0.03767290338873863\n",
      "2017-11-11 08:49:03: Loss at step 9962: 0.03771871328353882\n",
      "2017-11-11 08:49:03: Loss at step 9963: 0.03756895288825035\n",
      "2017-11-11 08:49:04: Loss at step 9964: 0.03765422850847244\n",
      "2017-11-11 08:49:04: Loss at step 9965: 0.03765817731618881\n",
      "2017-11-11 08:49:05: Loss at step 9966: 0.03766092658042908\n",
      "2017-11-11 08:49:05: Loss at step 9967: 0.037732258439064026\n",
      "2017-11-11 08:49:06: Loss at step 9968: 0.03766089677810669\n",
      "2017-11-11 08:49:06: Loss at step 9969: 0.037589527666568756\n",
      "2017-11-11 08:49:07: Loss at step 9970: 0.037676941603422165\n",
      "2017-11-11 08:49:07: Loss at step 9971: 0.037559013813734055\n",
      "2017-11-11 08:49:08: Loss at step 9972: 0.037588443607091904\n",
      "2017-11-11 08:49:08: Loss at step 9973: 0.03757845610380173\n",
      "2017-11-11 08:49:09: Loss at step 9974: 0.03762716427445412\n",
      "2017-11-11 08:49:09: Loss at step 9975: 0.03766744211316109\n",
      "2017-11-11 08:49:10: Loss at step 9976: 0.03764791414141655\n",
      "2017-11-11 08:49:10: Loss at step 9977: 0.037716418504714966\n",
      "2017-11-11 08:49:11: Loss at step 9978: 0.03767024353146553\n",
      "2017-11-11 08:49:11: Loss at step 9979: 0.03770032525062561\n",
      "2017-11-11 08:49:12: Loss at step 9980: 0.037594545632600784\n",
      "2017-11-11 08:49:12: Loss at step 9981: 0.03757457807660103\n",
      "2017-11-11 08:49:13: Loss at step 9982: 0.037660151720047\n",
      "2017-11-11 08:49:13: Loss at step 9983: 0.03758140280842781\n",
      "2017-11-11 08:49:14: Loss at step 9984: 0.03762486204504967\n",
      "2017-11-11 08:49:14: Loss at step 9985: 0.03758978843688965\n",
      "2017-11-11 08:49:15: Loss at step 9986: 0.03772318363189697\n",
      "2017-11-11 08:49:15: Loss at step 9987: 0.03760814666748047\n",
      "2017-11-11 08:49:16: Loss at step 9988: 0.03757762536406517\n",
      "2017-11-11 08:49:16: Loss at step 9989: 0.037597399204969406\n",
      "2017-11-11 08:49:17: Loss at step 9990: 0.037605829536914825\n",
      "2017-11-11 08:49:17: Loss at step 9991: 0.03759344667196274\n",
      "2017-11-11 08:49:18: Loss at step 9992: 0.03764664754271507\n",
      "2017-11-11 08:49:19: Loss at step 9993: 0.03757689520716667\n",
      "2017-11-11 08:49:19: Loss at step 9994: 0.037626542150974274\n",
      "2017-11-11 08:49:20: Loss at step 9995: 0.037591353058815\n",
      "2017-11-11 08:49:20: Loss at step 9996: 0.03762466832995415\n",
      "2017-11-11 08:49:21: Loss at step 9997: 0.03766592592000961\n",
      "2017-11-11 08:49:21: Loss at step 9998: 0.03769955411553383\n",
      "2017-11-11 08:49:22: Loss at step 9999: 0.037693824619054794\n",
      "2017-11-11 08:49:22: Loss at step 10000: 0.0377647764980793\n",
      "2017-11-11 08:49:23: Loss at step 10001: 0.037758562713861465\n",
      "2017-11-11 08:49:23: Loss at step 10002: 0.03764075040817261\n",
      "2017-11-11 08:49:24: Loss at step 10003: 0.03767051920294762\n",
      "2017-11-11 08:49:24: Loss at step 10004: 0.037602584809064865\n",
      "2017-11-11 08:49:25: Loss at step 10005: 0.037646569311618805\n",
      "2017-11-11 08:49:25: Loss at step 10006: 0.03762700781226158\n",
      "2017-11-11 08:49:26: Loss at step 10007: 0.037673961371183395\n",
      "2017-11-11 08:49:26: Loss at step 10008: 0.037721455097198486\n",
      "2017-11-11 08:49:27: Loss at step 10009: 0.03762326389551163\n",
      "2017-11-11 08:49:27: Loss at step 10010: 0.03757180646061897\n",
      "2017-11-11 08:49:28: Loss at step 10011: 0.03766809031367302\n",
      "2017-11-11 08:49:28: Loss at step 10012: 0.03760271891951561\n",
      "2017-11-11 08:49:29: Loss at step 10013: 0.03762657195329666\n",
      "2017-11-11 08:49:29: Loss at step 10014: 0.037640877068042755\n",
      "2017-11-11 08:49:30: Loss at step 10015: 0.03764377534389496\n",
      "2017-11-11 08:49:30: Loss at step 10016: 0.03759309649467468\n",
      "2017-11-11 08:49:31: Loss at step 10017: 0.037588540464639664\n",
      "2017-11-11 08:49:31: Loss at step 10018: 0.037640344351530075\n",
      "2017-11-11 08:49:32: Loss at step 10019: 0.037649963051080704\n",
      "2017-11-11 08:49:32: Loss at step 10020: 0.03764832764863968\n",
      "2017-11-11 08:49:33: Loss at step 10021: 0.037656866014003754\n",
      "2017-11-11 08:49:33: Loss at step 10022: 0.03771607577800751\n",
      "2017-11-11 08:49:34: Loss at step 10023: 0.03762369230389595\n",
      "2017-11-11 08:49:34: Loss at step 10024: 0.037647370249032974\n",
      "2017-11-11 08:49:35: Loss at step 10025: 0.03764410689473152\n",
      "2017-11-11 08:49:35: Loss at step 10026: 0.0377204529941082\n",
      "2017-11-11 08:49:36: Loss at step 10027: 0.037643659859895706\n",
      "2017-11-11 08:49:36: Loss at step 10028: 0.03769290819764137\n",
      "2017-11-11 08:49:37: Loss at step 10029: 0.037661876529455185\n",
      "2017-11-11 08:49:38: Loss at step 10030: 0.03759722411632538\n",
      "2017-11-11 08:49:38: Loss at step 10031: 0.03748268261551857\n",
      "2017-11-11 08:49:39: Loss at step 10032: 0.03756310045719147\n",
      "2017-11-11 08:49:39: Loss at step 10033: 0.037593990564346313\n",
      "2017-11-11 08:49:40: Loss at step 10034: 0.03768647462129593\n",
      "2017-11-11 08:49:40: Loss at step 10035: 0.037582434713840485\n",
      "2017-11-11 08:49:41: Loss at step 10036: 0.03766217827796936\n",
      "2017-11-11 08:49:41: Loss at step 10037: 0.03762754052877426\n",
      "2017-11-11 08:49:42: Loss at step 10038: 0.037632301449775696\n",
      "2017-11-11 08:49:42: Loss at step 10039: 0.037616681307554245\n",
      "2017-11-11 08:49:43: Loss at step 10040: 0.037572991102933884\n",
      "2017-11-11 08:49:43: Loss at step 10041: 0.03766699507832527\n",
      "2017-11-11 08:49:44: Loss at step 10042: 0.03762578219175339\n",
      "2017-11-11 08:49:44: Loss at step 10043: 0.037572480738162994\n",
      "2017-11-11 08:49:45: Loss at step 10044: 0.037542350590229034\n",
      "2017-11-11 08:49:45: Loss at step 10045: 0.037704940885305405\n",
      "2017-11-11 08:49:46: Loss at step 10046: 0.037593867629766464\n",
      "2017-11-11 08:49:46: Loss at step 10047: 0.037622030824422836\n",
      "2017-11-11 08:49:47: Loss at step 10048: 0.037643253803253174\n",
      "2017-11-11 08:49:47: Loss at step 10049: 0.03763379901647568\n",
      "2017-11-11 08:49:48: Loss at step 10050: 0.03759709373116493\n",
      "2017-11-11 08:49:48: Loss at step 10051: 0.03766521438956261\n",
      "2017-11-11 08:49:49: Loss at step 10052: 0.03754771873354912\n",
      "2017-11-11 08:49:49: Loss at step 10053: 0.037551987916231155\n",
      "2017-11-11 08:49:50: Loss at step 10054: 0.03759289160370827\n",
      "2017-11-11 08:49:50: Loss at step 10055: 0.0375995859503746\n",
      "2017-11-11 08:49:51: Loss at step 10056: 0.03761456161737442\n",
      "2017-11-11 08:49:51: Loss at step 10057: 0.037560075521469116\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-11-11 08:49:52: Loss at step 10058: 0.037553705275058746\n",
      "2017-11-11 08:49:53: Loss at step 10059: 0.037593498826026917\n",
      "2017-11-11 08:49:53: Loss at step 10060: 0.03761424124240875\n",
      "2017-11-11 08:49:54: Loss at step 10061: 0.03760572150349617\n",
      "2017-11-11 08:49:54: Loss at step 10062: 0.03760414943099022\n",
      "2017-11-11 08:49:55: Loss at step 10063: 0.037570543587207794\n",
      "2017-11-11 08:49:55: Loss at step 10064: 0.037687864154577255\n",
      "2017-11-11 08:49:56: Loss at step 10065: 0.03760770335793495\n",
      "2017-11-11 08:49:56: Loss at step 10066: 0.037720292806625366\n",
      "2017-11-11 08:49:57: Loss at step 10067: 0.03768230229616165\n",
      "2017-11-11 08:49:57: Loss at step 10068: 0.037552446126937866\n",
      "2017-11-11 08:49:58: Loss at step 10069: 0.03757903724908829\n",
      "2017-11-11 08:49:58: Loss at step 10070: 0.03763233497738838\n",
      "2017-11-11 08:49:59: Loss at step 10071: 0.03759200498461723\n",
      "2017-11-11 08:49:59: Loss at step 10072: 0.03768846020102501\n",
      "2017-11-11 08:50:00: Loss at step 10073: 0.03773735091090202\n",
      "2017-11-11 08:50:00: Loss at step 10074: 0.037654947489500046\n",
      "2017-11-11 08:50:01: Loss at step 10075: 0.03770944103598595\n",
      "2017-11-11 08:50:01: Loss at step 10076: 0.037560850381851196\n",
      "2017-11-11 08:50:02: Loss at step 10077: 0.03760891780257225\n",
      "2017-11-11 08:50:02: Loss at step 10078: 0.037667252123355865\n",
      "2017-11-11 08:50:03: Loss at step 10079: 0.03772055730223656\n",
      "2017-11-11 08:50:03: Loss at step 10080: 0.03766878694295883\n",
      "2017-11-11 08:50:04: Loss at step 10081: 0.03761117532849312\n",
      "2017-11-11 08:50:04: Loss at step 10082: 0.03759356215596199\n",
      "2017-11-11 08:50:05: Loss at step 10083: 0.03763645514845848\n",
      "2017-11-11 08:50:05: Loss at step 10084: 0.037594154477119446\n",
      "2017-11-11 08:50:06: Loss at step 10085: 0.03757103905081749\n",
      "2017-11-11 08:50:06: Loss at step 10086: 0.03759051486849785\n",
      "2017-11-11 08:50:07: Loss at step 10087: 0.037628673017024994\n",
      "2017-11-11 08:50:07: Loss at step 10088: 0.03758629038929939\n",
      "2017-11-11 08:50:08: Loss at step 10089: 0.03769730404019356\n",
      "2017-11-11 08:50:08: Loss at step 10090: 0.03768497332930565\n",
      "2017-11-11 08:50:09: Loss at step 10091: 0.037742823362350464\n",
      "2017-11-11 08:50:09: Loss at step 10092: 0.037615641951560974\n",
      "2017-11-11 08:50:10: Loss at step 10093: 0.03757768124341965\n",
      "2017-11-11 08:50:10: Loss at step 10094: 0.03763342276215553\n",
      "2017-11-11 08:50:11: Loss at step 10095: 0.03760944679379463\n",
      "2017-11-11 08:50:12: Loss at step 10096: 0.03759276866912842\n",
      "2017-11-11 08:50:12: Loss at step 10097: 0.03770216554403305\n",
      "2017-11-11 08:50:13: Loss at step 10098: 0.03771350532770157\n",
      "2017-11-11 08:50:13: Loss at step 10099: 0.037664301693439484\n",
      "2017-11-11 08:50:14: Loss at step 10100: 0.037732988595962524\n",
      "2017-11-11 08:50:14: Loss at step 10101: 0.037690795958042145\n",
      "2017-11-11 08:50:15: Loss at step 10102: 0.03766942769289017\n",
      "2017-11-11 08:50:15: Loss at step 10103: 0.037629615515470505\n",
      "2017-11-11 08:50:15: Loss at step 10104: 0.0376635305583477\n",
      "2017-11-11 08:50:16: Loss at step 10105: 0.03764384984970093\n",
      "2017-11-11 08:50:17: Loss at step 10106: 0.03772765398025513\n",
      "2017-11-11 08:50:17: Loss at step 10107: 0.03765649348497391\n",
      "2017-11-11 08:50:18: Loss at step 10108: 0.037585847079753876\n",
      "2017-11-11 08:50:18: Loss at step 10109: 0.03761793673038483\n",
      "2017-11-11 08:50:19: Loss at step 10110: 0.0377107709646225\n",
      "2017-11-11 08:50:19: Loss at step 10111: 0.037708353251218796\n",
      "2017-11-11 08:50:20: Loss at step 10112: 0.03763670474290848\n",
      "2017-11-11 08:50:20: Loss at step 10113: 0.0376119464635849\n",
      "2017-11-11 08:50:21: Loss at step 10114: 0.03770704194903374\n",
      "2017-11-11 08:50:21: Loss at step 10115: 0.0375753715634346\n",
      "2017-11-11 08:50:22: Loss at step 10116: 0.0375816710293293\n",
      "2017-11-11 08:50:22: Loss at step 10117: 0.03756280988454819\n",
      "2017-11-11 08:50:23: Loss at step 10118: 0.0376162976026535\n",
      "2017-11-11 08:50:23: Loss at step 10119: 0.03761676698923111\n",
      "2017-11-11 08:50:24: Loss at step 10120: 0.03764479234814644\n",
      "2017-11-11 08:50:25: Loss at step 10121: 0.03766653686761856\n",
      "2017-11-11 08:50:25: Loss at step 10122: 0.03760252892971039\n",
      "2017-11-11 08:50:26: Loss at step 10123: 0.03768351301550865\n",
      "2017-11-11 08:50:26: Loss at step 10124: 0.03761405125260353\n",
      "2017-11-11 08:50:27: Loss at step 10125: 0.037608660757541656\n",
      "2017-11-11 08:50:27: Loss at step 10126: 0.037621259689331055\n",
      "2017-11-11 08:50:28: Loss at step 10127: 0.037614770233631134\n",
      "2017-11-11 08:50:28: Loss at step 10128: 0.037526074796915054\n",
      "2017-11-11 08:50:29: Loss at step 10129: 0.03768863156437874\n",
      "2017-11-11 08:50:29: Loss at step 10130: 0.03753684088587761\n",
      "2017-11-11 08:50:30: Loss at step 10131: 0.03752174973487854\n",
      "2017-11-11 08:50:30: Loss at step 10132: 0.03768691420555115\n",
      "2017-11-11 08:50:31: Loss at step 10133: 0.03766521438956261\n",
      "2017-11-11 08:50:31: Loss at step 10134: 0.037587616592645645\n",
      "2017-11-11 08:50:32: Loss at step 10135: 0.03759549558162689\n",
      "2017-11-11 08:50:32: Loss at step 10136: 0.037636883556842804\n",
      "2017-11-11 08:50:33: Loss at step 10137: 0.037704985588788986\n",
      "2017-11-11 08:50:33: Loss at step 10138: 0.03755439817905426\n",
      "2017-11-11 08:50:34: Loss at step 10139: 0.037662751972675323\n",
      "2017-11-11 08:50:34: Loss at step 10140: 0.03761359304189682\n",
      "2017-11-11 08:50:35: Loss at step 10141: 0.037694111466407776\n",
      "2017-11-11 08:50:35: Loss at step 10142: 0.037704385817050934\n",
      "2017-11-11 08:50:36: Loss at step 10143: 0.0376298762857914\n",
      "2017-11-11 08:50:36: Loss at step 10144: 0.037686023861169815\n",
      "2017-11-11 08:50:37: Loss at step 10145: 0.03767434507608414\n",
      "2017-11-11 08:50:37: Loss at step 10146: 0.037768904119729996\n",
      "2017-11-11 08:50:38: Loss at step 10147: 0.03766913339495659\n",
      "2017-11-11 08:50:38: Loss at step 10148: 0.0376649834215641\n",
      "2017-11-11 08:50:39: Loss at step 10149: 0.03769104555249214\n",
      "2017-11-11 08:50:39: Loss at step 10150: 0.03755826875567436\n",
      "2017-11-11 08:50:40: Loss at step 10151: 0.03766433894634247\n",
      "2017-11-11 08:50:40: Loss at step 10152: 0.037606507539749146\n",
      "2017-11-11 08:50:41: Loss at step 10153: 0.03762945532798767\n",
      "2017-11-11 08:50:41: Loss at step 10154: 0.037585701793432236\n",
      "2017-11-11 08:50:42: Loss at step 10155: 0.03765285015106201\n",
      "2017-11-11 08:50:42: Loss at step 10156: 0.03772918879985809\n",
      "2017-11-11 08:50:43: Loss at step 10157: 0.03764764219522476\n",
      "2017-11-11 08:50:43: Loss at step 10158: 0.037620462477207184\n",
      "2017-11-11 08:50:44: Loss at step 10159: 0.03762850910425186\n",
      "2017-11-11 08:50:45: Loss at step 10160: 0.037567753344774246\n",
      "2017-11-11 08:50:45: Loss at step 10161: 0.037630997598171234\n",
      "2017-11-11 08:50:46: Loss at step 10162: 0.03767034038901329\n",
      "2017-11-11 08:50:46: Loss at step 10163: 0.037666551768779755\n",
      "2017-11-11 08:50:47: Loss at step 10164: 0.03755467012524605\n",
      "2017-11-11 08:50:47: Loss at step 10165: 0.03751405328512192\n",
      "2017-11-11 08:50:48: Loss at step 10166: 0.03760450333356857\n",
      "2017-11-11 08:50:48: Loss at step 10167: 0.03770417347550392\n",
      "2017-11-11 08:50:49: Loss at step 10168: 0.03762916103005409\n",
      "2017-11-11 08:50:49: Loss at step 10169: 0.03763318061828613\n",
      "2017-11-11 08:50:50: Loss at step 10170: 0.03760145232081413\n",
      "2017-11-11 08:50:50: Loss at step 10171: 0.03764430060982704\n",
      "2017-11-11 08:50:51: Loss at step 10172: 0.03772972896695137\n",
      "2017-11-11 08:50:51: Loss at step 10173: 0.03759988397359848\n",
      "2017-11-11 08:50:52: Loss at step 10174: 0.037660978734493256\n",
      "2017-11-11 08:50:52: Loss at step 10175: 0.03752060607075691\n",
      "2017-11-11 08:50:53: Loss at step 10176: 0.03755646198987961\n",
      "2017-11-11 08:50:53: Loss at step 10177: 0.03752213343977928\n",
      "2017-11-11 08:50:54: Loss at step 10178: 0.03767521306872368\n",
      "2017-11-11 08:50:54: Loss at step 10179: 0.03767727315425873\n",
      "2017-11-11 08:50:55: Loss at step 10180: 0.03763348236680031\n",
      "2017-11-11 08:50:55: Loss at step 10181: 0.03755190595984459\n",
      "2017-11-11 08:50:56: Loss at step 10182: 0.0376809723675251\n",
      "2017-11-11 08:50:56: Loss at step 10183: 0.03768375143408775\n",
      "2017-11-11 08:50:57: Loss at step 10184: 0.03759113326668739\n",
      "2017-11-11 08:50:57: Loss at step 10185: 0.03757384419441223\n",
      "2017-11-11 08:50:58: Loss at step 10186: 0.03759225457906723\n",
      "2017-11-11 08:50:58: Loss at step 10187: 0.03759624809026718\n",
      "2017-11-11 08:50:59: Loss at step 10188: 0.0375412218272686\n",
      "2017-11-11 08:50:59: Loss at step 10189: 0.03768240287899971\n",
      "2017-11-11 08:51:00: Loss at step 10190: 0.037575073540210724\n",
      "2017-11-11 08:51:00: Loss at step 10191: 0.037626635283231735\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-11-11 08:51:01: Loss at step 10192: 0.037651851773262024\n",
      "2017-11-11 08:51:01: Loss at step 10193: 0.037603795528411865\n",
      "2017-11-11 08:51:02: Loss at step 10194: 0.037712570279836655\n",
      "2017-11-11 08:51:02: Loss at step 10195: 0.03754232078790665\n",
      "2017-11-11 08:51:03: Loss at step 10196: 0.03764752298593521\n",
      "2017-11-11 08:51:04: Loss at step 10197: 0.037665966898202896\n",
      "2017-11-11 08:51:04: Loss at step 10198: 0.03765561431646347\n",
      "2017-11-11 08:51:05: Loss at step 10199: 0.03760680928826332\n",
      "2017-11-11 08:51:05: Loss at step 10200: 0.037787023931741714\n",
      "2017-11-11 08:51:06: Loss at step 10201: 0.037747833877801895\n",
      "2017-11-11 08:51:06: Loss at step 10202: 0.03765586018562317\n",
      "2017-11-11 08:51:07: Loss at step 10203: 0.037650782614946365\n",
      "2017-11-11 08:51:07: Loss at step 10204: 0.037724196910858154\n",
      "2017-11-11 08:51:08: Loss at step 10205: 0.03767876699566841\n",
      "2017-11-11 08:51:08: Loss at step 10206: 0.03762451931834221\n",
      "2017-11-11 08:51:09: Loss at step 10207: 0.037640828639268875\n",
      "2017-11-11 08:51:09: Loss at step 10208: 0.03754781559109688\n",
      "2017-11-11 08:51:10: Loss at step 10209: 0.03766831383109093\n",
      "2017-11-11 08:51:10: Loss at step 10210: 0.0376119427382946\n",
      "2017-11-11 08:51:11: Loss at step 10211: 0.037606380879879\n",
      "2017-11-11 08:51:11: Loss at step 10212: 0.037650059908628464\n",
      "2017-11-11 08:51:12: Loss at step 10213: 0.037648867815732956\n",
      "2017-11-11 08:51:12: Loss at step 10214: 0.03767764940857887\n",
      "2017-11-11 08:51:13: Loss at step 10215: 0.0376286618411541\n",
      "2017-11-11 08:51:13: Loss at step 10216: 0.03764825686812401\n",
      "2017-11-11 08:51:14: Loss at step 10217: 0.03760256990790367\n",
      "2017-11-11 08:51:14: Loss at step 10218: 0.03759973868727684\n",
      "2017-11-11 08:51:15: Loss at step 10219: 0.03770628571510315\n",
      "2017-11-11 08:51:15: Loss at step 10220: 0.0375979021191597\n",
      "2017-11-11 08:51:16: Loss at step 10221: 0.03764696046710014\n",
      "2017-11-11 08:51:16: Loss at step 10222: 0.03768772631883621\n",
      "2017-11-11 08:51:17: Loss at step 10223: 0.037596262991428375\n",
      "2017-11-11 08:51:18: Loss at step 10224: 0.03764531388878822\n",
      "2017-11-11 08:51:18: Loss at step 10225: 0.037600573152303696\n",
      "2017-11-11 08:51:19: Loss at step 10226: 0.03757978975772858\n",
      "2017-11-11 08:51:19: Loss at step 10227: 0.037599340081214905\n",
      "2017-11-11 08:51:20: Loss at step 10228: 0.03757646679878235\n",
      "2017-11-11 08:51:20: Loss at step 10229: 0.03760727867484093\n",
      "2017-11-11 08:51:20: Loss at step 10230: 0.037546608597040176\n",
      "2017-11-11 08:51:21: Loss at step 10231: 0.037626203149557114\n",
      "2017-11-11 08:51:21: Loss at step 10232: 0.03757701441645622\n",
      "2017-11-11 08:51:22: Loss at step 10233: 0.037666816264390945\n",
      "2017-11-11 08:51:23: Loss at step 10234: 0.03751664608716965\n",
      "2017-11-11 08:51:23: Loss at step 10235: 0.03765308856964111\n",
      "2017-11-11 08:51:24: Loss at step 10236: 0.0376741886138916\n",
      "2017-11-11 08:51:24: Loss at step 10237: 0.03762943670153618\n",
      "2017-11-11 08:51:25: Loss at step 10238: 0.03767300769686699\n",
      "2017-11-11 08:51:25: Loss at step 10239: 0.0376383438706398\n",
      "2017-11-11 08:51:26: Loss at step 10240: 0.03767824172973633\n",
      "2017-11-11 08:51:26: Loss at step 10241: 0.037626251578330994\n",
      "2017-11-11 08:51:27: Loss at step 10242: 0.037720900028944016\n",
      "2017-11-11 08:51:27: Loss at step 10243: 0.037634141743183136\n",
      "2017-11-11 08:51:28: Loss at step 10244: 0.03756047785282135\n",
      "2017-11-11 08:51:28: Loss at step 10245: 0.03764628246426582\n",
      "2017-11-11 08:51:29: Loss at step 10246: 0.03772905841469765\n",
      "2017-11-11 08:51:29: Loss at step 10247: 0.03766847401857376\n",
      "2017-11-11 08:51:30: Loss at step 10248: 0.03755657747387886\n",
      "2017-11-11 08:51:30: Loss at step 10249: 0.03760659694671631\n",
      "2017-11-11 08:51:31: Loss at step 10250: 0.03771941363811493\n",
      "2017-11-11 08:51:31: Loss at step 10251: 0.037565313279628754\n",
      "2017-11-11 08:51:32: Loss at step 10252: 0.03753088787198067\n",
      "2017-11-11 08:51:32: Loss at step 10253: 0.0375659316778183\n",
      "2017-11-11 08:51:33: Loss at step 10254: 0.03762517124414444\n",
      "2017-11-11 08:51:34: Loss at step 10255: 0.03765460103750229\n",
      "2017-11-11 08:51:34: Loss at step 10256: 0.037709977477788925\n",
      "2017-11-11 08:51:35: Loss at step 10257: 0.0376753956079483\n",
      "2017-11-11 08:51:35: Loss at step 10258: 0.03766985237598419\n",
      "2017-11-11 08:51:36: Loss at step 10259: 0.037654731422662735\n",
      "2017-11-11 08:51:36: Loss at step 10260: 0.037637483328580856\n",
      "2017-11-11 08:51:37: Loss at step 10261: 0.0376327820122242\n",
      "2017-11-11 08:51:37: Loss at step 10262: 0.03763921558856964\n",
      "2017-11-11 08:51:38: Loss at step 10263: 0.03767691180109978\n",
      "2017-11-11 08:51:38: Loss at step 10264: 0.037635017186403275\n",
      "2017-11-11 08:51:39: Loss at step 10265: 0.03763803467154503\n",
      "2017-11-11 08:51:39: Loss at step 10266: 0.037718359380960464\n",
      "2017-11-11 08:51:40: Loss at step 10267: 0.03767905756831169\n",
      "2017-11-11 08:51:40: Loss at step 10268: 0.037594154477119446\n",
      "2017-11-11 08:51:41: Loss at step 10269: 0.037640321999788284\n",
      "2017-11-11 08:51:41: Loss at step 10270: 0.03767142817378044\n",
      "2017-11-11 08:51:42: Loss at step 10271: 0.037627507001161575\n",
      "2017-11-11 08:51:42: Loss at step 10272: 0.037663500756025314\n",
      "2017-11-11 08:51:43: Loss at step 10273: 0.03765488788485527\n",
      "2017-11-11 08:51:43: Loss at step 10274: 0.03758009523153305\n",
      "2017-11-11 08:51:44: Loss at step 10275: 0.03765394166111946\n",
      "2017-11-11 08:51:44: Loss at step 10276: 0.037666935473680496\n",
      "2017-11-11 08:51:45: Loss at step 10277: 0.03773758187890053\n",
      "2017-11-11 08:51:45: Loss at step 10278: 0.037665728479623795\n",
      "2017-11-11 08:51:46: Loss at step 10279: 0.03760913014411926\n",
      "2017-11-11 08:51:46: Loss at step 10280: 0.037600453943014145\n",
      "2017-11-11 08:51:47: Loss at step 10281: 0.03767131268978119\n",
      "2017-11-11 08:51:47: Loss at step 10282: 0.0376380980014801\n",
      "2017-11-11 08:51:48: Loss at step 10283: 0.037577833980321884\n",
      "2017-11-11 08:51:48: Loss at step 10284: 0.03757468983530998\n",
      "2017-11-11 08:51:49: Loss at step 10285: 0.03765726462006569\n",
      "2017-11-11 08:51:49: Loss at step 10286: 0.03749898076057434\n",
      "2017-11-11 08:51:50: Loss at step 10287: 0.037690576165914536\n",
      "2017-11-11 08:51:50: Loss at step 10288: 0.03765431046485901\n",
      "2017-11-11 08:51:51: Loss at step 10289: 0.0376054123044014\n",
      "2017-11-11 08:51:52: Loss at step 10290: 0.037655510008335114\n",
      "2017-11-11 08:51:52: Loss at step 10291: 0.03765919432044029\n",
      "2017-11-11 08:51:53: Loss at step 10292: 0.03765415772795677\n",
      "2017-11-11 08:51:53: Loss at step 10293: 0.03766492009162903\n",
      "2017-11-11 08:51:54: Loss at step 10294: 0.03769342228770256\n",
      "2017-11-11 08:51:54: Loss at step 10295: 0.037700578570365906\n",
      "2017-11-11 08:51:55: Loss at step 10296: 0.03765566274523735\n",
      "2017-11-11 08:51:55: Loss at step 10297: 0.037628620862960815\n",
      "2017-11-11 08:51:56: Loss at step 10298: 0.03761311620473862\n",
      "2017-11-11 08:51:56: Loss at step 10299: 0.03767871856689453\n",
      "2017-11-11 08:51:57: Loss at step 10300: 0.037704020738601685\n",
      "2017-11-11 08:51:57: Loss at step 10301: 0.03757011890411377\n",
      "2017-11-11 08:51:58: Loss at step 10302: 0.037562496960163116\n",
      "2017-11-11 08:51:58: Loss at step 10303: 0.037587087601423264\n",
      "2017-11-11 08:51:59: Loss at step 10304: 0.037571363151073456\n",
      "2017-11-11 08:51:59: Loss at step 10305: 0.03765871748328209\n",
      "2017-11-11 08:52:00: Loss at step 10306: 0.03764263540506363\n",
      "2017-11-11 08:52:00: Loss at step 10307: 0.03767665848135948\n",
      "2017-11-11 08:52:01: Loss at step 10308: 0.03762173280119896\n",
      "2017-11-11 08:52:01: Loss at step 10309: 0.03753945976495743\n",
      "2017-11-11 08:52:02: Loss at step 10310: 0.03771745413541794\n",
      "2017-11-11 08:52:02: Loss at step 10311: 0.03759137541055679\n",
      "2017-11-11 08:52:03: Loss at step 10312: 0.03761155903339386\n",
      "2017-11-11 08:52:03: Loss at step 10313: 0.03756103664636612\n",
      "2017-11-11 08:52:04: Loss at step 10314: 0.03767085447907448\n",
      "2017-11-11 08:52:04: Loss at step 10315: 0.03766676411032677\n",
      "2017-11-11 08:52:05: Loss at step 10316: 0.03756614029407501\n",
      "2017-11-11 08:52:05: Loss at step 10317: 0.03757815435528755\n",
      "2017-11-11 08:52:06: Loss at step 10318: 0.03769524395465851\n",
      "2017-11-11 08:52:06: Loss at step 10319: 0.03768946975469589\n",
      "2017-11-11 08:52:07: Loss at step 10320: 0.03772221505641937\n",
      "2017-11-11 08:52:07: Loss at step 10321: 0.037561219185590744\n",
      "2017-11-11 08:52:08: Loss at step 10322: 0.03756478428840637\n",
      "2017-11-11 08:52:08: Loss at step 10323: 0.03759980574250221\n",
      "2017-11-11 08:52:09: Loss at step 10324: 0.037620510905981064\n",
      "2017-11-11 08:52:09: Loss at step 10325: 0.037600062787532806\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-11-11 08:52:10: Loss at step 10326: 0.03764718398451805\n",
      "2017-11-11 08:52:11: Loss at step 10327: 0.03760843351483345\n",
      "2017-11-11 08:52:11: Loss at step 10328: 0.037567052990198135\n",
      "2017-11-11 08:52:12: Loss at step 10329: 0.03763711452484131\n",
      "2017-11-11 08:52:12: Loss at step 10330: 0.037546467036008835\n",
      "2017-11-11 08:52:13: Loss at step 10331: 0.03762674704194069\n",
      "2017-11-11 08:52:13: Loss at step 10332: 0.037751760333776474\n",
      "2017-11-11 08:52:14: Loss at step 10333: 0.03762928023934364\n",
      "2017-11-11 08:52:14: Loss at step 10334: 0.03764347359538078\n",
      "2017-11-11 08:52:15: Loss at step 10335: 0.03761756420135498\n",
      "2017-11-11 08:52:15: Loss at step 10336: 0.03760705515742302\n",
      "2017-11-11 08:52:16: Loss at step 10337: 0.037680886685848236\n",
      "2017-11-11 08:52:16: Loss at step 10338: 0.03765212371945381\n",
      "2017-11-11 08:52:17: Loss at step 10339: 0.03763092681765556\n",
      "2017-11-11 08:52:17: Loss at step 10340: 0.037588704377412796\n",
      "2017-11-11 08:52:18: Loss at step 10341: 0.03771791234612465\n",
      "2017-11-11 08:52:18: Loss at step 10342: 0.03766666352748871\n",
      "2017-11-11 08:52:19: Loss at step 10343: 0.03763098269701004\n",
      "2017-11-11 08:52:19: Loss at step 10344: 0.03759957104921341\n",
      "2017-11-11 08:52:20: Loss at step 10345: 0.037695154547691345\n",
      "2017-11-11 08:52:20: Loss at step 10346: 0.03766931593418121\n",
      "2017-11-11 08:52:21: Loss at step 10347: 0.03768795356154442\n",
      "2017-11-11 08:52:21: Loss at step 10348: 0.037598300725221634\n",
      "2017-11-11 08:52:22: Loss at step 10349: 0.03760527819395065\n",
      "2017-11-11 08:52:22: Loss at step 10350: 0.03765549138188362\n",
      "2017-11-11 08:52:23: Loss at step 10351: 0.03777126595377922\n",
      "2017-11-11 08:52:23: Loss at step 10352: 0.037589702755212784\n",
      "2017-11-11 08:52:24: Loss at step 10353: 0.03758016973733902\n",
      "2017-11-11 08:52:24: Loss at step 10354: 0.037532635033130646\n",
      "2017-11-11 08:52:25: Loss at step 10355: 0.037607401609420776\n",
      "2017-11-11 08:52:25: Loss at step 10356: 0.037738535553216934\n",
      "2017-11-11 08:52:26: Loss at step 10357: 0.03762391582131386\n",
      "2017-11-11 08:52:26: Loss at step 10358: 0.037711407989263535\n",
      "2017-11-11 08:52:27: Loss at step 10359: 0.03766666725277901\n",
      "2017-11-11 08:52:27: Loss at step 10360: 0.03769000992178917\n",
      "2017-11-11 08:52:28: Loss at step 10361: 0.037707410752773285\n",
      "2017-11-11 08:52:28: Loss at step 10362: 0.03763866424560547\n",
      "2017-11-11 08:52:29: Loss at step 10363: 0.037730444222688675\n",
      "2017-11-11 08:52:29: Loss at step 10364: 0.03756549209356308\n",
      "2017-11-11 08:52:30: Loss at step 10365: 0.037635255604982376\n",
      "2017-11-11 08:52:30: Loss at step 10366: 0.0377129465341568\n",
      "2017-11-11 08:52:31: Loss at step 10367: 0.037655193358659744\n",
      "2017-11-11 08:52:31: Loss at step 10368: 0.03777126595377922\n",
      "2017-11-11 08:52:32: Loss at step 10369: 0.037740930914878845\n",
      "2017-11-11 08:52:33: Loss at step 10370: 0.03768245875835419\n",
      "2017-11-11 08:52:33: Loss at step 10371: 0.037742480635643005\n",
      "2017-11-11 08:52:34: Loss at step 10372: 0.037626802921295166\n",
      "2017-11-11 08:52:34: Loss at step 10373: 0.037624794989824295\n",
      "2017-11-11 08:52:35: Loss at step 10374: 0.0376502200961113\n",
      "2017-11-11 08:52:35: Loss at step 10375: 0.03765750303864479\n",
      "2017-11-11 08:52:36: Loss at step 10376: 0.03778883069753647\n",
      "2017-11-11 08:52:36: Loss at step 10377: 0.03765295073390007\n",
      "2017-11-11 08:52:37: Loss at step 10378: 0.03765979781746864\n",
      "2017-11-11 08:52:37: Loss at step 10379: 0.037626996636390686\n",
      "2017-11-11 08:52:38: Loss at step 10380: 0.03759033977985382\n",
      "2017-11-11 08:52:38: Loss at step 10381: 0.03765261173248291\n",
      "2017-11-11 08:52:39: Loss at step 10382: 0.03753179311752319\n",
      "2017-11-11 08:52:39: Loss at step 10383: 0.03764117881655693\n",
      "2017-11-11 08:52:40: Loss at step 10384: 0.037668000906705856\n",
      "2017-11-11 08:52:40: Loss at step 10385: 0.03759605810046196\n",
      "2017-11-11 08:52:41: Loss at step 10386: 0.03768397867679596\n",
      "2017-11-11 08:52:41: Loss at step 10387: 0.03757655620574951\n",
      "2017-11-11 08:52:42: Loss at step 10388: 0.037636637687683105\n",
      "2017-11-11 08:52:42: Loss at step 10389: 0.03750050067901611\n",
      "2017-11-11 08:52:43: Loss at step 10390: 0.03762882947921753\n",
      "2017-11-11 08:52:43: Loss at step 10391: 0.03759906068444252\n",
      "2017-11-11 08:52:44: Loss at step 10392: 0.0375419445335865\n",
      "2017-11-11 08:52:44: Loss at step 10393: 0.0376843623816967\n",
      "2017-11-11 08:52:45: Loss at step 10394: 0.037614814937114716\n",
      "2017-11-11 08:52:45: Loss at step 10395: 0.037569835782051086\n",
      "2017-11-11 08:52:46: Loss at step 10396: 0.037536270916461945\n",
      "2017-11-11 08:52:46: Loss at step 10397: 0.037578556686639786\n",
      "2017-11-11 08:52:47: Loss at step 10398: 0.03761148825287819\n",
      "2017-11-11 08:52:47: Loss at step 10399: 0.03771514818072319\n",
      "2017-11-11 08:52:48: Loss at step 10400: 0.03765183687210083\n",
      "2017-11-11 08:52:48: Loss at step 10401: 0.03769681230187416\n",
      "2017-11-11 08:52:49: Loss at step 10402: 0.037663161754608154\n",
      "2017-11-11 08:52:49: Loss at step 10403: 0.037694163620471954\n",
      "2017-11-11 08:52:50: Loss at step 10404: 0.03764686360955238\n",
      "2017-11-11 08:52:51: Loss at step 10405: 0.03768724575638771\n",
      "2017-11-11 08:52:51: Loss at step 10406: 0.03767572343349457\n",
      "2017-11-11 08:52:52: Loss at step 10407: 0.03758787736296654\n",
      "2017-11-11 08:52:52: Loss at step 10408: 0.03764607012271881\n",
      "2017-11-11 08:52:53: Loss at step 10409: 0.03766019269824028\n",
      "2017-11-11 08:52:53: Loss at step 10410: 0.03764081373810768\n",
      "2017-11-11 08:52:54: Loss at step 10411: 0.037601400166749954\n",
      "2017-11-11 08:52:54: Loss at step 10412: 0.037567298859357834\n",
      "2017-11-11 08:52:55: Loss at step 10413: 0.037512052804231644\n",
      "2017-11-11 08:52:55: Loss at step 10414: 0.03761128708720207\n",
      "2017-11-11 08:52:56: Loss at step 10415: 0.037648603320121765\n",
      "2017-11-11 08:52:56: Loss at step 10416: 0.037652552127838135\n",
      "2017-11-11 08:52:57: Loss at step 10417: 0.03765132278203964\n",
      "2017-11-11 08:52:57: Loss at step 10418: 0.03760029375553131\n",
      "2017-11-11 08:52:58: Loss at step 10419: 0.03764897957444191\n",
      "2017-11-11 08:52:58: Loss at step 10420: 0.0376184806227684\n",
      "2017-11-11 08:52:59: Loss at step 10421: 0.03771628439426422\n",
      "2017-11-11 08:52:59: Loss at step 10422: 0.03756198659539223\n",
      "2017-11-11 08:53:00: Loss at step 10423: 0.03764215111732483\n",
      "2017-11-11 08:53:00: Loss at step 10424: 0.03758886829018593\n",
      "2017-11-11 08:53:01: Loss at step 10425: 0.03770841658115387\n",
      "2017-11-11 08:53:01: Loss at step 10426: 0.03765692189335823\n",
      "2017-11-11 08:53:02: Loss at step 10427: 0.037656720727682114\n",
      "2017-11-11 08:53:02: Loss at step 10428: 0.0376531183719635\n",
      "2017-11-11 08:53:03: Loss at step 10429: 0.037558771669864655\n",
      "2017-11-11 08:53:03: Loss at step 10430: 0.03764094412326813\n",
      "2017-11-11 08:53:04: Loss at step 10431: 0.03770468384027481\n",
      "2017-11-11 08:53:04: Loss at step 10432: 0.0376826673746109\n",
      "2017-11-11 08:53:05: Loss at step 10433: 0.03764054551720619\n",
      "2017-11-11 08:53:05: Loss at step 10434: 0.03756105899810791\n",
      "2017-11-11 08:53:06: Loss at step 10435: 0.037614159286022186\n",
      "2017-11-11 08:53:06: Loss at step 10436: 0.03760753944516182\n",
      "2017-11-11 08:53:07: Loss at step 10437: 0.037614140659570694\n",
      "2017-11-11 08:53:07: Loss at step 10438: 0.037645891308784485\n",
      "2017-11-11 08:53:08: Loss at step 10439: 0.03759894520044327\n",
      "2017-11-11 08:53:08: Loss at step 10440: 0.03764462471008301\n",
      "2017-11-11 08:53:09: Loss at step 10441: 0.03762487322092056\n",
      "2017-11-11 08:53:09: Loss at step 10442: 0.03765636682510376\n",
      "2017-11-11 08:53:10: Loss at step 10443: 0.03756989911198616\n",
      "2017-11-11 08:53:11: Loss at step 10444: 0.037711840122938156\n",
      "2017-11-11 08:53:11: Loss at step 10445: 0.03762781247496605\n",
      "2017-11-11 08:53:12: Loss at step 10446: 0.03771213814616203\n",
      "2017-11-11 08:53:12: Loss at step 10447: 0.03762055188417435\n",
      "2017-11-11 08:53:13: Loss at step 10448: 0.03757784888148308\n",
      "2017-11-11 08:53:13: Loss at step 10449: 0.03774049133062363\n",
      "2017-11-11 08:53:14: Loss at step 10450: 0.03763055428862572\n",
      "2017-11-11 08:53:14: Loss at step 10451: 0.03763454407453537\n",
      "2017-11-11 08:53:15: Loss at step 10452: 0.037724800407886505\n",
      "2017-11-11 08:53:15: Loss at step 10453: 0.03769265115261078\n",
      "2017-11-11 08:53:16: Loss at step 10454: 0.037627074867486954\n",
      "2017-11-11 08:53:16: Loss at step 10455: 0.03766043111681938\n",
      "2017-11-11 08:53:17: Loss at step 10456: 0.037557847797870636\n",
      "2017-11-11 08:53:17: Loss at step 10457: 0.03767188638448715\n",
      "2017-11-11 08:53:18: Loss at step 10458: 0.03760543838143349\n",
      "2017-11-11 08:53:18: Loss at step 10459: 0.03765232861042023\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-11-11 08:53:19: Loss at step 10460: 0.03769218921661377\n",
      "2017-11-11 08:53:19: Loss at step 10461: 0.037730079144239426\n",
      "2017-11-11 08:53:20: Loss at step 10462: 0.03771062567830086\n",
      "2017-11-11 08:53:20: Loss at step 10463: 0.03768695518374443\n",
      "2017-11-11 08:53:21: Loss at step 10464: 0.037738554179668427\n",
      "2017-11-11 08:53:21: Loss at step 10465: 0.03773776814341545\n",
      "2017-11-11 08:53:22: Loss at step 10466: 0.037788841873407364\n",
      "2017-11-11 08:53:22: Loss at step 10467: 0.03765663877129555\n",
      "2017-11-11 08:53:23: Loss at step 10468: 0.03779149800539017\n",
      "2017-11-11 08:53:23: Loss at step 10469: 0.03778703510761261\n",
      "2017-11-11 08:53:24: Loss at step 10470: 0.03775092959403992\n",
      "2017-11-11 08:53:24: Loss at step 10471: 0.037903111428022385\n",
      "2017-11-11 08:53:25: Loss at step 10472: 0.037866778671741486\n",
      "2017-11-11 08:53:25: Loss at step 10473: 0.03791171312332153\n",
      "2017-11-11 08:53:26: Loss at step 10474: 0.037908583879470825\n",
      "2017-11-11 08:53:26: Loss at step 10475: 0.03788118436932564\n",
      "2017-11-11 08:53:27: Loss at step 10476: 0.038015369325876236\n",
      "2017-11-11 08:53:27: Loss at step 10477: 0.03800668194890022\n",
      "2017-11-11 08:53:28: Loss at step 10478: 0.03842245042324066\n",
      "2017-11-11 08:53:28: Loss at step 10479: 0.0383145771920681\n",
      "2017-11-11 08:53:29: Loss at step 10480: 0.03816092386841774\n",
      "2017-11-11 08:53:29: Loss at step 10481: 0.03845830634236336\n",
      "2017-11-11 08:53:30: Loss at step 10482: 0.0383608415722847\n",
      "2017-11-11 08:53:31: Loss at step 10483: 0.03836484253406525\n",
      "2017-11-11 08:53:31: Loss at step 10484: 0.03827507421374321\n",
      "2017-11-11 08:53:32: Loss at step 10485: 0.038554735481739044\n",
      "2017-11-11 08:53:32: Loss at step 10486: 0.03818707913160324\n",
      "2017-11-11 08:53:33: Loss at step 10487: 0.03810587897896767\n",
      "2017-11-11 08:53:33: Loss at step 10488: 0.03794814646244049\n",
      "2017-11-11 08:53:34: Loss at step 10489: 0.0386800579726696\n",
      "2017-11-11 08:53:34: Loss at step 10490: 0.038256194442510605\n",
      "2017-11-11 08:53:35: Loss at step 10491: 0.03855547308921814\n",
      "2017-11-11 08:53:35: Loss at step 10492: 0.03880966827273369\n",
      "2017-11-11 08:53:36: Loss at step 10493: 0.038637224584817886\n",
      "2017-11-11 08:53:36: Loss at step 10494: 0.03874252364039421\n",
      "2017-11-11 08:53:37: Loss at step 10495: 0.0389070063829422\n",
      "2017-11-11 08:53:37: Loss at step 10496: 0.03869837149977684\n",
      "2017-11-11 08:53:38: Loss at step 10497: 0.03869786113500595\n",
      "2017-11-11 08:53:38: Loss at step 10498: 0.03876299783587456\n",
      "2017-11-11 08:53:39: Loss at step 10499: 0.03873668983578682\n",
      "2017-11-11 08:53:39: Loss at step 10500: 0.038746099919080734\n",
      "2017-11-11 08:53:40: Loss at step 10501: 0.038706108927726746\n",
      "2017-11-11 08:53:40: Loss at step 10502: 0.03866828605532646\n",
      "2017-11-11 08:53:41: Loss at step 10503: 0.038633350282907486\n",
      "2017-11-11 08:53:41: Loss at step 10504: 0.0386313833296299\n",
      "2017-11-11 08:53:42: Loss at step 10505: 0.03859151154756546\n",
      "2017-11-11 08:53:42: Loss at step 10506: 0.038673028349876404\n",
      "2017-11-11 08:53:43: Loss at step 10507: 0.038568172603845596\n",
      "2017-11-11 08:53:43: Loss at step 10508: 0.03865673765540123\n",
      "2017-11-11 08:53:44: Loss at step 10509: 0.03858562558889389\n",
      "2017-11-11 08:53:44: Loss at step 10510: 0.038456156849861145\n",
      "2017-11-11 08:53:45: Loss at step 10511: 0.03857570141553879\n",
      "2017-11-11 08:53:45: Loss at step 10512: 0.03861498832702637\n",
      "2017-11-11 08:53:46: Loss at step 10513: 0.03862645477056503\n",
      "2017-11-11 08:53:46: Loss at step 10514: 0.038549989461898804\n",
      "2017-11-11 08:53:47: Loss at step 10515: 0.03859778121113777\n",
      "2017-11-11 08:53:47: Loss at step 10516: 0.0385882668197155\n",
      "2017-11-11 08:53:48: Loss at step 10517: 0.038512762635946274\n",
      "2017-11-11 08:53:48: Loss at step 10518: 0.03854626417160034\n",
      "2017-11-11 08:53:49: Loss at step 10519: 0.038500986993312836\n",
      "2017-11-11 08:53:49: Loss at step 10520: 0.03851766511797905\n",
      "2017-11-11 08:53:50: Loss at step 10521: 0.03859780356287956\n",
      "2017-11-11 08:53:50: Loss at step 10522: 0.03855002298951149\n",
      "2017-11-11 08:53:51: Loss at step 10523: 0.03847590461373329\n",
      "2017-11-11 08:53:52: Loss at step 10524: 0.038635868579149246\n",
      "2017-11-11 08:53:52: Loss at step 10525: 0.0385366827249527\n",
      "2017-11-11 08:53:52: Loss at step 10526: 0.038614995777606964\n",
      "2017-11-11 08:53:53: Loss at step 10527: 0.038510873913764954\n",
      "2017-11-11 08:53:54: Loss at step 10528: 0.03846003860235214\n",
      "2017-11-11 08:53:54: Loss at step 10529: 0.03857356682419777\n",
      "2017-11-11 08:53:54: Loss at step 10530: 0.03853147104382515\n",
      "2017-11-11 08:53:55: Loss at step 10531: 0.03853878006339073\n",
      "2017-11-11 08:53:56: Loss at step 10532: 0.038531504571437836\n",
      "2017-11-11 08:53:56: Loss at step 10533: 0.03852919116616249\n",
      "2017-11-11 08:53:57: Loss at step 10534: 0.038548149168491364\n",
      "2017-11-11 08:53:57: Loss at step 10535: 0.03858001157641411\n",
      "2017-11-11 08:53:58: Loss at step 10536: 0.03856462240219116\n",
      "2017-11-11 08:53:58: Loss at step 10537: 0.038475215435028076\n",
      "2017-11-11 08:53:59: Loss at step 10538: 0.03853773698210716\n",
      "2017-11-11 08:53:59: Loss at step 10539: 0.03858087211847305\n",
      "2017-11-11 08:54:00: Loss at step 10540: 0.03846098482608795\n",
      "2017-11-11 08:54:00: Loss at step 10541: 0.038408875465393066\n",
      "2017-11-11 08:54:01: Loss at step 10542: 0.03846682608127594\n",
      "2017-11-11 08:54:01: Loss at step 10543: 0.038622401654720306\n",
      "2017-11-11 08:54:02: Loss at step 10544: 0.03860105201601982\n",
      "2017-11-11 08:54:02: Loss at step 10545: 0.038582563400268555\n",
      "2017-11-11 08:54:03: Loss at step 10546: 0.03853989765048027\n",
      "2017-11-11 08:54:03: Loss at step 10547: 0.038513243198394775\n",
      "2017-11-11 08:54:04: Loss at step 10548: 0.038523729890584946\n",
      "2017-11-11 08:54:04: Loss at step 10549: 0.03858732432126999\n",
      "2017-11-11 08:54:05: Loss at step 10550: 0.038541462272405624\n",
      "2017-11-11 08:54:05: Loss at step 10551: 0.038478318601846695\n",
      "2017-11-11 08:54:06: Loss at step 10552: 0.03851402923464775\n",
      "2017-11-11 08:54:06: Loss at step 10553: 0.03858641907572746\n",
      "2017-11-11 08:54:07: Loss at step 10554: 0.038563814014196396\n",
      "2017-11-11 08:54:07: Loss at step 10555: 0.038542747497558594\n",
      "2017-11-11 08:54:08: Loss at step 10556: 0.03847763314843178\n",
      "2017-11-11 08:54:08: Loss at step 10557: 0.038449808955192566\n",
      "2017-11-11 08:54:09: Loss at step 10558: 0.03857598826289177\n",
      "2017-11-11 08:54:09: Loss at step 10559: 0.038518670946359634\n",
      "2017-11-11 08:54:10: Loss at step 10560: 0.03858250007033348\n",
      "2017-11-11 08:54:11: Loss at step 10561: 0.03852618858218193\n",
      "2017-11-11 08:54:11: Loss at step 10562: 0.03843476623296738\n",
      "2017-11-11 08:54:12: Loss at step 10563: 0.03846950829029083\n",
      "2017-11-11 08:54:12: Loss at step 10564: 0.03853204473853111\n",
      "2017-11-11 08:54:13: Loss at step 10565: 0.03856992349028587\n",
      "2017-11-11 08:54:13: Loss at step 10566: 0.038599833846092224\n",
      "2017-11-11 08:54:14: Loss at step 10567: 0.0385696217417717\n",
      "2017-11-11 08:54:14: Loss at step 10568: 0.03849116340279579\n",
      "2017-11-11 08:54:15: Loss at step 10569: 0.03849797695875168\n",
      "2017-11-11 08:54:15: Loss at step 10570: 0.038616735488176346\n",
      "2017-11-11 08:54:16: Loss at step 10571: 0.03855976462364197\n",
      "2017-11-11 08:54:16: Loss at step 10572: 0.03849266469478607\n",
      "2017-11-11 08:54:17: Loss at step 10573: 0.038514114916324615\n",
      "2017-11-11 08:54:17: Loss at step 10574: 0.03847653791308403\n",
      "2017-11-11 08:54:18: Loss at step 10575: 0.03855135291814804\n",
      "2017-11-11 08:54:18: Loss at step 10576: 0.038614265620708466\n",
      "2017-11-11 08:54:19: Loss at step 10577: 0.03850187733769417\n",
      "2017-11-11 08:54:19: Loss at step 10578: 0.0384935587644577\n",
      "2017-11-11 08:54:20: Loss at step 10579: 0.03852825611829758\n",
      "2017-11-11 08:54:20: Loss at step 10580: 0.03856215998530388\n",
      "2017-11-11 08:54:21: Loss at step 10581: 0.038586873561143875\n",
      "2017-11-11 08:54:21: Loss at step 10582: 0.03849220275878906\n",
      "2017-11-11 08:54:22: Loss at step 10583: 0.03861469030380249\n",
      "2017-11-11 08:54:22: Loss at step 10584: 0.03864484280347824\n",
      "2017-11-11 08:54:23: Loss at step 10585: 0.0385233610868454\n",
      "2017-11-11 08:54:23: Loss at step 10586: 0.038571715354919434\n",
      "2017-11-11 08:54:24: Loss at step 10587: 0.03850363940000534\n",
      "2017-11-11 08:54:24: Loss at step 10588: 0.03861542046070099\n",
      "2017-11-11 08:54:25: Loss at step 10589: 0.03857439383864403\n",
      "2017-11-11 08:54:26: Loss at step 10590: 0.03850372135639191\n",
      "2017-11-11 08:54:26: Loss at step 10591: 0.038525912910699844\n",
      "2017-11-11 08:54:26: Loss at step 10592: 0.03854577988386154\n",
      "2017-11-11 08:54:27: Loss at step 10593: 0.038648590445518494\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-11-11 08:54:27: Loss at step 10594: 0.03845330700278282\n",
      "2017-11-11 08:54:28: Loss at step 10595: 0.03853289783000946\n",
      "2017-11-11 08:54:28: Loss at step 10596: 0.0384829118847847\n",
      "2017-11-11 08:54:29: Loss at step 10597: 0.03851502761244774\n",
      "2017-11-11 08:54:29: Loss at step 10598: 0.038587622344493866\n",
      "2017-11-11 08:54:30: Loss at step 10599: 0.03859969973564148\n",
      "2017-11-11 08:54:31: Loss at step 10600: 0.0385841503739357\n",
      "2017-11-11 08:54:31: Loss at step 10601: 0.03856658190488815\n",
      "2017-11-11 08:54:32: Loss at step 10602: 0.038490377366542816\n",
      "2017-11-11 08:54:32: Loss at step 10603: 0.038515448570251465\n",
      "2017-11-11 08:54:33: Loss at step 10604: 0.03846147656440735\n",
      "2017-11-11 08:54:33: Loss at step 10605: 0.03847934305667877\n",
      "2017-11-11 08:54:34: Loss at step 10606: 0.038651179522275925\n",
      "2017-11-11 08:54:34: Loss at step 10607: 0.03856020048260689\n",
      "2017-11-11 08:54:35: Loss at step 10608: 0.03858015313744545\n",
      "2017-11-11 08:54:35: Loss at step 10609: 0.038412388414144516\n",
      "2017-11-11 08:54:36: Loss at step 10610: 0.03854681923985481\n",
      "2017-11-11 08:54:36: Loss at step 10611: 0.03856772556900978\n",
      "2017-11-11 08:54:37: Loss at step 10612: 0.03859613090753555\n",
      "2017-11-11 08:54:37: Loss at step 10613: 0.038531217724084854\n",
      "2017-11-11 08:54:38: Loss at step 10614: 0.038514379411935806\n",
      "2017-11-11 08:54:38: Loss at step 10615: 0.038429711014032364\n",
      "2017-11-11 08:54:39: Loss at step 10616: 0.03848841413855553\n",
      "2017-11-11 08:54:39: Loss at step 10617: 0.03859235346317291\n",
      "2017-11-11 08:54:40: Loss at step 10618: 0.03863914683461189\n",
      "2017-11-11 08:54:40: Loss at step 10619: 0.03858440741896629\n",
      "2017-11-11 08:54:41: Loss at step 10620: 0.03854329511523247\n",
      "2017-11-11 08:54:41: Loss at step 10621: 0.03856637701392174\n",
      "2017-11-11 08:54:42: Loss at step 10622: 0.03848530352115631\n",
      "2017-11-11 08:54:42: Loss at step 10623: 0.03842205926775932\n",
      "2017-11-11 08:54:43: Loss at step 10624: 0.038517117500305176\n",
      "2017-11-11 08:54:43: Loss at step 10625: 0.038514427840709686\n",
      "2017-11-11 08:54:44: Loss at step 10626: 0.03851928561925888\n",
      "2017-11-11 08:54:44: Loss at step 10627: 0.038495440036058426\n",
      "2017-11-11 08:54:45: Loss at step 10628: 0.038549330085515976\n",
      "2017-11-11 08:54:45: Loss at step 10629: 0.03854089602828026\n",
      "2017-11-11 08:54:46: Loss at step 10630: 0.03853659704327583\n",
      "2017-11-11 08:54:46: Loss at step 10631: 0.0385420098900795\n",
      "2017-11-11 08:54:47: Loss at step 10632: 0.038500647991895676\n",
      "2017-11-11 08:54:47: Loss at step 10633: 0.03856884315609932\n",
      "2017-11-11 08:54:48: Loss at step 10634: 0.03853565827012062\n",
      "2017-11-11 08:54:48: Loss at step 10635: 0.03861522674560547\n",
      "2017-11-11 08:54:49: Loss at step 10636: 0.038465239107608795\n",
      "2017-11-11 08:54:49: Loss at step 10637: 0.03842702507972717\n",
      "2017-11-11 08:54:50: Loss at step 10638: 0.03846720606088638\n",
      "2017-11-11 08:54:51: Loss at step 10639: 0.03849473223090172\n",
      "2017-11-11 08:54:51: Loss at step 10640: 0.03844158723950386\n",
      "2017-11-11 08:54:52: Loss at step 10641: 0.03861299529671669\n",
      "2017-11-11 08:54:52: Loss at step 10642: 0.0385856032371521\n",
      "2017-11-11 08:54:53: Loss at step 10643: 0.0385466143488884\n",
      "2017-11-11 08:54:53: Loss at step 10644: 0.03852659463882446\n",
      "2017-11-11 08:54:54: Loss at step 10645: 0.03850233182311058\n",
      "2017-11-11 08:54:54: Loss at step 10646: 0.038571298122406006\n",
      "2017-11-11 08:54:55: Loss at step 10647: 0.03869539126753807\n",
      "2017-11-11 08:54:55: Loss at step 10648: 0.03863224387168884\n",
      "2017-11-11 08:54:56: Loss at step 10649: 0.038554348051548004\n",
      "2017-11-11 08:54:56: Loss at step 10650: 0.038566797971725464\n",
      "2017-11-11 08:54:57: Loss at step 10651: 0.038547955453395844\n",
      "2017-11-11 08:54:57: Loss at step 10652: 0.038513731211423874\n",
      "2017-11-11 08:54:58: Loss at step 10653: 0.03835967183113098\n",
      "2017-11-11 08:54:58: Loss at step 10654: 0.038509074598550797\n",
      "2017-11-11 08:54:59: Loss at step 10655: 0.03856576606631279\n",
      "2017-11-11 08:54:59: Loss at step 10656: 0.03849172219634056\n",
      "2017-11-11 08:55:00: Loss at step 10657: 0.03862643614411354\n",
      "2017-11-11 08:55:00: Loss at step 10658: 0.038558341562747955\n",
      "2017-11-11 08:55:01: Loss at step 10659: 0.03855450823903084\n",
      "2017-11-11 08:55:01: Loss at step 10660: 0.03848356753587723\n",
      "2017-11-11 08:55:02: Loss at step 10661: 0.038543373346328735\n",
      "2017-11-11 08:55:02: Loss at step 10662: 0.0385906919836998\n",
      "2017-11-11 08:55:03: Loss at step 10663: 0.038468215614557266\n",
      "2017-11-11 08:55:03: Loss at step 10664: 0.038536470383405685\n",
      "2017-11-11 08:55:04: Loss at step 10665: 0.038532134145498276\n",
      "2017-11-11 08:55:04: Loss at step 10666: 0.038628071546554565\n",
      "2017-11-11 08:55:05: Loss at step 10667: 0.038457464426755905\n",
      "2017-11-11 08:55:05: Loss at step 10668: 0.038549091666936874\n",
      "2017-11-11 08:55:06: Loss at step 10669: 0.03846544772386551\n",
      "2017-11-11 08:55:06: Loss at step 10670: 0.03855122625827789\n",
      "2017-11-11 08:55:07: Loss at step 10671: 0.03842088580131531\n",
      "2017-11-11 08:55:07: Loss at step 10672: 0.03847869858145714\n",
      "2017-11-11 08:55:08: Loss at step 10673: 0.038651660084724426\n",
      "2017-11-11 08:55:09: Loss at step 10674: 0.03850322961807251\n",
      "2017-11-11 08:55:09: Loss at step 10675: 0.038601260632276535\n",
      "2017-11-11 08:55:10: Loss at step 10676: 0.03860044851899147\n",
      "2017-11-11 08:55:10: Loss at step 10677: 0.03853526711463928\n",
      "2017-11-11 08:55:11: Loss at step 10678: 0.03853866085410118\n",
      "2017-11-11 08:55:11: Loss at step 10679: 0.03848528861999512\n",
      "2017-11-11 08:55:12: Loss at step 10680: 0.038550566881895065\n",
      "2017-11-11 08:55:12: Loss at step 10681: 0.0385696105659008\n",
      "2017-11-11 08:55:13: Loss at step 10682: 0.038495197892189026\n",
      "2017-11-11 08:55:13: Loss at step 10683: 0.03845611587166786\n",
      "2017-11-11 08:55:14: Loss at step 10684: 0.038552939891815186\n",
      "2017-11-11 08:55:14: Loss at step 10685: 0.03850607946515083\n",
      "2017-11-11 08:55:15: Loss at step 10686: 0.0386742539703846\n",
      "2017-11-11 08:55:15: Loss at step 10687: 0.03852544724941254\n",
      "2017-11-11 08:55:16: Loss at step 10688: 0.038544051349163055\n",
      "2017-11-11 08:55:16: Loss at step 10689: 0.03849199414253235\n",
      "2017-11-11 08:55:17: Loss at step 10690: 0.03853961080312729\n",
      "2017-11-11 08:55:17: Loss at step 10691: 0.038456641137599945\n",
      "2017-11-11 08:55:18: Loss at step 10692: 0.03839502111077309\n",
      "2017-11-11 08:55:18: Loss at step 10693: 0.038516540080308914\n",
      "2017-11-11 08:55:19: Loss at step 10694: 0.03847295418381691\n",
      "2017-11-11 08:55:19: Loss at step 10695: 0.03848860412836075\n",
      "2017-11-11 08:55:20: Loss at step 10696: 0.038612864911556244\n",
      "2017-11-11 08:55:20: Loss at step 10697: 0.038512375205755234\n",
      "2017-11-11 08:55:21: Loss at step 10698: 0.03860965743660927\n",
      "2017-11-11 08:55:21: Loss at step 10699: 0.038518279790878296\n",
      "2017-11-11 08:55:22: Loss at step 10700: 0.03864573687314987\n",
      "2017-11-11 08:55:22: Loss at step 10701: 0.03855717182159424\n",
      "2017-11-11 08:55:23: Loss at step 10702: 0.03843624144792557\n",
      "2017-11-11 08:55:24: Loss at step 10703: 0.03841787576675415\n",
      "2017-11-11 08:55:24: Loss at step 10704: 0.03851921856403351\n",
      "2017-11-11 08:55:25: Loss at step 10705: 0.03854585811495781\n",
      "2017-11-11 08:55:25: Loss at step 10706: 0.038615837693214417\n",
      "2017-11-11 08:55:26: Loss at step 10707: 0.03848806023597717\n",
      "2017-11-11 08:55:26: Loss at step 10708: 0.03867283836007118\n",
      "2017-11-11 08:55:27: Loss at step 10709: 0.03852963075041771\n",
      "2017-11-11 08:55:27: Loss at step 10710: 0.03863606974482536\n",
      "2017-11-11 08:55:28: Loss at step 10711: 0.03851945698261261\n",
      "2017-11-11 08:55:28: Loss at step 10712: 0.038562703877687454\n",
      "2017-11-11 08:55:29: Loss at step 10713: 0.03863487020134926\n",
      "2017-11-11 08:55:29: Loss at step 10714: 0.03869152441620827\n",
      "2017-11-11 08:55:30: Loss at step 10715: 0.03854425624012947\n",
      "2017-11-11 08:55:30: Loss at step 10716: 0.03849831968545914\n",
      "2017-11-11 08:55:31: Loss at step 10717: 0.038626328110694885\n",
      "2017-11-11 08:55:31: Loss at step 10718: 0.038602568209171295\n",
      "2017-11-11 08:55:32: Loss at step 10719: 0.0385286808013916\n",
      "2017-11-11 08:55:32: Loss at step 10720: 0.03851523622870445\n",
      "2017-11-11 08:55:33: Loss at step 10721: 0.03846355527639389\n",
      "2017-11-11 08:55:33: Loss at step 10722: 0.038518402725458145\n",
      "2017-11-11 08:55:34: Loss at step 10723: 0.038519591093063354\n",
      "2017-11-11 08:55:34: Loss at step 10724: 0.03861429914832115\n",
      "2017-11-11 08:55:35: Loss at step 10725: 0.038605593144893646\n",
      "2017-11-11 08:55:35: Loss at step 10726: 0.038455430418252945\n",
      "2017-11-11 08:55:36: Loss at step 10727: 0.03853912651538849\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-11-11 08:55:36: Loss at step 10728: 0.038527753204107285\n",
      "2017-11-11 08:55:37: Loss at step 10729: 0.03854770585894585\n",
      "2017-11-11 08:55:38: Loss at step 10730: 0.03862135112285614\n",
      "2017-11-11 08:55:38: Loss at step 10731: 0.03851025924086571\n",
      "2017-11-11 08:55:39: Loss at step 10732: 0.0384451299905777\n",
      "2017-11-11 08:55:39: Loss at step 10733: 0.03859136253595352\n",
      "2017-11-11 08:55:40: Loss at step 10734: 0.03850875422358513\n",
      "2017-11-11 08:55:40: Loss at step 10735: 0.03852534294128418\n",
      "2017-11-11 08:55:41: Loss at step 10736: 0.03851693123579025\n",
      "2017-11-11 08:55:41: Loss at step 10737: 0.03853737190365791\n",
      "2017-11-11 08:55:42: Loss at step 10738: 0.03864918276667595\n",
      "2017-11-11 08:55:42: Loss at step 10739: 0.03862525522708893\n",
      "2017-11-11 08:55:43: Loss at step 10740: 0.03849922493100166\n",
      "2017-11-11 08:55:43: Loss at step 10741: 0.03850476071238518\n",
      "2017-11-11 08:55:44: Loss at step 10742: 0.038525450974702835\n",
      "2017-11-11 08:55:44: Loss at step 10743: 0.03851034492254257\n",
      "2017-11-11 08:55:45: Loss at step 10744: 0.03850220516324043\n",
      "2017-11-11 08:55:45: Loss at step 10745: 0.03849533572793007\n",
      "2017-11-11 08:55:46: Loss at step 10746: 0.03848846256732941\n",
      "2017-11-11 08:55:46: Loss at step 10747: 0.038577500730752945\n",
      "2017-11-11 08:55:47: Loss at step 10748: 0.03862515091896057\n",
      "2017-11-11 08:55:47: Loss at step 10749: 0.03855156898498535\n",
      "2017-11-11 08:55:48: Loss at step 10750: 0.03856818750500679\n",
      "2017-11-11 08:55:48: Loss at step 10751: 0.03856484219431877\n",
      "2017-11-11 08:55:49: Loss at step 10752: 0.038630541414022446\n",
      "2017-11-11 08:55:49: Loss at step 10753: 0.03854632377624512\n",
      "2017-11-11 08:55:50: Loss at step 10754: 0.03865763172507286\n",
      "2017-11-11 08:55:50: Loss at step 10755: 0.038562316447496414\n",
      "2017-11-11 08:55:51: Loss at step 10756: 0.03866540268063545\n",
      "2017-11-11 08:55:51: Loss at step 10757: 0.03862481564283371\n",
      "2017-11-11 08:55:52: Loss at step 10758: 0.03849506378173828\n",
      "2017-11-11 08:55:52: Loss at step 10759: 0.03848728537559509\n",
      "2017-11-11 08:55:53: Loss at step 10760: 0.038503460586071014\n",
      "2017-11-11 08:55:53: Loss at step 10761: 0.03848982974886894\n",
      "2017-11-11 08:55:54: Loss at step 10762: 0.038618408143520355\n",
      "2017-11-11 08:55:54: Loss at step 10763: 0.03856445476412773\n",
      "2017-11-11 08:55:55: Loss at step 10764: 0.03843514993786812\n",
      "2017-11-11 08:55:55: Loss at step 10765: 0.038514573127031326\n",
      "2017-11-11 08:55:56: Loss at step 10766: 0.03848462924361229\n",
      "2017-11-11 08:55:56: Loss at step 10767: 0.03858138993382454\n",
      "2017-11-11 08:55:57: Loss at step 10768: 0.03852151334285736\n",
      "2017-11-11 08:55:58: Loss at step 10769: 0.038497552275657654\n",
      "2017-11-11 08:55:58: Loss at step 10770: 0.03840894252061844\n",
      "2017-11-11 08:55:59: Loss at step 10771: 0.03859678655862808\n",
      "2017-11-11 08:55:59: Loss at step 10772: 0.03859091177582741\n",
      "2017-11-11 08:56:00: Loss at step 10773: 0.038551878184080124\n",
      "2017-11-11 08:56:00: Loss at step 10774: 0.038538940250873566\n",
      "2017-11-11 08:56:01: Loss at step 10775: 0.038539085537195206\n",
      "2017-11-11 08:56:01: Loss at step 10776: 0.03859776258468628\n",
      "2017-11-11 08:56:02: Loss at step 10777: 0.03847424313426018\n",
      "2017-11-11 08:56:02: Loss at step 10778: 0.03848496824502945\n",
      "2017-11-11 08:56:03: Loss at step 10779: 0.03851105645298958\n",
      "2017-11-11 08:56:03: Loss at step 10780: 0.038508858531713486\n",
      "2017-11-11 08:56:04: Loss at step 10781: 0.03855070471763611\n",
      "2017-11-11 08:56:04: Loss at step 10782: 0.03862844407558441\n",
      "2017-11-11 08:56:05: Loss at step 10783: 0.038482315838336945\n",
      "2017-11-11 08:56:05: Loss at step 10784: 0.038599226623773575\n",
      "2017-11-11 08:56:06: Loss at step 10785: 0.038471974432468414\n",
      "2017-11-11 08:56:06: Loss at step 10786: 0.038592588156461716\n",
      "2017-11-11 08:56:07: Loss at step 10787: 0.03846634551882744\n",
      "2017-11-11 08:56:07: Loss at step 10788: 0.038434866815805435\n",
      "2017-11-11 08:56:08: Loss at step 10789: 0.038467321544885635\n",
      "2017-11-11 08:56:08: Loss at step 10790: 0.03848205506801605\n",
      "2017-11-11 08:56:09: Loss at step 10791: 0.038708966225385666\n",
      "2017-11-11 08:56:09: Loss at step 10792: 0.038526035845279694\n",
      "2017-11-11 08:56:10: Loss at step 10793: 0.038628894835710526\n",
      "2017-11-11 08:56:10: Loss at step 10794: 0.038500379770994186\n",
      "2017-11-11 08:56:11: Loss at step 10795: 0.038579072803258896\n",
      "2017-11-11 08:56:11: Loss at step 10796: 0.038556840270757675\n",
      "2017-11-11 08:56:12: Loss at step 10797: 0.03862103074789047\n",
      "2017-11-11 08:56:12: Loss at step 10798: 0.03861663490533829\n",
      "2017-11-11 08:56:13: Loss at step 10799: 0.0385703444480896\n",
      "2017-11-11 08:56:14: Loss at step 10800: 0.03854099288582802\n",
      "2017-11-11 08:56:14: Loss at step 10801: 0.03847164288163185\n",
      "2017-11-11 08:56:15: Loss at step 10802: 0.03862221539020538\n",
      "2017-11-11 08:56:15: Loss at step 10803: 0.03854059427976608\n",
      "2017-11-11 08:56:16: Loss at step 10804: 0.03861723467707634\n",
      "2017-11-11 08:56:16: Loss at step 10805: 0.03857971727848053\n",
      "2017-11-11 08:56:17: Loss at step 10806: 0.03844335302710533\n",
      "2017-11-11 08:56:17: Loss at step 10807: 0.03849881514906883\n",
      "2017-11-11 08:56:18: Loss at step 10808: 0.038522493094205856\n",
      "2017-11-11 08:56:18: Loss at step 10809: 0.038621846586465836\n",
      "2017-11-11 08:56:19: Loss at step 10810: 0.03858121857047081\n",
      "2017-11-11 08:56:19: Loss at step 10811: 0.038463424891233444\n",
      "2017-11-11 08:56:20: Loss at step 10812: 0.03854328766465187\n",
      "2017-11-11 08:56:20: Loss at step 10813: 0.03855578601360321\n",
      "2017-11-11 08:56:21: Loss at step 10814: 0.03852061927318573\n",
      "2017-11-11 08:56:21: Loss at step 10815: 0.038492489606142044\n",
      "2017-11-11 08:56:22: Loss at step 10816: 0.03850150480866432\n",
      "2017-11-11 08:56:22: Loss at step 10817: 0.038526635617017746\n",
      "2017-11-11 08:56:23: Loss at step 10818: 0.0386129766702652\n",
      "2017-11-11 08:56:23: Loss at step 10819: 0.03851781785488129\n",
      "2017-11-11 08:56:24: Loss at step 10820: 0.038462936878204346\n",
      "2017-11-11 08:56:24: Loss at step 10821: 0.03866913542151451\n",
      "2017-11-11 08:56:25: Loss at step 10822: 0.03861064836382866\n",
      "2017-11-11 08:56:25: Loss at step 10823: 0.03847664222121239\n",
      "2017-11-11 08:56:26: Loss at step 10824: 0.03854936733841896\n",
      "2017-11-11 08:56:26: Loss at step 10825: 0.03852451965212822\n",
      "2017-11-11 08:56:27: Loss at step 10826: 0.03859421983361244\n",
      "2017-11-11 08:56:27: Loss at step 10827: 0.038582395762205124\n",
      "2017-11-11 08:56:28: Loss at step 10828: 0.03856067731976509\n",
      "2017-11-11 08:56:28: Loss at step 10829: 0.038543980568647385\n",
      "2017-11-11 08:56:29: Loss at step 10830: 0.03859985992312431\n",
      "2017-11-11 08:56:29: Loss at step 10831: 0.03851815685629845\n",
      "2017-11-11 08:56:30: Loss at step 10832: 0.038497425615787506\n",
      "2017-11-11 08:56:30: Loss at step 10833: 0.03861573338508606\n",
      "2017-11-11 08:56:31: Loss at step 10834: 0.038494404405355453\n",
      "2017-11-11 08:56:31: Loss at step 10835: 0.03850340098142624\n",
      "2017-11-11 08:56:32: Loss at step 10836: 0.038514237850904465\n",
      "2017-11-11 08:56:32: Loss at step 10837: 0.03839990124106407\n",
      "2017-11-11 08:56:33: Loss at step 10838: 0.03852818161249161\n",
      "2017-11-11 08:56:33: Loss at step 10839: 0.038576386868953705\n",
      "2017-11-11 08:56:34: Loss at step 10840: 0.03861137107014656\n",
      "2017-11-11 08:56:34: Loss at step 10841: 0.0385223813354969\n",
      "2017-11-11 08:56:35: Loss at step 10842: 0.03850789740681648\n",
      "2017-11-11 08:56:35: Loss at step 10843: 0.03852519392967224\n",
      "2017-11-11 08:56:36: Loss at step 10844: 0.03864607587456703\n",
      "2017-11-11 08:56:36: Loss at step 10845: 0.03859589993953705\n",
      "2017-11-11 08:56:37: Loss at step 10846: 0.03851206600666046\n",
      "2017-11-11 08:56:37: Loss at step 10847: 0.03856205195188522\n",
      "2017-11-11 08:56:38: Loss at step 10848: 0.03859826177358627\n",
      "2017-11-11 08:56:38: Loss at step 10849: 0.03862161189317703\n",
      "2017-11-11 08:56:39: Loss at step 10850: 0.038485363125801086\n",
      "2017-11-11 08:56:39: Loss at step 10851: 0.038533616811037064\n",
      "2017-11-11 08:56:40: Loss at step 10852: 0.03854813799262047\n",
      "2017-11-11 08:56:41: Loss at step 10853: 0.03853916376829147\n",
      "2017-11-11 08:56:41: Loss at step 10854: 0.03863015025854111\n",
      "2017-11-11 08:56:42: Loss at step 10855: 0.03846357762813568\n",
      "2017-11-11 08:56:42: Loss at step 10856: 0.03858768567442894\n",
      "2017-11-11 08:56:43: Loss at step 10857: 0.038476020097732544\n",
      "2017-11-11 08:56:43: Loss at step 10858: 0.03849033638834953\n",
      "2017-11-11 08:56:44: Loss at step 10859: 0.03857714682817459\n",
      "2017-11-11 08:56:44: Loss at step 10860: 0.03847282752394676\n",
      "2017-11-11 08:56:45: Loss at step 10861: 0.03850167989730835\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-11-11 08:56:45: Loss at step 10862: 0.03855906426906586\n",
      "2017-11-11 08:56:46: Loss at step 10863: 0.03860795125365257\n",
      "2017-11-11 08:56:46: Loss at step 10864: 0.038567475974559784\n",
      "2017-11-11 08:56:47: Loss at step 10865: 0.03853752464056015\n",
      "2017-11-11 08:56:47: Loss at step 10866: 0.03854330629110336\n",
      "2017-11-11 08:56:48: Loss at step 10867: 0.0384892039000988\n",
      "2017-11-11 08:56:48: Loss at step 10868: 0.038532957434654236\n",
      "2017-11-11 08:56:49: Loss at step 10869: 0.03852720186114311\n",
      "2017-11-11 08:56:49: Loss at step 10870: 0.03857119008898735\n",
      "2017-11-11 08:56:50: Loss at step 10871: 0.03858146443963051\n",
      "2017-11-11 08:56:50: Loss at step 10872: 0.0385398268699646\n",
      "2017-11-11 08:56:51: Loss at step 10873: 0.03861093893647194\n",
      "2017-11-11 08:56:51: Loss at step 10874: 0.03851896524429321\n",
      "2017-11-11 08:56:52: Loss at step 10875: 0.03861622139811516\n",
      "2017-11-11 08:56:52: Loss at step 10876: 0.038500428199768066\n",
      "2017-11-11 08:56:53: Loss at step 10877: 0.03858131170272827\n",
      "2017-11-11 08:56:53: Loss at step 10878: 0.03856614977121353\n",
      "2017-11-11 08:56:54: Loss at step 10879: 0.03853541985154152\n",
      "2017-11-11 08:56:54: Loss at step 10880: 0.03847415745258331\n",
      "2017-11-11 08:56:55: Loss at step 10881: 0.038522545248270035\n",
      "2017-11-11 08:56:55: Loss at step 10882: 0.03856975957751274\n",
      "2017-11-11 08:56:56: Loss at step 10883: 0.038528431206941605\n",
      "2017-11-11 08:56:57: Loss at step 10884: 0.03858174756169319\n",
      "2017-11-11 08:56:57: Loss at step 10885: 0.03852555528283119\n",
      "2017-11-11 08:56:58: Loss at step 10886: 0.03862089663743973\n",
      "2017-11-11 08:56:58: Loss at step 10887: 0.03858107700943947\n",
      "2017-11-11 08:56:59: Loss at step 10888: 0.03850959986448288\n",
      "2017-11-11 08:56:59: Loss at step 10889: 0.03851864114403725\n",
      "2017-11-11 08:57:00: Loss at step 10890: 0.0385390929877758\n",
      "2017-11-11 08:57:00: Loss at step 10891: 0.03850191459059715\n",
      "2017-11-11 08:57:01: Loss at step 10892: 0.03839398920536041\n",
      "2017-11-11 08:57:01: Loss at step 10893: 0.03842372074723244\n",
      "2017-11-11 08:57:02: Loss at step 10894: 0.038575440645217896\n",
      "2017-11-11 08:57:02: Loss at step 10895: 0.0384741872549057\n",
      "2017-11-11 08:57:03: Loss at step 10896: 0.0385831743478775\n",
      "2017-11-11 08:57:03: Loss at step 10897: 0.03848875313997269\n",
      "2017-11-11 08:57:04: Loss at step 10898: 0.038522131741046906\n",
      "2017-11-11 08:57:05: Loss at step 10899: 0.03863847255706787\n",
      "2017-11-11 08:57:05: Loss at step 10900: 0.038564134389162064\n",
      "2017-11-11 08:57:06: Loss at step 10901: 0.038594458252191544\n",
      "2017-11-11 08:57:06: Loss at step 10902: 0.038400012999773026\n",
      "2017-11-11 08:57:07: Loss at step 10903: 0.03846512734889984\n",
      "2017-11-11 08:57:07: Loss at step 10904: 0.03844268247485161\n",
      "2017-11-11 08:57:08: Loss at step 10905: 0.03837516903877258\n",
      "2017-11-11 08:57:08: Loss at step 10906: 0.03847680985927582\n",
      "2017-11-11 08:57:09: Loss at step 10907: 0.03859085962176323\n",
      "2017-11-11 08:57:09: Loss at step 10908: 0.03852745518088341\n",
      "2017-11-11 08:57:10: Loss at step 10909: 0.03862152621150017\n",
      "2017-11-11 08:57:10: Loss at step 10910: 0.038562335073947906\n",
      "2017-11-11 08:57:11: Loss at step 10911: 0.038514863699674606\n",
      "2017-11-11 08:57:11: Loss at step 10912: 0.03851408138871193\n",
      "2017-11-11 08:57:12: Loss at step 10913: 0.03852728381752968\n",
      "2017-11-11 08:57:12: Loss at step 10914: 0.038541991263628006\n",
      "2017-11-11 08:57:13: Loss at step 10915: 0.03856052830815315\n",
      "2017-11-11 08:57:13: Loss at step 10916: 0.03854016587138176\n",
      "2017-11-11 08:57:14: Loss at step 10917: 0.03855283558368683\n",
      "2017-11-11 08:57:14: Loss at step 10918: 0.03861968219280243\n",
      "2017-11-11 08:57:15: Loss at step 10919: 0.03861187770962715\n",
      "2017-11-11 08:57:15: Loss at step 10920: 0.03856416791677475\n",
      "2017-11-11 08:57:16: Loss at step 10921: 0.03853623569011688\n",
      "2017-11-11 08:57:16: Loss at step 10922: 0.0384596511721611\n",
      "2017-11-11 08:57:17: Loss at step 10923: 0.03853901848196983\n",
      "2017-11-11 08:57:18: Loss at step 10924: 0.038440901786088943\n",
      "2017-11-11 08:57:18: Loss at step 10925: 0.03852635622024536\n",
      "2017-11-11 08:57:19: Loss at step 10926: 0.03852682560682297\n",
      "2017-11-11 08:57:19: Loss at step 10927: 0.03852934017777443\n",
      "2017-11-11 08:57:20: Loss at step 10928: 0.03844600170850754\n",
      "2017-11-11 08:57:20: Loss at step 10929: 0.038494084030389786\n",
      "2017-11-11 08:57:21: Loss at step 10930: 0.03857094794511795\n",
      "2017-11-11 08:57:21: Loss at step 10931: 0.03854479640722275\n",
      "2017-11-11 08:57:22: Loss at step 10932: 0.038473498076200485\n",
      "2017-11-11 08:57:22: Loss at step 10933: 0.038468677550554276\n",
      "2017-11-11 08:57:23: Loss at step 10934: 0.03854893147945404\n",
      "2017-11-11 08:57:23: Loss at step 10935: 0.03859182447195053\n",
      "2017-11-11 08:57:24: Loss at step 10936: 0.038382891565561295\n",
      "2017-11-11 08:57:24: Loss at step 10937: 0.03850014507770538\n",
      "2017-11-11 08:57:25: Loss at step 10938: 0.038489021360874176\n",
      "2017-11-11 08:57:25: Loss at step 10939: 0.038606464862823486\n",
      "2017-11-11 08:57:26: Loss at step 10940: 0.03850622475147247\n",
      "2017-11-11 08:57:26: Loss at step 10941: 0.03853806480765343\n",
      "2017-11-11 08:57:27: Loss at step 10942: 0.0386442095041275\n",
      "2017-11-11 08:57:27: Loss at step 10943: 0.03850443288683891\n",
      "2017-11-11 08:57:28: Loss at step 10944: 0.03853130340576172\n",
      "2017-11-11 08:57:28: Loss at step 10945: 0.03850346431136131\n",
      "2017-11-11 08:57:29: Loss at step 10946: 0.03845258802175522\n",
      "2017-11-11 08:57:30: Loss at step 10947: 0.038489896804094315\n",
      "2017-11-11 08:57:30: Loss at step 10948: 0.03854038193821907\n",
      "2017-11-11 08:57:31: Loss at step 10949: 0.0385105237364769\n",
      "2017-11-11 08:57:31: Loss at step 10950: 0.03846574202179909\n",
      "2017-11-11 08:57:32: Loss at step 10951: 0.038563963025808334\n",
      "2017-11-11 08:57:32: Loss at step 10952: 0.03850679099559784\n",
      "2017-11-11 08:57:33: Loss at step 10953: 0.038601506501436234\n",
      "2017-11-11 08:57:33: Loss at step 10954: 0.038399554789066315\n",
      "2017-11-11 08:57:34: Loss at step 10955: 0.0385010801255703\n",
      "2017-11-11 08:57:34: Loss at step 10956: 0.03856966644525528\n",
      "2017-11-11 08:57:35: Loss at step 10957: 0.03846726566553116\n",
      "2017-11-11 08:57:35: Loss at step 10958: 0.038542646914720535\n",
      "2017-11-11 08:57:36: Loss at step 10959: 0.0384262315928936\n",
      "2017-11-11 08:57:36: Loss at step 10960: 0.03839690983295441\n",
      "2017-11-11 08:57:37: Loss at step 10961: 0.038580961525440216\n",
      "2017-11-11 08:57:37: Loss at step 10962: 0.03836149722337723\n",
      "2017-11-11 08:57:38: Loss at step 10963: 0.038598790764808655\n",
      "2017-11-11 08:57:39: Loss at step 10964: 0.03846120461821556\n",
      "2017-11-11 08:57:39: Loss at step 10965: 0.03857763856649399\n",
      "2017-11-11 08:57:40: Loss at step 10966: 0.03857788071036339\n",
      "2017-11-11 08:57:40: Loss at step 10967: 0.03856620937585831\n",
      "2017-11-11 08:57:41: Loss at step 10968: 0.03853126987814903\n",
      "2017-11-11 08:57:41: Loss at step 10969: 0.03850850835442543\n",
      "2017-11-11 08:57:42: Loss at step 10970: 0.038597334176301956\n",
      "2017-11-11 08:57:42: Loss at step 10971: 0.038485635071992874\n",
      "2017-11-11 08:57:43: Loss at step 10972: 0.038573138415813446\n",
      "2017-11-11 08:57:43: Loss at step 10973: 0.03851672261953354\n",
      "2017-11-11 08:57:44: Loss at step 10974: 0.03865465149283409\n",
      "2017-11-11 08:57:44: Loss at step 10975: 0.03853973373770714\n",
      "2017-11-11 08:57:45: Loss at step 10976: 0.03844907879829407\n",
      "2017-11-11 08:57:45: Loss at step 10977: 0.0385621041059494\n",
      "2017-11-11 08:57:46: Loss at step 10978: 0.038495153188705444\n",
      "2017-11-11 08:57:46: Loss at step 10979: 0.038445454090833664\n",
      "2017-11-11 08:57:47: Loss at step 10980: 0.03846663609147072\n",
      "2017-11-11 08:57:47: Loss at step 10981: 0.03863957151770592\n",
      "2017-11-11 08:57:48: Loss at step 10982: 0.03846340253949165\n",
      "2017-11-11 08:57:48: Loss at step 10983: 0.038654740899801254\n",
      "2017-11-11 08:57:49: Loss at step 10984: 0.038698118180036545\n",
      "2017-11-11 08:57:49: Loss at step 10985: 0.03862713649868965\n",
      "2017-11-11 08:57:50: Loss at step 10986: 0.03861764073371887\n",
      "2017-11-11 08:57:51: Loss at step 10987: 0.03860187903046608\n",
      "2017-11-11 08:57:51: Loss at step 10988: 0.03860888257622719\n",
      "2017-11-11 08:57:52: Loss at step 10989: 0.0386493057012558\n",
      "2017-11-11 08:57:52: Loss at step 10990: 0.03866348788142204\n",
      "2017-11-11 08:57:53: Loss at step 10991: 0.038573265075683594\n",
      "2017-11-11 08:57:53: Loss at step 10992: 0.03851602226495743\n",
      "2017-11-11 08:57:54: Loss at step 10993: 0.03857125714421272\n",
      "2017-11-11 08:57:54: Loss at step 10994: 0.03854185342788696\n",
      "2017-11-11 08:57:55: Loss at step 10995: 0.038640569895505905\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-11-11 08:57:55: Loss at step 10996: 0.0386175774037838\n",
      "2017-11-11 08:57:56: Loss at step 10997: 0.03868567943572998\n",
      "2017-11-11 08:57:56: Loss at step 10998: 0.03858464956283569\n",
      "2017-11-11 08:57:57: Loss at step 10999: 0.038629259914159775\n",
      "2017-11-11 08:57:57: Loss at step 11000: 0.038598839193582535\n",
      "2017-11-11 08:57:58: Loss at step 11001: 0.03850424662232399\n",
      "2017-11-11 08:57:58: Loss at step 11002: 0.03854585438966751\n",
      "2017-11-11 08:57:59: Loss at step 11003: 0.038447149097919464\n",
      "2017-11-11 08:57:59: Loss at step 11004: 0.03853709250688553\n",
      "2017-11-11 08:58:00: Loss at step 11005: 0.03847523033618927\n",
      "2017-11-11 08:58:00: Loss at step 11006: 0.038502246141433716\n",
      "2017-11-11 08:58:01: Loss at step 11007: 0.038628943264484406\n",
      "2017-11-11 08:58:01: Loss at step 11008: 0.038511067628860474\n",
      "2017-11-11 08:58:02: Loss at step 11009: 0.03861182928085327\n",
      "2017-11-11 08:58:02: Loss at step 11010: 0.0385601632297039\n",
      "2017-11-11 08:58:03: Loss at step 11011: 0.03867242485284805\n",
      "2017-11-11 08:58:03: Loss at step 11012: 0.03858216479420662\n",
      "2017-11-11 08:58:04: Loss at step 11013: 0.03845403715968132\n",
      "2017-11-11 08:58:05: Loss at step 11014: 0.03857152536511421\n",
      "2017-11-11 08:58:05: Loss at step 11015: 0.03861299529671669\n",
      "2017-11-11 08:58:06: Loss at step 11016: 0.03858686611056328\n",
      "2017-11-11 08:58:06: Loss at step 11017: 0.03862254321575165\n",
      "2017-11-11 08:58:07: Loss at step 11018: 0.038556527346372604\n",
      "2017-11-11 08:58:07: Loss at step 11019: 0.03859994560480118\n",
      "2017-11-11 08:58:08: Loss at step 11020: 0.038564421236515045\n",
      "2017-11-11 08:58:08: Loss at step 11021: 0.038609154522418976\n",
      "2017-11-11 08:58:09: Loss at step 11022: 0.03858973830938339\n",
      "2017-11-11 08:58:09: Loss at step 11023: 0.03857657313346863\n",
      "2017-11-11 08:58:10: Loss at step 11024: 0.038474421948194504\n",
      "2017-11-11 08:58:10: Loss at step 11025: 0.03855064511299133\n",
      "2017-11-11 08:58:11: Loss at step 11026: 0.038576457649469376\n",
      "2017-11-11 08:58:11: Loss at step 11027: 0.038568560034036636\n",
      "2017-11-11 08:58:12: Loss at step 11028: 0.038569990545511246\n",
      "2017-11-11 08:58:12: Loss at step 11029: 0.03851356357336044\n",
      "2017-11-11 08:58:13: Loss at step 11030: 0.03849708288908005\n",
      "2017-11-11 08:58:13: Loss at step 11031: 0.038580816239118576\n",
      "2017-11-11 08:58:14: Loss at step 11032: 0.03864094987511635\n",
      "2017-11-11 08:58:14: Loss at step 11033: 0.038673363626003265\n",
      "2017-11-11 08:58:15: Loss at step 11034: 0.03851555287837982\n",
      "2017-11-11 08:58:15: Loss at step 11035: 0.03860524296760559\n",
      "2017-11-11 08:58:16: Loss at step 11036: 0.03849083185195923\n",
      "2017-11-11 08:58:16: Loss at step 11037: 0.0385407917201519\n",
      "2017-11-11 08:58:17: Loss at step 11038: 0.038595832884311676\n",
      "2017-11-11 08:58:18: Loss at step 11039: 0.03856879100203514\n",
      "2017-11-11 08:58:18: Loss at step 11040: 0.038502927869558334\n",
      "2017-11-11 08:58:19: Loss at step 11041: 0.03847857564687729\n",
      "2017-11-11 08:58:19: Loss at step 11042: 0.03852009400725365\n",
      "2017-11-11 08:58:20: Loss at step 11043: 0.038610078394412994\n",
      "2017-11-11 08:58:20: Loss at step 11044: 0.03852082043886185\n",
      "2017-11-11 08:58:21: Loss at step 11045: 0.03868986293673515\n",
      "2017-11-11 08:58:21: Loss at step 11046: 0.03854870796203613\n",
      "2017-11-11 08:58:22: Loss at step 11047: 0.038582514971494675\n",
      "2017-11-11 08:58:22: Loss at step 11048: 0.038584548979997635\n",
      "2017-11-11 08:58:23: Loss at step 11049: 0.03857146203517914\n",
      "2017-11-11 08:58:23: Loss at step 11050: 0.03855602815747261\n",
      "2017-11-11 08:58:24: Loss at step 11051: 0.038505569100379944\n",
      "2017-11-11 08:58:24: Loss at step 11052: 0.03858087211847305\n",
      "2017-11-11 08:58:25: Loss at step 11053: 0.03861769288778305\n",
      "2017-11-11 08:58:25: Loss at step 11054: 0.03862476721405983\n",
      "2017-11-11 08:58:26: Loss at step 11055: 0.038555439561605453\n",
      "2017-11-11 08:58:26: Loss at step 11056: 0.038583751767873764\n",
      "2017-11-11 08:58:27: Loss at step 11057: 0.03858708217740059\n",
      "2017-11-11 08:58:27: Loss at step 11058: 0.03846685215830803\n",
      "2017-11-11 08:58:28: Loss at step 11059: 0.03855922818183899\n",
      "2017-11-11 08:58:28: Loss at step 11060: 0.03860839828848839\n",
      "2017-11-11 08:58:29: Loss at step 11061: 0.038554802536964417\n",
      "2017-11-11 08:58:29: Loss at step 11062: 0.03865707665681839\n",
      "2017-11-11 08:58:30: Loss at step 11063: 0.03855516389012337\n",
      "2017-11-11 08:58:31: Loss at step 11064: 0.03853363171219826\n",
      "2017-11-11 08:58:31: Loss at step 11065: 0.03862139210104942\n",
      "2017-11-11 08:58:32: Loss at step 11066: 0.03856976330280304\n",
      "2017-11-11 08:58:32: Loss at step 11067: 0.03864490985870361\n",
      "2017-11-11 08:58:33: Loss at step 11068: 0.038527362048625946\n",
      "2017-11-11 08:58:33: Loss at step 11069: 0.03859716281294823\n",
      "2017-11-11 08:58:34: Loss at step 11070: 0.03860670328140259\n",
      "2017-11-11 08:58:34: Loss at step 11071: 0.038553785532712936\n",
      "2017-11-11 08:58:35: Loss at step 11072: 0.03860803693532944\n",
      "2017-11-11 08:58:35: Loss at step 11073: 0.03848009184002876\n",
      "2017-11-11 08:58:36: Loss at step 11074: 0.038658421486616135\n",
      "2017-11-11 08:58:36: Loss at step 11075: 0.038496941328048706\n",
      "2017-11-11 08:58:37: Loss at step 11076: 0.038498405367136\n",
      "2017-11-11 08:58:37: Loss at step 11077: 0.03857751190662384\n",
      "2017-11-11 08:58:38: Loss at step 11078: 0.03862864524126053\n",
      "2017-11-11 08:58:38: Loss at step 11079: 0.038518793880939484\n",
      "2017-11-11 08:58:39: Loss at step 11080: 0.03855310007929802\n",
      "2017-11-11 08:58:39: Loss at step 11081: 0.03856438770890236\n",
      "2017-11-11 08:58:40: Loss at step 11082: 0.038550835102796555\n",
      "2017-11-11 08:58:40: Loss at step 11083: 0.0384536050260067\n",
      "2017-11-11 08:58:41: Loss at step 11084: 0.038520924746990204\n",
      "2017-11-11 08:58:41: Loss at step 11085: 0.03856769576668739\n",
      "2017-11-11 08:58:42: Loss at step 11086: 0.038558751344680786\n",
      "2017-11-11 08:58:42: Loss at step 11087: 0.03861241042613983\n",
      "2017-11-11 08:58:43: Loss at step 11088: 0.038648299872875214\n",
      "2017-11-11 08:58:44: Loss at step 11089: 0.03847334161400795\n",
      "2017-11-11 08:58:44: Loss at step 11090: 0.038595233112573624\n",
      "2017-11-11 08:58:45: Loss at step 11091: 0.03853050619363785\n",
      "2017-11-11 08:58:45: Loss at step 11092: 0.03864532336592674\n",
      "2017-11-11 08:58:46: Loss at step 11093: 0.03852105140686035\n",
      "2017-11-11 08:58:46: Loss at step 11094: 0.0384804792702198\n",
      "2017-11-11 08:58:47: Loss at step 11095: 0.03860931843519211\n",
      "2017-11-11 08:58:47: Loss at step 11096: 0.038645222783088684\n",
      "2017-11-11 08:58:48: Loss at step 11097: 0.038496874272823334\n",
      "2017-11-11 08:58:48: Loss at step 11098: 0.03851605951786041\n",
      "2017-11-11 08:58:49: Loss at step 11099: 0.0384836308658123\n",
      "2017-11-11 08:58:49: Loss at step 11100: 0.03851723298430443\n",
      "2017-11-11 08:58:50: Loss at step 11101: 0.03864790126681328\n",
      "2017-11-11 08:58:50: Loss at step 11102: 0.03863134607672691\n",
      "2017-11-11 08:58:51: Loss at step 11103: 0.03858477622270584\n",
      "2017-11-11 08:58:51: Loss at step 11104: 0.03856302425265312\n",
      "2017-11-11 08:58:52: Loss at step 11105: 0.038547202944755554\n",
      "2017-11-11 08:58:52: Loss at step 11106: 0.03858690336346626\n",
      "2017-11-11 08:58:53: Loss at step 11107: 0.03858332335948944\n",
      "2017-11-11 08:58:53: Loss at step 11108: 0.03856984153389931\n",
      "2017-11-11 08:58:54: Loss at step 11109: 0.03847309574484825\n",
      "2017-11-11 08:58:54: Loss at step 11110: 0.03851843997836113\n",
      "2017-11-11 08:58:55: Loss at step 11111: 0.03854089975357056\n",
      "2017-11-11 08:58:55: Loss at step 11112: 0.03852986544370651\n",
      "2017-11-11 08:58:56: Loss at step 11113: 0.038568053394556046\n",
      "2017-11-11 08:58:57: Loss at step 11114: 0.0386180616915226\n",
      "2017-11-11 08:58:57: Loss at step 11115: 0.03846292197704315\n",
      "2017-11-11 08:58:58: Loss at step 11116: 0.03858111426234245\n",
      "2017-11-11 08:58:58: Loss at step 11117: 0.03862454742193222\n",
      "2017-11-11 08:58:59: Loss at step 11118: 0.03857648745179176\n",
      "2017-11-11 08:58:59: Loss at step 11119: 0.03853621333837509\n",
      "2017-11-11 08:59:00: Loss at step 11120: 0.038548100739717484\n",
      "2017-11-11 08:59:00: Loss at step 11121: 0.03853559121489525\n",
      "2017-11-11 08:59:01: Loss at step 11122: 0.03851322457194328\n",
      "2017-11-11 08:59:01: Loss at step 11123: 0.03858168423175812\n",
      "2017-11-11 08:59:02: Loss at step 11124: 0.03867904096841812\n",
      "2017-11-11 08:59:02: Loss at step 11125: 0.03857770562171936\n",
      "2017-11-11 08:59:03: Loss at step 11126: 0.038637675344944\n",
      "2017-11-11 08:59:03: Loss at step 11127: 0.038524266332387924\n",
      "2017-11-11 08:59:04: Loss at step 11128: 0.03860430419445038\n",
      "2017-11-11 08:59:04: Loss at step 11129: 0.03860626369714737\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-11-11 08:59:05: Loss at step 11130: 0.038608379662036896\n",
      "2017-11-11 08:59:05: Loss at step 11131: 0.038562048226594925\n",
      "2017-11-11 08:59:06: Loss at step 11132: 0.03854592889547348\n",
      "2017-11-11 08:59:06: Loss at step 11133: 0.03863485902547836\n",
      "2017-11-11 08:59:07: Loss at step 11134: 0.03855282440781593\n",
      "2017-11-11 08:59:07: Loss at step 11135: 0.03860322758555412\n",
      "2017-11-11 08:59:08: Loss at step 11136: 0.03862272948026657\n",
      "2017-11-11 08:59:08: Loss at step 11137: 0.038607385009527206\n",
      "2017-11-11 08:59:09: Loss at step 11138: 0.03856740891933441\n",
      "2017-11-11 08:59:09: Loss at step 11139: 0.038479194045066833\n",
      "2017-11-11 08:59:10: Loss at step 11140: 0.038524433970451355\n",
      "2017-11-11 08:59:11: Loss at step 11141: 0.03847634792327881\n",
      "2017-11-11 08:59:11: Loss at step 11142: 0.038561176508665085\n",
      "2017-11-11 08:59:12: Loss at step 11143: 0.03854828700423241\n",
      "2017-11-11 08:59:12: Loss at step 11144: 0.03858862817287445\n",
      "2017-11-11 08:59:13: Loss at step 11145: 0.038637664169073105\n",
      "2017-11-11 08:59:13: Loss at step 11146: 0.03864265978336334\n",
      "2017-11-11 08:59:14: Loss at step 11147: 0.03855617344379425\n",
      "2017-11-11 08:59:14: Loss at step 11148: 0.03861197084188461\n",
      "2017-11-11 08:59:15: Loss at step 11149: 0.03855135664343834\n",
      "2017-11-11 08:59:15: Loss at step 11150: 0.03855506330728531\n",
      "2017-11-11 08:59:16: Loss at step 11151: 0.038439277559518814\n",
      "2017-11-11 08:59:16: Loss at step 11152: 0.03855448588728905\n",
      "2017-11-11 08:59:17: Loss at step 11153: 0.038722649216651917\n",
      "2017-11-11 08:59:17: Loss at step 11154: 0.03856567293405533\n",
      "2017-11-11 08:59:18: Loss at step 11155: 0.038439322263002396\n",
      "2017-11-11 08:59:18: Loss at step 11156: 0.03858204185962677\n",
      "2017-11-11 08:59:19: Loss at step 11157: 0.03865822032094002\n",
      "2017-11-11 08:59:19: Loss at step 11158: 0.038549646735191345\n",
      "2017-11-11 08:59:20: Loss at step 11159: 0.038570042699575424\n",
      "2017-11-11 08:59:20: Loss at step 11160: 0.038608018308877945\n",
      "2017-11-11 08:59:21: Loss at step 11161: 0.03853486105799675\n",
      "2017-11-11 08:59:21: Loss at step 11162: 0.03853409364819527\n",
      "2017-11-11 08:59:22: Loss at step 11163: 0.03850366175174713\n",
      "2017-11-11 08:59:22: Loss at step 11164: 0.03853437677025795\n",
      "2017-11-11 08:59:23: Loss at step 11165: 0.03859853371977806\n",
      "2017-11-11 08:59:24: Loss at step 11166: 0.038449615240097046\n",
      "2017-11-11 08:59:24: Loss at step 11167: 0.038476765155792236\n",
      "2017-11-11 08:59:25: Loss at step 11168: 0.03849196061491966\n",
      "2017-11-11 08:59:25: Loss at step 11169: 0.03853290528059006\n",
      "2017-11-11 08:59:26: Loss at step 11170: 0.038596268743276596\n",
      "2017-11-11 08:59:26: Loss at step 11171: 0.0384339839220047\n",
      "2017-11-11 08:59:27: Loss at step 11172: 0.03856942057609558\n",
      "2017-11-11 08:59:27: Loss at step 11173: 0.03860190883278847\n",
      "2017-11-11 08:59:28: Loss at step 11174: 0.03856190666556358\n",
      "2017-11-11 08:59:28: Loss at step 11175: 0.038478706032037735\n",
      "2017-11-11 08:59:29: Loss at step 11176: 0.0385950431227684\n",
      "2017-11-11 08:59:29: Loss at step 11177: 0.03849875554442406\n",
      "2017-11-11 08:59:30: Loss at step 11178: 0.03847264498472214\n",
      "2017-11-11 08:59:30: Loss at step 11179: 0.03850456327199936\n",
      "2017-11-11 08:59:31: Loss at step 11180: 0.038537994027137756\n",
      "2017-11-11 08:59:31: Loss at step 11181: 0.038562871515750885\n",
      "2017-11-11 08:59:32: Loss at step 11182: 0.03860822692513466\n",
      "2017-11-11 08:59:32: Loss at step 11183: 0.03852149099111557\n",
      "2017-11-11 08:59:33: Loss at step 11184: 0.03848664090037346\n",
      "2017-11-11 08:59:33: Loss at step 11185: 0.03849431499838829\n",
      "2017-11-11 08:59:34: Loss at step 11186: 0.03847230225801468\n",
      "2017-11-11 08:59:34: Loss at step 11187: 0.03850899636745453\n",
      "2017-11-11 08:59:35: Loss at step 11188: 0.038490332663059235\n",
      "2017-11-11 08:59:36: Loss at step 11189: 0.03854531794786453\n",
      "2017-11-11 08:59:36: Loss at step 11190: 0.038636207580566406\n",
      "2017-11-11 08:59:37: Loss at step 11191: 0.03862503170967102\n",
      "2017-11-11 08:59:37: Loss at step 11192: 0.03847167268395424\n",
      "2017-11-11 08:59:38: Loss at step 11193: 0.03866942599415779\n",
      "2017-11-11 08:59:38: Loss at step 11194: 0.03859143331646919\n",
      "2017-11-11 08:59:39: Loss at step 11195: 0.03854477033019066\n",
      "2017-11-11 08:59:39: Loss at step 11196: 0.03850731626152992\n",
      "2017-11-11 08:59:40: Loss at step 11197: 0.03854220733046532\n",
      "2017-11-11 08:59:40: Loss at step 11198: 0.03859983757138252\n",
      "2017-11-11 08:59:41: Loss at step 11199: 0.03863914683461189\n",
      "2017-11-11 08:59:41: Loss at step 11200: 0.038546595722436905\n",
      "2017-11-11 08:59:42: Loss at step 11201: 0.03864829242229462\n",
      "2017-11-11 08:59:42: Loss at step 11202: 0.038463689386844635\n",
      "2017-11-11 08:59:43: Loss at step 11203: 0.03869147598743439\n",
      "2017-11-11 08:59:43: Loss at step 11204: 0.038540396839380264\n",
      "2017-11-11 08:59:44: Loss at step 11205: 0.03861910477280617\n",
      "2017-11-11 08:59:44: Loss at step 11206: 0.038558971136808395\n",
      "2017-11-11 08:59:45: Loss at step 11207: 0.03867543488740921\n",
      "2017-11-11 08:59:45: Loss at step 11208: 0.03853233531117439\n",
      "2017-11-11 08:59:46: Loss at step 11209: 0.03851230815052986\n",
      "2017-11-11 08:59:46: Loss at step 11210: 0.03853403031826019\n",
      "2017-11-11 08:59:47: Loss at step 11211: 0.03855869174003601\n",
      "2017-11-11 08:59:48: Loss at step 11212: 0.03857061266899109\n",
      "2017-11-11 08:59:48: Loss at step 11213: 0.03848094120621681\n",
      "2017-11-11 08:59:49: Loss at step 11214: 0.0384647399187088\n",
      "2017-11-11 08:59:49: Loss at step 11215: 0.03849470615386963\n",
      "2017-11-11 08:59:50: Loss at step 11216: 0.03860675171017647\n",
      "2017-11-11 08:59:50: Loss at step 11217: 0.038507793098688126\n",
      "2017-11-11 08:59:51: Loss at step 11218: 0.03855424374341965\n",
      "2017-11-11 08:59:51: Loss at step 11219: 0.03848684951663017\n",
      "2017-11-11 08:59:52: Loss at step 11220: 0.03860568255186081\n",
      "2017-11-11 08:59:52: Loss at step 11221: 0.03859958052635193\n",
      "2017-11-11 08:59:53: Loss at step 11222: 0.03862153738737106\n",
      "2017-11-11 08:59:53: Loss at step 11223: 0.03861512616276741\n",
      "2017-11-11 08:59:54: Loss at step 11224: 0.038538359105587006\n",
      "2017-11-11 08:59:54: Loss at step 11225: 0.03852090612053871\n",
      "2017-11-11 08:59:55: Loss at step 11226: 0.038458410650491714\n",
      "2017-11-11 08:59:55: Loss at step 11227: 0.03855316713452339\n",
      "2017-11-11 08:59:56: Loss at step 11228: 0.0384930856525898\n",
      "2017-11-11 08:59:56: Loss at step 11229: 0.03847051411867142\n",
      "2017-11-11 08:59:57: Loss at step 11230: 0.03854764997959137\n",
      "2017-11-11 08:59:57: Loss at step 11231: 0.03861215338110924\n",
      "2017-11-11 08:59:58: Loss at step 11232: 0.03858591988682747\n",
      "2017-11-11 08:59:58: Loss at step 11233: 0.03855974227190018\n",
      "2017-11-11 08:59:59: Loss at step 11234: 0.03857837989926338\n",
      "2017-11-11 08:59:59: Loss at step 11235: 0.038551922887563705\n",
      "2017-11-11 09:00:00: Loss at step 11236: 0.03859396278858185\n",
      "2017-11-11 09:00:00: Loss at step 11237: 0.0385877750813961\n",
      "2017-11-11 09:00:01: Loss at step 11238: 0.03854214400053024\n",
      "2017-11-11 09:00:01: Loss at step 11239: 0.03848157823085785\n",
      "2017-11-11 09:00:02: Loss at step 11240: 0.038491979241371155\n",
      "2017-11-11 09:00:03: Loss at step 11241: 0.03848990425467491\n",
      "2017-11-11 09:00:03: Loss at step 11242: 0.038516417145729065\n",
      "2017-11-11 09:00:04: Loss at step 11243: 0.038484226912260056\n",
      "2017-11-11 09:00:04: Loss at step 11244: 0.03851323202252388\n",
      "2017-11-11 09:00:05: Loss at step 11245: 0.03854745626449585\n",
      "2017-11-11 09:00:05: Loss at step 11246: 0.03853284940123558\n",
      "2017-11-11 09:00:06: Loss at step 11247: 0.03862486407160759\n",
      "2017-11-11 09:00:06: Loss at step 11248: 0.03849673271179199\n",
      "2017-11-11 09:00:07: Loss at step 11249: 0.0385315865278244\n",
      "2017-11-11 09:00:07: Loss at step 11250: 0.038507793098688126\n",
      "2017-11-11 09:00:08: Loss at step 11251: 0.03853283077478409\n",
      "2017-11-11 09:00:08: Loss at step 11252: 0.03855988010764122\n",
      "2017-11-11 09:00:09: Loss at step 11253: 0.038552429527044296\n",
      "2017-11-11 09:00:09: Loss at step 11254: 0.03856243938207626\n",
      "2017-11-11 09:00:10: Loss at step 11255: 0.038552090525627136\n",
      "2017-11-11 09:00:10: Loss at step 11256: 0.03848773613572121\n",
      "2017-11-11 09:00:11: Loss at step 11257: 0.03858925402164459\n",
      "2017-11-11 09:00:11: Loss at step 11258: 0.03854776546359062\n",
      "2017-11-11 09:00:12: Loss at step 11259: 0.03842337802052498\n",
      "2017-11-11 09:00:12: Loss at step 11260: 0.03853006660938263\n",
      "2017-11-11 09:00:13: Loss at step 11261: 0.03851104900240898\n",
      "2017-11-11 09:00:13: Loss at step 11262: 0.03845427930355072\n",
      "2017-11-11 09:00:14: Loss at step 11263: 0.038529448211193085\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-11-11 09:00:14: Loss at step 11264: 0.03854534402489662\n",
      "2017-11-11 09:00:15: Loss at step 11265: 0.038461361080408096\n",
      "2017-11-11 09:00:15: Loss at step 11266: 0.038481250405311584\n",
      "2017-11-11 09:00:16: Loss at step 11267: 0.03855827450752258\n",
      "2017-11-11 09:00:17: Loss at step 11268: 0.038442619144916534\n",
      "2017-11-11 09:00:17: Loss at step 11269: 0.03844233974814415\n",
      "2017-11-11 09:00:18: Loss at step 11270: 0.03845497965812683\n",
      "2017-11-11 09:00:18: Loss at step 11271: 0.0384952574968338\n",
      "2017-11-11 09:00:19: Loss at step 11272: 0.03849072381854057\n",
      "2017-11-11 09:00:19: Loss at step 11273: 0.03855311870574951\n",
      "2017-11-11 09:00:20: Loss at step 11274: 0.03849302977323532\n",
      "2017-11-11 09:00:20: Loss at step 11275: 0.03861307352781296\n",
      "2017-11-11 09:00:21: Loss at step 11276: 0.0384707935154438\n",
      "2017-11-11 09:00:21: Loss at step 11277: 0.0385914109647274\n",
      "2017-11-11 09:00:22: Loss at step 11278: 0.038554590195417404\n",
      "2017-11-11 09:00:22: Loss at step 11279: 0.0385189987719059\n",
      "2017-11-11 09:00:23: Loss at step 11280: 0.03844897449016571\n",
      "2017-11-11 09:00:23: Loss at step 11281: 0.038588158786296844\n",
      "2017-11-11 09:00:24: Loss at step 11282: 0.03862593322992325\n",
      "2017-11-11 09:00:24: Loss at step 11283: 0.038525816053152084\n",
      "2017-11-11 09:00:25: Loss at step 11284: 0.03848675265908241\n",
      "2017-11-11 09:00:25: Loss at step 11285: 0.03851092979311943\n",
      "2017-11-11 09:00:26: Loss at step 11286: 0.038521911948919296\n",
      "2017-11-11 09:00:26: Loss at step 11287: 0.03860116004943848\n",
      "2017-11-11 09:00:27: Loss at step 11288: 0.03841421380639076\n",
      "2017-11-11 09:00:27: Loss at step 11289: 0.038493867963552475\n",
      "2017-11-11 09:00:28: Loss at step 11290: 0.03849775344133377\n",
      "2017-11-11 09:00:28: Loss at step 11291: 0.03855961188673973\n",
      "2017-11-11 09:00:29: Loss at step 11292: 0.03847038000822067\n",
      "2017-11-11 09:00:30: Loss at step 11293: 0.03851602226495743\n",
      "2017-11-11 09:00:30: Loss at step 11294: 0.038534052670001984\n",
      "2017-11-11 09:00:31: Loss at step 11295: 0.03842905908823013\n",
      "2017-11-11 09:00:31: Loss at step 11296: 0.03852595016360283\n",
      "2017-11-11 09:00:32: Loss at step 11297: 0.0384821854531765\n",
      "2017-11-11 09:00:32: Loss at step 11298: 0.03822013735771179\n",
      "2017-11-11 09:00:33: Loss at step 11299: 0.03807123377919197\n",
      "2017-11-11 09:00:33: Loss at step 11300: 0.03782729059457779\n",
      "2017-11-11 09:00:34: Loss at step 11301: 0.0380728654563427\n",
      "2017-11-11 09:00:34: Loss at step 11302: 0.037787895649671555\n",
      "2017-11-11 09:00:35: Loss at step 11303: 0.03778119385242462\n",
      "2017-11-11 09:00:35: Loss at step 11304: 0.03776542469859123\n",
      "2017-11-11 09:00:36: Loss at step 11305: 0.03774358704686165\n",
      "2017-11-11 09:00:36: Loss at step 11306: 0.037899866700172424\n",
      "2017-11-11 09:00:37: Loss at step 11307: 0.03776462748646736\n",
      "2017-11-11 09:00:37: Loss at step 11308: 0.03788525238633156\n",
      "2017-11-11 09:00:38: Loss at step 11309: 0.037808991968631744\n",
      "2017-11-11 09:00:38: Loss at step 11310: 0.0377182774245739\n",
      "2017-11-11 09:00:39: Loss at step 11311: 0.03784143924713135\n",
      "2017-11-11 09:00:39: Loss at step 11312: 0.03764841705560684\n",
      "2017-11-11 09:00:40: Loss at step 11313: 0.037846971303224564\n",
      "2017-11-11 09:00:40: Loss at step 11314: 0.03771699219942093\n",
      "2017-11-11 09:00:41: Loss at step 11315: 0.03781631588935852\n",
      "2017-11-11 09:00:41: Loss at step 11316: 0.03784067556262016\n",
      "2017-11-11 09:00:42: Loss at step 11317: 0.03774412348866463\n",
      "2017-11-11 09:00:42: Loss at step 11318: 0.03779955953359604\n",
      "2017-11-11 09:00:43: Loss at step 11319: 0.03776147589087486\n",
      "2017-11-11 09:00:44: Loss at step 11320: 0.03777001425623894\n",
      "2017-11-11 09:00:44: Loss at step 11321: 0.03774159401655197\n",
      "2017-11-11 09:00:45: Loss at step 11322: 0.0377890020608902\n",
      "2017-11-11 09:00:45: Loss at step 11323: 0.03775033727288246\n",
      "2017-11-11 09:00:46: Loss at step 11324: 0.03766080364584923\n",
      "2017-11-11 09:00:46: Loss at step 11325: 0.037744902074337006\n",
      "2017-11-11 09:00:47: Loss at step 11326: 0.0377206914126873\n",
      "2017-11-11 09:00:47: Loss at step 11327: 0.037856027483940125\n",
      "2017-11-11 09:00:48: Loss at step 11328: 0.037864137440919876\n",
      "2017-11-11 09:00:48: Loss at step 11329: 0.0376858189702034\n",
      "2017-11-11 09:00:49: Loss at step 11330: 0.03776807337999344\n",
      "2017-11-11 09:00:49: Loss at step 11331: 0.03772938996553421\n",
      "2017-11-11 09:00:50: Loss at step 11332: 0.037839677184820175\n",
      "2017-11-11 09:00:50: Loss at step 11333: 0.037709809839725494\n",
      "2017-11-11 09:00:51: Loss at step 11334: 0.03772323206067085\n",
      "2017-11-11 09:00:51: Loss at step 11335: 0.037705134600400925\n",
      "2017-11-11 09:00:52: Loss at step 11336: 0.037707746028900146\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-77d2b2017f47>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0miteration\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5689\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1000001\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mx_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_training_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miteration\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m5689\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_on_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'{0}: Loss at step {1}: {2}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrftime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"%Y-%m-%d %H:%M:%S\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miteration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0miteration\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m500\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-16-938657fd4f05>\u001b[0m in \u001b[0;36mload_training_batch\u001b[0;34m(n)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mload_training_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mx_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'{0}/training_data/x_batch-{1}.npy'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msavePath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0my_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'{0}/training_data/y_batch-{1}.npy'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msavePath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tensorflow/lib/python3.6/site-packages/numpy/lib/npyio.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(file, mmap_mode, allow_pickle, fix_imports, encoding)\u001b[0m\n\u001b[1;32m    417\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    418\u001b[0m                 return format.read_array(fid, allow_pickle=allow_pickle,\n\u001b[0;32m--> 419\u001b[0;31m                                          pickle_kwargs=pickle_kwargs)\n\u001b[0m\u001b[1;32m    420\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    421\u001b[0m             \u001b[0;31m# Try a pickle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tensorflow/lib/python3.6/site-packages/numpy/lib/format.py\u001b[0m in \u001b[0;36mread_array\u001b[0;34m(fp, allow_pickle, pickle_kwargs)\u001b[0m\n\u001b[1;32m    649\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misfileobj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    650\u001b[0m             \u001b[0;31m# We can use the fast fromfile() function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 651\u001b[0;31m             \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfromfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    652\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    653\u001b[0m             \u001b[0;31m# This is not a real file. We have to read it the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for iteration in range(5689,1000001):\n",
    "    x_batch, y_batch = load_training_batch(iteration % 5689)\n",
    "    loss = model.train_on_batch(np.array(x_batch), np.array(y_batch))\n",
    "    print('{0}: Loss at step {1}: {2}'.format(dt.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"), iteration, loss))\n",
    "    if iteration % 500 == 0:\n",
    "        model.save('{0}/model-{1}.h5'.format(savePath, iteration))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-11-11 09:01:47: Loss at step 11337: 0.037653692066669464\n",
      "2017-11-11 09:01:47: Loss at step 11338: 0.03768111392855644\n",
      "2017-11-11 09:01:48: Loss at step 11339: 0.03770895674824715\n",
      "2017-11-11 09:01:48: Loss at step 11340: 0.037628404796123505\n",
      "2017-11-11 09:01:49: Loss at step 11341: 0.03768160939216614\n",
      "2017-11-11 09:01:49: Loss at step 11342: 0.03778529539704323\n",
      "2017-11-11 09:01:49: Loss at step 11343: 0.037641026079654694\n",
      "2017-11-11 09:01:49: Loss at step 11344: 0.037737470120191574\n",
      "2017-11-11 09:01:50: Loss at step 11345: 0.03766437619924545\n",
      "2017-11-11 09:01:50: Loss at step 11346: 0.037668220698833466\n",
      "2017-11-11 09:01:51: Loss at step 11347: 0.03761690855026245\n",
      "2017-11-11 09:01:51: Loss at step 11348: 0.03764592111110687\n",
      "2017-11-11 09:01:52: Loss at step 11349: 0.03764431178569794\n",
      "2017-11-11 09:01:52: Loss at step 11350: 0.03767009079456329\n",
      "2017-11-11 09:01:53: Loss at step 11351: 0.03764393925666809\n",
      "2017-11-11 09:01:53: Loss at step 11352: 0.03774058818817139\n",
      "2017-11-11 09:01:54: Loss at step 11353: 0.037618931382894516\n",
      "2017-11-11 09:01:54: Loss at step 11354: 0.03777923434972763\n",
      "2017-11-11 09:01:54: Loss at step 11355: 0.037735652178525925\n",
      "2017-11-11 09:01:55: Loss at step 11356: 0.03764822334051132\n",
      "2017-11-11 09:01:55: Loss at step 11357: 0.03760647028684616\n",
      "2017-11-11 09:01:56: Loss at step 11358: 0.03761981055140495\n",
      "2017-11-11 09:01:56: Loss at step 11359: 0.037604786455631256\n",
      "2017-11-11 09:01:57: Loss at step 11360: 0.03775367885828018\n",
      "2017-11-11 09:01:57: Loss at step 11361: 0.037563733756542206\n",
      "2017-11-11 09:01:57: Loss at step 11362: 0.03761447221040726\n",
      "2017-11-11 09:01:58: Loss at step 11363: 0.03767477348446846\n",
      "2017-11-11 09:01:58: Loss at step 11364: 0.03771894425153732\n",
      "2017-11-11 09:01:59: Loss at step 11365: 0.03771040216088295\n",
      "2017-11-11 09:01:59: Loss at step 11366: 0.03762590512633324\n",
      "2017-11-11 09:02:00: Loss at step 11367: 0.037600982934236526\n",
      "2017-11-11 09:02:00: Loss at step 11368: 0.03765656054019928\n",
      "2017-11-11 09:02:01: Loss at step 11369: 0.037661850452423096\n",
      "2017-11-11 09:02:01: Loss at step 11370: 0.037629369646310806\n",
      "2017-11-11 09:02:02: Loss at step 11371: 0.0376211442053318\n",
      "2017-11-11 09:02:02: Loss at step 11372: 0.03773032873868942\n",
      "2017-11-11 09:02:03: Loss at step 11373: 0.037703320384025574\n",
      "2017-11-11 09:02:03: Loss at step 11374: 0.03758963569998741\n",
      "2017-11-11 09:02:04: Loss at step 11375: 0.03775186836719513\n",
      "2017-11-11 09:02:04: Loss at step 11376: 0.0376657210290432\n",
      "2017-11-11 09:02:05: Loss at step 11377: 0.03772860765457153\n",
      "2017-11-11 09:02:05: Loss at step 11378: 0.03758428245782852\n",
      "2017-11-11 09:02:06: Loss at step 11379: 0.03772633522748947\n",
      "2017-11-11 09:02:06: Loss at step 11380: 0.03772024065256119\n",
      "2017-11-11 09:02:07: Loss at step 11381: 0.03761853650212288\n",
      "2017-11-11 09:02:07: Loss at step 11382: 0.03766167163848877\n",
      "2017-11-11 09:02:08: Loss at step 11383: 0.03763690963387489\n",
      "2017-11-11 09:02:08: Loss at step 11384: 0.03762122988700867\n",
      "2017-11-11 09:02:09: Loss at step 11385: 0.0376279316842556\n",
      "2017-11-11 09:02:09: Loss at step 11386: 0.03763798251748085\n",
      "2017-11-11 09:02:10: Loss at step 11387: 0.03757580742239952\n",
      "2017-11-11 09:02:10: Loss at step 11388: 0.037581682205200195\n",
      "2017-11-11 09:02:11: Loss at step 11389: 0.037581827491521835\n",
      "2017-11-11 09:02:11: Loss at step 11390: 0.03756169602274895\n",
      "2017-11-11 09:02:12: Loss at step 11391: 0.03762206807732582\n",
      "2017-11-11 09:02:12: Loss at step 11392: 0.03767053037881851\n",
      "2017-11-11 09:02:13: Loss at step 11393: 0.03762030601501465\n",
      "2017-11-11 09:02:13: Loss at step 11394: 0.03763965889811516\n",
      "2017-11-11 09:02:14: Loss at step 11395: 0.03757677972316742\n",
      "2017-11-11 09:02:14: Loss at step 11396: 0.037531789392232895\n",
      "2017-11-11 09:02:15: Loss at step 11397: 0.03757669776678085\n",
      "2017-11-11 09:02:15: Loss at step 11398: 0.0376075878739357\n",
      "2017-11-11 09:02:16: Loss at step 11399: 0.037628449499607086\n",
      "2017-11-11 09:02:16: Loss at step 11400: 0.037635110318660736\n",
      "2017-11-11 09:02:17: Loss at step 11401: 0.03762081637978554\n",
      "2017-11-11 09:02:17: Loss at step 11402: 0.03759702295064926\n",
      "2017-11-11 09:02:17: Loss at step 11403: 0.03757729381322861\n",
      "2017-11-11 09:02:18: Loss at step 11404: 0.03770570829510689\n",
      "2017-11-11 09:02:19: Loss at step 11405: 0.03765704110264778\n",
      "2017-11-11 09:02:19: Loss at step 11406: 0.03750692307949066\n",
      "2017-11-11 09:02:20: Loss at step 11407: 0.03763515129685402\n",
      "2017-11-11 09:02:20: Loss at step 11408: 0.0375974178314209\n",
      "2017-11-11 09:02:20: Loss at step 11409: 0.03771026432514191\n",
      "2017-11-11 09:02:21: Loss at step 11410: 0.037638433277606964\n",
      "2017-11-11 09:02:21: Loss at step 11411: 0.03764374926686287\n",
      "2017-11-11 09:02:22: Loss at step 11412: 0.03759017586708069\n",
      "2017-11-11 09:02:22: Loss at step 11413: 0.03763078898191452\n",
      "2017-11-11 09:02:22: Loss at step 11414: 0.037645384669303894\n",
      "2017-11-11 09:02:23: Loss at step 11415: 0.03767551854252815\n",
      "2017-11-11 09:02:23: Loss at step 11416: 0.0376218818128109\n",
      "2017-11-11 09:02:24: Loss at step 11417: 0.03760666027665138\n",
      "2017-11-11 09:02:24: Loss at step 11418: 0.03762780874967575\n",
      "2017-11-11 09:02:25: Loss at step 11419: 0.03758304566144943\n",
      "2017-11-11 09:02:25: Loss at step 11420: 0.03754957765340805\n",
      "2017-11-11 09:02:26: Loss at step 11421: 0.03757980838418007\n",
      "2017-11-11 09:02:26: Loss at step 11422: 0.03762856498360634\n",
      "2017-11-11 09:02:27: Loss at step 11423: 0.0376565046608448\n",
      "2017-11-11 09:02:27: Loss at step 11424: 0.03748016804456711\n",
      "2017-11-11 09:02:28: Loss at step 11425: 0.03754943981766701\n",
      "2017-11-11 09:02:28: Loss at step 11426: 0.03765479102730751\n",
      "2017-11-11 09:02:29: Loss at step 11427: 0.03764708712697029\n",
      "2017-11-11 09:02:29: Loss at step 11428: 0.03760525956749916\n",
      "2017-11-11 09:02:30: Loss at step 11429: 0.03765171766281128\n",
      "2017-11-11 09:02:30: Loss at step 11430: 0.03760157898068428\n",
      "2017-11-11 09:02:31: Loss at step 11431: 0.03762773424386978\n",
      "2017-11-11 09:02:31: Loss at step 11432: 0.03772136569023132\n",
      "2017-11-11 09:02:32: Loss at step 11433: 0.03759552165865898\n",
      "2017-11-11 09:02:32: Loss at step 11434: 0.03767041116952896\n",
      "2017-11-11 09:02:33: Loss at step 11435: 0.0375853106379509\n",
      "2017-11-11 09:02:33: Loss at step 11436: 0.03755679354071617\n",
      "2017-11-11 09:02:34: Loss at step 11437: 0.037480443716049194\n",
      "2017-11-11 09:02:34: Loss at step 11438: 0.0376102551817894\n",
      "2017-11-11 09:02:35: Loss at step 11439: 0.037630271166563034\n",
      "2017-11-11 09:02:35: Loss at step 11440: 0.0375961996614933\n",
      "2017-11-11 09:02:36: Loss at step 11441: 0.03762533515691757\n",
      "2017-11-11 09:02:36: Loss at step 11442: 0.037556327879428864\n",
      "2017-11-11 09:02:37: Loss at step 11443: 0.03764384239912033\n",
      "2017-11-11 09:02:37: Loss at step 11444: 0.037592291831970215\n",
      "2017-11-11 09:02:38: Loss at step 11445: 0.03757098317146301\n",
      "2017-11-11 09:02:38: Loss at step 11446: 0.03758912533521652\n",
      "2017-11-11 09:02:39: Loss at step 11447: 0.037599626928567886\n",
      "2017-11-11 09:02:39: Loss at step 11448: 0.03759784623980522\n",
      "2017-11-11 09:02:39: Loss at step 11449: 0.03750084713101387\n",
      "2017-11-11 09:02:40: Loss at step 11450: 0.037656743079423904\n",
      "2017-11-11 09:02:40: Loss at step 11451: 0.03765041381120682\n",
      "2017-11-11 09:02:41: Loss at step 11452: 0.03754521906375885\n",
      "2017-11-11 09:02:41: Loss at step 11453: 0.037602733820676804\n",
      "2017-11-11 09:02:41: Loss at step 11454: 0.037532493472099304\n",
      "2017-11-11 09:02:42: Loss at step 11455: 0.037625961005687714\n",
      "2017-11-11 09:02:42: Loss at step 11456: 0.03764421492815018\n",
      "2017-11-11 09:02:43: Loss at step 11457: 0.03762393817305565\n",
      "2017-11-11 09:02:43: Loss at step 11458: 0.03761875629425049\n",
      "2017-11-11 09:02:43: Loss at step 11459: 0.03767932578921318\n",
      "2017-11-11 09:02:44: Loss at step 11460: 0.037569694221019745\n",
      "2017-11-11 09:02:44: Loss at step 11461: 0.03756599873304367\n",
      "2017-11-11 09:02:45: Loss at step 11462: 0.03761535510420799\n",
      "2017-11-11 09:02:45: Loss at step 11463: 0.03766639903187752\n",
      "2017-11-11 09:02:46: Loss at step 11464: 0.037578899413347244\n",
      "2017-11-11 09:02:46: Loss at step 11465: 0.03756069019436836\n",
      "2017-11-11 09:02:47: Loss at step 11466: 0.03763251379132271\n",
      "2017-11-11 09:02:47: Loss at step 11467: 0.037596702575683594\n",
      "2017-11-11 09:02:48: Loss at step 11468: 0.03765154629945755\n",
      "2017-11-11 09:02:48: Loss at step 11469: 0.037671953439712524\n",
      "2017-11-11 09:02:49: Loss at step 11470: 0.03760386258363724\n",
      "2017-11-11 09:02:49: Loss at step 11471: 0.037624139338731766\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-11-11 09:02:49: Loss at step 11472: 0.03760844096541405\n",
      "2017-11-11 09:02:50: Loss at step 11473: 0.03765947371721268\n",
      "2017-11-11 09:02:50: Loss at step 11474: 0.03767434135079384\n",
      "2017-11-11 09:02:51: Loss at step 11475: 0.037576161324977875\n",
      "2017-11-11 09:02:51: Loss at step 11476: 0.03762374445796013\n",
      "2017-11-11 09:02:51: Loss at step 11477: 0.0376090407371521\n",
      "2017-11-11 09:02:51: Loss at step 11478: 0.037656210362911224\n",
      "2017-11-11 09:02:52: Loss at step 11479: 0.03767867386341095\n",
      "2017-11-11 09:02:52: Loss at step 11480: 0.037609539926052094\n",
      "2017-11-11 09:02:53: Loss at step 11481: 0.037709835916757584\n",
      "2017-11-11 09:02:53: Loss at step 11482: 0.03770513832569122\n",
      "2017-11-11 09:02:54: Loss at step 11483: 0.03757726401090622\n",
      "2017-11-11 09:02:54: Loss at step 11484: 0.03766881301999092\n",
      "2017-11-11 09:02:54: Loss at step 11485: 0.037630245089530945\n",
      "2017-11-11 09:02:55: Loss at step 11486: 0.03760417550802231\n",
      "2017-11-11 09:02:55: Loss at step 11487: 0.03760704770684242\n",
      "2017-11-11 09:02:56: Loss at step 11488: 0.03766028955578804\n",
      "2017-11-11 09:02:56: Loss at step 11489: 0.037631891667842865\n",
      "2017-11-11 09:02:57: Loss at step 11490: 0.0375806950032711\n",
      "2017-11-11 09:02:57: Loss at step 11491: 0.03763418644666672\n",
      "2017-11-11 09:02:58: Loss at step 11492: 0.03753519803285599\n",
      "2017-11-11 09:02:58: Loss at step 11493: 0.03760041296482086\n",
      "2017-11-11 09:02:59: Loss at step 11494: 0.03759058564901352\n",
      "2017-11-11 09:02:59: Loss at step 11495: 0.03764558210968971\n",
      "2017-11-11 09:03:00: Loss at step 11496: 0.0375165194272995\n",
      "2017-11-11 09:03:00: Loss at step 11497: 0.03772837668657303\n",
      "2017-11-11 09:03:01: Loss at step 11498: 0.03753664717078209\n",
      "2017-11-11 09:03:01: Loss at step 11499: 0.037596650421619415\n",
      "2017-11-11 09:03:02: Loss at step 11500: 0.03768184781074524\n"
     ]
    }
   ],
   "source": [
    "iteration = 11337\n",
    "while True:\n",
    "    for n in np.random.permutation(5689):\n",
    "        x_batch, y_batch = load_training_batch(n)\n",
    "        loss = model.train_on_batch(x_batch, y_batch)\n",
    "        print('{0}: Loss at step {1}: {2}'.format(dt.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"), iteration, loss))\n",
    "        if iteration % 500 == 0:\n",
    "            model.save('{0}/model-{1}.h5'.format(savePath, iteration))\n",
    "        iteration += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of errors for batch size of  70000\n",
      "9352\n"
     ]
    }
   ],
   "source": [
    "# Run a test\n",
    "batchSize = 70000\n",
    "x_batch, y_batch, _ = next_training_batch(batchSize)\n",
    "\n",
    "predictions = model.predict(np.array(x_batch), batch_size = batchSize)\n",
    "bestSquares = [pred.argmax() for pred in predictions]\n",
    "unfrees = [(ys == 0).astype(int) for ys in y_batch]\n",
    "frees = [unfrees[i][bestSquares[i]] for i in range(batchSize)]\n",
    "print(\"Number of errors for batch size of \", batchSize)\n",
    "print(sum(frees))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3600"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "900*4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6300"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "900*7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
