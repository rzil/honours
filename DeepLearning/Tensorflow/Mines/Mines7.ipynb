{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Softmax classifier for guessing minesweeper board position and whether it has a mine or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ruben/anaconda3/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "# Import libraries for simulation\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import random as r\n",
    "import datetime as dt\n",
    "import multiprocessing as mp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dimensions = (8,8)\n",
    "mineProbability = 0.16      # Probability that a square contain a mine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Clears a square on the minesweeper board.\n",
    "# If it had a mine, return true\n",
    "# Otherwise if it has no adjacent mines, recursively run on adjacent squares\n",
    "# Return false\n",
    "def clearSquare(board,adjacency,row,col):\n",
    "    rows,cols = dimensions\n",
    "    if board[row,col] == 1:\n",
    "        return True\n",
    "    if adjacency[row,col] >= 0:\n",
    "        return False\n",
    "    n = 0\n",
    "    for r in range(row-1,row+2):\n",
    "        for c in range(col-1,col+2):\n",
    "            if 0 <= r and r < rows and 0 <= c and c < cols:\n",
    "                n += board[r,c]\n",
    "    adjacency[row,col] = n\n",
    "    if n == 0:\n",
    "        for r in range(row-1,row+2):\n",
    "            for c in range(col-1,col+2):\n",
    "                if 0 <= r and r < rows and 0 <= c and c < cols:\n",
    "                    clearSquare(board,adjacency,r,c)\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# This takes a mine board and gives a mine count with mines removed, and other random squares removed\n",
    "def boardPartialMineCounts(board):\n",
    "    clearProbability = r.uniform(0.05,0.5)\n",
    "    result = np.full(dimensions,-1)\n",
    "    for index, x in np.random.permutation(list(np.ndenumerate(board))):\n",
    "        row,col = index\n",
    "        if not(x) and result[row,col] == -1 and r.uniform(0,1) < clearProbability:\n",
    "            clearSquare(board,result,row,col)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Generates a random training batch of size n\n",
    "def randomBoard(i):\n",
    "    return(np.random.random(dimensions) < mineProbability)\n",
    "\n",
    "def encodeCountsOneHot(counts):\n",
    "    countsOneHot = np.zeros((counts.size,10))\n",
    "    countsOneHot[np.arange(counts.size), counts.flatten() + 1] = 1\n",
    "    return(countsOneHot.flatten())\n",
    "\n",
    "def validGuesses(boardAndCounts):\n",
    "    board,counts = boardAndCounts\n",
    "    validGuesses = np.append(((counts == -1).astype(int) - board).flatten().astype(float),\n",
    "        board.flatten().astype(float))\n",
    "    validGuessesSum = sum(validGuesses)\n",
    "    if validGuessesSum > 0:\n",
    "        return(validGuesses / validGuessesSum)\n",
    "    else:\n",
    "        return(np.zeros(board.size*2))\n",
    "\n",
    "try:\n",
    "    cpus = mp.cpu_count()\n",
    "except NotImplementedError:\n",
    "    cpus = 2   # arbitrary default\n",
    "\n",
    "pool = mp.Pool(processes=cpus)\n",
    "\n",
    "def next_training_batch(n):\n",
    "    boards = pool.map(randomBoard, range(n))\n",
    "    counts = pool.map(boardPartialMineCounts, boards)\n",
    "    batch_xs = pool.map(encodeCountsOneHot, counts)\n",
    "    batch_ys = pool.map(validGuesses, zip(boards,counts))\n",
    "    return(batch_xs, batch_ys, boards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the model\n",
    "rows, cols = dimensions\n",
    "size = rows*cols\n",
    "mineCountsOneHot = tf.placeholder(tf.float32, [None, size*10], name=\"mineCountsOneHot\")\n",
    "W = tf.Variable(tf.truncated_normal([size*10, size], stddev=0.01), name=\"W\")\n",
    "b = tf.Variable(tf.truncated_normal([size], stddev=0.01), name=\"b\")\n",
    "y = tf.matmul(mineCountsOneHot, W) + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def weight_variable(shape):\n",
    "  initial = tf.truncated_normal(shape, stddev=0.01)\n",
    "  return tf.Variable(initial)\n",
    "\n",
    "def bias_variable(shape):\n",
    "  initial = tf.truncated_normal(shape, stddev=0.01)\n",
    "  return tf.Variable(initial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def conv2d(x, W):\n",
    "  return tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], padding='SAME')\n",
    "\n",
    "def max_pool_2x2(x):\n",
    "  return tf.nn.max_pool(x, ksize=[1, 2, 2, 1],\n",
    "                        strides=[1, 2, 2, 1], padding='SAME')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_image = tf.reshape(y, [-1, rows, cols, 1])\n",
    "\n",
    "# First convolution layer\n",
    "W_conv1 = weight_variable([5, 5, 1, 32])\n",
    "b_conv1 = bias_variable([32])\n",
    "\n",
    "h_conv1 = tf.nn.relu(conv2d(y_image, W_conv1) + b_conv1)\n",
    "h_pool1 = max_pool_2x2(h_conv1)\n",
    "\n",
    "# Second convolution layer\n",
    "W_conv2 = weight_variable([5, 5, 32, 64])\n",
    "b_conv2 = bias_variable([64])\n",
    "\n",
    "h_conv2 = tf.nn.relu(conv2d(h_pool1, W_conv2) + b_conv2)\n",
    "h_pool2 = max_pool_2x2(h_conv2)\n",
    "\n",
    "# Fully connected layer\n",
    "W_fc1 = weight_variable([(rows // 4) * (cols // 4) * 64, 1024])\n",
    "b_fc1 = bias_variable([1024])\n",
    "\n",
    "h_pool2_flat = tf.reshape(h_pool2, [-1, (rows // 4) * (cols // 4) * 64])\n",
    "h_fc1 = tf.nn.relu(tf.matmul(h_pool2_flat, W_fc1) + b_fc1)\n",
    "\n",
    "# Dropout\n",
    "keep_prob = tf.placeholder(tf.float32)\n",
    "h_fc1_drop = tf.nn.dropout(h_fc1, keep_prob)\n",
    "\n",
    "# Output layer\n",
    "W_fc2 = weight_variable([1024, size*2])\n",
    "b_fc2 = bias_variable([size*2])\n",
    "\n",
    "y_conv = tf.matmul(h_fc1_drop, W_fc2) + b_fc2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "validGuessAverages = tf.placeholder(tf.float32, [None, size*2], name=\"validGuessAverages\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Loss function\n",
    "cross_entropy = tf.reduce_mean(\n",
    "    tf.nn.softmax_cross_entropy_with_logits(labels=validGuessAverages, logits=y_conv))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summaries for tensorboard\n",
    "with tf.name_scope('W_reshape'):\n",
    "    image_shaped_W = tf.reshape(W, [-1, size*10, size, 1])\n",
    "    tf.summary.image('W', image_shaped_W, 1000)\n",
    "\n",
    "with tf.name_scope('b_reshape'):\n",
    "    image_shaped_b = tf.reshape(b, [-1, rows, cols, 1])\n",
    "    tf.summary.image('b', image_shaped_b, 1000)\n",
    "\n",
    "with tf.name_scope('W_conv1_reshape'):\n",
    "    image_shaped_W_conv1 = tf.reshape(W_conv1, [-1, 5*5, 32, 1])\n",
    "    tf.summary.image('W_conv1', image_shaped_W_conv1, 1000)\n",
    "\n",
    "with tf.name_scope('W_conv2_reshape'):\n",
    "    image_shaped_W_conv2 = tf.reshape(W_conv2, [-1, 5*32, 5*64, 1])\n",
    "    tf.summary.image('W_conv2', image_shaped_W_conv2, 1000)\n",
    "\n",
    "with tf.name_scope('W_fc1_reshape'):\n",
    "    image_shaped_W_fc1 = tf.reshape(W_fc1, [-1, (rows // 4) * (cols // 4) * 64, 1024, 1])\n",
    "    tf.summary.image('W_fc1', image_shaped_W_fc1, 1000)\n",
    "\n",
    "with tf.name_scope('b_fc1_reshape'):\n",
    "    image_shaped_b_fc1 = tf.reshape(b_fc1, [-1, 32, 32, 1])\n",
    "    tf.summary.image('b_fc1', image_shaped_b_fc1, 1000)\n",
    "\n",
    "with tf.name_scope('W_fc2_reshape'):\n",
    "    image_shaped_W_fc2 = tf.reshape(W_fc2, [-1, 1024, size*2, 1])\n",
    "    tf.summary.image('W_fc2', image_shaped_W_fc2, 1000)\n",
    "\n",
    "with tf.name_scope('b_fc2_reshape'):\n",
    "    image_shaped_b_fc2 = tf.reshape(b_fc2, [-1, rows*2, cols, 1])\n",
    "    tf.summary.image('b_fc2', image_shaped_b_fc2, 1000)\n",
    "\n",
    "_ = tf.summary.scalar('loss', cross_entropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Optimiser\n",
    "train_step = tf.train.AdamOptimizer(1e-4).minimize(cross_entropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "savePathPrefix = './tf.Mines7/'\n",
    "\n",
    "modelDataPath = savePathPrefix + str(dimensions) + '/'\n",
    "\n",
    "def summaryPath(run):\n",
    "    return(savePathPrefix + 'runs/' + str(run) + '/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create session and initialise or restore stuff\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "sess = tf.InteractiveSession()\n",
    "\n",
    "merged = tf.summary.merge_all()\n",
    "writer = tf.summary.FileWriter(summaryPath(2), sess.graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.global_variables_initializer().run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./tf.Mines7/(8, 8)/model-500\n"
     ]
    }
   ],
   "source": [
    "# Restore model?\n",
    "saver.restore(sess, modelDataPath + \"model-500\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-11-07 22:48:21: Loss at step 500: 4.15547\n",
      "Model saved in file: ./tf.Mines7/(8, 8)/model-500\n",
      "2017-11-07 22:48:23: Loss at step 501: 4.16083\n",
      "2017-11-07 22:48:26: Loss at step 502: 4.15455\n",
      "2017-11-07 22:48:28: Loss at step 503: 4.16372\n",
      "2017-11-07 22:48:30: Loss at step 504: 4.15998\n",
      "2017-11-07 22:48:32: Loss at step 505: 4.16758\n",
      "2017-11-07 22:48:34: Loss at step 506: 4.15288\n",
      "2017-11-07 22:48:37: Loss at step 507: 4.15988\n",
      "2017-11-07 22:48:39: Loss at step 508: 4.1558\n",
      "2017-11-07 22:48:41: Loss at step 509: 4.15529\n",
      "2017-11-07 22:48:44: Loss at step 510: 4.16095\n",
      "Model saved in file: ./tf.Mines7/(8, 8)/model-510\n",
      "2017-11-07 22:48:46: Loss at step 511: 4.15329\n",
      "2017-11-07 22:48:49: Loss at step 512: 4.15399\n",
      "2017-11-07 22:48:51: Loss at step 513: 4.16003\n",
      "2017-11-07 22:48:53: Loss at step 514: 4.15884\n",
      "2017-11-07 22:48:56: Loss at step 515: 4.13847\n",
      "2017-11-07 22:48:58: Loss at step 516: 4.15752\n",
      "2017-11-07 22:49:01: Loss at step 517: 4.15615\n",
      "2017-11-07 22:49:03: Loss at step 518: 4.16768\n",
      "2017-11-07 22:49:05: Loss at step 519: 4.15051\n",
      "2017-11-07 22:49:07: Loss at step 520: 4.14866\n",
      "Model saved in file: ./tf.Mines7/(8, 8)/model-520\n",
      "2017-11-07 22:49:10: Loss at step 521: 4.14604\n",
      "2017-11-07 22:49:12: Loss at step 522: 4.15502\n",
      "2017-11-07 22:49:14: Loss at step 523: 4.15357\n",
      "2017-11-07 22:49:16: Loss at step 524: 4.14194\n",
      "2017-11-07 22:49:19: Loss at step 525: 4.15882\n",
      "2017-11-07 22:49:21: Loss at step 526: 4.15903\n",
      "2017-11-07 22:49:23: Loss at step 527: 4.16503\n",
      "2017-11-07 22:49:25: Loss at step 528: 4.15723\n",
      "2017-11-07 22:49:28: Loss at step 529: 4.16432\n",
      "2017-11-07 22:49:30: Loss at step 530: 4.1529\n",
      "Model saved in file: ./tf.Mines7/(8, 8)/model-530\n",
      "2017-11-07 22:49:32: Loss at step 531: 4.15312\n",
      "2017-11-07 22:49:34: Loss at step 532: 4.15271\n",
      "2017-11-07 22:49:37: Loss at step 533: 4.15921\n",
      "2017-11-07 22:49:40: Loss at step 534: 4.14752\n",
      "2017-11-07 22:49:43: Loss at step 535: 4.15875\n",
      "2017-11-07 22:49:45: Loss at step 536: 4.14735\n",
      "2017-11-07 22:49:47: Loss at step 537: 4.159\n",
      "2017-11-07 22:49:49: Loss at step 538: 4.14609\n",
      "2017-11-07 22:49:52: Loss at step 539: 4.13516\n",
      "2017-11-07 22:49:54: Loss at step 540: 4.15714\n",
      "Model saved in file: ./tf.Mines7/(8, 8)/model-540\n",
      "2017-11-07 22:49:56: Loss at step 541: 4.1595\n",
      "2017-11-07 22:49:59: Loss at step 542: 4.15019\n",
      "2017-11-07 22:50:01: Loss at step 543: 4.14867\n",
      "2017-11-07 22:50:04: Loss at step 544: 4.15665\n",
      "2017-11-07 22:50:07: Loss at step 545: 4.16521\n",
      "2017-11-07 22:50:09: Loss at step 546: 4.14755\n",
      "2017-11-07 22:50:12: Loss at step 547: 4.15658\n",
      "2017-11-07 22:50:14: Loss at step 548: 4.16472\n",
      "2017-11-07 22:50:17: Loss at step 549: 4.1664\n",
      "2017-11-07 22:50:19: Loss at step 550: 4.15264\n",
      "Model saved in file: ./tf.Mines7/(8, 8)/model-550\n",
      "2017-11-07 22:50:21: Loss at step 551: 4.1598\n",
      "2017-11-07 22:50:23: Loss at step 552: 4.1532\n",
      "2017-11-07 22:50:26: Loss at step 553: 4.15679\n",
      "2017-11-07 22:50:28: Loss at step 554: 4.15446\n",
      "2017-11-07 22:50:30: Loss at step 555: 4.14901\n",
      "2017-11-07 22:50:32: Loss at step 556: 4.14168\n",
      "2017-11-07 22:50:34: Loss at step 557: 4.15615\n",
      "2017-11-07 22:50:37: Loss at step 558: 4.15118\n",
      "2017-11-07 22:50:40: Loss at step 559: 4.15396\n",
      "2017-11-07 22:50:42: Loss at step 560: 4.14836\n",
      "Model saved in file: ./tf.Mines7/(8, 8)/model-560\n",
      "2017-11-07 22:50:45: Loss at step 561: 4.15355\n",
      "2017-11-07 22:50:47: Loss at step 562: 4.14664\n",
      "2017-11-07 22:50:49: Loss at step 563: 4.15166\n",
      "2017-11-07 22:50:51: Loss at step 564: 4.14973\n",
      "2017-11-07 22:50:53: Loss at step 565: 4.15078\n",
      "2017-11-07 22:50:56: Loss at step 566: 4.15149\n",
      "2017-11-07 22:50:58: Loss at step 567: 4.14601\n",
      "2017-11-07 22:51:00: Loss at step 568: 4.14139\n",
      "2017-11-07 22:51:02: Loss at step 569: 4.14911\n",
      "2017-11-07 22:51:05: Loss at step 570: 4.14568\n",
      "Model saved in file: ./tf.Mines7/(8, 8)/model-570\n",
      "2017-11-07 22:51:08: Loss at step 571: 4.15213\n",
      "2017-11-07 22:51:10: Loss at step 572: 4.15621\n",
      "2017-11-07 22:51:13: Loss at step 573: 4.14987\n",
      "2017-11-07 22:51:15: Loss at step 574: 4.15367\n",
      "2017-11-07 22:51:18: Loss at step 575: 4.1382\n",
      "2017-11-07 22:51:20: Loss at step 576: 4.15786\n",
      "2017-11-07 22:51:22: Loss at step 577: 4.1521\n",
      "2017-11-07 22:51:24: Loss at step 578: 4.14472\n",
      "2017-11-07 22:51:27: Loss at step 579: 4.14584\n",
      "2017-11-07 22:51:29: Loss at step 580: 4.14613\n",
      "Model saved in file: ./tf.Mines7/(8, 8)/model-580\n",
      "2017-11-07 22:51:32: Loss at step 581: 4.15528\n",
      "2017-11-07 22:51:35: Loss at step 582: 4.15405\n",
      "2017-11-07 22:51:37: Loss at step 583: 4.14138\n",
      "2017-11-07 22:51:39: Loss at step 584: 4.13389\n",
      "2017-11-07 22:51:41: Loss at step 585: 4.15489\n",
      "2017-11-07 22:51:44: Loss at step 586: 4.16288\n",
      "2017-11-07 22:51:46: Loss at step 587: 4.15518\n",
      "2017-11-07 22:51:49: Loss at step 588: 4.14564\n",
      "2017-11-07 22:51:52: Loss at step 589: 4.14932\n",
      "2017-11-07 22:51:54: Loss at step 590: 4.15056\n",
      "Model saved in file: ./tf.Mines7/(8, 8)/model-590\n",
      "2017-11-07 22:51:57: Loss at step 591: 4.15152\n",
      "2017-11-07 22:51:59: Loss at step 592: 4.13745\n",
      "2017-11-07 22:52:01: Loss at step 593: 4.14341\n",
      "2017-11-07 22:52:04: Loss at step 594: 4.1367\n",
      "2017-11-07 22:52:06: Loss at step 595: 4.14586\n",
      "2017-11-07 22:52:08: Loss at step 596: 4.15572\n",
      "2017-11-07 22:52:11: Loss at step 597: 4.15408\n",
      "2017-11-07 22:52:13: Loss at step 598: 4.15473\n",
      "2017-11-07 22:52:16: Loss at step 599: 4.14913\n",
      "2017-11-07 22:52:18: Loss at step 600: 4.13446\n",
      "Model saved in file: ./tf.Mines7/(8, 8)/model-600\n",
      "2017-11-07 22:52:21: Loss at step 601: 4.13931\n",
      "2017-11-07 22:52:23: Loss at step 602: 4.13991\n",
      "2017-11-07 22:52:25: Loss at step 603: 4.14528\n",
      "2017-11-07 22:52:27: Loss at step 604: 4.14582\n",
      "2017-11-07 22:52:30: Loss at step 605: 4.15011\n",
      "2017-11-07 22:52:33: Loss at step 606: 4.14811\n",
      "2017-11-07 22:52:35: Loss at step 607: 4.14385\n",
      "2017-11-07 22:52:37: Loss at step 608: 4.14488\n",
      "2017-11-07 22:52:40: Loss at step 609: 4.14223\n",
      "2017-11-07 22:52:42: Loss at step 610: 4.14675\n",
      "Model saved in file: ./tf.Mines7/(8, 8)/model-610\n",
      "2017-11-07 22:52:44: Loss at step 611: 4.14669\n",
      "2017-11-07 22:52:46: Loss at step 612: 4.14806\n",
      "2017-11-07 22:52:49: Loss at step 613: 4.15395\n",
      "2017-11-07 22:52:52: Loss at step 614: 4.13596\n",
      "2017-11-07 22:52:54: Loss at step 615: 4.14209\n",
      "2017-11-07 22:52:56: Loss at step 616: 4.13897\n",
      "2017-11-07 22:52:59: Loss at step 617: 4.15012\n",
      "2017-11-07 22:53:01: Loss at step 618: 4.14372\n",
      "2017-11-07 22:53:03: Loss at step 619: 4.14501\n",
      "2017-11-07 22:53:06: Loss at step 620: 4.13226\n",
      "Model saved in file: ./tf.Mines7/(8, 8)/model-620\n",
      "2017-11-07 22:53:08: Loss at step 621: 4.1486\n",
      "2017-11-07 22:53:10: Loss at step 622: 4.14438\n",
      "2017-11-07 22:53:12: Loss at step 623: 4.13314\n",
      "2017-11-07 22:53:14: Loss at step 624: 4.13441\n",
      "2017-11-07 22:53:17: Loss at step 625: 4.14414\n",
      "2017-11-07 22:53:20: Loss at step 626: 4.14701\n",
      "2017-11-07 22:53:22: Loss at step 627: 4.14835\n",
      "2017-11-07 22:53:25: Loss at step 628: 4.14019\n",
      "2017-11-07 22:53:27: Loss at step 629: 4.13749\n",
      "2017-11-07 22:53:29: Loss at step 630: 4.1435\n",
      "Model saved in file: ./tf.Mines7/(8, 8)/model-630\n",
      "2017-11-07 22:53:31: Loss at step 631: 4.1498\n",
      "2017-11-07 22:53:33: Loss at step 632: 4.14652\n",
      "2017-11-07 22:53:36: Loss at step 633: 4.147\n",
      "2017-11-07 22:53:38: Loss at step 634: 4.1457\n",
      "2017-11-07 22:53:40: Loss at step 635: 4.14202\n",
      "2017-11-07 22:53:42: Loss at step 636: 4.13586\n",
      "2017-11-07 22:53:45: Loss at step 637: 4.14863\n",
      "2017-11-07 22:53:48: Loss at step 638: 4.13918\n",
      "2017-11-07 22:53:50: Loss at step 639: 4.14346\n"
     ]
    }
   ],
   "source": [
    "# Train\n",
    "for iteration in range(500,100001):\n",
    "    batch_xs, batch_ys, _ = next_training_batch(10000)\n",
    "    summary, loss, _ = sess.run([merged, cross_entropy, train_step],\n",
    "                                 feed_dict={mineCountsOneHot: batch_xs, validGuessAverages: batch_ys, keep_prob: 0.5})\n",
    "    writer.add_summary(summary, iteration)\n",
    "    print('%s: Loss at step %s: %s' % (dt.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"), iteration, loss))\n",
    "    if iteration % 10 == 0:\n",
    "        save_path = saver.save(sess, modelDataPath + 'model', global_step=iteration)\n",
    "        print(\"Model saved in file: %s\" % save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test trained model on larger batch size\n",
    "batch_xs, batch_ys, _ = next_training_batch(10000)\n",
    "print(sess.run(cross_entropy, feed_dict={mineCountsOneHot: batch_xs, validGuessAverages: batch_ys}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run a test\n",
    "batchSize = 10000\n",
    "batch_xs, batch_ys,_ = next_training_batch(batchSize)\n",
    "\n",
    "predictions = sess.run(tf.nn.softmax(y), feed_dict={mineCountsOneHot: batch_xs, validGuessAverages: batch_ys})\n",
    "bestSquares = [pred.argmax() for pred in predictions]\n",
    "unfrees = (batch_ys == 0).astype(int)\n",
    "frees = [unfrees[i][bestSquares[i]] for i in range(batchSize)]\n",
    "print(\"Number of errors for batch size of \", batchSize)\n",
    "print(sum(frees))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Find boards that we failed on\n",
    "batchSize = 1000\n",
    "batch_xs, batch_ys, _ = next_training_batch(batchSize)\n",
    "\n",
    "predictions = sess.run(tf.nn.softmax(y), feed_dict={mineCountsOneHot: batch_xs, validGuessAverages: batch_ys})\n",
    "bestSquares = [pred.argmax() for pred in predictions]\n",
    "unfrees = (batch_ys == 0).astype(int)\n",
    "guesses = [unfrees[i][bestSquares[i]] for i in range(batchSize)]\n",
    "for i in range(batchSize):\n",
    "    if guesses[i] == 1:\n",
    "        print(batch_xs[i].reshape(dimensions))\n",
    "        summary = sess.run(tf.summary.image('mine_miss', tf.reshape((batch_xs[i]+1).astype(float),[-1,rows,cols,1]), 100))\n",
    "        writer.add_summary(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#batch_xs = [[-1,1,-1,0,0,0,-1,-1,-1,1,1,1,-1,-1,1,2,2,1,1,-1,2,1,1,-1,-1,2,2,-1,-1,2,-1,1,1,0,-1,-1,2,-1,-1,4,-1,2,-1,1,2,-1,1,0,1,2,-1,3,2,2,1,-1,2,-1,1,0,0,1,1,-1,-1,-1,-1,-1,-1,1,1,-1,-1,0,0,3,-1,4,1,2,-1,1,-1,-1,0,0,0,2,-1,-1,-1,2,-1,1,0,0,0,-1,1,2,-1,2,1,2,2,3,3,2,-1,-1,1,-1,1,-1,0,1,2,-1,-1,-1,1,1,1,-1,1,0,-1,-1,-1,-1,-1,-1,-1,-1,0,-1,-1,-1,-1,-1,1,-1,-1,-1]]\n",
    "batch_xs0 = [-1] * (size)\n",
    "batch_xs0[0] = 1\n",
    "batch_xs0[1] = 1\n",
    "batch_xs0[cols] = 1\n",
    "\n",
    "predictions = sess.run(tf.nn.softmax(y), feed_dict={mineCounts: [batch_xs0]})\n",
    "bestSquares = [pred.argmax() for pred in predictions]\n",
    "\n",
    "print(bestSquares[0] // cols, bestSquares[0] % cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.save(\"./W\", sess.run(W))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.save(\"./b\", sess.run(b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.savez(\"./model\", sess.run([W,b]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
