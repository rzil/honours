{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Softmax classifier for guessing minesweeper board position and whether it has a mine or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ruben/anaconda3/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "# Import libraries for simulation\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import random as r\n",
    "import datetime as dt\n",
    "import multiprocessing as mp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dimensions = (8,8)\n",
    "mineProbability = 0.16      # Probability that a square contain a mine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Clears a square on the minesweeper board.\n",
    "# If it had a mine, return true\n",
    "# Otherwise if it has no adjacent mines, recursively run on adjacent squares\n",
    "# Return false\n",
    "def clearSquare(board,adjacency,row,col):\n",
    "    rows,cols = dimensions\n",
    "    if board[row,col] == 1:\n",
    "        return True\n",
    "    if adjacency[row,col] >= 0:\n",
    "        return False\n",
    "    n = 0\n",
    "    for r in range(row-1,row+2):\n",
    "        for c in range(col-1,col+2):\n",
    "            if 0 <= r and r < rows and 0 <= c and c < cols:\n",
    "                n += board[r,c]\n",
    "    adjacency[row,col] = n\n",
    "    if n == 0:\n",
    "        for r in range(row-1,row+2):\n",
    "            for c in range(col-1,col+2):\n",
    "                if 0 <= r and r < rows and 0 <= c and c < cols:\n",
    "                    clearSquare(board,adjacency,r,c)\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# This takes a mine board and gives a mine count with mines removed, and other random squares removed\n",
    "def boardPartialMineCounts(board):\n",
    "    clearProbability = r.uniform(0.05,0.5)\n",
    "    result = np.full(dimensions,-1)\n",
    "    for index, x in np.random.permutation(list(np.ndenumerate(board))):\n",
    "        row,col = index\n",
    "        if not(x) and result[row,col] == -1 and r.uniform(0,1) < clearProbability:\n",
    "            clearSquare(board,result,row,col)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Generates a random training batch of size n\n",
    "def randomBoard(i):\n",
    "    return(np.random.random(dimensions) < mineProbability)\n",
    "\n",
    "def encodeCountsOneHot(counts):\n",
    "    countsOneHot = np.zeros((counts.size,10))\n",
    "    countsOneHot[np.arange(counts.size), counts.flatten() + 1] = 1\n",
    "    return(countsOneHot.flatten())\n",
    "\n",
    "def validGuesses(boardAndCounts):\n",
    "    board,counts = boardAndCounts\n",
    "    validGuesses = np.append(((counts == -1).astype(int) - board).flatten().astype(float),\n",
    "        board.flatten().astype(float))\n",
    "    validGuessesSum = sum(validGuesses)\n",
    "    if validGuessesSum > 0:\n",
    "        return(validGuesses / validGuessesSum)\n",
    "    else:\n",
    "        return(np.zeros(board.size*2))\n",
    "\n",
    "def next_training_batch(n):\n",
    "    try:\n",
    "        cpus = mp.cpu_count()\n",
    "    except NotImplementedError:\n",
    "        cpus = 2   # arbitrary default\n",
    "    \n",
    "    pool = mp.Pool(processes=cpus)\n",
    "    boards = pool.map(randomBoard, range(n))\n",
    "    counts = pool.map(boardPartialMineCounts, boards)\n",
    "    batch_xs = pool.map(encodeCountsOneHot, counts)\n",
    "    batch_ys = pool.map(validGuesses, zip(boards,counts))\n",
    "    return(batch_xs, batch_ys, boards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the model\n",
    "rows, cols = dimensions\n",
    "size = rows*cols\n",
    "mineCountsOneHot = tf.placeholder(tf.float32, [None, size*10], name=\"mineCountsOneHot\")\n",
    "W = tf.Variable(tf.truncated_normal([size*10, size], stddev=0.01), name=\"W\")\n",
    "b = tf.Variable(tf.truncated_normal([size], stddev=0.01), name=\"b\")\n",
    "y = tf.matmul(mineCountsOneHot, W) + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def weight_variable(shape):\n",
    "  initial = tf.truncated_normal(shape, stddev=0.01)\n",
    "  return tf.Variable(initial)\n",
    "\n",
    "def bias_variable(shape):\n",
    "  initial = tf.truncated_normal(shape, stddev=0.01)\n",
    "  return tf.Variable(initial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def conv2d(x, W):\n",
    "  return tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], padding='SAME')\n",
    "\n",
    "def max_pool_2x2(x):\n",
    "  return tf.nn.max_pool(x, ksize=[1, 2, 2, 1],\n",
    "                        strides=[1, 2, 2, 1], padding='SAME')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_image = tf.reshape(y, [-1, rows, cols, 1])\n",
    "\n",
    "# First convolution layer\n",
    "W_conv1 = weight_variable([5, 5, 1, 32])\n",
    "b_conv1 = bias_variable([32])\n",
    "\n",
    "h_conv1 = tf.nn.relu(conv2d(y_image, W_conv1) + b_conv1)\n",
    "h_pool1 = max_pool_2x2(h_conv1)\n",
    "\n",
    "# Second convolution layer\n",
    "W_conv2 = weight_variable([5, 5, 32, 64])\n",
    "b_conv2 = bias_variable([64])\n",
    "\n",
    "h_conv2 = tf.nn.relu(conv2d(h_pool1, W_conv2) + b_conv2)\n",
    "h_pool2 = max_pool_2x2(h_conv2)\n",
    "\n",
    "# Fully connected layer\n",
    "W_fc1 = weight_variable([(rows // 4) * (cols // 4) * 64, 1024])\n",
    "b_fc1 = bias_variable([1024])\n",
    "\n",
    "h_pool2_flat = tf.reshape(h_pool2, [-1, (rows // 4) * (cols // 4) * 64])\n",
    "h_fc1 = tf.nn.relu(tf.matmul(h_pool2_flat, W_fc1) + b_fc1)\n",
    "\n",
    "# Dropout\n",
    "keep_prob = tf.placeholder(tf.float32)\n",
    "h_fc1_drop = tf.nn.dropout(h_fc1, keep_prob)\n",
    "\n",
    "# Output layer\n",
    "W_fc2 = weight_variable([1024, size*2])\n",
    "b_fc2 = bias_variable([size*2])\n",
    "\n",
    "y_conv = tf.matmul(h_fc1_drop, W_fc2) + b_fc2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "validGuessAverages = tf.placeholder(tf.float32, [None, size*2], name=\"validGuessAverages\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Loss function\n",
    "cross_entropy = tf.reduce_mean(\n",
    "    tf.nn.softmax_cross_entropy_with_logits(labels=validGuessAverages, logits=y_conv))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summaries for tensorboard\n",
    "with tf.name_scope('W_reshape'):\n",
    "    image_shaped_W = tf.reshape(W, [-1, size*10, size, 1])\n",
    "    tf.summary.image('W', image_shaped_W, 1000)\n",
    "\n",
    "with tf.name_scope('b_reshape'):\n",
    "    image_shaped_b = tf.reshape(b, [-1, rows, cols, 1])\n",
    "    tf.summary.image('b', image_shaped_b, 1000)\n",
    "\n",
    "with tf.name_scope('W_conv1_reshape'):\n",
    "    image_shaped_W_conv1 = tf.reshape(W_conv1, [-1, 5*5, 32, 1])\n",
    "    tf.summary.image('W_conv1', image_shaped_W_conv1, 1000)\n",
    "\n",
    "with tf.name_scope('W_conv2_reshape'):\n",
    "    image_shaped_W_conv2 = tf.reshape(W_conv2, [-1, 5*32, 5*64, 1])\n",
    "    tf.summary.image('W_conv2', image_shaped_W_conv2, 1000)\n",
    "\n",
    "with tf.name_scope('W_fc1_reshape'):\n",
    "    image_shaped_W_fc1 = tf.reshape(W_fc1, [-1, (rows // 4) * (cols // 4) * 64, 1024, 1])\n",
    "    tf.summary.image('W_fc1', image_shaped_W_fc1, 1000)\n",
    "\n",
    "with tf.name_scope('b_fc1_reshape'):\n",
    "    image_shaped_b_fc1 = tf.reshape(b_fc1, [-1, 32, 32, 1])\n",
    "    tf.summary.image('b_fc1', image_shaped_b_fc1, 1000)\n",
    "\n",
    "with tf.name_scope('W_fc2_reshape'):\n",
    "    image_shaped_W_fc2 = tf.reshape(W_fc2, [-1, 1024, size*2, 1])\n",
    "    tf.summary.image('W_fc2', image_shaped_W_fc2, 1000)\n",
    "\n",
    "with tf.name_scope('b_fc2_reshape'):\n",
    "    image_shaped_b_fc2 = tf.reshape(b_fc2, [-1, rows*2, cols, 1])\n",
    "    tf.summary.image('b_fc2', image_shaped_b_fc2, 1000)\n",
    "\n",
    "_ = tf.summary.scalar('loss', cross_entropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Optimiser\n",
    "train_step = tf.train.AdamOptimizer(1e-4).minimize(cross_entropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "savePathPrefix = './tf.Mines7/'\n",
    "\n",
    "modelDataPath = savePathPrefix + str(dimensions) + '/'\n",
    "\n",
    "def summaryPath(run):\n",
    "    return(savePathPrefix + 'runs/' + str(run) + '/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create session and initialise or restore stuff\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "sess = tf.InteractiveSession()\n",
    "\n",
    "merged = tf.summary.merge_all()\n",
    "writer = tf.summary.FileWriter(summaryPath(2), sess.graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.global_variables_initializer().run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./tf.Mines7/(8, 8)/model-500\n"
     ]
    }
   ],
   "source": [
    "# Restore model?\n",
    "saver.restore(sess, modelDataPath + \"model-500\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-11-07 22:27:56: Loss at step 500: 4.16753\n",
      "Model saved in file: ./tf.Mines7/(8, 8)/model-500\n",
      "2017-11-07 22:27:59: Loss at step 501: 4.16508\n",
      "2017-11-07 22:28:01: Loss at step 502: 4.16522\n",
      "2017-11-07 22:28:03: Loss at step 503: 4.16439\n",
      "2017-11-07 22:28:06: Loss at step 504: 4.16712\n",
      "2017-11-07 22:28:08: Loss at step 505: 4.16418\n",
      "2017-11-07 22:28:10: Loss at step 506: 4.15744\n",
      "2017-11-07 22:28:13: Loss at step 507: 4.15824\n",
      "2017-11-07 22:28:16: Loss at step 508: 4.15448\n",
      "2017-11-07 22:28:18: Loss at step 509: 4.15706\n",
      "2017-11-07 22:28:21: Loss at step 510: 4.15516\n",
      "Model saved in file: ./tf.Mines7/(8, 8)/model-510\n",
      "2017-11-07 22:28:23: Loss at step 511: 4.15855\n",
      "2017-11-07 22:28:26: Loss at step 512: 4.15605\n",
      "2017-11-07 22:28:29: Loss at step 513: 4.15382\n",
      "2017-11-07 22:28:32: Loss at step 514: 4.15822\n",
      "2017-11-07 22:28:35: Loss at step 515: 4.15429\n",
      "2017-11-07 22:28:37: Loss at step 516: 4.15056\n",
      "2017-11-07 22:28:40: Loss at step 517: 4.15017\n",
      "2017-11-07 22:28:42: Loss at step 518: 4.15399\n",
      "2017-11-07 22:28:45: Loss at step 519: 4.15253\n",
      "2017-11-07 22:28:47: Loss at step 520: 4.14859\n",
      "Model saved in file: ./tf.Mines7/(8, 8)/model-520\n",
      "2017-11-07 22:28:50: Loss at step 521: 4.14593\n",
      "2017-11-07 22:28:52: Loss at step 522: 4.14347\n",
      "2017-11-07 22:28:55: Loss at step 523: 4.14955\n",
      "2017-11-07 22:28:58: Loss at step 524: 4.14619\n",
      "2017-11-07 22:29:00: Loss at step 525: 4.14578\n",
      "2017-11-07 22:29:03: Loss at step 526: 4.14356\n",
      "2017-11-07 22:29:05: Loss at step 527: 4.14483\n",
      "2017-11-07 22:29:08: Loss at step 528: 4.14285\n",
      "2017-11-07 22:29:10: Loss at step 529: 4.14142\n",
      "2017-11-07 22:29:13: Loss at step 530: 4.14302\n",
      "Model saved in file: ./tf.Mines7/(8, 8)/model-530\n",
      "2017-11-07 22:29:15: Loss at step 531: 4.1423\n",
      "2017-11-07 22:29:18: Loss at step 532: 4.14347\n",
      "2017-11-07 22:29:20: Loss at step 533: 4.1401\n",
      "2017-11-07 22:29:23: Loss at step 534: 4.14109\n",
      "2017-11-07 22:29:25: Loss at step 535: 4.14062\n",
      "2017-11-07 22:29:28: Loss at step 536: 4.13966\n",
      "2017-11-07 22:29:31: Loss at step 537: 4.14066\n",
      "2017-11-07 22:29:33: Loss at step 538: 4.13866\n",
      "2017-11-07 22:29:36: Loss at step 539: 4.13804\n",
      "2017-11-07 22:29:38: Loss at step 540: 4.13714\n",
      "Model saved in file: ./tf.Mines7/(8, 8)/model-540\n",
      "2017-11-07 22:29:41: Loss at step 541: 4.13547\n",
      "2017-11-07 22:29:44: Loss at step 542: 4.13374\n",
      "2017-11-07 22:29:46: Loss at step 543: 4.13538\n",
      "2017-11-07 22:29:49: Loss at step 544: 4.13613\n",
      "2017-11-07 22:29:51: Loss at step 545: 4.13858\n"
     ]
    }
   ],
   "source": [
    "# Train\n",
    "for iteration in range(500,100001):\n",
    "    batch_xs, batch_ys, _ = next_training_batch(10000)\n",
    "    summary, loss, _ = sess.run([merged, cross_entropy, train_step],\n",
    "                                 feed_dict={mineCountsOneHot: batch_xs, validGuessAverages: batch_ys, keep_prob: 0.5})\n",
    "    writer.add_summary(summary, iteration)\n",
    "    print('%s: Loss at step %s: %s' % (dt.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"), iteration, loss))\n",
    "    if iteration % 10 == 0:\n",
    "        save_path = saver.save(sess, modelDataPath + 'model', global_step=iteration)\n",
    "        print(\"Model saved in file: %s\" % save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test trained model on larger batch size\n",
    "batch_xs, batch_ys, _ = next_training_batch(10000)\n",
    "print(sess.run(cross_entropy, feed_dict={mineCountsOneHot: batch_xs, validGuessAverages: batch_ys}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run a test\n",
    "batchSize = 10000\n",
    "batch_xs, batch_ys,_ = next_training_batch(batchSize)\n",
    "\n",
    "predictions = sess.run(tf.nn.softmax(y), feed_dict={mineCountsOneHot: batch_xs, validGuessAverages: batch_ys})\n",
    "bestSquares = [pred.argmax() for pred in predictions]\n",
    "unfrees = (batch_ys == 0).astype(int)\n",
    "frees = [unfrees[i][bestSquares[i]] for i in range(batchSize)]\n",
    "print(\"Number of errors for batch size of \", batchSize)\n",
    "print(sum(frees))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Find boards that we failed on\n",
    "batchSize = 1000\n",
    "batch_xs, batch_ys, _ = next_training_batch(batchSize)\n",
    "\n",
    "predictions = sess.run(tf.nn.softmax(y), feed_dict={mineCountsOneHot: batch_xs, validGuessAverages: batch_ys})\n",
    "bestSquares = [pred.argmax() for pred in predictions]\n",
    "unfrees = (batch_ys == 0).astype(int)\n",
    "guesses = [unfrees[i][bestSquares[i]] for i in range(batchSize)]\n",
    "for i in range(batchSize):\n",
    "    if guesses[i] == 1:\n",
    "        print(batch_xs[i].reshape(dimensions))\n",
    "        summary = sess.run(tf.summary.image('mine_miss', tf.reshape((batch_xs[i]+1).astype(float),[-1,rows,cols,1]), 100))\n",
    "        writer.add_summary(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#batch_xs = [[-1,1,-1,0,0,0,-1,-1,-1,1,1,1,-1,-1,1,2,2,1,1,-1,2,1,1,-1,-1,2,2,-1,-1,2,-1,1,1,0,-1,-1,2,-1,-1,4,-1,2,-1,1,2,-1,1,0,1,2,-1,3,2,2,1,-1,2,-1,1,0,0,1,1,-1,-1,-1,-1,-1,-1,1,1,-1,-1,0,0,3,-1,4,1,2,-1,1,-1,-1,0,0,0,2,-1,-1,-1,2,-1,1,0,0,0,-1,1,2,-1,2,1,2,2,3,3,2,-1,-1,1,-1,1,-1,0,1,2,-1,-1,-1,1,1,1,-1,1,0,-1,-1,-1,-1,-1,-1,-1,-1,0,-1,-1,-1,-1,-1,1,-1,-1,-1]]\n",
    "batch_xs0 = [-1] * (size)\n",
    "batch_xs0[0] = 1\n",
    "batch_xs0[1] = 1\n",
    "batch_xs0[cols] = 1\n",
    "\n",
    "predictions = sess.run(tf.nn.softmax(y), feed_dict={mineCounts: [batch_xs0]})\n",
    "bestSquares = [pred.argmax() for pred in predictions]\n",
    "\n",
    "print(bestSquares[0] // cols, bestSquares[0] % cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.save(\"./W\", sess.run(W))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.save(\"./b\", sess.run(b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.savez(\"./model\", sess.run([W,b]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
