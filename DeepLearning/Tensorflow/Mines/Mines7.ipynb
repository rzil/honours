{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Softmax classifier for guessing minesweeper board position and whether it has a mine or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "# Import libraries for simulation\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import random as r\n",
    "import datetime as dt\n",
    "import multiprocessing as mp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dimensions = (8,8)\n",
    "mineProbability = 0.16      # Probability that a square contain a mine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clears a square on the minesweeper board.\n",
    "# If it had a mine, return true\n",
    "# Otherwise if it has no adjacent mines, recursively run on adjacent squares\n",
    "# Return false\n",
    "def clearSquare(board,adjacency,row,col):\n",
    "    rows,cols = dimensions\n",
    "    if board[row,col] == 1:\n",
    "        return True\n",
    "    if adjacency[row,col] >= 0:\n",
    "        return False\n",
    "    n = 0\n",
    "    for r in range(row-1,row+2):\n",
    "        for c in range(col-1,col+2):\n",
    "            if 0 <= r and r < rows and 0 <= c and c < cols:\n",
    "                n += board[r,c]\n",
    "    adjacency[row,col] = n\n",
    "    if n == 0:\n",
    "        for r in range(row-1,row+2):\n",
    "            for c in range(col-1,col+2):\n",
    "                if 0 <= r and r < rows and 0 <= c and c < cols:\n",
    "                    clearSquare(board,adjacency,r,c)\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This takes a mine board and gives a mine count with mines removed, and other random squares removed\n",
    "def boardPartialMineCounts(board):\n",
    "    clearProbability = r.uniform(0.05,0.5)\n",
    "    result = np.full(dimensions,-1)\n",
    "    for index, x in np.random.permutation(list(np.ndenumerate(board))):\n",
    "        row,col = index\n",
    "        if not(x) and result[row,col] == -1 and r.uniform(0,1) < clearProbability:\n",
    "            clearSquare(board,result,row,col)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generates a random training batch of size n\n",
    "def randomBoard(i):\n",
    "    return(np.random.random(dimensions) < mineProbability)\n",
    "\n",
    "def encodeCountsOneHot(counts):\n",
    "    countsOneHot = np.zeros((counts.size,10))\n",
    "    countsOneHot[np.arange(counts.size), counts.flatten() + 1] = 1\n",
    "    return(countsOneHot.flatten())\n",
    "\n",
    "def validGuesses(boardAndCounts):\n",
    "    board,counts = boardAndCounts\n",
    "    validGuesses = np.append(((counts == -1).astype(int) - board).flatten().astype(float),\n",
    "        board.flatten().astype(float))\n",
    "    validGuessesSum = sum(validGuesses)\n",
    "    if validGuessesSum > 0:\n",
    "        return(validGuesses / validGuessesSum)\n",
    "    else:\n",
    "        return(np.zeros(board.size*2))\n",
    "\n",
    "try:\n",
    "    cpus = mp.cpu_count()\n",
    "except NotImplementedError:\n",
    "    cpus = 2   # arbitrary default\n",
    "\n",
    "pool = mp.Pool(processes=cpus)\n",
    "\n",
    "def next_training_batch(n):\n",
    "    boards = pool.map(randomBoard, range(n))\n",
    "    counts = pool.map(boardPartialMineCounts, boards)\n",
    "    batch_xs = pool.map(encodeCountsOneHot, counts)\n",
    "    batch_ys = pool.map(validGuesses, zip(boards,counts))\n",
    "    return(batch_xs, batch_ys, boards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the model\n",
    "rows, cols = dimensions\n",
    "size = rows*cols\n",
    "mineCountsOneHot = tf.placeholder(tf.float32, [None, size*10], name=\"mineCountsOneHot\")\n",
    "W = tf.Variable(tf.truncated_normal([size*10, size], stddev=0.01), name=\"W\")\n",
    "b = tf.Variable(tf.truncated_normal([size], stddev=0.01), name=\"b\")\n",
    "y = tf.matmul(mineCountsOneHot, W) + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weight_variable(shape):\n",
    "  initial = tf.truncated_normal(shape, stddev=0.01)\n",
    "  return tf.Variable(initial)\n",
    "\n",
    "def bias_variable(shape):\n",
    "  initial = tf.truncated_normal(shape, stddev=0.01)\n",
    "  return tf.Variable(initial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv2d(x, W):\n",
    "  return tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], padding='SAME')\n",
    "\n",
    "def max_pool_2x2(x):\n",
    "  return tf.nn.max_pool(x, ksize=[1, 2, 2, 1],\n",
    "                        strides=[1, 2, 2, 1], padding='SAME')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_image = tf.reshape(y, [-1, rows, cols, 1])\n",
    "\n",
    "# First convolution layer\n",
    "W_conv1 = weight_variable([5, 5, 1, 32])\n",
    "b_conv1 = bias_variable([32])\n",
    "\n",
    "h_conv1 = tf.nn.relu(conv2d(y_image, W_conv1) + b_conv1)\n",
    "h_pool1 = max_pool_2x2(h_conv1)\n",
    "\n",
    "# Second convolution layer\n",
    "W_conv2 = weight_variable([5, 5, 32, 64])\n",
    "b_conv2 = bias_variable([64])\n",
    "\n",
    "h_conv2 = tf.nn.relu(conv2d(h_pool1, W_conv2) + b_conv2)\n",
    "h_pool2 = max_pool_2x2(h_conv2)\n",
    "\n",
    "# Third convolution layer\n",
    "W_conv3 = weight_variable([5, 5, 64, 64])\n",
    "b_conv3 = bias_variable([64])\n",
    "\n",
    "h_conv3 = tf.nn.relu(conv2d(h_pool2, W_conv3) + b_conv3)\n",
    "h_pool3 = max_pool_2x2(h_conv3)\n",
    "\n",
    "# Fully connected layer\n",
    "W_fc1 = weight_variable([64, 1024])\n",
    "b_fc1 = bias_variable([1024])\n",
    "\n",
    "h_pool3_flat = tf.reshape(h_pool3, [-1, 64])\n",
    "h_fc1 = tf.nn.relu(tf.matmul(h_pool3_flat, W_fc1) + b_fc1)\n",
    "\n",
    "# Dropout\n",
    "keep_prob = tf.placeholder(tf.float32)\n",
    "h_fc1_drop = tf.nn.dropout(h_fc1, keep_prob)\n",
    "\n",
    "# Output layer\n",
    "W_fc2 = weight_variable([1024, size*2])\n",
    "b_fc2 = bias_variable([size*2])\n",
    "\n",
    "y_conv = tf.matmul(h_fc1_drop, W_fc2) + b_fc2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "validGuessAverages = tf.placeholder(tf.float32, [None, size*2], name=\"validGuessAverages\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss function\n",
    "cross_entropy = tf.reduce_mean(\n",
    "    tf.nn.softmax_cross_entropy_with_logits(labels=validGuessAverages, logits=y_conv))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Counts the number of errors if we take the best guess for each sample\n",
    "def countErrors(xs,ys):\n",
    "    predictions = sess.run(y_conv, feed_dict={mineCountsOneHot: batch_xs, keep_prob: 1.0})\n",
    "    bestSquares = pool.map(np.argmax, predictions)\n",
    "    unfrees = [(b == 0).astype(int) for b in batch_ys]\n",
    "    frees = [unfrees[i][bestSquares[i]] for i in range(len(batch_xs))]\n",
    "    return(sum(frees))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summaries for tensorboard\n",
    "_ = tf.summary.scalar('loss', cross_entropy)\n",
    "\n",
    "errors = tf.placeholder(tf.int32, (), name=\"errors\")\n",
    "_ = tf.summary.scalar('errors', errors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimiser\n",
    "train_step = tf.train.AdamOptimizer(1e-4).minimize(cross_entropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "savePathPrefix = './tf.Mines7/' + str(dimensions) + '/'\n",
    "\n",
    "modelDataPath = savePathPrefix\n",
    "\n",
    "def summaryPath(run):\n",
    "    return(savePathPrefix + 'runs/' + str(run) + '/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create session and initialise or restore stuff\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "sess = tf.InteractiveSession()\n",
    "\n",
    "merged = tf.summary.merge_all()\n",
    "writer = tf.summary.FileWriter(summaryPath(4), sess.graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.global_variables_initializer().run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./tf.Mines7/(8, 8)/model-5280\n"
     ]
    }
   ],
   "source": [
    "# Restore model?\n",
    "saver.restore(sess, modelDataPath + \"model-5280\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-11-09 01:11:01: Loss at step 5281: 3.90554. Errors 1371\n",
      "2017-11-09 01:11:03: Loss at step 5282: 3.91501. Errors 1244\n",
      "2017-11-09 01:11:05: Loss at step 5283: 3.93045. Errors 1378\n",
      "2017-11-09 01:11:07: Loss at step 5284: 3.91485. Errors 1336\n",
      "2017-11-09 01:11:10: Loss at step 5285: 3.92611. Errors 1328\n",
      "2017-11-09 01:11:12: Loss at step 5286: 3.93262. Errors 1307\n",
      "2017-11-09 01:11:14: Loss at step 5287: 3.92561. Errors 1350\n",
      "2017-11-09 01:11:16: Loss at step 5288: 3.91912. Errors 1371\n",
      "2017-11-09 01:11:19: Loss at step 5289: 3.91504. Errors 1346\n",
      "2017-11-09 01:11:21: Loss at step 5290: 3.93764. Errors 1437\n",
      "Model saved in file: ./tf.Mines7/(8, 8)/model-5290\n",
      "2017-11-09 01:11:23: Loss at step 5291: 3.91827. Errors 1323\n",
      "2017-11-09 01:11:26: Loss at step 5292: 3.90529. Errors 1276\n",
      "2017-11-09 01:11:28: Loss at step 5293: 3.9209. Errors 1297\n",
      "2017-11-09 01:11:30: Loss at step 5294: 3.93685. Errors 1321\n",
      "2017-11-09 01:11:33: Loss at step 5295: 3.92287. Errors 1310\n",
      "2017-11-09 01:11:35: Loss at step 5296: 3.92008. Errors 1314\n",
      "2017-11-09 01:11:37: Loss at step 5297: 3.91258. Errors 1335\n",
      "2017-11-09 01:11:40: Loss at step 5298: 3.91226. Errors 1315\n",
      "2017-11-09 01:11:42: Loss at step 5299: 3.92085. Errors 1322\n",
      "2017-11-09 01:11:44: Loss at step 5300: 3.91789. Errors 1334\n",
      "Model saved in file: ./tf.Mines7/(8, 8)/model-5300\n",
      "2017-11-09 01:11:47: Loss at step 5301: 3.91584. Errors 1295\n",
      "2017-11-09 01:11:49: Loss at step 5302: 3.9224. Errors 1309\n",
      "2017-11-09 01:11:51: Loss at step 5303: 3.93977. Errors 1349\n",
      "2017-11-09 01:11:54: Loss at step 5304: 3.90405. Errors 1309\n",
      "2017-11-09 01:11:56: Loss at step 5305: 3.92569. Errors 1350\n",
      "2017-11-09 01:11:58: Loss at step 5306: 3.91976. Errors 1392\n",
      "2017-11-09 01:12:00: Loss at step 5307: 3.91415. Errors 1310\n",
      "2017-11-09 01:12:03: Loss at step 5308: 3.9211. Errors 1291\n",
      "2017-11-09 01:12:05: Loss at step 5309: 3.91227. Errors 1291\n",
      "2017-11-09 01:12:07: Loss at step 5310: 3.91358. Errors 1322\n",
      "Model saved in file: ./tf.Mines7/(8, 8)/model-5310\n",
      "2017-11-09 01:12:10: Loss at step 5311: 3.9016. Errors 1326\n",
      "2017-11-09 01:12:12: Loss at step 5312: 3.90672. Errors 1263\n",
      "2017-11-09 01:12:14: Loss at step 5313: 3.90479. Errors 1259\n",
      "2017-11-09 01:12:16: Loss at step 5314: 3.92288. Errors 1312\n",
      "2017-11-09 01:12:19: Loss at step 5315: 3.91924. Errors 1317\n",
      "2017-11-09 01:12:21: Loss at step 5316: 3.9067. Errors 1280\n",
      "2017-11-09 01:12:23: Loss at step 5317: 3.90293. Errors 1254\n",
      "2017-11-09 01:12:25: Loss at step 5318: 3.89464. Errors 1220\n",
      "2017-11-09 01:12:28: Loss at step 5319: 3.92555. Errors 1300\n",
      "2017-11-09 01:12:30: Loss at step 5320: 3.92314. Errors 1282\n",
      "Model saved in file: ./tf.Mines7/(8, 8)/model-5320\n",
      "2017-11-09 01:12:32: Loss at step 5321: 3.93042. Errors 1309\n",
      "2017-11-09 01:12:34: Loss at step 5322: 3.91139. Errors 1234\n",
      "2017-11-09 01:12:36: Loss at step 5323: 3.90303. Errors 1308\n",
      "2017-11-09 01:12:39: Loss at step 5324: 3.91251. Errors 1306\n",
      "2017-11-09 01:12:41: Loss at step 5325: 3.91316. Errors 1290\n",
      "2017-11-09 01:12:43: Loss at step 5326: 3.91606. Errors 1259\n",
      "2017-11-09 01:12:45: Loss at step 5327: 3.91894. Errors 1285\n",
      "2017-11-09 01:12:47: Loss at step 5328: 3.91605. Errors 1256\n",
      "2017-11-09 01:12:50: Loss at step 5329: 3.90706. Errors 1283\n",
      "2017-11-09 01:12:52: Loss at step 5330: 3.91084. Errors 1281\n",
      "Model saved in file: ./tf.Mines7/(8, 8)/model-5330\n",
      "2017-11-09 01:12:54: Loss at step 5331: 3.92059. Errors 1254\n",
      "2017-11-09 01:12:56: Loss at step 5332: 3.90489. Errors 1240\n",
      "2017-11-09 01:12:58: Loss at step 5333: 3.91185. Errors 1244\n",
      "2017-11-09 01:13:00: Loss at step 5334: 3.92021. Errors 1317\n",
      "2017-11-09 01:13:03: Loss at step 5335: 3.93027. Errors 1424\n",
      "2017-11-09 01:13:05: Loss at step 5336: 3.90909. Errors 1315\n",
      "2017-11-09 01:13:07: Loss at step 5337: 3.90485. Errors 1303\n",
      "2017-11-09 01:13:09: Loss at step 5338: 3.91198. Errors 1259\n",
      "2017-11-09 01:13:12: Loss at step 5339: 3.923. Errors 1325\n",
      "2017-11-09 01:13:14: Loss at step 5340: 3.9192. Errors 1286\n",
      "Model saved in file: ./tf.Mines7/(8, 8)/model-5340\n",
      "2017-11-09 01:13:16: Loss at step 5341: 3.90863. Errors 1283\n",
      "2017-11-09 01:13:18: Loss at step 5342: 3.90116. Errors 1266\n",
      "2017-11-09 01:13:21: Loss at step 5343: 3.90775. Errors 1264\n",
      "2017-11-09 01:13:23: Loss at step 5344: 3.90232. Errors 1242\n",
      "2017-11-09 01:13:25: Loss at step 5345: 3.92231. Errors 1298\n",
      "2017-11-09 01:13:28: Loss at step 5346: 3.92733. Errors 1278\n",
      "2017-11-09 01:13:30: Loss at step 5347: 3.91832. Errors 1303\n",
      "2017-11-09 01:13:33: Loss at step 5348: 3.91495. Errors 1288\n",
      "2017-11-09 01:13:35: Loss at step 5349: 3.91875. Errors 1321\n",
      "2017-11-09 01:13:37: Loss at step 5350: 3.92585. Errors 1287\n",
      "Model saved in file: ./tf.Mines7/(8, 8)/model-5350\n",
      "2017-11-09 01:13:39: Loss at step 5351: 3.92333. Errors 1399\n",
      "2017-11-09 01:13:41: Loss at step 5352: 3.92362. Errors 1294\n",
      "2017-11-09 01:13:44: Loss at step 5353: 3.90963. Errors 1294\n",
      "2017-11-09 01:13:46: Loss at step 5354: 3.91422. Errors 1327\n",
      "2017-11-09 01:13:48: Loss at step 5355: 3.91732. Errors 1323\n",
      "2017-11-09 01:13:50: Loss at step 5356: 3.92618. Errors 1247\n",
      "2017-11-09 01:13:52: Loss at step 5357: 3.92614. Errors 1343\n",
      "2017-11-09 01:13:54: Loss at step 5358: 3.91672. Errors 1288\n",
      "2017-11-09 01:13:57: Loss at step 5359: 3.91465. Errors 1298\n",
      "2017-11-09 01:13:59: Loss at step 5360: 3.91561. Errors 1288\n",
      "Model saved in file: ./tf.Mines7/(8, 8)/model-5360\n",
      "2017-11-09 01:14:01: Loss at step 5361: 3.9223. Errors 1296\n",
      "2017-11-09 01:14:03: Loss at step 5362: 3.92366. Errors 1296\n",
      "2017-11-09 01:14:05: Loss at step 5363: 3.92103. Errors 1343\n",
      "2017-11-09 01:14:08: Loss at step 5364: 3.91641. Errors 1248\n",
      "2017-11-09 01:14:10: Loss at step 5365: 3.91054. Errors 1319\n",
      "2017-11-09 01:14:12: Loss at step 5366: 3.92308. Errors 1236\n",
      "2017-11-09 01:14:14: Loss at step 5367: 3.92963. Errors 1275\n",
      "2017-11-09 01:14:16: Loss at step 5368: 3.92861. Errors 1304\n",
      "2017-11-09 01:14:18: Loss at step 5369: 3.92827. Errors 1311\n",
      "2017-11-09 01:14:21: Loss at step 5370: 3.91519. Errors 1328\n",
      "Model saved in file: ./tf.Mines7/(8, 8)/model-5370\n",
      "2017-11-09 01:14:23: Loss at step 5371: 3.91374. Errors 1301\n",
      "2017-11-09 01:14:25: Loss at step 5372: 3.90508. Errors 1281\n",
      "2017-11-09 01:14:27: Loss at step 5373: 3.91722. Errors 1371\n",
      "2017-11-09 01:14:30: Loss at step 5374: 3.90109. Errors 1290\n",
      "2017-11-09 01:14:32: Loss at step 5375: 3.90957. Errors 1258\n",
      "2017-11-09 01:14:34: Loss at step 5376: 3.91497. Errors 1322\n",
      "2017-11-09 01:14:36: Loss at step 5377: 3.91545. Errors 1315\n",
      "2017-11-09 01:14:38: Loss at step 5378: 3.92482. Errors 1339\n",
      "2017-11-09 01:14:40: Loss at step 5379: 3.92092. Errors 1304\n",
      "2017-11-09 01:14:43: Loss at step 5380: 3.92671. Errors 1224\n",
      "Model saved in file: ./tf.Mines7/(8, 8)/model-5380\n",
      "2017-11-09 01:14:45: Loss at step 5381: 3.91061. Errors 1261\n",
      "2017-11-09 01:14:47: Loss at step 5382: 3.91772. Errors 1299\n",
      "2017-11-09 01:14:49: Loss at step 5383: 3.92626. Errors 1296\n",
      "2017-11-09 01:14:51: Loss at step 5384: 3.91353. Errors 1295\n",
      "2017-11-09 01:14:53: Loss at step 5385: 3.91588. Errors 1289\n",
      "2017-11-09 01:14:56: Loss at step 5386: 3.91669. Errors 1329\n",
      "2017-11-09 01:14:58: Loss at step 5387: 3.91587. Errors 1288\n",
      "2017-11-09 01:15:00: Loss at step 5388: 3.90195. Errors 1251\n",
      "2017-11-09 01:15:02: Loss at step 5389: 3.91232. Errors 1269\n",
      "2017-11-09 01:15:04: Loss at step 5390: 3.91707. Errors 1269\n",
      "Model saved in file: ./tf.Mines7/(8, 8)/model-5390\n",
      "2017-11-09 01:15:06: Loss at step 5391: 3.91684. Errors 1326\n",
      "2017-11-09 01:15:08: Loss at step 5392: 3.90758. Errors 1314\n",
      "2017-11-09 01:15:11: Loss at step 5393: 3.93357. Errors 1306\n",
      "2017-11-09 01:15:13: Loss at step 5394: 3.92075. Errors 1288\n",
      "2017-11-09 01:15:15: Loss at step 5395: 3.91595. Errors 1212\n",
      "2017-11-09 01:15:17: Loss at step 5396: 3.91917. Errors 1313\n",
      "2017-11-09 01:15:19: Loss at step 5397: 3.92216. Errors 1251\n",
      "2017-11-09 01:15:21: Loss at step 5398: 3.91883. Errors 1318\n",
      "2017-11-09 01:15:24: Loss at step 5399: 3.91588. Errors 1277\n",
      "2017-11-09 01:15:26: Loss at step 5400: 3.92038. Errors 1306\n",
      "Model saved in file: ./tf.Mines7/(8, 8)/model-5400\n",
      "2017-11-09 01:15:28: Loss at step 5401: 3.91369. Errors 1272\n",
      "2017-11-09 01:15:30: Loss at step 5402: 3.92817. Errors 1337\n",
      "2017-11-09 01:15:32: Loss at step 5403: 3.91551. Errors 1267\n",
      "2017-11-09 01:15:35: Loss at step 5404: 3.9136. Errors 1245\n",
      "2017-11-09 01:15:37: Loss at step 5405: 3.91562. Errors 1317\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-11-09 01:15:39: Loss at step 5406: 3.90758. Errors 1249\n",
      "2017-11-09 01:15:41: Loss at step 5407: 3.91508. Errors 1298\n",
      "2017-11-09 01:15:43: Loss at step 5408: 3.92009. Errors 1276\n",
      "2017-11-09 01:15:45: Loss at step 5409: 3.92945. Errors 1316\n",
      "2017-11-09 01:15:48: Loss at step 5410: 3.92789. Errors 1298\n",
      "Model saved in file: ./tf.Mines7/(8, 8)/model-5410\n"
     ]
    }
   ],
   "source": [
    "# Train\n",
    "for iteration in range(5281,100001):\n",
    "    batch_xs, batch_ys, _ = next_training_batch(10000)\n",
    "    errorCount = countErrors(batch_xs,batch_ys)\n",
    "    summary, loss, _ = sess.run([merged, cross_entropy, train_step],\n",
    "                                 feed_dict={mineCountsOneHot: batch_xs, validGuessAverages: batch_ys, keep_prob: 0.5, errors: errorCount})\n",
    "    writer.add_summary(summary, iteration)\n",
    "    print('%s: Loss at step %s: %s. Errors %s' % (dt.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"), iteration, loss, errorCount))\n",
    "    if iteration % 10 == 0:\n",
    "        save_path = saver.save(sess, modelDataPath + 'model', global_step=iteration)\n",
    "        print(\"Model saved in file: %s\" % save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test trained model on larger batch size\n",
    "batch_xs, batch_ys, _ = next_training_batch(10000)\n",
    "print(sess.run(cross_entropy, feed_dict={mineCountsOneHot: batch_xs, validGuessAverages: batch_ys, keep_prob: 1.0}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run a test\n",
    "batchSize = 10000\n",
    "batch_xs, batch_ys,_ = next_training_batch(batchSize)\n",
    "\n",
    "#countErrors(batch_xs,batch_ys)\n",
    "len(batch_xs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find boards that we failed on\n",
    "batchSize = 1000\n",
    "batch_xs, batch_ys, _ = next_training_batch(batchSize)\n",
    "\n",
    "predictions = sess.run(tf.nn.softmax(y), feed_dict={mineCountsOneHot: batch_xs, validGuessAverages: batch_ys})\n",
    "bestSquares = [pred.argmax() for pred in predictions]\n",
    "unfrees = (batch_ys == 0).astype(int)\n",
    "guesses = [unfrees[i][bestSquares[i]] for i in range(batchSize)]\n",
    "for i in range(batchSize):\n",
    "    if guesses[i] == 1:\n",
    "        print(batch_xs[i].reshape(dimensions))\n",
    "        summary = sess.run(tf.summary.image('mine_miss', tf.reshape((batch_xs[i]+1).astype(float),[-1,rows,cols,1]), 100))\n",
    "        writer.add_summary(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#batch_xs = [[-1,1,-1,0,0,0,-1,-1,-1,1,1,1,-1,-1,1,2,2,1,1,-1,2,1,1,-1,-1,2,2,-1,-1,2,-1,1,1,0,-1,-1,2,-1,-1,4,-1,2,-1,1,2,-1,1,0,1,2,-1,3,2,2,1,-1,2,-1,1,0,0,1,1,-1,-1,-1,-1,-1,-1,1,1,-1,-1,0,0,3,-1,4,1,2,-1,1,-1,-1,0,0,0,2,-1,-1,-1,2,-1,1,0,0,0,-1,1,2,-1,2,1,2,2,3,3,2,-1,-1,1,-1,1,-1,0,1,2,-1,-1,-1,1,1,1,-1,1,0,-1,-1,-1,-1,-1,-1,-1,-1,0,-1,-1,-1,-1,-1,1,-1,-1,-1]]\n",
    "batch_xs0 = [-1] * (size)\n",
    "batch_xs0[0] = 1\n",
    "batch_xs0[1] = 1\n",
    "batch_xs0[cols] = 1\n",
    "\n",
    "predictions = sess.run(tf.nn.softmax(y), feed_dict={mineCounts: [batch_xs0]})\n",
    "bestSquares = [pred.argmax() for pred in predictions]\n",
    "\n",
    "print(bestSquares[0] // cols, bestSquares[0] % cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"./W\", sess.run(W))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"./b\", sess.run(b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez(\"./model\", sess.run([W,b]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
