{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ruben/anaconda3/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "# Import libraries for simulation\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import random as r\n",
    "import datetime as dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dimensions = (12,12)\n",
    "mineProbability = 0.2      # Probability that a square contain a mine\n",
    "missingProbability = 0.1   # Probability that a square is missing adjacency info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# count the number of mines in the proximity of given square, including square itself\n",
    "def countMines(board,r,c):\n",
    "    count = 0\n",
    "    rows, cols = board.shape\n",
    "    for i in [r-1,r,r+1]:\n",
    "        if i >= 0 and i < rows:\n",
    "            for j in [c-1,c,c+1]:\n",
    "                if j >= 0 and j < cols:\n",
    "                    count += int(board[i,j])\n",
    "    return count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def minesweepMatrix(dimensions):\n",
    "    rows,cols = dimensions\n",
    "    size = rows * cols\n",
    "    A = np.zeros([size,size],dtype=int)\n",
    "    for rA in range(size):\n",
    "        for cA in range(size):\n",
    "            inRow, inCol = divmod(rA,cols)\n",
    "            outRow, outCol = divmod(cA,cols)\n",
    "            A[rA,cA] = abs(inRow-outRow) <= 1 and abs(inCol-outCol) <= 1\n",
    "    return(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Converts a board of mines into a board of mine counts\n",
    "'''\n",
    "def boardMineCounts_(board):\n",
    "    mineInfo = np.zeros(board.shape, dtype = int)\n",
    "    rows, cols = board.shape\n",
    "    for i in range(rows):\n",
    "        for j in range(cols):\n",
    "            mineInfo[i,j] = countMines(board,i,j)\n",
    "    return mineInfo\n",
    "'''\n",
    "def boardMineCounts(board):\n",
    "    return(minesweepMatrix(board.shape).dot(board.flatten()).reshape(board.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def boardPartialMineCounts(board):\n",
    "    result = boardMineCounts(board)\n",
    "    for index, x in np.ndenumerate(board):\n",
    "        if x: result[index] = -1\n",
    "        elif r.uniform(0, 1) < missingProbability: result[index] = -1\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Generates a random training batch of size at most n\n",
    "def next_training_batch(n):\n",
    "    batch_xs = []\n",
    "    batch_ys = []\n",
    "    for _ in range(n):\n",
    "        board = np.random.random(dimensions) < mineProbability\n",
    "        counts = boardPartialMineCounts(board)\n",
    "        frees = board.flatten().astype(float)\n",
    "        freesSum = sum(frees)\n",
    "        if freesSum > 0:\n",
    "            batch_xs.append(counts.flatten())\n",
    "            batch_ys.append(frees / freesSum)\n",
    "    return (np.asarray(batch_xs), np.asarray(batch_ys))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the model\n",
    "rows, cols = dimensions\n",
    "size = rows*cols\n",
    "mineCounts = tf.placeholder(tf.int32, [None, size], name=\"mineCounts\")\n",
    "mineCountsOneHot = tf.reshape(tf.one_hot(mineCounts+1,10), [-1, size*10])\n",
    "W = tf.Variable(tf.random_normal([size*10, size], stddev=0.01), name=\"W\")\n",
    "b = tf.Variable(tf.random_normal([size], stddev=0.01), name=\"b\")\n",
    "y = tf.matmul(mineCountsOneHot, W) + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "mineFreeAverages = tf.placeholder(tf.float32, [None, size], name=\"mineFreeAverages\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Loss function\n",
    "cross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=mineFreeAverages, logits=y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summaries for tensorboard\n",
    "with tf.name_scope('W_reshape'):\n",
    "    image_shaped_W = tf.reshape(W, [-1, size*10, size, 1])\n",
    "    tf.summary.image('W', image_shaped_W, 1000)\n",
    "\n",
    "with tf.name_scope('b_reshape'):\n",
    "    image_shaped_b = tf.reshape(b, [-1, rows, cols, 1])\n",
    "    tf.summary.image('b', image_shaped_b, 1000)\n",
    "\n",
    "_ = tf.summary.scalar('accuracy', cross_entropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Optimiser\n",
    "train_step = tf.train.AdamOptimizer().minimize(cross_entropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create session and initialise or restore stuff\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "sess = tf.InteractiveSession()\n",
    "\n",
    "merged = tf.summary.merge_all()\n",
    "writer = tf.summary.FileWriter('.', sess.graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.global_variables_initializer().run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Restore model?\n",
    "#saver.restore(sess, \"./saves.tf.Mines3/model-1000\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-11-05 14:55:20: Accuracy at step 0: 4.97697\n",
      "Model saved in file: ./saves.tf.Mines3/model-0\n",
      "2017-11-05 14:55:26: Accuracy at step 10: 4.94447\n",
      "2017-11-05 14:55:33: Accuracy at step 20: 4.90134\n",
      "2017-11-05 14:55:39: Accuracy at step 30: 4.87258\n",
      "2017-11-05 14:55:46: Accuracy at step 40: 4.83213\n",
      "2017-11-05 14:55:53: Accuracy at step 50: 4.79532\n",
      "2017-11-05 14:55:59: Accuracy at step 60: 4.76595\n",
      "2017-11-05 14:56:06: Accuracy at step 70: 4.73029\n",
      "2017-11-05 14:56:12: Accuracy at step 80: 4.69795\n",
      "2017-11-05 14:56:19: Accuracy at step 90: 4.66942\n",
      "2017-11-05 14:56:25: Accuracy at step 100: 4.636\n",
      "2017-11-05 14:56:32: Accuracy at step 110: 4.62983\n",
      "2017-11-05 14:56:39: Accuracy at step 120: 4.58871\n",
      "2017-11-05 14:56:45: Accuracy at step 130: 4.56895\n",
      "2017-11-05 14:56:52: Accuracy at step 140: 4.53597\n",
      "2017-11-05 14:56:58: Accuracy at step 150: 4.51945\n",
      "2017-11-05 14:57:05: Accuracy at step 160: 4.48905\n",
      "2017-11-05 14:57:12: Accuracy at step 170: 4.46237\n",
      "2017-11-05 14:57:19: Accuracy at step 180: 4.45361\n",
      "2017-11-05 14:57:25: Accuracy at step 190: 4.42313\n",
      "2017-11-05 14:57:32: Accuracy at step 200: 4.40394\n",
      "2017-11-05 14:57:39: Accuracy at step 210: 4.38065\n",
      "2017-11-05 14:57:45: Accuracy at step 220: 4.37048\n",
      "2017-11-05 14:57:52: Accuracy at step 230: 4.34222\n",
      "2017-11-05 14:57:58: Accuracy at step 240: 4.32369\n",
      "2017-11-05 14:58:05: Accuracy at step 250: 4.30834\n",
      "2017-11-05 14:58:11: Accuracy at step 260: 4.27803\n",
      "2017-11-05 14:58:18: Accuracy at step 270: 4.26074\n",
      "2017-11-05 14:58:25: Accuracy at step 280: 4.25482\n",
      "2017-11-05 14:58:31: Accuracy at step 290: 4.22575\n",
      "2017-11-05 14:58:38: Accuracy at step 300: 4.21434\n",
      "2017-11-05 14:58:44: Accuracy at step 310: 4.2111\n",
      "2017-11-05 14:58:51: Accuracy at step 320: 4.18609\n",
      "2017-11-05 14:58:57: Accuracy at step 330: 4.19265\n",
      "2017-11-05 14:59:04: Accuracy at step 340: 4.16409\n",
      "2017-11-05 14:59:11: Accuracy at step 350: 4.16277\n",
      "2017-11-05 14:59:17: Accuracy at step 360: 4.1259\n",
      "2017-11-05 14:59:24: Accuracy at step 370: 4.13216\n",
      "2017-11-05 14:59:30: Accuracy at step 380: 4.09474\n",
      "2017-11-05 14:59:37: Accuracy at step 390: 4.10563\n",
      "2017-11-05 14:59:43: Accuracy at step 400: 4.07903\n",
      "2017-11-05 14:59:50: Accuracy at step 410: 4.07621\n",
      "2017-11-05 14:59:56: Accuracy at step 420: 4.07132\n",
      "2017-11-05 15:00:03: Accuracy at step 430: 4.0445\n",
      "2017-11-05 15:00:09: Accuracy at step 440: 4.04109\n",
      "2017-11-05 15:00:16: Accuracy at step 450: 4.04463\n",
      "2017-11-05 15:00:23: Accuracy at step 460: 4.0151\n",
      "2017-11-05 15:00:29: Accuracy at step 470: 4.00097\n",
      "2017-11-05 15:00:36: Accuracy at step 480: 3.99627\n",
      "2017-11-05 15:00:43: Accuracy at step 490: 3.97572\n",
      "2017-11-05 15:00:49: Accuracy at step 500: 3.99832\n",
      "2017-11-05 15:00:56: Accuracy at step 510: 3.96744\n",
      "2017-11-05 15:01:02: Accuracy at step 520: 3.98782\n",
      "2017-11-05 15:01:09: Accuracy at step 530: 3.95116\n",
      "2017-11-05 15:01:15: Accuracy at step 540: 3.93488\n",
      "2017-11-05 15:01:22: Accuracy at step 550: 3.97381\n",
      "2017-11-05 15:01:28: Accuracy at step 560: 3.97012\n",
      "2017-11-05 15:01:35: Accuracy at step 570: 3.94661\n",
      "2017-11-05 15:01:42: Accuracy at step 580: 3.91853\n",
      "2017-11-05 15:01:48: Accuracy at step 590: 3.91627\n",
      "2017-11-05 15:01:55: Accuracy at step 600: 3.91424\n",
      "2017-11-05 15:02:02: Accuracy at step 610: 3.90393\n",
      "2017-11-05 15:02:08: Accuracy at step 620: 3.89249\n",
      "2017-11-05 15:02:15: Accuracy at step 630: 3.91438\n",
      "2017-11-05 15:02:21: Accuracy at step 640: 3.84861\n",
      "2017-11-05 15:02:28: Accuracy at step 650: 3.84931\n"
     ]
    }
   ],
   "source": [
    "# Train\n",
    "for iteration in range(10001):\n",
    "    batch_xs, batch_ys = next_training_batch(100)\n",
    "    if iteration % 10 == 0:\n",
    "        summary, acc, _ = sess.run([merged, cross_entropy, train_step],\n",
    "                                   feed_dict={mineCounts: batch_xs, mineFreeAverages: batch_ys})\n",
    "        writer.add_summary(summary, iteration)\n",
    "        print('%s: Accuracy at step %s: %s' % (dt.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"), iteration, acc))\n",
    "    else:\n",
    "        _ = sess.run(train_step, feed_dict={mineCounts: batch_xs, mineFreeAverages: batch_ys})\n",
    "    if iteration % 1000 == 0:\n",
    "        save_path = saver.save(sess, './saves.tf.Mines3/model', global_step=iteration)\n",
    "        print(\"Model saved in file: %s\" % save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test trained model\n",
    "batch_xs, batch_ys = next_training_batch(1000)\n",
    "print(sess.run(cross_entropy, feed_dict={mineCounts: batch_xs, mineFreeAverages: batch_ys}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run a test\n",
    "batchSize = 100000\n",
    "batch_xs, batch_ys = next_training_batch(batchSize)\n",
    "\n",
    "predictions = sess.run(tf.nn.softmax(y), feed_dict={mineCounts: batch_xs, mineFreeAverages: batch_ys})\n",
    "bestSquares = [pred.argmax() for pred in predictions]\n",
    "frees = [batch_ys[i][bestSquares[i]] for i in range(batchSize)]\n",
    "print(\"Number of errors for batch size of %d\", batchSize)\n",
    "print(sum(frees))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
