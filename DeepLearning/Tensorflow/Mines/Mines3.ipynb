{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ruben/anaconda3/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "# Import libraries for simulation\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import random as r\n",
    "import datetime as dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dimensions = (16,16)\n",
    "mineProbability = 0.2      # Probability that a square contain a mine\n",
    "missingProbability = 0.5   # Probability that a square is missing adjacency info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# This is a matrix that maps mine board vectors to mine count vectors\n",
    "def minesweepMatrix(dimensions):\n",
    "    rows,cols = dimensions\n",
    "    size = rows * cols\n",
    "    A = np.zeros([size,size],dtype=int)\n",
    "    for rA in range(size):\n",
    "        for cA in range(size):\n",
    "            inRow, inCol = divmod(rA,cols)\n",
    "            outRow, outCol = divmod(cA,cols)\n",
    "            A[rA,cA] = abs(inRow-outRow) <= 1 and abs(inCol-outCol) <= 1\n",
    "    return(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Converts a board of mines into a board of mine counts\n",
    "def boardMineCounts(board):\n",
    "    return(minesweepMatrix(board.shape).dot(board.flatten()).reshape(board.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# This takes a mine board and gives a mine count with mines removed, and other random squares removed\n",
    "def boardPartialMineCounts(board):\n",
    "    result = boardMineCounts(board)\n",
    "    for index, x in np.ndenumerate(board):\n",
    "        if x: result[index] = -1\n",
    "        elif r.uniform(0, 1) < missingProbability: result[index] = -1\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Generates a random training batch of size at most n\n",
    "def next_training_batch(n):\n",
    "    batch_xs = []\n",
    "    batch_ys = []\n",
    "    for _ in range(n):\n",
    "        board = np.random.random(dimensions) < mineProbability\n",
    "        counts = boardPartialMineCounts(board)\n",
    "        frees = (1 - board).flatten().astype(float)\n",
    "        freesSum = sum(frees)\n",
    "        if freesSum > 0:\n",
    "            batch_xs.append(counts.flatten())\n",
    "            batch_ys.append(frees / freesSum)\n",
    "    return (np.asarray(batch_xs), np.asarray(batch_ys))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create the model\n",
    "rows, cols = dimensions\n",
    "size = rows*cols\n",
    "mineCounts = tf.placeholder(tf.int32, [None, size], name=\"mineCounts\")\n",
    "mineCountsOneHot = tf.reshape(tf.one_hot(mineCounts+1,10), [-1, size*10])\n",
    "W = tf.Variable(tf.random_normal([size*10, size], stddev=0.01), name=\"W\")\n",
    "b = tf.Variable(tf.random_normal([size], stddev=0.01), name=\"b\")\n",
    "y = tf.matmul(mineCountsOneHot, W) + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mineFreeAverages = tf.placeholder(tf.float32, [None, size], name=\"mineFreeAverages\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Loss function\n",
    "cross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=mineFreeAverages, logits=y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Summaries for tensorboard\n",
    "with tf.name_scope('W_reshape'):\n",
    "    image_shaped_W = tf.reshape(W, [-1, size*10, size, 1])\n",
    "    tf.summary.image('W', image_shaped_W, 1000)\n",
    "\n",
    "with tf.name_scope('b_reshape'):\n",
    "    image_shaped_b = tf.reshape(b, [-1, rows, cols, 1])\n",
    "    tf.summary.image('b', image_shaped_b, 1000)\n",
    "\n",
    "_ = tf.summary.scalar('accuracy', cross_entropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Optimiser\n",
    "train_step = tf.train.AdamOptimizer().minimize(cross_entropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create session and initialise or restore stuff\n",
    "savePath = './saves.tf.Mines3/' + str(dimensions) + '/'\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "sess = tf.InteractiveSession()\n",
    "\n",
    "merged = tf.summary.merge_all()\n",
    "writer = tf.summary.FileWriter('.', sess.graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.global_variables_initializer().run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Restore model?\n",
    "#saver.restore(sess, savePath + \"model-10000\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-11-05 19:09:42: Accuracy at step 0: 5.5594\n",
      "Model saved in file: ./saves.tf.Mines3/(16, 16)/model-0\n",
      "2017-11-05 19:10:05: Accuracy at step 10: 5.55122\n",
      "2017-11-05 19:10:27: Accuracy at step 20: 5.54606\n",
      "2017-11-05 19:10:50: Accuracy at step 30: 5.5413\n",
      "2017-11-05 19:11:12: Accuracy at step 40: 5.53729\n",
      "2017-11-05 19:11:35: Accuracy at step 50: 5.5352\n",
      "2017-11-05 19:11:58: Accuracy at step 60: 5.53117\n",
      "2017-11-05 19:12:20: Accuracy at step 70: 5.52908\n",
      "2017-11-05 19:12:43: Accuracy at step 80: 5.5265\n",
      "2017-11-05 19:13:05: Accuracy at step 90: 5.52514\n",
      "2017-11-05 19:13:28: Accuracy at step 100: 5.5223\n",
      "2017-11-05 19:13:51: Accuracy at step 110: 5.52158\n",
      "2017-11-05 19:14:13: Accuracy at step 120: 5.51888\n",
      "2017-11-05 19:14:36: Accuracy at step 130: 5.51745\n",
      "2017-11-05 19:14:58: Accuracy at step 140: 5.5161\n",
      "2017-11-05 19:15:21: Accuracy at step 150: 5.51441\n",
      "2017-11-05 19:15:44: Accuracy at step 160: 5.51482\n",
      "2017-11-05 19:16:06: Accuracy at step 170: 5.51461\n",
      "2017-11-05 19:16:29: Accuracy at step 180: 5.51407\n",
      "2017-11-05 19:16:51: Accuracy at step 190: 5.51331\n",
      "2017-11-05 19:17:14: Accuracy at step 200: 5.51058\n",
      "2017-11-05 19:17:37: Accuracy at step 210: 5.51082\n",
      "2017-11-05 19:17:59: Accuracy at step 220: 5.51013\n",
      "2017-11-05 19:18:22: Accuracy at step 230: 5.50881\n",
      "2017-11-05 19:18:44: Accuracy at step 240: 5.5098\n",
      "2017-11-05 19:19:07: Accuracy at step 250: 5.50831\n",
      "2017-11-05 19:19:30: Accuracy at step 260: 5.5067\n",
      "2017-11-05 19:19:52: Accuracy at step 270: 5.50804\n",
      "2017-11-05 19:20:15: Accuracy at step 280: 5.50685\n",
      "2017-11-05 19:20:37: Accuracy at step 290: 5.50761\n",
      "2017-11-05 19:21:00: Accuracy at step 300: 5.50845\n",
      "2017-11-05 19:21:22: Accuracy at step 310: 5.50604\n",
      "2017-11-05 19:21:45: Accuracy at step 320: 5.50509\n",
      "2017-11-05 19:22:08: Accuracy at step 330: 5.50585\n",
      "2017-11-05 19:22:30: Accuracy at step 340: 5.50426\n",
      "2017-11-05 19:22:53: Accuracy at step 350: 5.50444\n",
      "2017-11-05 19:23:16: Accuracy at step 360: 5.50507\n",
      "2017-11-05 19:23:39: Accuracy at step 370: 5.50597\n",
      "2017-11-05 19:24:02: Accuracy at step 380: 5.50471\n",
      "2017-11-05 19:24:25: Accuracy at step 390: 5.50616\n",
      "2017-11-05 19:24:48: Accuracy at step 400: 5.50452\n",
      "2017-11-05 19:25:11: Accuracy at step 410: 5.50561\n",
      "2017-11-05 19:25:33: Accuracy at step 420: 5.50472\n",
      "2017-11-05 19:25:56: Accuracy at step 430: 5.50448\n",
      "2017-11-05 19:26:18: Accuracy at step 440: 5.50667\n",
      "2017-11-05 19:26:41: Accuracy at step 450: 5.5018\n",
      "2017-11-05 19:27:03: Accuracy at step 460: 5.50454\n",
      "2017-11-05 19:27:26: Accuracy at step 470: 5.5042\n",
      "2017-11-05 19:27:49: Accuracy at step 480: 5.50421\n",
      "2017-11-05 19:28:11: Accuracy at step 490: 5.50296\n",
      "2017-11-05 19:28:34: Accuracy at step 500: 5.50367\n",
      "2017-11-05 19:28:56: Accuracy at step 510: 5.50453\n",
      "2017-11-05 19:29:19: Accuracy at step 520: 5.50378\n",
      "2017-11-05 19:29:42: Accuracy at step 530: 5.50327\n",
      "2017-11-05 19:30:04: Accuracy at step 540: 5.50343\n",
      "2017-11-05 19:30:27: Accuracy at step 550: 5.50451\n",
      "2017-11-05 19:30:49: Accuracy at step 560: 5.50338\n",
      "2017-11-05 19:31:12: Accuracy at step 570: 5.5039\n",
      "2017-11-05 19:31:35: Accuracy at step 580: 5.50377\n",
      "2017-11-05 19:31:57: Accuracy at step 590: 5.50373\n",
      "2017-11-05 19:32:20: Accuracy at step 600: 5.5029\n",
      "2017-11-05 19:32:42: Accuracy at step 610: 5.50346\n",
      "2017-11-05 19:33:05: Accuracy at step 620: 5.50321\n",
      "2017-11-05 19:33:27: Accuracy at step 630: 5.50288\n",
      "2017-11-05 19:33:50: Accuracy at step 640: 5.50188\n",
      "2017-11-05 19:34:13: Accuracy at step 650: 5.50226\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-46a985090670>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Train\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0miteration\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10001\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mbatch_xs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_ys\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext_training_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0miteration\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m10\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         summary, acc, _ = sess.run([merged, cross_entropy, train_step],\n",
      "\u001b[0;32m<ipython-input-6-4d8e8ac9caa3>\u001b[0m in \u001b[0;36mnext_training_batch\u001b[0;34m(n)\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0mboard\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdimensions\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mmineProbability\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m         \u001b[0mcounts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mboardPartialMineCounts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mboard\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m         \u001b[0mfrees\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mboard\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mfreesSum\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfrees\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-c3d0d5c89dc2>\u001b[0m in \u001b[0;36mboardPartialMineCounts\u001b[0;34m(board)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mboardPartialMineCounts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mboard\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mboardMineCounts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mboard\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndenumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mboard\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muniform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mmissingProbability\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-40f4568274db>\u001b[0m in \u001b[0;36mboardMineCounts\u001b[0;34m(board)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Converts a board of mines into a board of mine counts\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mboardMineCounts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mboard\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0;32mreturn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mminesweepMatrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mboard\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mboard\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mboard\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-3-298b8d8d714c>\u001b[0m in \u001b[0;36mminesweepMatrix\u001b[0;34m(dimensions)\u001b[0m\n\u001b[1;32m      7\u001b[0m             \u001b[0minRow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minCol\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdivmod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrA\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcols\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m             \u001b[0moutRow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutCol\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdivmod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcA\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcols\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m             \u001b[0mA\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrA\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcA\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minRow\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0moutRow\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minCol\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0moutCol\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0;32mreturn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mA\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Train\n",
    "for iteration in range(10001):\n",
    "    batch_xs, batch_ys = next_training_batch(100)\n",
    "    if iteration % 10 == 0:\n",
    "        summary, loss, _ = sess.run([merged, cross_entropy, train_step],\n",
    "                                   feed_dict={mineCounts: batch_xs, mineFreeAverages: batch_ys})\n",
    "        writer.add_summary(summary, iteration)\n",
    "        print('%s: Loss at step %s: %s' % (dt.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"), iteration, loss))\n",
    "    else:\n",
    "        _ = sess.run(train_step, feed_dict={mineCounts: batch_xs, mineFreeAverages: batch_ys})\n",
    "    if iteration % 1000 == 0:\n",
    "        save_path = saver.save(sess, savePath + 'model', global_step=iteration)\n",
    "        print(\"Model saved in file: %s\" % save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.50243\n"
     ]
    }
   ],
   "source": [
    "# Test trained model on larger batch size\n",
    "batch_xs, batch_ys = next_training_batch(1000)\n",
    "print(sess.run(cross_entropy, feed_dict={mineCounts: batch_xs, mineFreeAverages: batch_ys}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of errors for batch size of  10000\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "# Run a test\n",
    "batchSize = 10000\n",
    "batch_xs, batch_ys = next_training_batch(batchSize)\n",
    "\n",
    "predictions = sess.run(tf.nn.softmax(y), feed_dict={mineCounts: batch_xs, mineFreeAverages: batch_ys})\n",
    "bestSquares = [pred.argmax() for pred in predictions]\n",
    "board = (batch_ys == 0).astype(int)\n",
    "frees = [board[i][bestSquares[i]] for i in range(batchSize)]\n",
    "print(\"Number of errors for batch size of \", batchSize)\n",
    "print(sum(frees))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
