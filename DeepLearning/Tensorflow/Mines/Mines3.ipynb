{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ruben/anaconda3/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "# Import libraries for simulation\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import random as r\n",
    "import datetime as dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dimensions = (8,8)\n",
    "mineProbability = 0.2      # Probability that a square contain a mine\n",
    "missingProbability = 0.1   # Probability that a square is missing adjacency info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# count the number of mines in the proximity of given square, including square itself\n",
    "def countMines(board,r,c):\n",
    "    count = 0\n",
    "    rows, cols = board.shape\n",
    "    for i in [r-1,r,r+1]:\n",
    "        if i >= 0 and i < rows:\n",
    "            for j in [c-1,c,c+1]:\n",
    "                if j >= 0 and j < cols:\n",
    "                    count += int(board[i,j])\n",
    "    return count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def minesweepMatrix(dimensions):\n",
    "    rows,cols = dimensions\n",
    "    size = rows * cols\n",
    "    A = np.zeros([size,size],dtype=int)\n",
    "    for rA in range(size):\n",
    "        for cA in range(size):\n",
    "            inRow, inCol = divmod(rA,cols)\n",
    "            outRow, outCol = divmod(cA,cols)\n",
    "            A[rA,cA] = abs(inRow-outRow) <= 1 and abs(inCol-outCol) <= 1\n",
    "    return(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Converts a board of mines into a board of mine counts\n",
    "'''\n",
    "def boardMineCounts_(board):\n",
    "    mineInfo = np.zeros(board.shape, dtype = int)\n",
    "    rows, cols = board.shape\n",
    "    for i in range(rows):\n",
    "        for j in range(cols):\n",
    "            mineInfo[i,j] = countMines(board,i,j)\n",
    "    return mineInfo\n",
    "'''\n",
    "def boardMineCounts(board):\n",
    "    return(minesweepMatrix(board.shape).dot(board.flatten()).reshape(board.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def boardPartialMineCounts(board):\n",
    "    result = boardMineCounts(board)\n",
    "    for index, x in np.ndenumerate(board):\n",
    "        if x: result[index] = -1\n",
    "        elif r.uniform(0, 1) < missingProbability: result[index] = -1\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Generates a random training batch of size at most n\n",
    "def next_training_batch(n):\n",
    "    batch_xs = []\n",
    "    batch_ys = []\n",
    "    for _ in range(n):\n",
    "        board = np.random.random(dimensions) < mineProbability\n",
    "        counts = boardPartialMineCounts(board)\n",
    "        frees = (1 - board).flatten().astype(float)\n",
    "        freesSum = sum(frees)\n",
    "        if freesSum > 0:\n",
    "            batch_xs.append(counts.flatten())\n",
    "            batch_ys.append(frees / freesSum)\n",
    "    return (np.asarray(batch_xs), np.asarray(batch_ys))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create the model\n",
    "rows, cols = dimensions\n",
    "size = rows*cols\n",
    "mineCounts = tf.placeholder(tf.int32, [None, size], name=\"mineCounts\")\n",
    "mineCountsOneHot = tf.reshape(tf.one_hot(mineCounts+1,10), [-1, size*10])\n",
    "W = tf.Variable(tf.random_normal([size*10, size], stddev=0.01), name=\"W\")\n",
    "b = tf.Variable(tf.random_normal([size], stddev=0.01), name=\"b\")\n",
    "y = tf.matmul(mineCountsOneHot, W) + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mineFreeAverages = tf.placeholder(tf.float32, [None, size], name=\"mineFreeAverages\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Loss function\n",
    "cross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=mineFreeAverages, logits=y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Summaries for tensorboard\n",
    "with tf.name_scope('W_reshape'):\n",
    "    image_shaped_W = tf.reshape(W, [-1, size*10, size, 1])\n",
    "    tf.summary.image('W', image_shaped_W, 1000)\n",
    "\n",
    "with tf.name_scope('b_reshape'):\n",
    "    image_shaped_b = tf.reshape(b, [-1, rows, cols, 1])\n",
    "    tf.summary.image('b', image_shaped_b, 1000)\n",
    "\n",
    "_ = tf.summary.scalar('accuracy', cross_entropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Optimiser\n",
    "train_step = tf.train.AdamOptimizer().minimize(cross_entropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create session and initialise or restore stuff\n",
    "savePath = './saves.tf.Mines3/' + str(dimensions) + '/'\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "sess = tf.InteractiveSession()\n",
    "\n",
    "merged = tf.summary.merge_all()\n",
    "writer = tf.summary.FileWriter('.', sess.graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.global_variables_initializer().run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Restore model?\n",
    "#saver.restore(sess, savePath + \"model-10000\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-11-05 17:39:03: Accuracy at step 0: 4.16288\n",
      "Model saved in file: ./saves.tf.Mines3/(8, 8)/model-0\n",
      "2017-11-05 17:39:05: Accuracy at step 10: 4.15359\n",
      "2017-11-05 17:39:06: Accuracy at step 20: 4.14428\n",
      "2017-11-05 17:39:08: Accuracy at step 30: 4.13688\n",
      "2017-11-05 17:39:09: Accuracy at step 40: 4.13064\n",
      "2017-11-05 17:39:10: Accuracy at step 50: 4.1244\n",
      "2017-11-05 17:39:12: Accuracy at step 60: 4.12026\n",
      "2017-11-05 17:39:13: Accuracy at step 70: 4.11397\n",
      "2017-11-05 17:39:15: Accuracy at step 80: 4.10943\n",
      "2017-11-05 17:39:16: Accuracy at step 90: 4.10581\n",
      "2017-11-05 17:39:17: Accuracy at step 100: 4.10156\n",
      "2017-11-05 17:39:19: Accuracy at step 110: 4.10029\n",
      "2017-11-05 17:39:20: Accuracy at step 120: 4.09381\n",
      "2017-11-05 17:39:21: Accuracy at step 130: 4.09285\n",
      "2017-11-05 17:39:23: Accuracy at step 140: 4.08786\n",
      "2017-11-05 17:39:24: Accuracy at step 150: 4.08756\n",
      "2017-11-05 17:39:26: Accuracy at step 160: 4.08354\n",
      "2017-11-05 17:39:27: Accuracy at step 170: 4.07956\n",
      "2017-11-05 17:39:28: Accuracy at step 180: 4.07744\n",
      "2017-11-05 17:39:30: Accuracy at step 190: 4.07533\n",
      "2017-11-05 17:39:31: Accuracy at step 200: 4.07553\n",
      "2017-11-05 17:39:33: Accuracy at step 210: 4.07284\n",
      "2017-11-05 17:39:34: Accuracy at step 220: 4.07159\n",
      "2017-11-05 17:39:35: Accuracy at step 230: 4.0692\n",
      "2017-11-05 17:39:37: Accuracy at step 240: 4.06697\n",
      "2017-11-05 17:39:38: Accuracy at step 250: 4.06731\n",
      "2017-11-05 17:39:39: Accuracy at step 260: 4.06464\n",
      "2017-11-05 17:39:41: Accuracy at step 270: 4.06471\n",
      "2017-11-05 17:39:42: Accuracy at step 280: 4.06364\n",
      "2017-11-05 17:39:44: Accuracy at step 290: 4.05914\n",
      "2017-11-05 17:39:45: Accuracy at step 300: 4.05521\n",
      "2017-11-05 17:39:46: Accuracy at step 310: 4.06227\n",
      "2017-11-05 17:39:48: Accuracy at step 320: 4.05912\n",
      "2017-11-05 17:39:49: Accuracy at step 330: 4.05912\n",
      "2017-11-05 17:39:51: Accuracy at step 340: 4.06138\n",
      "2017-11-05 17:39:52: Accuracy at step 350: 4.05144\n",
      "2017-11-05 17:39:53: Accuracy at step 360: 4.04912\n",
      "2017-11-05 17:39:55: Accuracy at step 370: 4.05961\n",
      "2017-11-05 17:39:56: Accuracy at step 380: 4.05131\n",
      "2017-11-05 17:39:57: Accuracy at step 390: 4.06074\n",
      "2017-11-05 17:39:59: Accuracy at step 400: 4.05298\n",
      "2017-11-05 17:40:00: Accuracy at step 410: 4.04946\n",
      "2017-11-05 17:40:02: Accuracy at step 420: 4.04882\n",
      "2017-11-05 17:40:03: Accuracy at step 430: 4.04858\n",
      "2017-11-05 17:40:04: Accuracy at step 440: 4.04668\n",
      "2017-11-05 17:40:06: Accuracy at step 450: 4.04845\n",
      "2017-11-05 17:40:07: Accuracy at step 460: 4.04449\n",
      "2017-11-05 17:40:09: Accuracy at step 470: 4.04928\n",
      "2017-11-05 17:40:10: Accuracy at step 480: 4.04999\n",
      "2017-11-05 17:40:11: Accuracy at step 490: 4.04952\n",
      "2017-11-05 17:40:13: Accuracy at step 500: 4.04911\n",
      "2017-11-05 17:40:14: Accuracy at step 510: 4.04884\n",
      "2017-11-05 17:40:16: Accuracy at step 520: 4.04709\n",
      "2017-11-05 17:40:17: Accuracy at step 530: 4.0445\n",
      "2017-11-05 17:40:18: Accuracy at step 540: 4.04241\n",
      "2017-11-05 17:40:20: Accuracy at step 550: 4.04968\n",
      "2017-11-05 17:40:21: Accuracy at step 560: 4.04012\n",
      "2017-11-05 17:40:23: Accuracy at step 570: 4.04228\n",
      "2017-11-05 17:40:24: Accuracy at step 580: 4.03781\n",
      "2017-11-05 17:40:25: Accuracy at step 590: 4.04455\n",
      "2017-11-05 17:40:27: Accuracy at step 600: 4.0442\n",
      "2017-11-05 17:40:28: Accuracy at step 610: 4.04447\n",
      "2017-11-05 17:40:29: Accuracy at step 620: 4.04533\n",
      "2017-11-05 17:40:31: Accuracy at step 630: 4.03544\n",
      "2017-11-05 17:40:32: Accuracy at step 640: 4.04039\n",
      "2017-11-05 17:40:34: Accuracy at step 650: 4.04412\n",
      "2017-11-05 17:40:35: Accuracy at step 660: 4.03607\n",
      "2017-11-05 17:40:36: Accuracy at step 670: 4.04714\n",
      "2017-11-05 17:40:38: Accuracy at step 680: 4.04073\n",
      "2017-11-05 17:40:39: Accuracy at step 690: 4.03896\n",
      "2017-11-05 17:40:41: Accuracy at step 700: 4.03639\n",
      "2017-11-05 17:40:42: Accuracy at step 710: 4.04443\n",
      "2017-11-05 17:40:43: Accuracy at step 720: 4.04657\n",
      "2017-11-05 17:40:45: Accuracy at step 730: 4.03865\n",
      "2017-11-05 17:40:46: Accuracy at step 740: 4.039\n",
      "2017-11-05 17:40:47: Accuracy at step 750: 4.04187\n",
      "2017-11-05 17:40:49: Accuracy at step 760: 4.04001\n",
      "2017-11-05 17:40:50: Accuracy at step 770: 4.0432\n",
      "2017-11-05 17:40:52: Accuracy at step 780: 4.04524\n",
      "2017-11-05 17:40:53: Accuracy at step 790: 4.04087\n",
      "2017-11-05 17:40:54: Accuracy at step 800: 4.03699\n",
      "2017-11-05 17:40:56: Accuracy at step 810: 4.04189\n",
      "2017-11-05 17:40:57: Accuracy at step 820: 4.03885\n",
      "2017-11-05 17:40:58: Accuracy at step 830: 4.04581\n",
      "2017-11-05 17:41:00: Accuracy at step 840: 4.04648\n",
      "2017-11-05 17:41:01: Accuracy at step 850: 4.03788\n",
      "2017-11-05 17:41:03: Accuracy at step 860: 4.04166\n",
      "2017-11-05 17:41:04: Accuracy at step 870: 4.04042\n",
      "2017-11-05 17:41:05: Accuracy at step 880: 4.03824\n",
      "2017-11-05 17:41:07: Accuracy at step 890: 4.0428\n",
      "2017-11-05 17:41:08: Accuracy at step 900: 4.04587\n",
      "2017-11-05 17:41:10: Accuracy at step 910: 4.03678\n",
      "2017-11-05 17:41:11: Accuracy at step 920: 4.03337\n",
      "2017-11-05 17:41:12: Accuracy at step 930: 4.04265\n",
      "2017-11-05 17:41:14: Accuracy at step 940: 4.04039\n",
      "2017-11-05 17:41:15: Accuracy at step 950: 4.04115\n",
      "2017-11-05 17:41:16: Accuracy at step 960: 4.03304\n",
      "2017-11-05 17:41:18: Accuracy at step 970: 4.03838\n",
      "2017-11-05 17:41:19: Accuracy at step 980: 4.04274\n",
      "2017-11-05 17:41:21: Accuracy at step 990: 4.03604\n",
      "2017-11-05 17:41:22: Accuracy at step 1000: 4.04149\n",
      "Model saved in file: ./saves.tf.Mines3/(8, 8)/model-1000\n",
      "2017-11-05 17:41:23: Accuracy at step 1010: 4.03547\n",
      "2017-11-05 17:41:25: Accuracy at step 1020: 4.04192\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-53db83afba40>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Train\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0miteration\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4001\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mbatch_xs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_ys\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext_training_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0miteration\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m10\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         summary, acc, _ = sess.run([merged, cross_entropy, train_step],\n",
      "\u001b[0;32m<ipython-input-7-4d8e8ac9caa3>\u001b[0m in \u001b[0;36mnext_training_batch\u001b[0;34m(n)\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0mboard\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdimensions\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mmineProbability\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m         \u001b[0mcounts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mboardPartialMineCounts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mboard\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m         \u001b[0mfrees\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mboard\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mfreesSum\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfrees\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-c3d0d5c89dc2>\u001b[0m in \u001b[0;36mboardPartialMineCounts\u001b[0;34m(board)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mboardPartialMineCounts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mboard\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mboardMineCounts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mboard\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndenumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mboard\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muniform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mmissingProbability\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-cffc1e2a38c8>\u001b[0m in \u001b[0;36mboardMineCounts\u001b[0;34m(board)\u001b[0m\n\u001b[1;32m     10\u001b[0m '''\n\u001b[1;32m     11\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mboardMineCounts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mboard\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0;32mreturn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mminesweepMatrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mboard\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mboard\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mboard\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-4-298b8d8d714c>\u001b[0m in \u001b[0;36mminesweepMatrix\u001b[0;34m(dimensions)\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mrA\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mcA\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m             \u001b[0minRow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minCol\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdivmod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrA\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcols\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m             \u001b[0moutRow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutCol\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdivmod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcA\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcols\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m             \u001b[0mA\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrA\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcA\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minRow\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0moutRow\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minCol\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0moutCol\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Train\n",
    "for iteration in range(4001):\n",
    "    batch_xs, batch_ys = next_training_batch(100)\n",
    "    if iteration % 10 == 0:\n",
    "        summary, acc, _ = sess.run([merged, cross_entropy, train_step],\n",
    "                                   feed_dict={mineCounts: batch_xs, mineFreeAverages: batch_ys})\n",
    "        writer.add_summary(summary, iteration)\n",
    "        print('%s: Accuracy at step %s: %s' % (dt.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"), iteration, acc))\n",
    "    else:\n",
    "        _ = sess.run(train_step, feed_dict={mineCounts: batch_xs, mineFreeAverages: batch_ys})\n",
    "    if iteration % 1000 == 0:\n",
    "        save_path = saver.save(sess, savePath + 'model', global_step=iteration)\n",
    "        print(\"Model saved in file: %s\" % save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.04015\n"
     ]
    }
   ],
   "source": [
    "# Test trained model\n",
    "batch_xs, batch_ys = next_training_batch(1000)\n",
    "print(sess.run(cross_entropy, feed_dict={mineCounts: batch_xs, mineFreeAverages: batch_ys}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of errors for batch size of  100000\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "# Run a test\n",
    "batchSize = 100000\n",
    "batch_xs, batch_ys = next_training_batch(batchSize)\n",
    "\n",
    "predictions = sess.run(tf.nn.softmax(y), feed_dict={mineCounts: batch_xs, mineFreeAverages: batch_ys})\n",
    "bestSquares = [pred.argmax() for pred in predictions]\n",
    "board = (batch_ys == 0).astype(int)\n",
    "frees = [board[i][bestSquares[i]] for i in range(batchSize)]\n",
    "print(\"Number of errors for batch size of \", batchSize)\n",
    "print(sum(frees))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
